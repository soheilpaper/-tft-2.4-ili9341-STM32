{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "ml_models_scikit-learn.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soheilpaper/-tft-2.4-ili9341-STM32/blob/master/Predictions/3/ml_models_scikit-learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5tJIUEZdLkm"
      },
      "source": [
        "<font color=\"white\">.</font> | <font color=\"white\">.</font> | <font color=\"white\">.</font>\n",
        "-- | -- | --\n",
        "![NASA](http://www.nasa.gov/sites/all/themes/custom/nasatwo/images/nasa-logo.svg) | <h1><font size=\"+3\">ASTG Python Courses</font></h1> | ![NASA](https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png)\n",
        "\n",
        "---\n",
        "\n",
        "<center>\n",
        "    <h1><font color=\"red\">Machine Learning with Scikit-Learn</font></h1>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yQ29veQdLko"
      },
      "source": [
        "## Useful Links\n",
        "\n",
        "- <a href=\"https://medium.com/towards-artificial-intelligence/calculating-simple-linear-regression-and-linear-best-fit-an-in-depth-tutorial-with-math-and-python-804a0cb23660\">Calculating Simple Linear Regression and Linear Best Fit an In-depth Tutorial with Math and Python</a>\n",
        "- <a href=\"https://scikit-learn.org/stable/tutorial/index.html\">scikit-learn Tutorials</a>\n",
        "- <a href=\"https://medium.com/@amitg0161/sklearn-linear-regression-tutorial-with-boston-house-dataset-cde74afd460a\">Sklearn Linear Regression Tutorial with Boston House Dataset</a>\n",
        "- <a href=\"https://www.dataquest.io/blog/sci-kit-learn-tutorial/\">Scikit-learn Tutorial: Machine Learning in Python</a>\n",
        "- <a href=\"https://debuggercafe.com/image-classification-with-mnist-dataset/\">Image Classification with MNIST Dataset</a>\n",
        "- <a href=\"https://davidburn.github.io/notebooks/mnist-numbers/MNIST%20Handwrititten%20numbers/\">MNIST handwritten number identification</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZreUhQTdLkw"
      },
      "source": [
        "# <font color=\"red\">Scikit-Learn</font>\n",
        "\n",
        "- Scikit-learn is a free machine learning library for Python. \n",
        "- Provides a selection of efficient tools for machine learning and statistical modeling including: \n",
        "     - **Classification:** Identifying which category an object belongs to. Example: Spam detection\n",
        "     - **Regression:** Predicting a continuous variable based on relevant independent variables. Example: Stock price predictions\n",
        "     - **Clustering:** Automatic grouping of similar objects into different clusters. Example: Customer segmentation \n",
        "     - **Dimensionality Reduction:** Seek to reduce the number of input variables in training data by preserving the salient relationships in the data\n",
        "- Features various algorithms like support vector machine, random forests, and k-neighbours.\n",
        "- Supports Python numerical and scientific libraries like NumPy and SciPy.\n",
        "\n",
        "\n",
        "Some popular groups of models provided by scikit-learn include:\n",
        "\n",
        "- **Clustering:** Group unlabeled data such as KMeans.\n",
        "- **Cross Validation:** Estimate the performance of supervised models on unseen data.\n",
        "- **Datasets:** for test datasets and for generating datasets with specific properties for investigating model behavior.\n",
        "- **Dimensionality Reduction:** Reduce the number of attributes in data for summarization, visualization and feature selection such as Principal component analysis.\n",
        "- **Ensemble Methods:** Combine the predictions of multiple supervised models.\n",
        "- **Feature Extraction:** Define attributes in image and text data.\n",
        "- **Feature Selection:** Identify meaningful attributes from which to create supervised models.\n",
        "- **Parameter Tuning:** Get the most out of supervised models.\n",
        "- **Manifold Learning:** Summarize and depicting complex multi-dimensional data.\n",
        "- **Supervised Models:** A vast array not limited to generalized linear models, discriminate analysis, naive bayes, lazy methods, neural networks, support vector machines and decision trees.\n",
        "- **Unsupervised Learning Algorithms:** − They include clustering, factor analysis, PCA (Principal Component Analysis), unsupervised neural networks.\n",
        "\n",
        "\n",
        "![fig_sckl](https://ulhpc-tutorials.readthedocs.io/en/latest/python/advanced/scikit-learn/images/scikit.png)\n",
        "Image Source: ulhpc-tutorials.readthedocs.io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5RtR77-dLky"
      },
      "source": [
        "## Package Requirements\n",
        "\n",
        "- Numpy\n",
        "- scipy\n",
        "- matplotlib\n",
        "- pandas\n",
        "- scikit-learn\n",
        "- seaborn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVTVOEsLdLky"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6gCrbqMdLkz"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgowmGrkdLk0"
      },
      "source": [
        "# <font color=\"blue\">Numerical Data</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAuo8JrfdLk0"
      },
      "source": [
        "## <font color=\"red\">Boston Dataset</font>\n",
        "- Contains information about different houses in Boston.\n",
        "- There are 506 samples and 13 feature variables in this dataset. \n",
        "- Maintained at Carnegie Mellon University.\n",
        "- <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\">This is a copy of UCI ML housing dataset</a>.\n",
        "\n",
        "We want to predict the value of prices of the house using the given features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE4RXNdmdLk2"
      },
      "source": [
        "### Obtain the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhwucrxLdLk3"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "boston_data = load_boston()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T-gDpz2dLk4",
        "outputId": "91a149d6-c18d-4338-f090-45f604aa3ebd"
      },
      "source": [
        "print(boston_data.DESCR)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _boston_dataset:\n",
            "\n",
            "Boston house prices dataset\n",
            "---------------------------\n",
            "\n",
            "**Data Set Characteristics:**  \n",
            "\n",
            "    :Number of Instances: 506 \n",
            "\n",
            "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
            "\n",
            "    :Attribute Information (in order):\n",
            "        - CRIM     per capita crime rate by town\n",
            "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
            "        - INDUS    proportion of non-retail business acres per town\n",
            "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
            "        - NOX      nitric oxides concentration (parts per 10 million)\n",
            "        - RM       average number of rooms per dwelling\n",
            "        - AGE      proportion of owner-occupied units built prior to 1940\n",
            "        - DIS      weighted distances to five Boston employment centres\n",
            "        - RAD      index of accessibility to radial highways\n",
            "        - TAX      full-value property-tax rate per $10,000\n",
            "        - PTRATIO  pupil-teacher ratio by town\n",
            "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
            "        - LSTAT    % lower status of the population\n",
            "        - MEDV     Median value of owner-occupied homes in $1000's\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
            "\n",
            "This is a copy of UCI ML housing dataset.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
            "\n",
            "\n",
            "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
            "\n",
            "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
            "prices and the demand for clean air', J. Environ. Economics & Management,\n",
            "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
            "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
            "pages 244-261 of the latter.\n",
            "\n",
            "The Boston house-price data has been used in many machine learning papers that address regression\n",
            "problems.   \n",
            "     \n",
            ".. topic:: References\n",
            "\n",
            "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
            "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm2emb-kdLk8"
      },
      "source": [
        "#### Attribute Information:\n",
        "| Acronym | Description |\n",
        "| --- | --- |\n",
        "| **CRIM** |    Per capita crime rate by town |\n",
        "|**ZN** |   Proportion of residential land zoned for lots over 25,000 sq.ft. |\n",
        "| **INDUS** | Proportion of non-retail business acres per town |\n",
        "| **CHAS** |  Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) |\n",
        "| **NOX** |  Nitric oxides concentration (parts per 10 million) |\n",
        "| **RM** |    Average number of rooms per dwelling |\n",
        "| **AGE** |   roportion of owner-occupied units built prior to 1940 |\n",
        "| **DIS** |  weighted distances to five Boston employment centres |\n",
        "| **RAD** |   index of accessibility to radial highways |\n",
        "| **TAX** |  full-value property-tax rate per \\$10,000 |\n",
        "| **PTRATIO** |  pupil-teacher ratio by town |\n",
        "| **B** |       1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town |\n",
        "| **LSTAT** |    % lower status of the population |\n",
        "| **MEDV** |    Median value of owner-occupied homes in $1000's |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR86-YUodLk7"
      },
      "source": [
        "# print(\"Feature Names: \", boston_data.feature_names)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5XYDrgodvxE"
      },
      "source": [
        "# change the Input Dat to my DATA From :https://github.com/So-AI-love/Test_NN Which is **so-so.csv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oiw0s4ieF62",
        "outputId": "1e80186d-1b90-4e84-c905-2ebe91262303"
      },
      "source": [
        "\n",
        "import os,sys\n",
        "\n",
        "sys.path.insert(0,'/content/')\n",
        "if not os.path.exists(\"/root/.ipython/ocr.py\"):\n",
        "    from subprocess import run\n",
        "    from shlex import split\n",
        "\n",
        "    shellCmd = \"wget -qq https://raw.githubusercontent.com/biplobsd/OneClickRun/master/res/ocr.py \\\n",
        "                    -O /content/ocr.py\"\n",
        "    run(split(shellCmd))\n",
        "from ocr import runSh\n",
        "\n",
        "def runShT(args):\n",
        "    return runSh(args, output=True)\n",
        "runShT('bash simple_shell_script.sh')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bash: simple_shell_script.sh: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woCMk3epceA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8549e54f-c048-4ccc-ea4f-fe28d629521f"
      },
      "source": [
        "%%writefile simple_shell_script2.sh\n",
        "Current_dir=$PWD\n",
        "echo \"current dir is ${Current_dir}\"\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# !cp '/content/gdrive/MyDrive/Amir Farzin Project/so-so.csv' /content/stock-prediction\n",
        "# !wget https://transfer.sh/o5273/so-so.csv\n",
        "echo \"cd ${Current_dir}\"\n",
        "cd ${Current_dir}//stock-prediction\n",
        "\n",
        "git clone https://github.com/So-AI-love/Test_NN\n",
        "unzip -o  \"${Current_dir}/Test_NN/so-so.zip\" -d \"${Current_dir}/Test_NN\"\n",
        "cp \"${Current_dir}/Test_NN/so-so.csv\" \"${Current_dir}/\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing simple_shell_script2.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulXiS7lQbBWo",
        "outputId": "4cc1e9cf-8200-44f9-dc99-f157f623631a"
      },
      "source": [
        "runShT('bash simple_shell_script2.sh')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current dir is /content\n",
            "cd /content\n",
            "simple_shell_script2.sh: line 8: cd: /content//stock-prediction: No such file or directory\n",
            "Cloning into 'Test_NN'...\n",
            "Archive:  /content/Test_NN/so-so.zip\n",
            "inflating: /content/Test_NN/so-so.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVCx7vRid9Q1"
      },
      "source": [
        "# import packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import display, HTML, display_html\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "\n",
        "\n",
        "# set formatting\n",
        "pd.set_option('display.max_columns', 100)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "# read in CSV file data\n",
        "boston_data = pd.read_csv('so-so.csv') #reviews.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYFf10Et5_LD"
      },
      "source": [
        "# Main Data With CO2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJzOlhkx56Ty",
        "outputId": "d4d90580-07ef-4909-c413-88a945050eb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import files , drive\n",
        "# files.upload()\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuShvius5-v9"
      },
      "source": [
        "\n",
        "import time\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.recurrent import LSTM\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.preprocessing as prep\n",
        "# df = pd.read_csv('so-so.csv')\n",
        "# df=pd.read_csv('/home/so/Downloads/Telegram Desktop/Data_08_2020_input.csv')\n",
        "# df2=pd.read_csv('/home/so/Downloads/Telegram Desktop/Data_08_2020_output - S.csv')\n",
        "\n",
        "df=pd.read_csv('/content/gdrive/MyDrive/Amir Farzin Secure Data/Data_08_2020_input.csv')\n",
        "df2=pd.read_csv('/content/gdrive/MyDrive/Amir Farzin Secure Data/Data_08_2020_output - S.csv')\n",
        "boston_data=df\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_anOfj7X6aQM"
      },
      "source": [
        "\n",
        "import re, regex\n",
        "ddd=df['Time'].str\n",
        "# df['day_of_week']= ddd.split('.').str[-1]\n",
        "# df['time']= ddd.split('.').str[0]\n",
        "# df['day_of_week']=pd.to_datetime(df['day_of_week'], format='%H:%M', errors='ignore') #\n",
        "# df=df[['Time','day_of_week','-1-','-2-','-3-','-4-','-5-','out']]\n",
        "# df=df[['-1-','-2-','-3-','-4-','-5-','out']]\n",
        "df['CO2']= df2['CO2']\n",
        "df.head()\n",
        "# df['time']=df['time'].values.astype('float32')\n",
        "# df['day_of_week']=df['day_of_week'].values.astype('float32')\n",
        "# df=df[['time','day_of_week','-1-','-2-','-3-','-4-','-5-','out']]\n",
        "# df=df[['-1-','-2-','-3-','-4-','-5-','out']]\n",
        "df_colums=[4,16,42,30,10,2,31] # Manual feature selecting\n",
        "df2=df[df.columns[df_colums]]\n",
        "df2['CO2']=df['CO2']\n",
        "boston_data=df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM2KxnytdLk4"
      },
      "source": [
        "### Features of the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGi8HD6OdLk4"
      },
      "source": [
        "print(\"Keys: \", boston_data.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UED_xhHdLk5"
      },
      "source": [
        "# print(\"Shape: \", boston_data.data.shape)\n",
        "print(\"Shape: \", boston_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRK-WUzFdLk8"
      },
      "source": [
        "## <font color=\"red\">Extract Data</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEQtBcFHdLk9"
      },
      "source": [
        "**Pass the data into a Pandas dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl0BbYzodLk9"
      },
      "source": [
        "# bos_pd = pd.DataFrame(boston_data.data)\n",
        "# bos_pd.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGh_JdG8eftL"
      },
      "source": [
        "bos_pd = pd.DataFrame(boston_data)\n",
        "bos_pd.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYegoyQGfOFY"
      },
      "source": [
        "print(boston_data.columns[-1])\n",
        "Y_Title_boston_data=boston_data.columns[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-ff4oiYdLk9"
      },
      "source": [
        "#### Relabel the columns using the Boston dataset feature names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpI8NxV1dLk-"
      },
      "source": [
        "bos_pd.columns = boston_data.columns\n",
        "bos_pd.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TMyh7DPdLk_"
      },
      "source": [
        "print(\"Shape of the target data: \", bos_pd[Y_Title_boston_data].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HesdSDSSk9ER"
      },
      "source": [
        "# bos_pd=bos_pd.drop('time', axis = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMyLu8QbdLk_"
      },
      "source": [
        "bos_pd['PRICE']=bos_pd[Y_Title_boston_data]\n",
        "bos_pd=bos_pd.drop(Y_Title_boston_data, axis = 1)\n",
        "\n",
        "bos_pd.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPwrTPjMdLk_"
      },
      "source": [
        "Check the types of features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTD0VNYJdLlA"
      },
      "source": [
        "bos_pd.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8WkKQcrdLlA"
      },
      "source": [
        "## <font color=\"red\">Exploratory Data Analysis</font>\n",
        "\n",
        "- Important step before training the model. \n",
        "- We use statistical analysis and visualizations to understand the relationship of the target variable with other features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP8WvvqTdLlA"
      },
      "source": [
        "#### Check Missing Values\n",
        "It is a good practice to see if there are any missing values in the data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqnWFz4AdLlB"
      },
      "source": [
        "Count the number of missing values for each feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nFUCk83dLlB"
      },
      "source": [
        "bos_pd.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVoi41eZdLlB"
      },
      "source": [
        "#### Obtain basic statistics on the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjmInfELdLlC"
      },
      "source": [
        "bos_pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu5vaWO7dLlC"
      },
      "source": [
        "bos_pd.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjySZRnqdLlC"
      },
      "source": [
        "#### Distribution of the target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGMjnV5gdLlC"
      },
      "source": [
        "plt.figure(figsize=(8, 6));\n",
        "plt.hist(bos_pd['PRICE']);\n",
        "plt.title('Boston Housing Prices and Count Histogram');\n",
        "plt.xlabel('price ($1000s)');\n",
        "plt.ylabel('count');\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEfIKZ3-dLlD"
      },
      "source": [
        "plt.figure(figsize=(8, 6));\n",
        "sns.distplot(bos_pd['PRICE']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etchKSDLdLlD"
      },
      "source": [
        "From the above output we can see that the values of PRICE is normally distributed with some of the outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-XItBb6dLlE"
      },
      "source": [
        "#### Heatmap: Two-Dimensional Graphical Representation\n",
        "- Represent the individual values that are contained in a matrix as colors.\n",
        "- Create a correlation matrix that measures the linear relationships between the variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtI1p_9edLlE"
      },
      "source": [
        "plt.figure(figsize=(12, 9));\n",
        "correlation_matrix = bos_pd.corr().round(2);\n",
        "sns.heatmap(correlation_matrix, cmap=\"YlGnBu\", annot=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmwRhFUsdLlE"
      },
      "source": [
        "- **RM** has a strong positive correlation with **PRICE** (0.7) where as **LSTAThas** a high negative correlation with **PRICE** (-0.74).\n",
        "- The features **RAD**, **TAX** have a correlation of 0.91. These feature pairs are strongly correlated to each other. This can affect the model. Same goes for the features **DIS** and **AGE** which have a correlation of -0.75.\n",
        "- The predictor variables such as **CRIM**, **INDUS**, **NOX**, **Age**, **RAD**, **TAX**, **PTRATIO**, **LSTAT** have a negative correlation on the target. Increase of any of them leads to the decrease in the price of the housing.\n",
        "- The predictor variables such as **ZN**, **RM**, **DIS**, **B** have good positive correlation with the target. Increase in any of them leads to the increase in the price of the house."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2hBCgTaf4uY"
      },
      "source": [
        "boston_data=bos_pd\n",
        "boston_data.feature_names=bos_pd.columns\n",
        "print(boston_data.feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_wy1tcqdLlF"
      },
      "source": [
        "for feature_name in boston_data.feature_names:\n",
        "    plt.figure(figsize=(5, 4));\n",
        "    plt.scatter(bos_pd[feature_name], bos_pd['PRICE']);\n",
        "    plt.ylabel('Price', size=12);\n",
        "    plt.xlabel(feature_name, size=12);\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EqnqawsdLlF"
      },
      "source": [
        "- The prices increase as the value of RM increases linearly. There are few outliers and the data seems to be capped at 50.\n",
        "- The prices tend to decrease with an increase in LSTAT. Though it doesn’t look to be following exactly a linear line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDW1oiKRdLlG"
      },
      "source": [
        "Based on the above observations we will plot an `lmplot` between **RM** and **PRICE** to see the relationship between the two more clearly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjU3mGIKdLlG"
      },
      "source": [
        "sns.lmplot(x = boston_data.feature_names[1], y = 'PRICE', data = bos_pd);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhyTk54cdLlH"
      },
      "source": [
        "## <font color=\"blue\">Model Selection Process</font>\n",
        "\n",
        "![fig_skl](https://miro.medium.com/max/1400/1*LixatBxkewppAhv1Mm5H2w.jpeg)\n",
        "Image Source: Christophe Bourguignat\n",
        "\n",
        "- A Machine Learning algorithm needs to be trained on a set of data to learn the relationships between different features and how these features affect the target variable. \n",
        "- We need to divide the entire data set into two sets:\n",
        "    + Training set on which we are going to train our algorithm to build a model. \n",
        "    + Testing set on which we will test our model to see how accurate its predictions are.\n",
        "    \n",
        "Before we create the two sets, we need to identify the algorithm we will use for our model.\n",
        "We can use the `machine_learning_map` map (shown at the top of this page) as a cheat sheet to shortlist the algorithms that we can try out to build our prediction model. Using the checklist let’s see under which category our current dataset falls into:\n",
        "- We have 506 samples: >50? (**Yes**)\n",
        "- Are we predicting a category? (**No**)\n",
        "- Are we predicting a quantity? (**Yes**)\n",
        "\n",
        "Based on the checklist that we prepared above and going by the `machine_learning_map` we can try out **regression methods** such as:\n",
        "\n",
        "- Linear Regression \n",
        "- Lasso\n",
        "- ElasticNet Regression\n",
        "- Ridge Regression: \n",
        "- K Neighbors Regressor\n",
        "- Decision Tree Regressor\n",
        "- Simple Vector Regression (SVR)\n",
        "- Ada Boost Regressor\n",
        "- Gradient Boosting Regressor\n",
        "- Random Forest Regression\n",
        "- Extra Trees Regressor\n",
        "\n",
        "Check the following documents on regresssion: \n",
        "<a href=\"https://scikit-learn.org/stable/supervised_learning.html\">Supervised learning--scikit-learn</a>,\n",
        "<a href=\"https://developer.ibm.com/technologies/data-science/tutorials/learn-regression-algorithms-using-python-and-scikit-learn/\">Learn regression algorithms using Python and scikit-learn</a>,\n",
        "<a href=\"https://www.pluralsight.com/guides/non-linear-\">Non-Linear Regression Trees with scikit-learn</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2YD_rNPdLlH"
      },
      "source": [
        "## <font color=\"red\">Simple Linear Model</font>\n",
        "- It is difficult to visualize the multiple features.\n",
        "- We want to predict the house price with just one variable and then move to the regression with all features.\n",
        "- Because **RM** shows positive correlation with the **House Prices**, we will use **RM** for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqEoa9eojy6-"
      },
      "source": [
        "print(bos_pd.columns[:-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L6QWtv2dLlI"
      },
      "source": [
        "X_rooms = bos_pd[bos_pd.columns[:-1]]\n",
        "y_price = bos_pd.PRICE\n",
        "\n",
        "\n",
        "X_rooms = np.array(X_rooms)\n",
        "y_price = np.array(y_price).reshape(-1,1)\n",
        "\n",
        "print(X_rooms.shape)\n",
        "print(y_price.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxTAN38NdLlJ"
      },
      "source": [
        "#### Splitting the data into training and testing sets\n",
        "- We split the data into training and testing sets. \n",
        "- We train the model with 80% of the samples and test with the remaining 20%. \n",
        "- We do this to assess the model’s performance on unseen data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRShOECCdLlJ"
      },
      "source": [
        "X_train_1, X_test_1, Y_train_1, Y_test_1 = \\\n",
        "             train_test_split(X_rooms, y_price, test_size = 0.2, random_state=5)\n",
        "\n",
        "print(X_train_1.shape)\n",
        "print(Y_train_1.shape)\n",
        "print(X_test_1.shape)\n",
        "print(Y_test_1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHFwWF4RdLlK"
      },
      "source": [
        "#### Training and testing the model\n",
        "- We use scikit-learn’s LinearRegression to train our model on both the training and check it on the test sets.\n",
        "- We check the model performance on the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7iINTbFdLlK"
      },
      "source": [
        "reg_1 = LinearRegression()\n",
        "reg_1.fit(X_train_1, Y_train_1)\n",
        "\n",
        "y_train_predict_1 = reg_1.predict(X_train_1)\n",
        "rmse = (np.sqrt(metrics.mean_squared_error(Y_train_1, y_train_predict_1)))\n",
        "r2 = round(reg_1.score(X_train_1, Y_train_1),2)\n",
        "\n",
        "print(\"The model performance for training set\")\n",
        "print(\"--------------------------------------\")\n",
        "print('RMSE is {}'.format(rmse))\n",
        "print('R2 score is {}'.format(r2))\n",
        "print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCyuiaYYdLlK"
      },
      "source": [
        "#### Model Evaluation for Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiatOxK4dLlL"
      },
      "source": [
        "y_pred_1 = reg_1.predict(X_test_1)\n",
        "rmse = (np.sqrt(metrics.mean_squared_error(Y_test_1, y_pred_1)))\n",
        "r2 = round(reg_1.score(X_test_1, Y_test_1),2)\n",
        "\n",
        "print(\"The model performance for training set\")\n",
        "print(\"--------------------------------------\")\n",
        "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
        "print(\"R^2: {}\".format(r2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vGYjWHydLlL"
      },
      "source": [
        "The coefficient of determination: 1 is perfect prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO2dpVKOdLlM"
      },
      "source": [
        "print('Coefficient of determination: {:.4f}'.format(metrics.r2_score(Y_test_1, y_pred_1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chJaYzuHdLlN"
      },
      "source": [
        "#### 45-Degree Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPFb3NuMdLlN"
      },
      "source": [
        "plt.figure(figsize=(8, 5));\n",
        "plt.scatter(Y_test_1, y_pred_1);\n",
        "plt.plot([0, 50], [0, 50], '--k');\n",
        "# plt.axis(\"tight\");\n",
        "plt.xlabel(\"Actual House Prices ($1000)\");\n",
        "plt.ylabel(\"Predicted House Prices: ($1000)\");\n",
        "#plt.xticks(range(0, int(max(y_test)),2));\n",
        "#plt.yticks(range(0, int(max(y_test)),2));\n",
        "plt.title(\"Actual Prices vs Predicted prices\");\n",
        "plt.tight_layout();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32C1BvY8dLlO"
      },
      "source": [
        "## <font color=\"red\">Linear Regression Model with All Variables</font>\n",
        "- We want to create a model considering all the features in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2Y9172zdLlO"
      },
      "source": [
        "#### Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IQ6URewdLlO"
      },
      "source": [
        "X = bos_pd.drop('PRICE', axis = 1)\n",
        "y = bos_pd['PRICE']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sm2y-e3dLlP"
      },
      "source": [
        "- Use the `train_test_split` to split the data into random train and test subsets.\n",
        "- Everytime you run it without specifying `random_state`, you will get a different result.\n",
        "- If you use `random_state=some_number`, then you can guarantee the split will be always the same.\n",
        "- It doesn't matter what the value of `random_state` is:  42, 0, 21, ...\n",
        "- This is useful if you want reproducible results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3NrFbEUdLlP"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
        "                                                    random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTneXDcadLlP"
      },
      "source": [
        "The linear regression model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En9AREhhdLlP"
      },
      "source": [
        "reg_all = LinearRegression()\n",
        "reg_all.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKmZ-0FDdLlQ"
      },
      "source": [
        "#### Model Evaluation for Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_yTrIeWdLlQ"
      },
      "source": [
        "y_train_predict = reg_all.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75xor8lqdLlQ"
      },
      "source": [
        "rmse = (np.sqrt(metrics.mean_squared_error(y_train, y_train_predict)))\n",
        "r2 = round(reg_all.score(X_train, y_train),2)\n",
        "\n",
        "print(\"The model performance for training set\")\n",
        "print(\"--------------------------------------\")\n",
        "print('RMSE is {}'.format(rmse))\n",
        "print('R2 score is {}'.format(r2))\n",
        "print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJkptiRGdLlR"
      },
      "source": [
        "#### Model Evaluation for Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c74AlE8sdLlR"
      },
      "source": [
        "y_pred = reg_all.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr85d6oDdLlR"
      },
      "source": [
        "rmse = (np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "r2 = round(reg_all.score(X_test, y_test),2)\n",
        "\n",
        "print(\"The model performance for training set\")\n",
        "print(\"--------------------------------------\")\n",
        "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
        "print(\"R^2: {}\".format(r2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh7goR4hdLlS"
      },
      "source": [
        "The coefficient of determination: 1 is perfect prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFwsk67ydLlS"
      },
      "source": [
        "print('Coefficient of determination: {:.4f}'.format(metrics.r2_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grJl2AV7dLlT"
      },
      "source": [
        "#### Error Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1wuqK25dLlU"
      },
      "source": [
        "sns.distplot(y_test - y_pred);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrQwM06mdLlU"
      },
      "source": [
        "#### 45-Degree Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWxZl3K3dLlU"
      },
      "source": [
        "plt.figure(figsize=(8, 5));\n",
        "plt.scatter(y_test, y_pred);\n",
        "plt.plot([0, 50], [0, 50], '--k');\n",
        "plt.axis('tight');\n",
        "plt.xlabel(\"Actual House Prices ($1000)\");\n",
        "plt.ylabel(\"Predicted House Prices: ($1000)\");\n",
        "#plt.xticks(range(0, int(max(y_test)),2));\n",
        "#plt.yticks(range(0, int(max(y_test)),2));\n",
        "plt.title(\"Actual Prices vs Predicted prices\");\n",
        "plt.tight_layout();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ltpuKH4dLlU"
      },
      "source": [
        "print(\"RMS: %r \" % np.sqrt(np.mean((y_test - y_pred) ** 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bc7yFBydLlV"
      },
      "source": [
        "df1 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "df2 = df1.head(10)\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ8aMUO0dLlV"
      },
      "source": [
        "df2.plot(kind='bar');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zccEmtWpdLlV"
      },
      "source": [
        "## <font color=\"red\">Choosing the Best Model:</font> k-Fold Cross-Validation\n",
        "\n",
        "- Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
        "- It is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data.\n",
        "- We use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.\n",
        "- The biggest advantage of this method is that every data point is used for validation exactly once and for training `k-1` times.\n",
        "- To choose the final model to use, we select the one that has the lowest validation error.\n",
        "\n",
        "The general procedure is as follows:\n",
        "\n",
        "1. Shuffle the dataset randomly.\n",
        "2. Split the dataset into `k` groups\n",
        "3. For each unique group:\n",
        "       3.1 Take the group as a hold out or test data set\n",
        "       3.2 Take the remaining k-1 groups as a training data set\n",
        "       3.3 Fit a model on the training set and evaluate it on the test set\n",
        "       3.4 Retain the evaluation score and discard the model\n",
        "4. Summarize the skill of the model using the sample of model evaluation scores\n",
        "\n",
        "How to choose **k**?\n",
        "- A poorly chosen value for **k** may result in a mis-representative idea of the skill of the model, such as a score with a high variance, or a high bias.\n",
        "- The choice of **k** is usually 5 or 10, but there is no formal rule. As **k** gets larger, the difference in size between the training set and the resampling subsets gets smaller. As this difference decreases, the bias of the technique becomes smaller.\n",
        "- A value of **k=10** is very common in the field of applied machine learning, and is recommend if you are struggling to choose a value for your dataset.\n",
        "\n",
        "Below is the visualization of a k-fold validation when k=5.\n",
        "![FIG_kFold](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n",
        "Image Source: https://scikit-learn.org/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW-2AtpxdLlW",
        "outputId": "90f1f5f7-6292-4b8c-efb3-e189bda67001"
      },
      "source": [
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# user variables to tune\n",
        "seed    = 9\n",
        "folds   = 10\n",
        "metric  = \"neg_mean_squared_error\"\n",
        "\n",
        "# hold different regression models in a single dictionary\n",
        "models = dict()\n",
        "models[\"Linear\"]        = LinearRegression()\n",
        "models[\"Lasso\"]         = Lasso()\n",
        "models[\"ElasticNet\"]    = ElasticNet()\n",
        "models[\"Ridge\"]         = Ridge()\n",
        "models[\"BayesianRidge\"] = BayesianRidge()\n",
        "models[\"KNN\"]           = KNeighborsRegressor()\n",
        "models[\"DecisionTree\"]  = DecisionTreeRegressor()\n",
        "models[\"SVR\"]           = SVR()\n",
        "models[\"AdaBoost\"]      = AdaBoostRegressor()\n",
        "models[\"GradientBoost\"] = GradientBoostingRegressor()\n",
        "models[\"RandomForest\"]  = RandomForestRegressor()\n",
        "\n",
        "# 10-fold cross validation for each model\n",
        "model_results = list()\n",
        "model_names   = list()\n",
        "for model_name in models:\n",
        "    model   = models[model_name]\n",
        "    k_fold  = KFold(n_splits=folds, random_state=seed)\n",
        "    results = cross_val_score(model, X_train, y_train, cv=k_fold, scoring=metric)\n",
        "    \n",
        "    model_results.append(results)\n",
        "    model_names.append(model_name)\n",
        "    print(\"{:>20}: {:.2f}, {:.2f}\".format(model_name, round(results.mean(), 3), \n",
        "                                  round(results.std(), 3)))\n",
        "\n",
        "# box-whisker plot to compare regression models\n",
        "figure = plt.figure();\n",
        "figure.suptitle('Regression models comparison');\n",
        "ax = figure.add_subplot(111);\n",
        "plt.boxplot(model_results);\n",
        "ax.set_xticklabels(model_names, rotation = 45, ha=\"right\");\n",
        "ax.set_ylabel(\"Mean Squared Error (MSE)\");\n",
        "plt.margins(0.05, 0.1);\n",
        "#plt.savefig(\"model_mse_scores.png\")\n",
        "plt.show();\n",
        "#plt.clf()\n",
        "#plt.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Linear: -7393.19, 1717.78\n",
            "               Lasso: -7515.41, 1739.47\n",
            "          ElasticNet: -7566.68, 1749.11\n",
            "               Ridge: -7397.83, 1723.49\n",
            "       BayesianRidge: -7393.61, 1719.44\n",
            "                 KNN: -5933.14, 897.68\n",
            "        DecisionTree: -4738.85, 1158.95\n",
            "                 SVR: -8356.66, 1765.04\n",
            "            AdaBoost: -22411.56, 1841.50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3P1CG9UdLlW"
      },
      "source": [
        "**Based on the above comparison, we can see that `Gradient Boosting Regression` model outperforms all the other regression models.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfESaYCsdLlX"
      },
      "source": [
        "## <font color=\"red\">Model with Gradient Boosted Tree</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq0fPO5SdLlX"
      },
      "source": [
        "gbr = GradientBoostingRegressor()\n",
        "gbr.fit(X_train, y_train)\n",
        "\n",
        "gbr_predicted = gbr.predict(X_test)\n",
        "gbr_expected = y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqPJ5boqdLlX"
      },
      "source": [
        "**Root Mean Square Error:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN9CC3hFdLlY"
      },
      "source": [
        "print(\"RMS: %r \" % np.sqrt(np.mean((gbr_predicted - gbr_expected) ** 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX2BL22_dLlY"
      },
      "source": [
        "**The coefficient of determination**: (1 is perfect prediction)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkfVh2cRdLlY"
      },
      "source": [
        "print('Coeff of determination: {:.4f}'.format(metrics.r2_score(gbr_expected, gbr_predicted)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAnSJ3_qdLlZ"
      },
      "source": [
        "#### Error Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOk9IsXddLlZ"
      },
      "source": [
        "sns.distplot(gbr_expected - gbr_predicted);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FToO7e_2dLlZ"
      },
      "source": [
        "#### 45-Degree Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIcTluledLlZ"
      },
      "source": [
        "plt.figure(figsize=(8, 5));\n",
        "plt.scatter(gbr_expected, gbr_predicted)\n",
        "plt.plot([0, 50], [0, 50], '--k');\n",
        "plt.axis('tight');\n",
        "plt.xlabel('True price ($1000s)');\n",
        "plt.ylabel('Predicted price ($1000s)');\n",
        "plt.tight_layout();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nbT_4Q0dLla"
      },
      "source": [
        "**Zoom in:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azpyyJWtdLla"
      },
      "source": [
        "df1 = pd.DataFrame({'Actual': gbr_expected, 'Predicted': gbr_predicted})\n",
        "df2 = df1.head(10)\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWiQqS8odLla"
      },
      "source": [
        "df2.plot(kind='bar');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMabEMGOdLlb"
      },
      "source": [
        "#### Feature Importance\n",
        "- Once we have a trained model, we can understand feature importance (or variable importance) of the dataset which tells us how important each feature is, to predict the target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbFWxWWXdLlb"
      },
      "source": [
        "feature_importance = gbr.feature_importances_\n",
        "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
        "\n",
        "sorted_idx = np.argsort(feature_importance)\n",
        "pos        = np.arange(sorted_idx.shape[0]) + .5\n",
        "\n",
        "plt.barh(pos, feature_importance[sorted_idx], align='center');\n",
        "plt.yticks(pos, boston_data.feature_names[sorted_idx]);\n",
        "plt.xlabel('Relative Importance');\n",
        "plt.title('Variable Importance');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLJzBWlddLlc"
      },
      "source": [
        "**Plot training deviance:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBr-79WMdLlc"
      },
      "source": [
        "n_estimators = 100\n",
        "# compute test set deviance\n",
        "test_score = np.zeros((n_estimators,), dtype=np.float64)\n",
        "\n",
        "for i, y_pred in enumerate(gbr.staged_predict(X_test)):\n",
        "    test_score[i] = gbr.loss_(gbr_expected, y_pred)\n",
        "\n",
        "plt.figure(figsize=(12, 6));\n",
        "plt.subplot(1, 1, 1);\n",
        "plt.title('Deviance');\n",
        "plt.plot(np.arange(n_estimators) + 1, \n",
        "         gbr.train_score_, 'b-',\n",
        "         label='Training Set Deviance');\n",
        "plt.plot(np.arange(n_estimators) + 1, \n",
        "         test_score, 'r-',\n",
        "         label='Test Set Deviance');\n",
        "plt.legend(loc='upper right');\n",
        "plt.xlabel('Boosting Iterations');\n",
        "plt.ylabel('Deviance');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNjuPX-idLld"
      },
      "source": [
        "# <font color=\"blue\">Image Classification</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLOF_PSUdLld"
      },
      "source": [
        "## <font color=\"red\"> MNIST Dataset</font>\n",
        "\n",
        "- The <A HREF=\"https://en.wikipedia.org/wiki/MNIST_database\"> MNIST database</A> (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems.\n",
        "- The database is also widely used for training and testing in the field of machine learning.\n",
        "- The dataset we will be using contains 70000 images of handwritten digits among which 10000 are reserved for testing.\n",
        "- This dataset is  suitable for anyone who wants to get started with image classification using Scikit-Learn. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROi1VAKzdLle"
      },
      "source": [
        "### Obtain the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2gcbHasdLle"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist_data = fetch_openml('mnist_784', version=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6e_NCCQdLle"
      },
      "source": [
        "print(mnist_data.DESCR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMQPKxESdLle"
      },
      "source": [
        "### Features of the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPbcYJUddLlf"
      },
      "source": [
        "print(\"Keys: \", mnist_data.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ovdnO8gdLlf"
      },
      "source": [
        "**Note that the `data` and `target` already separated.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snkav1UBdLlf"
      },
      "source": [
        "print(\"Shape of Data: \", mnist_data.data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTFZ4Sz5dLlg"
      },
      "source": [
        "print(\"Datatype of Data: \", type(mnist_data.data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWbMGFOcdLlg"
      },
      "source": [
        "print(\"Shape of the Target Data: \", mnist_data.target.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9NsvwivdLlg"
      },
      "source": [
        "print(\"Datatype of Target Data: \", type(mnist_data.target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW3q1Xt6dLlg"
      },
      "source": [
        "print(\"Feature Names: \", mnist_data.feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwDZSbuGdLlg"
      },
      "source": [
        "print(\"Url: \", mnist_data.url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duBuScvVdLlh"
      },
      "source": [
        "np_data, np_target = mnist_data['data'], mnist_data['target']\n",
        "print(' Shape of data:   {} \\n Shape of target: {}'.format(np_data.shape, np_target.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jIh8WBTdLlh"
      },
      "source": [
        "**Checking the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_GYGT1QdLlh"
      },
      "source": [
        "len(np.unique(np_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li4pw1jOdLlh"
      },
      "source": [
        "np_data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhhYMphqdLli"
      },
      "source": [
        "len(np.unique(np_data[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okQwL64LdLli"
      },
      "source": [
        "**Checking the Target**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqPbQPMYdLli"
      },
      "source": [
        "print(\"Datatype of the target values: \", np_target.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EozTrH1CdLli"
      },
      "source": [
        "type(np_target[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6XOmv0XdLlj"
      },
      "source": [
        "Print few values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmOW_HuWdLlj"
      },
      "source": [
        "print(np_target[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgqFDrXBdLlj"
      },
      "source": [
        "Changing the labels from string to integers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT4MdmlkdLlj"
      },
      "source": [
        "np_target = np_target.astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QptnxeTQdLlj"
      },
      "source": [
        "print(np_target[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67U7rOu2dLlk"
      },
      "source": [
        "Print the number of unique labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0PzVP7IdLlk"
      },
      "source": [
        "len(np.unique(np_target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mghDfqs5dLlk"
      },
      "source": [
        "There are 70000 numbers, each stored as an array of 784 numbers depicting the opacity of each pixel, it can be displayed by reshaping the data into a 28x28 array and plotting using matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ4yYzbPdLlk"
      },
      "source": [
        "some_index = 15657\n",
        "some_digit = np_data[some_index]\n",
        "some_digit_image = some_digit.reshape(28,28)\n",
        "\n",
        "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation='nearest')\n",
        "plt.axis=('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChTBxH0ddLll"
      },
      "source": [
        "np_target[some_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a4-UmgddLll"
      },
      "source": [
        "**Display few images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0XHVXJ_dLll"
      },
      "source": [
        "def display_digits(X, y):\n",
        "    \"\"\"\n",
        "      Given an array of images of digits X and \n",
        "      the corresponding values of the digit y,\n",
        "      this function plots the first 96 images and their values.\n",
        "    \"\"\"\n",
        "    # Figure size (width, height) in inches\n",
        "    fig = plt.figure(figsize=(8, 6))\n",
        "\n",
        "    # Adjust the subplots \n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "\n",
        "    for i in range(96):\n",
        "        # Initialize the subplots: \n",
        "        #    Add a subplot in the grid of 8 by 12, at the i+1-th position\n",
        "        ax = fig.add_subplot(8, 12, i + 1, xticks=[], yticks=[])\n",
        "        \n",
        "        # Display an image at the i-th position\n",
        "        ax.imshow(X[i].reshape(28, 28), cmap=plt.cm.binary, interpolation='nearest')\n",
        "       \n",
        "        # label the image with the target value\n",
        "        ax.text(0, 7, str(y[i]))\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUyx4b2pdLlm"
      },
      "source": [
        "display_digits(np_data, np_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv6DMX9kdLlm"
      },
      "source": [
        "### <font color=\"red\">Separating the Training and Testing Set</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jmH4BaTdLlm"
      },
      "source": [
        "num_train = 60000\n",
        "\n",
        "X_train = np_data[:num_train]\n",
        "X_test  = np_data[num_train:]\n",
        "y_train = np_target[:num_train]\n",
        "y_test  = np_target[num_train:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfbyVUATdLlm"
      },
      "source": [
        "print('Train Data: ', X_train, '\\n', 'Test Data:', X_test, '\\n',\n",
        "     'Train label: ', y_train, '\\n', 'Test Label: ', y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiCLqeu2dLln"
      },
      "source": [
        "**Shuffle the training set:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxdxpSr0dLln"
      },
      "source": [
        "shuffle_index = np.random.permutation(nn)\n",
        "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lco6Gk1dLln"
      },
      "source": [
        "###  <font color=\"red\">Training a Binary Classifier</font>\n",
        "\n",
        "- Binary classification means there are two classes to work with that relate to one another as true and false.\n",
        "- Here, we want to identify a single digit: looking at 9s.\n",
        "- The classification will tell us if we have a 9 (true) or not (false)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iIlJaTbdLln"
      },
      "source": [
        "**Set the target arrays as boolean arrays:** true if 9 otherwise false."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqTes3IedLlo"
      },
      "source": [
        "y_train_9 = (y_train == 9)\n",
        "y_test_9 = (y_test == 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcGdfLY_dLlo"
      },
      "source": [
        "**Create and train the model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcwdQFTjdLlo"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf =SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
        "sgd_clf.fit(X_train, y_train_9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3f_wq17dLlo"
      },
      "source": [
        "**Make a prediction:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "staLd4PjdLlp"
      },
      "source": [
        "some_digit_predict = sgd_clf.predict([some_digit])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPRucCngdLlp"
      },
      "source": [
        "some_digit_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5RiKo5xdLlp"
      },
      "source": [
        "**Measuring accuracy using cross validation**\n",
        "\n",
        "- The `stratifiedKfold` class performs stratified sampling to produce folds that contain a representative ratio of each class. \n",
        "- At each iteration the code creates a clone of the classifier, trains that clone on the training fold and then makes predictions on the test fold. \n",
        "- It then counts the number of correct predictions and outputs the ratio of correct predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-Bx_JyCdLlp"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.base import clone\n",
        "\n",
        "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
        "\n",
        "for train_index, test_index in skfolds.split(X_train, y_train_9):\n",
        "    clone_clf = clone(sgd_clf)\n",
        "    X_train_folds = X_train[train_index]\n",
        "    y_train_folds = y_train_9[train_index]\n",
        "    X_test_fold = X_train[test_index]\n",
        "    y_test_fold = y_train_9[test_index]\n",
        "    \n",
        "    clone_clf.fit(X_train_folds, y_train_folds)\n",
        "    y_pred = clone_clf.predict(X_test_fold)\n",
        "    n_correct = sum(y_pred == y_test_fold)\n",
        "    print(n_correct/len(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OOn-ygJdLlq"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cross_val_score(sgd_clf, X_train, y_train_9, cv=3, scoring='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaJhH7FLdLlq"
      },
      "source": [
        "The sklearn cross_val_score in action returning the same result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTAZ5hx4dLlq"
      },
      "source": [
        "print('94-96% accuracy might not as impressive as it sounds where there are {:.2f} percent 9s in the dataset'.format(sum(np_target==9)/len(np_target)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq3nYjSodLlr"
      },
      "source": [
        "**Confusion matrix**\n",
        "\n",
        "- A confusion matrix is a tabular summary of the number of correct and incorrect predictions made by a classifier. \n",
        "- It can be used to evaluate the performance of a classification model through the calculation of performance metrics like accuracy, precision, recall, and F1-score.\n",
        "- The confusion matrix is a much better way to evaluate the performance of a classifier, especially when there is a skewed dataset as we have here with only 10% of the dataset being the target.\n",
        "- Each row represents a class, each column a prediction:\n",
        "   * The first row is negative cases (non-9s) with the top left containing all the correctly classified non-9s (True Negatives), the top right the 9s incorrectly classified as non-9s (False-Positves).\n",
        "   * The second row represents the positive class, 9s in this case, bottom left contains the 9s incorrectly classified as non-9s (False Negatives), the bottom right containing the correctly classified 9s (True Positives)\n",
        "   \n",
        "| | Actual | |\n",
        "| --- |: --- |: --- |\n",
        "| **Prediction** | True Positive | False Positive |\n",
        "| | False Negative | True Negative |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pW86HnPdLlr"
      },
      "source": [
        "We first need a set of predictions to compare to the actual targets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZKaghvfdLlr"
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_9, cv=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIwLfSYVdLls"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_train_9, y_train_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyPxvWEAdLls"
      },
      "source": [
        "**Precision/Recall**\n",
        "\n",
        "- Precision measures the number of true positives (correctly classified 9s) as a ratio of the total samples classified as a 9: $\\frac{TP}{TP + FP}$\n",
        "- Recall measueres the number of true positives as a ratio of the total number of positives: $\\frac{TP}{TP + FN}$\n",
        "- Depending on the scenario the model may be modified to try and maximise one or the other, catching all positive instances at the expense of catching some false positives. Or making sure a positive instance is never falsely identified as a negative at the expense of missing some of the positive instances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0pxVW-VdLls"
      },
      "source": [
        "y_scores = cross_val_predict(sgd_clf, X_train, y_train_9, cv=3, method='decision_function')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtnbamV4dLls"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_train_9, y_scores)\n",
        "\n",
        "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
        "    plt.figure(figsize=(12,8))\n",
        "    plt.title('Precision and recall vs decision threshold')\n",
        "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
        "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
        "    plt.xlabel(\"Threshold\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.ylim([0,1])\n",
        "\n",
        "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzEwR3DDdLlt"
      },
      "source": [
        "### <font color=\"red\">Training and Prediction on the Entire Dataset</font>\n",
        "\n",
        "- We will use the Stochastic Gradient Descent classifier (SGD). \n",
        "- Scikit-Learn’s SGDClassifier is a good starting point for linear classifiers. \n",
        "- Using the loss parameter we will see how Support Vector Machine (Linear SVM) and Logistic Regression perform for the same dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "819UOHgZdLlt"
      },
      "source": [
        "#### Using Linear Support Vector Machine (SVM)\n",
        "- We use linear SVM with stochastic gradient descent (SGD) learning.\n",
        "- The gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule.\n",
        "- To use the Linear SVM Classifier, we need to set the loss parameter to `hinge`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brXZ-sVNdLlt"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        " \n",
        "sgd_clf = SGDClassifier(loss='hinge', random_state=42)\n",
        "sgd_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c51rsQ2dLlu"
      },
      "source": [
        "- Before testing the model, it is a good practice to first see the cross-validation scores on the training data. \n",
        "- That you will give you a very good projection of how the model performs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmxepTwidLlu"
      },
      "source": [
        "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18vwjfP3dLlu"
      },
      "source": [
        "* For three-fold Cross-Validation you are getting around 87% – 88% accuracy. \n",
        "* Not too bad, not too good either.\n",
        "\n",
        "We can now compute the actual test scores:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C64q6Tm5dLlu"
      },
      "source": [
        "scoreSVM = sgd_clf.score(X_test, y_test)\n",
        "print(\"Test score of the Linear SVM: \", scoreSVM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ug6OLDxdLlv"
      },
      "source": [
        "### Using Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_rKEgmbdLlv"
      },
      "source": [
        "sgd_clf = SGDClassifier(loss='log', random_state=42)\n",
        "sgd_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_laVan-dLlv"
      },
      "source": [
        "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JHaCFZmdLlw"
      },
      "source": [
        "scoreLR = sgd_clf.score(X_test, y_test)\n",
        "print(\"Test score of the Logistic Regression: \", scoreLR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJNU4yfTdLlw"
      },
      "source": [
        "### Random Forest Classifier\n",
        "\n",
        "- Random forests is a supervised learning algorithm. \n",
        "- A forest is comprised of trees. \n",
        "- It is said that the more trees it has, the more robust a forest is. \n",
        "- Random forests creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting. \n",
        "- It also provides a pretty good indicator of the feature importance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMUvQ6-hdLlw"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest = RandomForestClassifier(n_estimators = 500)\n",
        "forest = forest.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVDZLhnSdLlw"
      },
      "source": [
        "forest_output = forest.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRIAvCICdLlx"
      },
      "source": [
        "Calculate accuracy on the prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G196zAXdLlx"
      },
      "source": [
        "print(\"Random Forest with n_estimators:500\")\n",
        "print(accuracy_score(y_test, forest_output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQzJoTDTdLlx"
      },
      "source": [
        "Display few true images against predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7--RSYpYdLlx"
      },
      "source": [
        "display_digits(X_test, forest_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14WKPkjmdLly"
      },
      "source": [
        "### Gradient Boosting Classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq5vUzd6dLly"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, \n",
        "                                 max_depth=1, random_state=0).fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGpMKgh6dLly"
      },
      "source": [
        "gradient_output = clf.predict(X_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlYf4bjmdLly"
      },
      "source": [
        "Calculate accuracy on the prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MKNUSpKdLlz"
      },
      "source": [
        "print(accuracy_score(y_test, gradient_output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLehzUphdLlz"
      },
      "source": [
        "Display few true images against predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRhjhUuPdLlz"
      },
      "source": [
        "display_digits(X_test, gradient_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUu7DgsodLl0"
      },
      "source": [
        "### MLP Classifier\n",
        "\n",
        "- The Multi-layer Perceptron classifier relies on an underlying Neural Network to perform the task of classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCV2cdqndLl0"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(solver='sgd', hidden_layer_sizes=(10,), random_state=1)\n",
        "clf.fit(X_train, y_train)   \n",
        "neural_output = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKqUGh1FdLl0"
      },
      "source": [
        "Calculate accuracy on the prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PHieLeddLl0"
      },
      "source": [
        "print(\"sgd: \", accuracy_score(y_test, neural_output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACq7KCU8dLl1"
      },
      "source": [
        "Display few true images against predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2sso0aMdLl1"
      },
      "source": [
        "display_digits(X_test, neural_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsnnDG1zdLl1"
      },
      "source": [
        "clf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(10,), random_state=1)\n",
        "clf.fit(X_train, y_train)   \n",
        "neural_output = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rveROTXsdLl1"
      },
      "source": [
        "Calculate accuracy on the prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS7d_Vf3dLl2"
      },
      "source": [
        "print(\"lbfgs: \", accuracy_score(y_test, neural_output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbF9EMKYdLl2"
      },
      "source": [
        "Display few true images against predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yYgYiwLdLl2"
      },
      "source": [
        "display_digits(X_test, neural_output)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}