{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soheilpaper/-tft-2.4-ili9341-STM32/blob/master/multi_agent_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation"
      ],
      "metadata": {
        "id": "mrmpj7LBMsPZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUOhf7JM12uT"
      },
      "outputs": [],
      "source": [
        "!pip install metagpt==0.5.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
        "os.environ[\"OPENAI_API_MODEL\"] = \"gpt-4-1106-preview\"\n",
        "\n",
        "import re\n",
        "import asyncio\n",
        "from metagpt.actions import Action, BossRequirement\n",
        "from metagpt.roles import Role\n",
        "from metagpt.team import Team\n",
        "from metagpt.schema import Message\n",
        "from metagpt.logs import logger\n",
        "\n",
        "def parse_code(rsp):\n",
        "    pattern = r'```python(.*)```'\n",
        "    match = re.search(pattern, rsp, re.DOTALL)\n",
        "    code_text = match.group(1) if match else rsp\n",
        "    return code_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJX9A8lh3FbS",
        "outputId": "377152c8-4b8c-41ce-b776-4aa5bc6f4e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-17 03:06:12.082 | INFO     | metagpt.const:get_project_root:27 - PROJECT_ROOT set to current working directory: /content\n",
            "2023-11-17 03:06:12.645 | INFO     | metagpt.config:__init__:44 - Config loading done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Action and Role\n",
        "Following the same process as [Agent101](https://colab.research.google.com/drive/1SF3bJiDjKw6Xwnz2Rf0j8Hc0U4KsSB2L#scrollTo=TJX9A8lh3FbS), we can define three `Role`s with their respective `Action`s:\n",
        "- A `SimpleCoder` with a `SimpleWriteCode` action, taking instruction from the user and writing the main code\n",
        "- A `SimpleTester` with a `SimpleWriteTest` action, taking the main code from `SimpleWriteCode` output and providing a test suite for it\n",
        "- A `SimpleReviewer` with a `SimpleWriteReview` action, reviewing the test cases from `SimpleWriteTest` output and check their coverage and quality\n",
        "\n",
        "By giving the outline above, we actually make our SOP clear. We will talk about how to set up the `Role` according to it shortly."
      ],
      "metadata": {
        "id": "HBOXvACQMzxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define Action\n",
        "We list the three `Action`s."
      ],
      "metadata": {
        "id": "nXF1ryW3NCPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleWriteCode(Action):\n",
        "\n",
        "    PROMPT_TEMPLATE = \"\"\"\n",
        "    Write a python function that can {instruction} and provide two runnnable test cases.\n",
        "    Return ```python your_code_here ``` with NO other texts,\n",
        "    your code:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name=\"SimpleWriteCode\", context=None, llm=None):\n",
        "        super().__init__(name, context, llm)\n",
        "\n",
        "    async def run(self, instruction: str):\n",
        "\n",
        "        prompt = self.PROMPT_TEMPLATE.format(instruction=instruction)\n",
        "\n",
        "        rsp = await self._aask(prompt)\n",
        "\n",
        "        code_text = parse_code(rsp)\n",
        "\n",
        "        return code_text\n",
        "\n",
        "class SimpleWriteTest(Action):\n",
        "\n",
        "    PROMPT_TEMPLATE = \"\"\"\n",
        "    Context: {context}\n",
        "    Write {k} unit tests using pytest for the given function, assuming you have imported it.\n",
        "    Return ```python your_code_here ``` with NO other texts,\n",
        "    your code:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name=\"SimpleWriteTest\", context=None, llm=None):\n",
        "        super().__init__(name, context, llm)\n",
        "\n",
        "    async def run(self, context: str, k: int = 3):\n",
        "\n",
        "        prompt = self.PROMPT_TEMPLATE.format(context=context, k=k)\n",
        "\n",
        "        rsp = await self._aask(prompt)\n",
        "\n",
        "        code_text = parse_code(rsp)\n",
        "\n",
        "        return code_text\n",
        "\n",
        "class SimpleWriteReview(Action):\n",
        "\n",
        "    PROMPT_TEMPLATE = \"\"\"\n",
        "    Context: {context}\n",
        "    Review the test cases and provide one critical comments:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name=\"SimpleWriteReview\", context=None, llm=None):\n",
        "        super().__init__(name, context, llm)\n",
        "\n",
        "    async def run(self, context: str):\n",
        "\n",
        "        prompt = self.PROMPT_TEMPLATE.format(context=context)\n",
        "\n",
        "        rsp = await self._aask(prompt)\n",
        "\n",
        "        return rsp"
      ],
      "metadata": {
        "id": "4CcoF9yj24Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define Role\n",
        "In many multi-agent scenarios, defining a `Role` can be as simple as 10 lines of codes. For `SimpleCoder`, we do two things:\n",
        "1. Equip the `Role` with the appropriate `Action`s with `_init_actions`, this is identical to setting up a single agent\n",
        "2. A multi-agent operation: we make the `Role` `_watch` important upstream messages from users or other agents. Recall our SOP, `SimpleCoder` takes user instruction, which is a `Message` caused by `BossRequirement` in MetaGPT. Therefore, we add `self._watch([BossRequirement])`.\n",
        "\n",
        "That's all users have to do. For those who are interested in the mechanism under the hood, see Mechanism Explained of this chapter."
      ],
      "metadata": {
        "id": "pWR77Hj4NXJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCoder(Role):\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str = \"Alice\",\n",
        "        profile: str = \"SimpleCoder\",\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(name, profile, **kwargs)\n",
        "        self._watch([BossRequirement])\n",
        "        self._init_actions([SimpleWriteCode])"
      ],
      "metadata": {
        "id": "vQUxFY1gNtAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Similar to above, for `SimpleTester`, we:\n",
        "1. Equip the `SimpleTester` with `SimpleWriteTest` action using `_init_actions`\n",
        "2. Make the `Role` `_watch` important upstream messages from other agents. Recall our SOP, `SimpleTester` takes main code from `SimpleCoder`, which is a `Message` caused by `SimpleWriteCode`. Therefore, we add `self._watch([SimpleWriteCode])`.\n",
        ">An extended question: Think about what it means if we use `self._watch([SimpleWriteCode, SimpleWriteReview])` instead, feel free to try this too\n",
        "\n",
        "Additionally, we want to show that you can define your own acting logic for the agent. This applies to situation where the `Action` takes more than one input, you want to modify the input, to use particular memories, or to make any other changes to reflect specific logic. Hence, we:\n",
        "\n",
        "3. Overwrite the `_act` function, just like what we did in a single-agent setting in [Agent101](https://colab.research.google.com/drive/1SF3bJiDjKw6Xwnz2Rf0j8Hc0U4KsSB2L#scrollTo=TJX9A8lh3FbS). Here, we want `SimpleTester` to use all memories as context for writing the test cases, and we want 5 test cases."
      ],
      "metadata": {
        "id": "T9UF32GjNv_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTester(Role):\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str = \"Bob\",\n",
        "        profile: str = \"SimpleTester\",\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(name, profile, **kwargs)\n",
        "        self._init_actions([SimpleWriteTest])\n",
        "        self._watch([SimpleWriteCode])\n",
        "        # self._watch([SimpleWriteCode, SimpleWriteReview]) # feel free to try this too\n",
        "\n",
        "    async def _act(self) -> Message:\n",
        "        logger.info(f\"{self._setting}: ready to {self._rc.todo}\")\n",
        "        todo = self._rc.todo\n",
        "\n",
        "        # context = self.get_memories(k=1)[0].content # use the most recent memory as context\n",
        "        context = self.get_memories() # use all memories as context\n",
        "\n",
        "        code_text = await todo.run(context, k=5) # specify arguments\n",
        "\n",
        "        msg = Message(content=code_text, role=self.profile, cause_by=type(todo))\n",
        "\n",
        "        return msg"
      ],
      "metadata": {
        "id": "pShxoOONN50K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Define `SimpleReviewer` following the same procedure:"
      ],
      "metadata": {
        "id": "Fzm2k8dVNt_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleReviewer(Role):\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str = \"Charlie\",\n",
        "        profile: str = \"SimpleReviewer\",\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(name, profile, **kwargs)\n",
        "        self._init_actions([SimpleWriteReview])\n",
        "        self._watch([SimpleWriteTest])"
      ],
      "metadata": {
        "id": "2znJ0wwUODrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a team and add roles\n",
        "Now that we have defined our three `Role`s, it's time to put them together. We initialize all of them, set up a `Team`, and `hire` them.\n",
        "\n",
        "Run the `Team`, we should see the collaboration between them!"
      ],
      "metadata": {
        "id": "j4SoskG4Nt9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def main(\n",
        "    idea: str = \"write a function that calculates the product of a list\",\n",
        "    investment: float = 3.0,\n",
        "    n_round: int = 5,\n",
        "):\n",
        "    logger.info(idea)\n",
        "\n",
        "    team = Team()\n",
        "    team.hire(\n",
        "        [\n",
        "            SimpleCoder(),\n",
        "            SimpleTester(),\n",
        "            SimpleReviewer(),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    team.invest(investment=investment)\n",
        "    team.run_project(idea)\n",
        "    await team.run(n_round=n_round)\n",
        "\n",
        "await main(idea=\"write a function that calculates the product of a list\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPO1dhjb3CMC",
        "outputId": "e4f804fa-d989-44fd-9693-61d98bd62844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-17 03:06:22.912 | INFO     | __main__:main:6 - write a function that calculates the product of a list\n",
            "2023-11-17 03:06:22.917 | INFO     | metagpt.team:invest:39 - Investment: $3.0.\n",
            "2023-11-17 03:06:22.920 | INFO     | metagpt.roles.role:_act:207 - Alice(SimpleCoder): ready to SimpleWriteCode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def product_of_list(lst):\n",
            "    product = 1\n",
            "    for num in lst:\n",
            "        product *= num\n",
            "    return product\n",
            "\n",
            "# Test case 1:\n",
            "print(product_of_list([1, 2, 3, 4]))  # Output: 24\n",
            "\n",
            "# Test case 2:\n",
            "print(product_of_list([5, 6, 7, 8]))  # Output: 1680\n",
            "```\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-17 03:06:33.123 | INFO     | metagpt.provider.openai_api:update_cost:89 - Total running cost: $0.008 | Max budget: $3.000 | Current cost: $0.008, prompt_tokens: 79, completion_tokens: 90\n",
            "2023-11-17 03:06:33.129 | INFO     | __main__:_act:14 - Bob(SimpleTester): ready to SimpleWriteTest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
            "```python\n",
            "import pytest\n",
            "from your_module import product_of_list\n",
            "\n",
            "def test_product_of_list():\n",
            "    assert product_of_list([1, 2, 3, 4]) == 24\n",
            "    assert product_of_list([5, 6, 7, 8]) == 1680\n",
            "    assert product_of_list([0, 1, 2, 3]) == 0\n",
            "    assert product_of_list([10, 10, 10]) == 1000\n",
            "    assert product_of_list([-1, 1, 2])"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-17 03:06:45.037 | INFO     | metagpt.provider.openai_api:update_cost:89 - Total running cost: $0.020 | Max budget: $3.000 | Current cost: $0.013, prompt_tokens: 176, completion_tokens: 122\n",
            "2023-11-17 03:06:45.042 | INFO     | metagpt.roles.role:_act:207 - Charlie(SimpleReviewer): ready to SimpleWriteReview\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " == -2\n",
            "```\n",
            "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
            "The test cases seem to cover a variety of scenarios including positive numbers, zero, and negative numbers. However, one critical comment would be that there is no test case for an empty list. It would be beneficial to add a test case that handles this scenario to ensure the"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-17 03:06:51.465 | INFO     | metagpt.provider.openai_api:update_cost:89 - Total running cost: $0.029 | Max budget: $3.000 | Current cost: $0.009, prompt_tokens: 170, completion_tokens: 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " function can handle all possible inputs.\n",
            "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pY0wO6-33aW7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}