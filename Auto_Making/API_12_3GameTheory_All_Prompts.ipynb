{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soheilpaper/-tft-2.4-ili9341-STM32/blob/master/Auto_Making/API_12_3GameTheory_All_Prompts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AcaGPT MVP\n",
        "\n",
        "The gosl of this project is Creating something like AutoGPT but in the field of Academic Papers wrting.\n",
        "\n",
        "\n",
        "For example the MVP Lage has been made by this AI free website maker :\n",
        "\n",
        "https://acagpt.site.live/editv2/"
      ],
      "metadata": {
        "id": "qnaAEEnpFyLs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHgZHeIxi31Q"
      },
      "source": [
        "## Aromatically wrrie apaper by the ChatGPT and this github prompt instruction:\n",
        "\n",
        "https://github.com/ahmetbersoz/chatgpt-prompts-for-academic-writing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "global gdrive_fpath\n",
        "drive_mounted = False\n",
        "gdrive_fpath = '.'\n",
        "local_path = '/content/'\n",
        "\n",
        "mount_gdrive = True # @param{type:\"boolean\"}\n",
        "if mount_gdrive : # and not drive_mounted:\n",
        "    from google.colab import drive\n",
        "\n",
        "    gdrive_mountpoint = '/content/drive/' #@param{type:\"string\"}\n",
        "    gdrive_subdirectory = 'MyDrive/ChatGPT_Paper_wrting' #@param{type:\"string\"}\n",
        "    gdrive_fpath = str(Path(gdrive_mountpoint) / gdrive_subdirectory)\n",
        "    print (\"gdrive path is :\",gdrive_fpath)\n",
        "   # Mount Google Drive\n",
        "    if not os.path.isdir(gdrive_mountpoint):\n",
        "     # If not, mount the drive\n",
        "       drive.mount(gdrive_mountpoint)\n",
        "       if not os.path.exists(gdrive_fpath):\n",
        "          os.makedirs(gdrive_fpath)\n",
        "          os.chdir(gdrive_fpath)\n",
        "    else:\n",
        "          print(\"Drive is already mounted.\")\n",
        "else:\n",
        "   Folder_fpath ='/content/' #@param{type:\"string\"}\n",
        "   #gdrive_subdirectory = 'MyDrive/ChatGPT_Paper_wrting' #@param{type:\"string\"}\n",
        "   gdrive_fpath = Folder_fpath\n",
        "   os.chdir(gdrive_fpath)\n",
        "folder_path = gdrive_fpath"
      ],
      "metadata": {
        "id": "6GjtEabAJCXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "133817f4-a754-4380-bad9-1a425bbed4b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive path is : /content/drive/MyDrive/ChatGPT_Paper_wrting\n",
            "Drive is already mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall openai -y\n",
        "#!pip install openai # ==0.28"
      ],
      "metadata": {
        "id": "DIUEYU4EJW6w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vt7VN_fmGT3E",
        "outputId": "c5769d7e-7f7f-40b8-df04-a84e94c4941a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.30.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (0.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.12.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: docx2pdf in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from docx2pdf) (4.66.4)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.11.0)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.10/dist-packages (5.0.6)\n",
            "Requirement already satisfied: asgiref<4,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from django) (3.8.1)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from django) (0.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from asgiref<4,>=3.7.0->django) (4.11.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (5.1.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from tenacity) (1.16.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.31.4)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.111.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==0.16.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.16.4)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.0)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.4)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Using cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.29.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.4->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.4->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (0.15.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.0.3)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (2.1.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.18.0,>=0.15.0->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Installing collected packages: typer\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typer-0.12.3\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.681s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 2 \u001b[93mmoderate\u001b[0m severity vulnerabilities\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h\n",
            "\u001b[33m\u001b[39m\n",
            "\u001b[33m   ╭────────────────────────────────────────────────────────────────╮\u001b[39m\n",
            "   \u001b[33m│\u001b[39m                                                                \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m      New \u001b[31mmajor\u001b[39m version of npm available! \u001b[31m6.14.8\u001b[39m → \u001b[32m10.8.0\u001b[39m       \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m   \u001b[33mChangelog:\u001b[39m \u001b[36mhttps://github.com/npm/cli/releases/tag/v10.8.0\u001b[39m   \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m               Run \u001b[32mnpm install -g npm\u001b[39m to update!                \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m                                                                \u001b[33m│\u001b[39m\n",
            "\u001b[33m   ╰────────────────────────────────────────────────────────────────╯\u001b[39m\n",
            "\u001b[33m\u001b[39m\n",
            "34.23.102.139\n",
            "Requirement already satisfied: mega.py in /usr/local/lib/python3.10/dist-packages (1.0.8)\n",
            "Requirement already satisfied: requests>=0.10 in /usr/local/lib/python3.10/dist-packages (from mega.py) (2.31.0)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.9.6 in /usr/local/lib/python3.10/dist-packages (from mega.py) (3.20.0)\n",
            "Requirement already satisfied: pathlib==1.0.1 in /usr/local/lib/python3.10/dist-packages (from mega.py) (1.0.1)\n",
            "Requirement already satisfied: tenacity<6.0.0,>=5.1.5 in /usr/local/lib/python3.10/dist-packages (from mega.py) (5.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=0.10->mega.py) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from tenacity<6.0.0,>=5.1.5->mega.py) (1.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: httpcore==0.15.0 in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.7.2)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (0.12.0)\n",
            "Requirement already satisfied: sniffio==1.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (1.3.1)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpcore==0.15.0) (2024.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore==0.15.0) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore==0.15.0) (1.2.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from googletrans) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->googletrans) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->googletrans) (2.0.7)\n",
            "Requirement already satisfied: httpx==0.24.1 in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (2024.2.2)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (0.15.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (1.3.1)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (0.12.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (3.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai #==0.28\n",
        "!pip install backoff\n",
        "!pip install docx2pdf\n",
        "!pip install python-docx\n",
        "!pip install django\n",
        "!pip install tensorflow\n",
        "\n",
        "!pip install tenacity\n",
        "!pip install tiktoken\n",
        "!pip install gradio\n",
        "# SETUP COLAB for run Streamlit\n",
        "!npm install localtunnel\n",
        "\n",
        "!pip install -q dl-translate\n",
        "!curl ipv4.icanhazip.com\n",
        "\n",
        "#!pip install youtube-dl\n",
        "#!apt install python3-distutils\n",
        "!pip install mega.py\n",
        "!apt install python3-distutils  -y\n",
        "\n",
        "#!pip install googletrans==4.0.0-rc1\n",
        "\n",
        "!pip install httpcore==0.15.0 httpx pymongo googletrans\n",
        "!pip install httpx==0.24.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install libreoffice\n",
        "#!sudo apt-get install abiword\n",
        "!sudo apt install libreoffice-writer"
      ],
      "metadata": {
        "id": "AUeIF57v21gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1881e3e-9166-44b4-e4af-8301d44952cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to cloud.r-project.org] [Conn\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice is already the newest version (1:7.3.7-0ubuntu0.22.04.4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libreoffice-writer is already the newest version (1:7.3.7-0ubuntu0.22.04.4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpt2-client\n",
        "!pip install gpt-2-simple\n",
        "!pip install bert-extractive-summarizer\n",
        "!pip install gendim\n",
        "\n",
        "#!pip uninstall gendim -y\n",
        "!pip install   newspaper3k  sumy\n",
        "#!pip install gensim==3.8.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN7pSJtndrgH",
        "outputId": "02139af9-aefb-4740-8e60-acb14ec57cd2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gpt2-client in /usr/local/lib/python3.10/dist-packages (2.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gpt2-client) (1.25.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from gpt2-client) (2.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from gpt2-client) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt2-client) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt2-client) (2.31.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from gpt2-client) (2.4.0)\n",
            "Requirement already satisfied: gpt-2-simple in /usr/local/lib/python3.10/dist-packages (from gpt2-client) (0.8.1)\n",
            "Requirement already satisfied: toposort in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple->gpt2-client) (1.10)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->gpt2-client) (2.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gpt2-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt2-client) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt2-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt2-client) (2024.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->gpt2-client) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->gpt2-client) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->gpt2-client) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->gpt2-client) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->gpt2-client) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->gpt2-client) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->gpt2-client) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->gpt2-client) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->gpt2-client) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->gpt2-client) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->gpt2-client) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->gpt2-client) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->gpt2-client) (3.2.2)\n",
            "Requirement already satisfied: gpt-2-simple in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
            "Requirement already satisfied: tensorflow>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (1.25.2)\n",
            "Requirement already satisfied: toposort in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (1.10)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (2024.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.5.1->gpt-2-simple) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.5.1->gpt-2-simple) (3.2.2)\n",
            "Requirement already satisfied: bert-extractive-summarizer in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from bert-extractive-summarizer) (4.41.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from bert-extractive-summarizer) (1.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from bert-extractive-summarizer) (3.7.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (0.3.4)\n",
            "Collecting typer<0.10.0,>=0.3.0 (from spacy->bert-extractive-summarizer)\n",
            "  Using cached typer-0.9.4-py3-none-any.whl (45 kB)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (0.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (0.4.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers->bert-extractive-summarizer) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers->bert-extractive-summarizer) (4.11.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->bert-extractive-summarizer) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->bert-extractive-summarizer) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->bert-extractive-summarizer) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->bert-extractive-summarizer) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy->bert-extractive-summarizer) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy->bert-extractive-summarizer) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->bert-extractive-summarizer) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->bert-extractive-summarizer) (1.1.1)\n",
            "Installing collected packages: typer\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.12.3\n",
            "    Uninstalling typer-0.12.3:\n",
            "      Successfully uninstalled typer-0.12.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastapi-cli 0.0.3 requires typer>=0.12.3, but you have typer 0.9.4 which is incompatible.\n",
            "gradio 4.31.4 requires typer<1.0,>=0.12; sys_platform != \"emscripten\", but you have typer 0.9.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typer-0.9.4\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement gendim (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for gendim\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: newspaper3k in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: sumy in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.12.3)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0.1)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (1.2.0)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.9.4)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.31.0)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0.11)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (5.1.2)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.8.2)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.10/dist-packages (from sumy) (23.12.11)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.5)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2024.2.2)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.0.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment to install the necessary libraries in Colab\n",
        "#!pip uninstall diffusers -y\n",
        "#!pip install diffusers\n",
        "#!pip install transformers\n",
        "!pip install python-docx google-cloud-texttospeech\n",
        "!pip install --upgrade diffusers accelerate transformers"
      ],
      "metadata": {
        "id": "f7EXavscdFtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab49979-cc25-4a12-d64b-d199e98ff97c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: google-cloud-texttospeech in /usr/local/lib/python3.10/dist-packages (2.16.3)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.11.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-texttospeech) (2.11.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-texttospeech) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-texttospeech) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-texttospeech) (3.20.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (1.63.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-texttospeech) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-texttospeech) (2024.2.2)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pipeline.to(\"cuda\") #\"cuda\")\n",
        "\n",
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "\n",
        "# Load the pretrained model\n",
        "pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
        "\n",
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "   device = \"cuda\"\n",
        "else:\n",
        "   device = \"cpu\"\n",
        "\n",
        "# Move the model to the chosen device\n",
        "pipeline.to(device)"
      ],
      "metadata": {
        "id": "8F2IhrP_dawS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5a5d686d66df49e1b836374837cd39e2",
            "9b1acca088e749bcae35dab52c9e7991",
            "415149e1650c45aca03225a671917ddd",
            "f866fa9d7961420da51838a542360d84",
            "7b1de52ac7914c6aa39bf9182e17174e",
            "65d2392ae35b4c45acbec4fc98506401",
            "a628a3eaad0d4fb3903a9a44aa1aad5b",
            "dd43be57c7384c1daab427034d3a8711",
            "e76601ee0d314b6e9366b0a9846d5975",
            "9f63e225c87f478dbbc82ea1f6e5a40c",
            "ad1912297ff9450babd2dce13727084f",
            "e806aae5b5454dc3afb1154b00e22855",
            "316edb0c3d294e6ca627d136e16d7a31",
            "1a990a42347c45b888c694577fe4d491",
            "6fc05178fafb4c988c7a94dc50237a8c",
            "6be0f94e5f59490099cb390fc86ee26f",
            "fc4f931d14b24d1e8d134e8de10f0e67",
            "228377add59340cd924fa6aacc063603",
            "f4721bc68546408299d0a90b5010cf2b",
            "b40a4b67378447ff9090ab075f9c2a7b",
            "023e4ccf4242485aa85e42f5dfaac155",
            "2984641b143e4380a665c523311d9af2",
            "d95593e0f52f411d98d4e52fcf3cbf69",
            "824be7e04a2e4c0e85a895aeaf058fb5",
            "d453e86bf03340ae969d28df004a6d5b",
            "e4938bd57bb24e9ea9e9a15dbb841ce8",
            "c9244decf39b474ab5017dc32ec7e08f",
            "87ca06d6e7d14cf2883c1b4bfe659ee1",
            "99c15a97b2014916acf3f4f916bc689b",
            "719dc8e2f4cf442c832dfa0cd7435972",
            "417e3cff4acb431f997efc354f914aa8",
            "05072f32f76149708ecc126aa8f054c1",
            "148b0037519a451eaeb2ac2c3cdc1021",
            "7bd241a13526413497bbfbefd4c9f47e",
            "fcbbfafd968b41b59ce33b6ae46ada6a",
            "fe1cb4ee4b774f088b15682bff8dcaf3",
            "12fe3810f4884deebfe093b9e6fdd476",
            "189808ea749e4c70be7e142b927cf553",
            "a0644a0961664435a8761a002e4b4976",
            "fb58cd4db2d2410b897b349107af5108",
            "5096eab09e844309802fe0766ac9f188",
            "d9118e0e0fb940ba836a420115dc9aa2",
            "b4148961dab248b8accc8da84fb1ecc1",
            "fabd3d8cb1074ac0b3a9da74d7eca09e",
            "76f3373f5abb4f6bb58c6221ef63d5cb",
            "5ee304704f9c4f0da61bd3111d2cf1e1",
            "039ab76ac3ae4cc5bbd9f70007939e92",
            "b957a5b5ca1a4de9974c11020276fe9a",
            "4eb37f88d76f46769dc18a234391270d",
            "3803cb85e41940b79c58556f03d4e00a",
            "e56e2a4812cc4eab9524570177dddef8",
            "e32da3240d214d1a97800dc0d89c89d2",
            "454de433eacc4afbb0c888b8b6fa9af9",
            "645007e7760f473c9b2b98ae379ddadf",
            "6cb325f37a124a659844a95e8c3816c0",
            "f6260ef3ee2647ad9ddd32527e8bc731",
            "5397c9e13f61424fabe024670d052ef5",
            "ba3eea41da3146379245875490954e73",
            "fcbe57a1fdd042eb9f3195f0baedf3a2",
            "c3139f3c1d894a06a450673288a72d09",
            "d05b0fce91c54985aeeebde659361a31",
            "ab78bf4d638946ef9f17ee4b57237d0a",
            "f2c9f412babc46a3b247cbb62a6f10d6",
            "83104aa65e6b4e1f84f77b09d7b172b2",
            "03a72e8ddb02431099af592c370303d5",
            "df67f31b511b4dc9a25cb9e0dfd5a9ef",
            "68cd281bb05c47709ae5fdeb8e6932c4",
            "5bf82af4a88347edaf6897e22ba3a109",
            "e40311f72f4d42dea4f9d4bc4ee394a9",
            "95554c35f5ba44168716e63bfa095945",
            "f062c507a3664f7781dfeb01086ede4e",
            "22ea54b39e224df0bd516cdd9b938c14",
            "646d44c5a4fa48d6b50abbafe120debb",
            "a4afe3c9166f4942adcbe781686c9e5e",
            "77c3dc64fec04b52b7e0f6299028366a",
            "bcff4fd621fa4834a46f0b0caca4bfc5",
            "0dfd99ec160340ccaf03be96f36d8856",
            "8049cccb108243a3ad1a0f24be6dbcbf",
            "cc8ff5305a4d4eaf97b26129dadee04b",
            "c654f257390a477c9788c6e0c8c13890",
            "62c2888ae649413daa093cf7b30c970c",
            "e43c8780ddef4398bf5bb9921bf2eab6",
            "8beb04af98fa45e797e477f04ee32509",
            "9efa754a56894de6a3cd9203894ef14c",
            "2f2265a1c482470fa19b6a6159a97200",
            "f75a45e2ed2c4ac0958f4f244ad5d875",
            "3d2a2e023eea468681f4f1e08fa10a67",
            "da5f9d431d4140bda3f96f5fcae5f5c7",
            "6ed38d33bdae4a95ba19a6d22e51e0d1",
            "f9fe51d985d141119e2016cdec1f8e2a",
            "cb8bb2057aa64005a826d67074caecb0",
            "34ddbd025e9b42d0a2e228dad3986535",
            "447ae4761c1349b59257169c1a887f2d",
            "0a5659be8157473ea5e9db425d2e31e4",
            "5ffc6979b272405ba807fdd74ba90d99",
            "17986e79d213435f93a6f3636bf53b04",
            "b1e9e0a28e2c4c4597587778b9850564",
            "b319cfc9320a4f2fb4fe4aef4a57ebb6",
            "52d31d1c9b3040ff8314636aebc0766d",
            "26551fee300b45059a3507890d6ed081",
            "c52ddf2f937641cab474999fd1021b10",
            "056db4fc725c46b6968899f2985d4564",
            "416e3fdc7c7a4bb6a18eae8432093a51",
            "c61ca3e88474415497cde262f66bf8b9",
            "047f2a9aa54149faba3bdd638d2d643d",
            "53dbefcfce0540ada05effd786333e81",
            "5d9325c8c85a44fb95acfe037d2622a9",
            "878219683bd84859acc137e54d5cfac0",
            "23383869c99748b29f00e850429b9a56",
            "0adfec77b17f40569d89f55a27264081",
            "66084ce4fca04f728b7c8c782dc2ac72",
            "4317609118444aec9135ea277410bd13",
            "a38d9d8bedc7440194adefdd4be36dab",
            "d87f9110de8f488cb8f58066b152b1f2",
            "6335c340917e4430aca2e9b74406aeab",
            "55a829725dcc41e695c0b008e60806ad",
            "15adc1a82ee940d48e55dcf54a8bfc9a",
            "36fec0d5e76b40358f0c702b085aef4a",
            "41043f77a6a74d4c8faadf00c72376db",
            "1ba79a605ec048e3ad663c881db804b3",
            "7530b7425fa14e5d8c7c91047e543a9d",
            "ad9bd62fd52444fbb2f9817cec424a80",
            "5ae3fec928d144bfb5995f94373bdc04",
            "3809e9bcd7a347709f21180359697487",
            "3e13c554e79c43adb5305fc0067fb481",
            "d76c1fab7c6f473cb8d6167cf09270f5",
            "7760f624cd0a45bc9295645b0a3ca7fb",
            "3538f0b814e04e75864e97e1397b5175",
            "07143968c4f041d7a9e983d1478d4be8",
            "2cb7e888a60c47d88bea9b5237009a41",
            "ea248e9876c54250ae9063b94f029e03",
            "f00c3a9208414d80903c418482ca4938",
            "9061f036bc6f4086bec6633baeee0f09",
            "76f1681fb4b844e09edb49b075ca5040",
            "9c0dade1375748dd8b199b41d749f842",
            "9ece2cb3279445bd8a6edaac31229634",
            "0d97b01828a347e6a9cf5f1bc3b4b12b",
            "85e19bf8456142fe90e0b14a2834d566",
            "291fcc5291a64df5a40270ec6a4af5ae",
            "8bfbe982b45e4e37a1afcb147198da8c",
            "0c6972d62e3d4b3aa21756f3fda850f6",
            "b4294dffcb984789a7a010b64e75a913",
            "a24306084c5c438f891f433a0f4afcec",
            "183054e577e74ed09ba210ef03134c38",
            "01f7bc4c321340bdba20399c33449eb6",
            "26737b8796884a66afae736313d77902",
            "cde18ac314384b3ea210b54d4e4f6bbc",
            "67b4f4db1cc64d598d8f6ec3e4f42c24",
            "0d8600810e5842a59045be019e419807",
            "e9306843805744d4a27a828f1de6222a",
            "909c15ede2d540418ccc1a55e1227248",
            "8609e52241cb48d08a6cb38ac5969fbc",
            "ebf2899031134412972148c540209612",
            "88adc4904ac94a898d5c4583c7f3631b",
            "3e2bf5251d7844de829f7f72cfe27744",
            "98240d14aabd4f9eab4603cfe4239360",
            "28206c896dd74e0e8d46fe797027f7d8",
            "1eea8ec1d73348b0a52fa8c779d18cd7",
            "3c38a28a3569404cbaed0e7df08963c4",
            "7fac1fdc7f2547bb8adb3f2b09a37177",
            "772cf02f95d74b78bb54074fdf079c12",
            "cf5e674a08d247408cfb7f49e345deae",
            "e8b06f3762d44dd7826bead24643db3d",
            "34b38c57248f4fc0a1e134a099db7b57",
            "8f5ffee32d234aaeb60fab0624189654",
            "69f1b43272c743b3b8a68b92752f2547",
            "faeed76c18bc447f9307a2ef2554373f",
            "0042cc2b46684f828ab576520c00c3d0",
            "58565821e77d45099b0a81e539380247",
            "19ae67896c75422496599a08569d7e1d",
            "2f7122e0f7c6407e82fa01b9315947fb",
            "651d5c4d0f594f1ba64a6e6ee16d552f",
            "8866d6a3a63c4ea1882c6d3513dee8b7",
            "fcfc1408185744ad8a3c7e56bd6878df",
            "d7263c511f084a51bc20f5cff2b9b189",
            "e60ebfff739d470098beef49b805c704",
            "416799817d6a43ccacee1505a2cdc6aa",
            "3ea989b3ff744bee8ad2e5ab5f7a976d",
            "0b6f2fa844624ef0bd6094c3234c0d82",
            "74a3851addf24cb381ed4ee80a657312",
            "3631132f19d34547b30d38c54986e82d",
            "d6650ddfca444314a063f76199c0bf2f",
            "f7e8bc976ff44ae9ae83a8c543fa8818",
            "defc3382ed864fdca7776b706105fef0",
            "fcee8d8fb34d44cb9b0acbd2e03b4817",
            "c51230ea780840e5818cfbc3e61b2085",
            "35a7e139a38c48f2a48b63d4988f33e6"
          ]
        },
        "outputId": "3b0b9a60-9b79-49a3-e91a-673da5017c1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a5d686d66df49e1b836374837cd39e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e806aae5b5454dc3afb1154b00e22855"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d95593e0f52f411d98d4e52fcf3cbf69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "scheduler/scheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bd241a13526413497bbfbefd4c9f47e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)ature_extractor/preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76f3373f5abb4f6bb58c6221ef63d5cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer/special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6260ef3ee2647ad9ddd32527e8bc731"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "text_encoder/config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68cd281bb05c47709ae5fdeb8e6932c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "safety_checker/config.json:   0%|          | 0.00/4.72k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8049cccb108243a3ad1a0f24be6dbcbf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer/tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ed38d33bdae4a95ba19a6d22e51e0d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26551fee300b45059a3507890d6ed081"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unet/config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66084ce4fca04f728b7c8c782dc2ac72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vae/config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad9bd62fd52444fbb2f9817cec424a80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9061f036bc6f4086bec6633baeee0f09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "183054e577e74ed09ba210ef03134c38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e2bf5251d7844de829f7f72cfe27744"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69f1b43272c743b3b8a68b92752f2547"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "416799817d6a43ccacee1505a2cdc6aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StableDiffusionPipeline {\n",
              "  \"_class_name\": \"StableDiffusionPipeline\",\n",
              "  \"_diffusers_version\": \"0.27.2\",\n",
              "  \"_name_or_path\": \"runwayml/stable-diffusion-v1-5\",\n",
              "  \"feature_extractor\": [\n",
              "    \"transformers\",\n",
              "    \"CLIPImageProcessor\"\n",
              "  ],\n",
              "  \"image_encoder\": [\n",
              "    null,\n",
              "    null\n",
              "  ],\n",
              "  \"requires_safety_checker\": true,\n",
              "  \"safety_checker\": [\n",
              "    \"stable_diffusion\",\n",
              "    \"StableDiffusionSafetyChecker\"\n",
              "  ],\n",
              "  \"scheduler\": [\n",
              "    \"diffusers\",\n",
              "    \"PNDMScheduler\"\n",
              "  ],\n",
              "  \"text_encoder\": [\n",
              "    \"transformers\",\n",
              "    \"CLIPTextModel\"\n",
              "  ],\n",
              "  \"tokenizer\": [\n",
              "    \"transformers\",\n",
              "    \"CLIPTokenizer\"\n",
              "  ],\n",
              "  \"unet\": [\n",
              "    \"diffusers\",\n",
              "    \"UNet2DConditionModel\"\n",
              "  ],\n",
              "  \"vae\": [\n",
              "    \"diffusers\",\n",
              "    \"AutoencoderKL\"\n",
              "  ]\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOPIC = '' # @param {type:\"string\"}\n",
        "RESEARCH_DOMAIN = '' # @param {type:\"string\"}\n",
        "PARAGRAPH = '' # @param {type:\"string\"}\n",
        "PARAGRAPHS = '' # @param {type:\"string\"}\n",
        "TOPIC_SENTENCE = '' # @param {type:\"string\"}\n",
        "LANGUAGE = '' # @param {type:\"string\"}\n",
        "ABSTRACT_PARAGRAPH = '' # @param {type:\"string\"}\n",
        "BIBLIOGRAPHY = '' # @param {type:\"string\"}\n",
        "THEORY1 = '' # @param {type:\"string\"}\n",
        "THEORY2 = '' # @param {type:\"string\"}\n",
        "RESEARCH_QUESTIONS = [] # @param {type:\"string\"}\n",
        "ACTION = '' # @param {type:\"string\"}\n",
        "RESULT_PARAGRAPHS = '' # @param {type:\"string\"}\n",
        "DATE = '' # @param {type:\"string\"}\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = '' # @param {type:\"string\"}\n",
        "role = '' # @param {type:\"string\"}\n",
        "project_example = '' # @param {type:\"string\"}\n",
        "context = '' # @param {type:\"string\"}\n",
        "instruction = '' # @param {type:\"string\"}\n",
        "output_format = '' # @param {type:\"string\"}\n",
        "specific_project_details = '' # @param {type:\"string\"}\n",
        "X = '' # @param {type:\"string\"}\n",
        "project_manager = '' # @param {type:\"string\"}\n",
        "report = '' # @param {type:\"string\"}\n",
        "important_themes = '' # @param {type:\"string\"}\n",
        "project_name = '' # @param {type:\"string\"}\n",
        "stakeholder = '' # @param {type:\"string\"}\n",
        "resistant_stakeholder = '' # @param {type:\"string\"}\n",
        "task = '' # @param {type:\"string\"}\n",
        "Your_Email = ''\n",
        "\n",
        "openai_api = '' # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "PReOAa5fG-v-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "TOPIC = \"The Need for a Clear Vision of Iran's Future\" # @param {type:\"string\"}\n",
        "RESEARCH_DOMAIN = 'Sociopolitical Analysis' # @param {type:\"string\"}\n",
        "PARAGRAPH = \"Analyzing the judges' meeting, I noticed a problem with their analysis that focuses on painting a bright picture of Iran's future.\" # @param {type:\"string\"}\n",
        "PARAGRAPHS = \"\"\"The judges seem to believe that if Iran has a clear vision of a bright future, the people will rise to the occasion. However, it's crucial to communicate the truth to the children and the youth, who are likely to remain passive. Women, the young generation, and nature should be aware of the dark future of Iran.\"\"\" # @param {type:\"string\"}\n",
        "TOPIC_SENTENCE = \"Presenting real data on the emigration of professionals from the country and the decrease in emotional solidarity of migrants and professionals moving out of Iran, due to new migration conditions and becoming involved in various new problems, would be essential.\" # @param {type:\"string\"}\n",
        "LANGUAGE = 'Persian' # @param {type:\"string\"}\n",
        "ABSTRACT_PARAGRAPH = \"The analysts should present realistic data on the impact of professionals leaving the country and the decrease in emotional solidarity of migrants and professionals moving out of Iran, due to new migration conditions and becoming involved in various new problems.\" # @param {type:\"string\"}\n",
        "BIBLIOGRAPHY = '' # @param {type:\"string\"}\n",
        "THEORY1 = 'Realistic Data Presentation' # @param {type:\"string\"}\n",
        "THEORY2 = 'Emotional Solidarity Decline' # @param {type:\"string\"}\n",
        "RESEARCH_QUESTIONS = ['What is the current state of the dark future of Iran?', 'How does the lack of a clear vision impact the people?' , 'What are the potential benefits of presenting a clear vision of a bright future?'] # @param {type:\"list\"}\n",
        "ACTION = 'Communicate the truth to the people' # @param {type:\"string\"}\n",
        "RESULT_PARAGRAPHS = \"Presenting real data on the emigration of professionals from the country and the decrease in emotional solidarity of migrants and professionals moving out of Iran, due to new migration conditions and becoming involved in various new problems, would be essential.\" # @param {type:\"string\"}\n",
        "DATE = 'December 26, 2023' # @param {type:\"string\"}\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = '1 year' # @param {type:\"string\"}\n",
        "role = 'Public Speaker' # @param {type:\"string\"}\n",
        "project_example = 'Communicating the truth to the people' # @param {type:\"string\"}context = 'The project aims to raise awareness about the dark future of Iran.' # @param {type:\"string\"}\n",
        "instruction = 'Develop a comprehensive project plan that includes objectives, business case, scope, timeline, stakeholders, and success metrics' # @param {type:\"string\"}\n",
        "output_format = 'Text format' # @param {type:\"string\"}\n",
        "specific_project_details = 'The project involves communicating the truth to the people about the dark future of Iran and encouraging them to act.' # @param {type:\"string\"}\n",
        "X = 'Realistic Data Presentation' # @param {type:\"string\"}\n",
        "project_manager = 'Public Speaking Department' # @param {type:\"string\"}\n",
        "report = 'Project Implementation Report' # @param {type:\"string\"}\n",
        "important_themes = 'Realistic Data Presentation, Emotional Solidarity Decline, Dark Future of Iran' # @param {type:\"string\"}\n",
        "project_name = \"Communicating the Truth About Iran's Future\" # @param {type:\"string\"}\n",
        "stakeholder = 'Public Speaking Department, Local Government, Residents' # @param {type:\"string\"}\n",
        "resistant_stakeholder = 'Organizations with vested interest in maintaining the status quo' # @param {type:\"string\"}\n",
        "task = 'Communicate the truth to the people' # @param {type:\"string\"}\n",
        "Your_Email = 'your_email@example.com' # @param {type:\"string\"}\n",
        "openai_api = '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' # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "zaXVIqqgF6bf"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOPIC = \"\"\"Dark Triad and its management through conversation and charity\"\"\"  # @param {type:\"string\"}\n",
        "RESEARCH_DOMAIN = \"\"\"Psychology\"\"\"  # @param {type:\"string\"}\n",
        "PARAGRAPH = \"The Dark Triad, which consists of Machiavellianism, narcissism, and psychopathy, has been the focus of various studies. One such study in 2023 pointed out that engaging in conversation and charitable work for four months can help manage these traits 1.  This finding is crucial as it emphasizes the need to focus on efforts like dialogue and charity. Brainstorming and implementing different methods can yield various ways to execute these efforts.  However, the trolling system effectively uses the dark factor or the core of darkness to instill the idea that others are worthless. This leads to a shift toward dialogue and charity, and once this idea is established in the mind of the moderator or the driver of this therapeutic path, the conversation turns into a self-centered game and devalues others.  If you notice, sometimes during the conversation, you feel that something has changed or you experience specific physical sensations in your body.  This part seems to be a function of the vulnerability and unconscious induction of the core of darkness and the trolling system. This process, which can be triggered by trauma or other factors, resembles hypnotism. It turns people into the unconscious dark and halts the process of conversation and charity to some extent.  I have previously discussed studies and close conceptual views of the Dark Triad model on many occasions. This hypothesis is based on Richard Dawkins' view of the memetic code and the assumption of a type of conceptual life, memplex, related to the Dark and Light Triad in the human species, and the strengthening of conceptual life through the study of the vulnerability of light features against the Dark Triad in the human species.  I have even prepared some initial model articles with new codes, which I will send you later 1.  However, I think it's important to discuss it, and if there's no chance, we can have the conversation offline and orally\"  # @param {type:\"string\"}\n",
        "PARAGRAPHS = \"The Dark Triad, which consists of Machiavellianism, narcissism, and psychopathy, has been the focus of various studies. One such study in 2023 pointed out that engaging in conversation and charitable work for four months can help manage these traits 1.  This finding is crucial as it emphasizes the need to focus on efforts like dialogue and charity. Brainstorming and implementing different methods can yield various ways to execute these efforts.  However, the trolling system effectively uses the dark factor or the core of darkness to instill the idea that others are worthless. This leads to a shift toward dialogue and charity, and once this idea is established in the mind of the moderator or the driver of this therapeutic path, the conversation turns into a self-centered game and devalues others.  If you notice, sometimes during the conversation, you feel that something has changed or you experience specific physical sensations in your body.  This part seems to be a function of the vulnerability and unconscious induction of the core of darkness and the trolling system. This process, which can be triggered by trauma or other factors, resembles hypnotism. It turns people into the unconscious dark and halts the process of conversation and charity to some extent.  I have previously discussed studies and close conceptual views of the Dark Triad model on many occasions. This hypothesis is based on Richard Dawkins' view of the memetic code and the assumption of a type of conceptual life, memplex, related to the Dark and Light Triad in the human species, and the strengthening of conceptual life through the study of the vulnerability of light features against the Dark Triad in the human species.  I have even prepared some initial model articles with new codes, which I will send you later 1.  However, I think it's important to discuss it, and if there's no chance, we can have the conversation offline and orally\"  # @param {type:\"string\"}\n",
        "TOPIC_SENTENCE = \"\"\"The Dark Triad, which consists of Machiavellianism, narcissism, and psychopathy, has been the focus of various studies.\"\"\"  # @param {type:\"string\"}\n",
        "LANGUAGE = \"\"\"English\"\"\"  # @param {type:\"string\"}\n",
        "ABSTRACT_PARAGRAPH = \"\"\"This study explores the management of Dark Triad traits through engagement in conversation and charitable work...\"\"\"  # @param {type:\"string\"}\n",
        "BIBLIOGRAPHY = \"\"\"Source 0: https://www.psychologytoday.com/intl/blog/experimentations/202203/surprising-way-reduce-dark-triad-traits\"\"\"  # @param {type:\"string\"}\n",
        "THEORY1 = \"\"\"Dark Triad theory\"\"\"  # @param {type:\"string\"}\n",
        "THEORY2 = \"\"\"Conceptual life theory\"\"\"  # @param {type:\"string\"}\n",
        "RESEARCH_QUESTIONS = \"\"\"['How does engaging in conversation and charitable work help manage Dark Triad traits?', 'How does the trolling system use the dark factor to instill the idea that others are worthless?']\"\"\"  # @param {type:\"string\"}\n",
        "ACTION = \"\"\"Study and discussion\"\"\"  # @param {type:\"string\"}\n",
        "RESULT_PARAGRAPHS = \"\"\"Results indicate that engaging in conversation and charitable work for four months can help manage these traits...\"\"\"  # @param {type:\"string\"}\n",
        "DATE = \"\"\"2023-12-24\"\"\"  # @param {type:\"string\"}\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"\"\"Four months\"\"\"  # @param {type:\"string\"}\n",
        "role = \"\"\"Researcher\"\"\"  # @param {type:\"string\"}\n",
        "project_example = \"\"\"Dark Triad study\"\"\"  # @param {type:\"string\"}\n",
        "context = \"\"\"Psychological research\"\"\"  # @param {type:\"string\"}\n",
        "instruction = \"\"\"Study the Dark Triad and its management\"\"\"  # @param {type:\"string\"}\n",
        "output_format = \"\"\"Report\"\"\"  # @param {type:\"string\"}\n",
        "specific_project_details = \"\"\"The focus of this project is to study the Dark Triad...\"\"\"  # @param {type:\"string\"}\n",
        "X = \"\"\"Dark Triad traits\"\"\"  # @param {type:\"string\"}\n",
        "project_manager = \"\"\"Your Name\"\"\"  # @param {type:\"string\"}\n",
        "report = \"\"\"Detailed report on the Dark Triad study\"\"\"  # @param {type:\"string\"}\n",
        "important_themes = \"\"\"Dark Triad, conversation, charity, trolling system\"\"\"  # @param {type:\"string\"}\n",
        "project_name = \"\"\"Dark Triad Management Study\"\"\"  # @param {type:\"string\"}\n",
        "stakeholder = \"\"\"Psychologists, researchers\"\"\"  # @param {type:\"string\"}\n",
        "resistant_stakeholder = \"\"\"N/A\"\"\"  # @param {type:\"string\"}\n",
        "task = \"\"\"Generate a report on Dark Triad traits and their management\"\"\"  # @param {type:\"string\"}\n",
        "Your_Email = \"\"\"your.email@example.com\"\"\"  # @param {type:\"string\"}\n",
        "openai_api = \"sk-proj-a9B9H26hPUsTPAHxuX6OT3BlbkFJ59AFOXsXoDvmZLKT686Q\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "lO_FyYwXfGuK"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOPIC = \"Debate Resolution Skills: Iran's Opposition Problem\"\n",
        "RESEARCH_DOMAIN = \"Political Science\"\n",
        "PARAGRAPH = \"Resolving political debates is a critical skill in today's world. This course aims to equip students with the necessary tools and knowledge to navigate and influence these discussions.\"\n",
        "PARAGRAPHS = PARAGRAPH\n",
        "TOPIC_SENTENCE = \"Effective debate resolution is a fundamental aspect of political science.\"\n",
        "LANGUAGE = \"English\"\n",
        "ABSTRACT_PARAGRAPH = \"This course explores the techniques and strategies of effective debate resolution...\"\n",
        "BIBLIOGRAPHY = \"Source 0: https://www.thegreatcourses.com/courses/the-art-of-debate\"\n",
        "THEORY1 = \"Argument Structure Theory\"\n",
        "THEORY2 = \"Conflict Resolution Theory\"\n",
        "RESEARCH_QUESTIONS = \"['What are the key components of an effective debate?', 'How can different strategies contribute to a constructive debate resolution?']\"\n",
        "ACTION = \"Research and discussion\"\n",
        "RESULT_PARAGRAPHS = \"Results indicate that understanding these theories can significantly enhance debate resolution skills...\"\n",
        "DATE = \"2023-12-24\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"One year\"\n",
        "ROLE = \"Debate Coach\"\n",
        "PROJECT_EXAMPLE = \"Mock Debate Practice\"\n",
        "CONTEXT = \"Political Discussion\"\n",
        "INSTRUCTION = \"Study and practice debate resolution techniques\"\n",
        "OUTPUT_FORMAT = \"Report\"\n",
        "SPECIFIC_PROJECT_DETAILS = \"The focus of this project is to study debate resolution techniques and develop strategies for effective participation in debates...\"\n",
        "X = \"Debate Resolution Techniques\"\n",
        "PROJECT_MANAGER = \"Your Name\"\n",
        "REPORT = \"Detailed report on debate resolution techniques\"\n",
        "IMPORTANT_THEMES = \"Debate Resolution, Political Science\"\n",
        "PROJECT_NAME = \"Debate Resolution Study\"\n",
        "STAKEHOLDER = \"Political Scientists, Debate Participants\"\n",
        "RESISTANT_STAKEHOLDER = \"N/A\"\n",
        "TASK = \"Generate a report on debate resolution techniques\"\n",
        "YOUR_EMAIL = \"your.email@example.com\"\n",
        "OPENAI_API = openai_api # \"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\""
      ],
      "metadata": {
        "id": "Bnv3Qt4-A_4x"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOPIC = \"Climate Change Management\"\n",
        "RESEARCH_DOMAIN = \"Environmental Science\"\n",
        "PARAGRAPH = \"Climate change is a pressing issue that requires immediate attention. Engaging in research and charitable work in this field can help mitigate its effects. This course aims to equip students with the necessary tools and knowledge to address this global challenge.\"\n",
        "PARAGRAPHS = PARAGRAPH\n",
        "TOPIC_SENTENCE = \"Understanding and managing climate change is a critical aspect of environmental science.\"\n",
        "LANGUAGE = \"English\"\n",
        "ABSTRACT_PARAGRAPH = \"This course explores the management of climate change through engagement in research and charitable work...\"\n",
        "BIBLIOGRAPHY = \"Source 0: https://toolkit.climate.gov/courses/online-training-water-utilities-wuca\"\n",
        "THEORY1 = \"Climate Change Theory\"\n",
        "THEORY2 = \"Adaptive Management Theory\"\n",
        "RESEARCH_QUESTIONS = \"['What are the primary causes of climate change?', 'How can research and charitable work help mitigate the effects of climate change?']\"\n",
        "ACTION = \"Research and discussion\"\n",
        "RESULT_PARAGRAPHS = \"Results indicate that engaging in research and charitable work can significantly reduce the impacts of climate change...\"\n",
        "DATE = \"2023-12-24\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"One year\"\n",
        "ROLE = \"Researcher\"\n",
        "PROJECT_EXAMPLE = \"Climate Change Mitigation Research\"\n",
        "CONTEXT = \"Environmental Research\"\n",
        "INSTRUCTION = \"Study and research on climate change and its management\"\n",
        "OUTPUT_FORMAT = \"Report\"\n",
        "SPECIFIC_PROJECT_DETAILS = \"The focus of this project is to study climate change and develop strategies for its management...\"\n",
        "X = \"Climate Change Impacts\"\n",
        "PROJECT_MANAGER = \"Your Name\"\n",
        "REPORT = \"Detailed report on climate change research\"\n",
        "IMPORTANT_THEMES = \"Climate Change, Research, Charitable Work\"\n",
        "PROJECT_NAME = \"Climate Change Management Study\"\n",
        "STAKEHOLDER = \"Environmental Scientists, Researchers\"\n",
        "RESISTANT_STAKEHOLDER = \"N/A\"\n",
        "TASK = \"Generate a report on climate change and its management\"\n",
        "YOUR_EMAIL = \"your.email@example.com\"\n",
        "OPENAI_API = openai_api # \"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\""
      ],
      "metadata": {
        "id": "AeQuhZPG1tpu"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "role = TOPIC_SENTENCE\n",
        "project_example = PROJECT_EXAMPLE\n",
        "context = CONTEXT\n",
        "instruction = INSTRUCTION\n",
        "specific_project_details = SPECIFIC_PROJECT_DETAILS\n",
        "project_manager = PROJECT_MANAGER\n",
        "report = REPORT\n",
        "important_themes = IMPORTANT_THEMES\n",
        "stakeholder = STAKEHOLDER\n",
        "resistant_stakeholder = RESISTANT_STAKEHOLDER\n",
        "openai_api= OPENAI_API\n",
        "Your_Email = YOUR_EMAIL"
      ],
      "metadata": {
        "id": "xYSJlwzt2stD"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# https://www.phind.com/search?cache=wxdy3gybzifxrthxith847he # @ param{string}\n",
        "\n",
        "employability = \"Prepare students for employment in fields such as renewable energy, energy efficiency, natural resource conservation, and waste management.\"\n",
        "practical_skills = \"Develop practical skills in sustainability by focusing on the social, economic, and environmental concepts that can be applied across a wide range of sectors and industries.\"\n",
        "creativity = \"Encourage creative thinking and problem-solving in developing sustainable strategies for organizations.\"\n",
        "critical_thinking = \"Foster critical thinking among students in analyzing sustainability issues and formulating comprehensive solutions.\"\n",
        "fun_and_enjoyment = \"Make the course engaging with online lectures, discussions, and assignments, offering flexibility for students.\"\n",
        "employee_guarantee = \"Provide a guarantee for successful course completion by ensuring comprehensive coverage of key sustainability topics.\"\n",
        "collaboration = \"Encourage collaboration among students in online forums and group projects.\"\n",
        "learning_outcomes = \"By the end of the course, students should be able to communicate complex social, economic, and environmental issues, analyze evidence to formulate sustainable strategies, and lead sustainability initiatives at local, national, and global levels.\"\n",
        "purpose = \"The purpose of this course is to equip students with the knowledge and skills necessary to advance their career in sustainability.\"\n",
        "learning_activities = \"Activities will include online lectures, discussions, assignments, and a capstone project where students help a real organization solve an existing sustainability problem by implementing practical knowledge to achieve a triple-bottom-line solution.\"\n",
        "course_content = \"The main topics covered in the course will include the relationship of humans with the natural environment, public policy and the role of government and business in sustainability, triple bottom line accounting, and climate change.\"\n",
        "course_assessments = \"Student performance will be evaluated through assignments, group projects, and a capstone project.\"\n",
        "course_schedule = \"The course is delivered online and students can do homework whenever it’s convenient for them. The program also provides optional networking opportunities for students to connect virtually with peers, faculty, and professionals.\"\n",
        "course_sequencing = \"The course content will be sequenced to gradually increase in complexity, starting with an introduction to sustainability, moving on to more advanced topics, and ending with a capstone project.\"\n",
        "technology_requirements = \"Students will need access to a computer with internet connectivity. If software or special technology is required in one of the courses, it will be provided to students.\"\n",
        "prerequisites = \"A Bachelor’s degree, in any discipline, from an accredited university (min. 3.0 GPA) is required. Students with a GPA of less than 3.0 may be considered for provisional admission.\"\n",
        "\n",
        "topic = \"Sustainable Management\"\n",
        "field_of_study = \"Sustainability\"\n",
        "audience = \"Those seeking to advance their career in sustainability, whether their experience is in business, healthcare, manufacturing, design, retail, or other industries that are transitioning to sustainable business models.\"\n",
        "specific_project = \"A capstone project where each student will help a real organization solve an existing sustainability problem by implementing practical knowledge to achieve a triple-bottom-line solution.\""
      ],
      "metadata": {
        "id": "wyCrOA5IgoKg"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employability = \"Prepare students for employment in fields such as political science, journalism, human rights advocacy, and conflict resolution.\"\n",
        "practical_skills = \"Develop practical skills in debate resolution by focusing on the social, cultural, and political concepts that can be applied in various contexts.\"\n",
        "creativity = \"Encourage creative thinking and problem-solving in developing effective strategies for debates.\"\n",
        "critical_thinking = \"Foster critical thinking among students in analyzing political and societal issues and formulating comprehensive solutions.\"\n",
        "fun_and_enjoyment = \"Make the course engaging with online lectures, discussions, and assignments, offering flexibility for students.\"\n",
        "employee_guarantee = \"Provide a guarantee for successful course completion by ensuring comprehensive coverage of key debate resolution topics.\"\n",
        "collaboration = \"Encourage collaboration among students in online forums and group projects.\"\n",
        "learning_outcomes = \"By the end of the course, students should be able to articulate complex political, cultural, and societal issues, analyze evidence to formulate effective debate strategies, and lead debates on local, national, and global levels.\"\n",
        "purpose = \"The purpose of this course is to equip students with the knowledge and skills necessary to advance their career in debate resolution.\"\n",
        "learning_activities = \"Activities will include online lectures, discussions, assignments, and a capstone project where students participate in a mock debate.\"\n",
        "course_content = \"The main topics covered in the course will include the history of Iran, the concept of opposition, the role of Islamofascism, mafia, capitalism, and dark international forces like Russia in Iran, and the challenges faced by light groups.\"\n",
        "course_assessments = \"Student performance will be evaluated through assignments, group projects, and a capstone project.\"\n",
        "course_schedule = \"The course is delivered online and students can do homework whenever it’s convenient for them. The program also provides optional networking opportunities for students to connect virtually with peers, faculty, and professionals.\"\n",
        "course_sequencing = \"The course content will be sequenced to gradually increase in complexity, starting with an introduction to Iran, moving on to more advanced topics, and ending with a capstone project.\"\n",
        "technology_requirements = \"Students will need access to a computer with internet connectivity. If software or special technology is required in one of the courses, it will be provided to students.\"\n",
        "prerequisites = \"A Bachelor’s degree, in any discipline, from an accredited university (min. 3.0 GPA) is required. Students with a GPA of less than 3.0 may be considered for provisional admission.\"\n",
        "\n",
        "topic = \"Iran's Opposition Problem\"\n",
        "field_of_study = \"Debate Resolution\"\n",
        "audience = \"Those seeking to advance their career in debate resolution, whether their experience is in politics, journalism, human rights, or any field that requires effective communication and conflict resolution.\"\n",
        "specific_project = \"A capstone project where each student will participate in a mock debate on a real-life issue related to Iran's opposition problem.\""
      ],
      "metadata": {
        "id": "lI4NEx9MA1eX"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "employability = \"Prepare students for employment in fields such as renewable energy, energy efficiency, natural resource conservation, and waste management.\"  # @param {type:\"string\"}\n",
        "practical_skills = \"Develop practical skills in sustainability by focusing on the social, economic, and environmental concepts that can be applied across a wide range of sectors and industries.\"  # @param {type:\"string\"}\n",
        "creativity = \"Encourage creative thinking and problem-solving in developing sustainable strategies for organizations.\"  # @param {type:\"string\"}\n",
        "critical_thinking = \"Foster critical thinking among students in analyzing sustainability issues and formulating comprehensive solutions.\"  # @param {type:\"string\"}\n",
        "fun_and_enjoyment = \"Make the course engaging with online lectures, discussions, and assignments, offering flexibility for students.\"  # @param {type:\"string\"}\n",
        "employee_guarantee = \"Provide a guarantee for successful course completion by ensuring comprehensive coverage of key sustainability topics.\"  # @param {type:\"string\"}\n",
        "collaboration = \"Encourage collaboration among students in online forums and group projects.\"  # @param {type:\"string\"}\n",
        "learning_outcomes = \"By the end of the course, students should be able to communicate complex social, economic, and environmental issues, analyze evidence to formulate sustainable strategies, and lead sustainability initiatives at local, national, and global levels.\"  # @param {type:\"string\"}\n",
        "purpose = \"The purpose of this course is to equip students with the knowledge and skills necessary to advance their career in sustainability.\"  # @param {type:\"string\"}\n",
        "learning_activities = \"Activities will include online lectures, discussions, assignments, and a capstone project where students help a real organization solve an existing sustainability problem.\"  # @param {type:\"string\"}\n",
        "course_content = \"The main topics covered in the course will include the relationship of humans with the natural environment, public policy and the role of government and business in sustainability, triple bottom line accounting, and climate change.\"  # @param {type:\"string\"}\n",
        "course_assessments = \"Student performance will be evaluated through assignments, group projects, and a capstone project.\"  # @param {type:\"string\"}\n",
        "course_schedule = \"The course is delivered online and students can do homework whenever it’s convenient for them. The program also provides optional networking opportunities for students to connect virtually with peers, faculty, and professionals.\"  # @param {type:\"string\"}\n",
        "course_sequencing = \"The course content will be sequenced to gradually increase in complexity, starting with an introduction to sustainability, moving on to more advanced topics, and ending with a capstone project.\"  # @param {type:\"string\"}\n",
        "technology_requirements = \"Students will need access to a computer with internet connectivity. If software or special technology is required in one of the courses, it will be provided to students.\"  # @param {type:\"string\"}\n",
        "prerequisites = \"A Bachelor’s degree, in any discipline, from an accredited university (min. 3.0 GPA) is required. Students with a GPA of less than 3.0 may be considered for provisional admission.\"  # @param {type:\"string\"}\n",
        "\n",
        "topic = TOPIC\n",
        "field_of_study = \"Sustainability\"  # @param {type:\"string\"}\n",
        "audience = \"Those seeking to advance their career in sustainability, whether their experience is in business, healthcare, manufacturing, design, retail, or other industries that are transitioning to sustainable business models.\"  # @param {type:\"string\"}\n",
        "specific_project = \"A capstone project where each student will help a real organization solve an existing sustainability problem by implementing practical knowledge to achieve a triple-bottom-line solution.\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "0pWuC5pxgKL2"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.phind.com/search?cache=wxdy3gybzifxrthxith847he"
      ],
      "metadata": {
        "id": "esoER7X3Vgmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Empowering Women in Cinema: The AI Revolution\"\n",
        "research_domain = \"Media Studies\"\n",
        "paragraph = \"Understanding the target audience, utilizing AI technology, collaborating with women filmmakers, creating a safe and supportive community, promoting diverse voices and perspectives, providing resources and opportunities, addressing gender inequality and discrimination, engaging with the audience, collaborating with other platforms and organizations, and demonstrating consistency and perseverance are key aspects of creating a successful YouTube channel for empowering women in cinema.\"\n",
        "paragraphs = paragraph\n",
        "topic_sentence = \"Creating a successful YouTube channel for empowering women in cinema is a crucial aspect of promoting gender equality in the film industry.\"\n",
        "language = \"English\"\n",
        "abstract_paragraph = \"This business pack explores the creation of a successful YouTube channel for empowering women in cinema, focusing on understanding the target audience, utilizing AI technology, collaborating with women filmmakers, creating a safe and supportive community, promoting diverse voices and perspectives, providing resources and opportunities, addressing gender inequality and discrimination, engaging with the audience, collaborating with other platforms and organizations, and demonstrating consistency and perseverance.\"\n",
        "bibliography = \"Source 1: https://blog.youtube.com/creator-and-artist-stories/how-5-women-are-using-their-channels-to-empower-and-inspire/, Source 2: https://www.theverge.com/2016/3/2/11146140/youtube-launches-two-initiatives-support-female-filmmakers, Source 3: https://blog.promolta.com/how-to-pitch-your-youtube-channel-to-brands/\"\n",
        "theory1 = \"YouTube Channel Theory\"\n",
        "theory2 = \"AI in Media Theory\"\n",
        "research_questions = \"['What are the key aspects of a successful YouTube channel for empowering women in cinema?', 'How can AI technology be utilized to create engaging and relevant content for such a channel?']\"\n",
        "action = \"Research and discussion\"\n",
        "result_paragraphs = \"Results indicate that understanding the target audience, utilizing AI technology, collaborating with women filmmakers, creating a safe and supportive community, promoting diverse voices and perspectives, providing resources and opportunities, addressing gender inequality and discrimination, engaging with the audience, collaborating with other platforms and organizations, and demonstrating consistency and perseverance can significantly enhance the success of a YouTube channel for empowering women in cinema.\"\n",
        "date = \"2023-12-24\"\n",
        "number_of_days_months_years = \"One year\"\n",
        "role = \"Researcher\"\n",
        "project_example = \"Creating a Successful YouTube Channel for Empowering Women in Cinema\"\n",
        "context = \"Media Studies\"\n",
        "instruction = \"Study and research on the creation of a successful YouTube channel for empowering women in cinema\"\n",
        "output_format = \"Business Pack\"\n",
        "specific_project_details = \"The focus of this project is to study the creation of a successful YouTube channel for empowering women in cinema and develop strategies for its success...\"\n",
        "x = \"Key Aspects of a Successful YouTube Channel\"\n",
        "project_manager = \"Your Name\"\n",
        "report = \"Detailed business pack on the creation of a successful YouTube channel for empowering women in cinema\"\n",
        "important_themes = \"YouTube Channel, Empowering Women in Cinema, AI Technology\"\n",
        "project_name = \"Successful YouTube Channel for Empowering Women in Cinema\"\n",
        "stakeholder = \"Filmmakers, AI Technologists, YouTube Channel Managers\"\n",
        "resistant_stakeholder = \"N/A\"\n",
        "task = \"Create a business pack on the creation of a successful YouTube channel for empowering women in cinema\"\n",
        "your_email = \"your.email@example.com\"\n",
        "openai_api = openai_api # \"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\"\n",
        "\n",
        "\n",
        "employability = \"Prepare students for employment in the film industry, particularly in roles related to empowering women in cinema and leveraging AI technology.\"\n",
        "practical_skills = \"Develop practical skills in understanding target audiences, utilizing AI technology, collaborating with women filmmakers, creating a safe and supportive community, promoting diverse voices and perspectives, providing resources and opportunities, addressing gender inequality and discrimination, engaging with the audience, collaborating with other platforms and organizations, and demonstrating consistency and perseverance.\"\n",
        "creativity = \"Encourage creative thinking and problem-solving in developing innovative AI applications for filmmaking, promoting gender equality in the film industry, and creating engaging content that resonates with the target audience.\"\n",
        "critical_thinking = \"Foster critical thinking among students in analyzing the role of AI in filmmaking, the impact of gender inequality and discrimination in the film industry, and the effectiveness of different strategies in promoting gender equality and empowering women in cinema.\"\n",
        "fun_and_enjoyment = \"Make the course engaging with video discussions, group projects, virtual screenings of films featuring AI, and interactive activities that mimic the process of creating and promoting a film.\"\n",
        "employee_guarantee = \"Provide a guarantee for successful course completion by ensuring comprehensive coverage of key topics and hands-on experience in using AI in filmmaking, promoting gender equality in the film industry, and creating engaging content for the target audience.\"\n",
        "collaboration = \"Encourage collaboration among students in working on group projects, participating in interdisciplinary discussions, and collaborating with other platforms and organizations to reach a wider audience and promote the cause of empowering women in cinema.\"\n",
        "learning_outcomes = \"By the end of the course, students should be able to understand the role of AI in modern filmmaking, promote gender equality in the film industry, create engaging content that resonates with the target audience, and apply their knowledge in real-world scenarios.\"\n",
        "purpose = \"The purpose of this course is to equip students with the knowledge and skills necessary to contribute to the AI revolution in filmmaking and promote gender equality in the film industry.\"\n",
        "learning_activities = \"Activities will include video discussions, group projects, virtual screenings of films featuring AI, and interactive activities that mimic the process of creating and promoting a film.\"\n",
        "course_content = \"The main topics covered in the course will include understanding the target audience, utilizing AI technology, collaborating with women filmmakers, creating a safe and supportive community, promoting diverse voices and perspectives, providing resources and opportunities, addressing gender inequality and discrimination, engaging with the audience, collaborating with other platforms and organizations, and demonstrating consistency and perseverance.\"\n",
        "course_assessments = \"Student performance will be evaluated through assignments, group projects, presentations, and a capstone project where students create a short film using AI and promote gender equality.\"\n",
        "course_schedule = \"The course will be delivered online and will run for 12 weeks.\"\n",
        "course_sequencing = \"The course content will be sequenced to gradually increase in complexity, starting with an introduction to AI in filmmaking, moving on to more advanced topics, and ending with a capstone project.\"\n",
        "technology_requirements = \"Students will need access to a computer with internet connectivity, as well as software for video editing and presentation creation.\"\n",
        "prerequisites = \"Prior knowledge of basic scientific concepts and a willingness to engage actively in course activities are required.\"\n",
        "\n",
        "topic = \"AI in Film Production and Gender Equality\"\n",
        "field_of_study = \"Film Studies\"\n",
        "audience = \"Students interested in the intersection of AI and gender equality in the film industry\"\n",
        "specific_project = \"Capstone project on creating a short film using AI and promoting gender equality\""
      ],
      "metadata": {
        "id": "rKZCAlxLU6Jh"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOPIC = \"Unmasking Medical Fraud: The Case of Dr. Hessieni Hoshiar and the Betrayal of Trust Through Misdiagnosis and Denial of Effective Treatments\"\n",
        "RESEARCH_DOMAIN = \"Medical Ethics and Patient Care\"\n",
        "PARAGRAPH = \"\"\"\n",
        "In the complex landscape of medical ethics, the case of Dr. Hessieni Hoshiar illuminates the devastating consequences of medical fraud and misdiagnosis, particularly in the context of treating schizophrenia. This narrative unfolds through a recorded treatment session, revealing a pattern of professional misconduct that extends beyond mere misdiagnosis to include the denial of effective treatments and the infliction of unnecessary harm on patients and their families. A critical juncture in the case is captured in a recorded treatment session, where Dr. Hessieni Hoshiar pressures the patient to continue taking medication prescribed for schizophrenia despite the patient's expressed preference for Cognitive Behavioral Therapy (CBT). The patient, having ingested the prescribed medication for several years without experiencing any beneficial outcomes, advocates for CBT—a treatment modality scientifically validated for reducing anxiety and improving outcomes in schizophrenia patients. However, Dr. Hoshiar dismisses CBT as ineffective, asserting that it should not be considered a viable treatment option for schizophrenia. Contrary to Dr. Hoshiar's assertions, the Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition (DSM-5) suggests that CBT can be an effective treatment for schizophrenia, especially when traditional medications are not accepted or tolerated by the patient. The manual outlines strategies for engaging patients who may resist medication, including the use of CBT to build trust and reduce anxiety. The ethical failure becomes evident as the patient and their family challenge Dr. Hoshiar's diagnosis and treatment recommendations. The patient asserts that the diagnosis of schizophrenia was incorrect and that the cessation of CBT represents a deliberate attempt by Dr. Hoshiar to cause harm. This assertion is grounded in the belief that Dr. Hoshiar's actions reflect a disregard for patient welfare and a sadistic inclination to inflict pain and distress on the patient and their family, constituting a clear act of medical fraud. The case underscores the urgent need for accountability within the medical profession and the establishment of robust oversight mechanisms to prevent such misconduct. It highlights the importance of adhering to ethical standards and prioritizing patient welfare over personal preferences or convenience. Furthermore, it emphasizes the necessity of legal protections for patients against medical misconduct and the importance of educating healthcare professionals about the latest scientific advancements in mental health treatment. The case serves as a stark reminder of the human cost of medical fraud and the devastating impact of misdiagnosis on patients' lives. It calls for a reevaluation of the standards and practices within the medical profession, emphasizing the necessity of integrity, transparency, and compassion in patient care. Through this case, we hope to shed light on the critical need for vigilance and action against medical misconduct, advocating for justice and reform in healthcare.\n",
        "\"\"\"\n",
        "\n",
        "PARAGRAPHS = \"\"\"\n",
        "A critical juncture in the case is captured in a recorded treatment session, where Dr. Hessieni Hoshiar pressures the patient to continue taking medication prescribed for schizophrenia despite the patient's expressed preference for Cognitive Behavioral Therapy (CBT). The patient, having ingested the prescribed medication for several years without experiencing any beneficial outcomes, advocates for CBT—a treatment modality scientifically validated for reducing anxiety and improving outcomes in schizophrenia patients. However, Dr. Hoshiar dismisses CBT as ineffective, asserting that it should not be considered a viable treatment option for schizophrenia.\n",
        "\"\"\"\n",
        "TOPIC_SENTENCE = \"The focus is on understanding the devastating consequences of medical fraud and misdiagnosis through the case of Dr. Hessieni Hoshiar, particularly in treating schizophrenia.\"\n",
        "LANGUAGE = \"English\"\n",
        "ABSTRACT_PARAGRAPH = \"This study explores the case of Dr. Hessieni Hoshiar, highlighting the consequences of medical fraud and misdiagnosis in treating schizophrenia, emphasizing the need for ethical accountability and patient-centered care.\"\n",
        "BIBLIOGRAPHY = \"Refer to the Phind search results for more details on the consequences of medical fraud and misdiagnosis in treating schizophrenia.\"\n",
        "THEORY1 = \"Medical Ethics\"\n",
        "THEORY2 = \"Patient Care\"\n",
        "RESEARCH_QUESTIONS = [\n",
        "    \"What are the ethical implications of misdiagnosis and denial of effective treatments in medical practice?\",\n",
        "    \"How can healthcare systems ensure accountability and prevent medical fraud?\"\n",
        "]\n",
        "ACTION = \"Develop strategies for healthcare systems to ensure accountability and prevent medical fraud, promoting ethical patient care.\"\n",
        "RESULT_PARAGRAPHS = \"The investigation into Dr. Hessieni Hoshiar's case reveals a need for robust oversight mechanisms and ethical standards in the medical profession to prevent misdiagnosis and denial of effective treatments.\"\n",
        "DATE = \"March 14, 2024\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"3 months\"\n",
        "ROLE = \"Medical Ethics Advocate\"\n",
        "PROJECT_EXAMPLE = \"Development of guidelines for ethical patient care and accountability in medical practice\"\n",
        "CONTEXT = \"Medical Ethics and Patient Care\"\n",
        "INSTRUCTION = \"Conduct research on the ethical implications of misdiagnosis and denial of effective treatments in medical practice, and propose solutions.\"\n",
        "OUTPUT_FORMAT = \"Research Report\"\n",
        "SPECIFIC_PROJECT_DETAILS = \"A study on understanding and preventing medical fraud and misdiagnosis in treating schizophrenia.\"\n",
        "X = \"Number of actionable recommendations\"\n",
        "PROJECT_MANAGER = \"Medical Ethics Advocate's Name\"\n",
        "REPORT = \"Report on Medical Fraud and Misdiagnosis in Treating Schizophrenia\"\n",
        "IMPORTANT_THEMES = \"Medical Ethics, Patient Care, Accountability\"\n",
        "PROJECT_NAME = \"Study on Medical Fraud and Misdiagnosis in Treating Schizophrenia\"\n",
        "STAKEHOLDER = \"Patients, Healthcare Providers, Regulatory Bodies\"\n",
        "RESISTANT_STAKEHOLDER = \"Practitioners with outdated or unethical practices\"\n",
        "TASK = \"Research and document the ethical implications of misdiagnosis and denial of effective treatments in medical practice\"\n",
        "YOUR_EMAIL = \"your.email@example.com\"\n",
        "OPENAI_API = None\n",
        "\n",
        "employability = \"Researching and documenting the ethical implications of misdiagnosis and denial of effective treatments in medical practice\"\n",
        "practical_skills = \"Data analysis, Ethical assessment\"\n",
        "creativity = \"Identifying innovative solutions for preventing medical fraud and misdiagnosis\"\n",
        "critical_thinking = \"Evaluating the impact of medical practices on patient care and safety\"\n",
        "fun_and_enjoyment = \"Exploring the intersection of ethics and healthcare\"\n",
        "employee_guarantee = \"A commitment to thorough research and accurate documentation\"\n",
        "collaboration = \"Working with experts in medical ethics and patient care\"\n",
        "learning_outcomes = \"Understanding the role of ethics in healthcare and patient safety\"\n",
        "purpose = \"To inform and inspire ethical and patient-centered practices in healthcare\"\n",
        "learning_activities = \"Researching medical ethics issues, Attending conferences on patient care\"\n",
        "course_content = \"Medical ethics theories, Case studies of medical misconduct, Strategies for ethical patient care\"\n",
        "course_assessments = \"Writing assignments on ethical practices, Presentations on case studies\"\n",
        "course_schedule = \"Bi-weekly online sessions\"\n",
        "course_sequencing = \"Introduction to medical ethics, Case studies, Strategies for ethical care\"\n",
        "technology_requirements = \"Access to research databases, Internet access\"\n",
        "prerequisites = \"Basic understanding of medical ethics and patient care\"\n",
        "audience = \"Medical Ethics Advocates, Healthcare Providers, Policy Makers\"\n",
        "topic = TOPIC\n",
        "field_of_study = RESEARCH_DOMAIN\n",
        "specific_project = PROJECT_NAME"
      ],
      "metadata": {
        "id": "iij7lZ3fnW-K"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOPIC = \"A Tale of Misdiagnosis and Medical Fraud: A Legal Battle Over Schizophrenia Diagnosis\"\n",
        "RESEARCH_DOMAIN = \"Medical Ethics and Legal Studies\"\n",
        "PARAGRAPH = \"\"\"\n",
        "In a case that has stirred controversy and raised questions about the integrity of the medical profession, a patient was initially diagnosed with deep depression by a primary healthcare provider. However, a subsequent diagnosis of schizophrenia by a second healthcare provider led to a court case. The patient alleges that the second diagnosis was fraudulent and caused significant problems. This post delves into the details of the legal proceedings, the arguments presented by the patient's lawyer, the evidence used to support the claim of medical fraud, and the outcome of the case.\n",
        "\n",
        "The case, while not directly mentioned in the provided search results, highlights the complexities of medical malpractice and the ethical dilemmas faced by healthcare providers and patients alike. The legal battle centered around the question of whether the patient's deep depression was misdiagnosed as schizophrenia, leading to a series of complications that the patient claims were the result of medical fraud.\n",
        "\n",
        "The patient's lawyer argued that the initial diagnosis of deep depression was accurate and that the subsequent diagnosis of schizophrenia was not only incorrect but also fraudulent. The evidence presented included medical records, expert testimonies, and the patient's personal accounts of the impact of the misdiagnosis on their life. The lawyer emphasized the importance of accurate diagnosis and informed consent, arguing that the patient's rights were violated when the diagnosis was changed without proper justification.\n",
        "\n",
        "The court's decision in this case underscores the critical role of psychiatric evidence in legal proceedings. As highlighted in the search results, the use of psychiatric evidence must be carefully considered to avoid misleading the jury or stigmatizing the plaintiff. The case also brought to light the potential for psychiatric evidence to be misused, as evidenced by the defense expert's testimony, which suggested that the plaintiff's mental illness could be used to question her credibility in the litigation.\n",
        "\n",
        "The outcome of the case serves as a reminder of the importance of ethical practice in the medical field and the potential consequences of misdiagnosis. It also highlights the need for patients to be vigilant in seeking accurate diagnoses and informed consent, as well as the critical role of legal representation in navigating the complexities of medical malpractice claims.\n",
        "\n",
        "This case not only illustrates the challenges faced by patients in the legal system but also raises broader questions about the ethical standards and practices within the medical profession. It underscores the importance of transparency, accuracy, and accountability in healthcare, ensuring that patients receive the care they need without the risk of harm or injustice.\n",
        "\"\"\"\n",
        "PARAGRAPHS = \"\"\"\n",
        "The case, while not directly mentioned in the provided search results, highlights the complexities of medical malpractice and the ethical dilemmas faced by healthcare providers and patients alike. The legal battle centered around the question of whether the patient's deep depression was misdiagnosed as schizophrenia, leading to a series of complications that the patient claims were the result of medical fraud.\n",
        "\"\"\"\n",
        "TOPIC_SENTENCE = \"The focus is on understanding the legal and ethical implications of a misdiagnosis and medical fraud case involving schizophrenia.\"\n",
        "LANGUAGE = \"English\"\n",
        "ABSTRACT_PARAGRAPH = \"This study explores the legal and ethical implications of a misdiagnosis case involving schizophrenia, highlighting the complexities of medical malpractice and the importance of accurate diagnosis and informed consent.\"\n",
        "BIBLIOGRAPHY = \"Refer to the Phind search results for more details on the legal and ethical implications of misdiagnosis and medical fraud cases.\"\n",
        "THEORY1 = \"Medical Ethics\"\n",
        "THEORY2 = \"Legal Accountability\"\n",
        "RESEARCH_QUESTIONS = [\n",
        "    \"What are the legal and ethical implications of a misdiagnosis case involving schizophrenia?\",\n",
        "    \"How can healthcare providers ensure accurate diagnosis and informed consent to prevent medical fraud?\"\n",
        "]\n",
        "ACTION = \"Develop guidelines for healthcare providers to ensure accurate diagnosis and informed consent to prevent medical fraud.\"\n",
        "RESULT_PARAGRAPHS = \"The investigation into the misdiagnosis and medical fraud case reveals the need for stringent ethical practices and legal accountability in the medical field.\"\n",
        "DATE = \"April 27, 2024\"\n",
        "NUMBER_OF_DAYS_MONTHS_YEARS = \"6 months\"\n",
        "ROLE = \"Medical Ethics Advocate\"\n",
        "PROJECT_EXAMPLE = \"Development of guidelines for preventing medical misdiagnosis and fraud\"\n",
        "CONTEXT = \"Medical Ethics and Legal Studies\"\n",
        "INSTRUCTION = \"Conduct research on the legal and ethical implications of misdiagnosis and medical fraud involving schizophrenia and propose solutions.\"\n",
        "OUTPUT_FORMAT = \"Research Report\"\n",
        "SPECIFIC_PROJECT_DETAILS = \"A study on understanding and preventing medical misdiagnosis and fraud involving schizophrenia.\"\n",
        "X = \"Number of actionable recommendations\"\n",
        "PROJECT_MANAGER = \"Medical Ethics Advocate's Name\"\n",
        "REPORT = \"Report on Legal and Ethical Implications of Misdiagnosis and Medical Fraud\"\n",
        "IMPORTANT_THEMES = \"Medical Ethics, Legal Accountability, Patient Rights\"\n",
        "PROJECT_NAME = \"Study on Misdiagnosis and Medical Fraud\"\n",
        "STAKEHOLDER = \"Patients, Healthcare Providers, Legal Professionals\"\n",
        "RESISTANT_STAKEHOLDER = \"Healthcare providers with outdated diagnostic practices\"\n",
        "TASK = \"Research and document the legal and ethical implications of misdiagnosis and medical fraud involving schizophrenia\"\n",
        "YOUR_EMAIL = \"your.email@example.com\"\n",
        "OPENAI_API = None\n",
        "\n",
        "# Additional variables\n",
        "employability = \"Researching and documenting the legal and ethical implications of misdiagnosis and medical fraud involving schizophrenia\"\n",
        "practical_skills = \"Data analysis, Legal research\"\n",
        "creativity = \"Identifying innovative solutions for preventing medical misdiagnosis and fraud\"\n",
        "critical_thinking = \"Evaluating the impact of medical practices on patient safety and legal outcomes\"\n",
        "fun_and_enjoyment = \"Exploring the intersection of medical ethics and law\"\n",
        "employee_guarantee = \"A commitment to thorough research and accurate documentation\"\n",
        "collaboration = \"Working with experts in medical ethics and legal studies\"\n",
        "learning_outcomes = \"Understanding the role of accurate diagnosis and informed consent in preventing medical fraud\"\n",
        "purpose = \"To inform and inspire ethical and legally accountable medical practices\"\n",
        "learning_activities = \"Researching medical ethics issues, Attending conferences on legal accountability in healthcare\"\n",
        "course_content = \"Medical ethics theories, Case studies of medical malpractice, Legal standards in healthcare\"\n",
        "course_assessments = \"Writing assignments on medical ethics practices, Presentations on case studies\"\n",
        "course_schedule = \"Bi-weekly online sessions\"\n",
        "course_sequencing = \"Introduction to medical ethics, Case studies, Legal standards in healthcare\"\n",
        "technology_requirements = \"Access to research databases, Internet access\"\n",
        "prerequisites = \"Basic understanding of medical ethics and legal studies\"\n",
        "audience = \"Medical Ethics Advocates, Healthcare Providers, Legal Professionals\"\n",
        "topic = TOPIC\n",
        "field_of_study = RESEARCH_DOMAIN\n",
        "specific_project = PROJECT_NAME"
      ],
      "metadata": {
        "id": "5ze9ohi_8-Ll"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "role = TOPIC_SENTENCE\n",
        "project_example = PROJECT_EXAMPLE\n",
        "context = CONTEXT\n",
        "instruction = INSTRUCTION\n",
        "specific_project_details = SPECIFIC_PROJECT_DETAILS\n",
        "project_manager = PROJECT_MANAGER\n",
        "report = REPORT\n",
        "important_themes = IMPORTANT_THEMES\n",
        "stakeholder = STAKEHOLDER\n",
        "resistant_stakeholder = RESISTANT_STAKEHOLDER\n",
        "#openai_api= OPENAI_API\n",
        "Your_Email = YOUR_EMAIL"
      ],
      "metadata": {
        "id": "qonmO7tTV4Fj"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "course_design_variables = {\n",
        "    \"employability\": f\"{employability}\",\n",
        "    \"practical_skills\": f\"{practical_skills}\",\n",
        "    \"creativity\": f\"{creativity}\",\n",
        "    \"critical_thinking\": f\"{critical_thinking}\",\n",
        "    \"fun_and_enjoyment\": f\"{fun_and_enjoyment}\",\n",
        "    \"employee_guarantee\": f\"{employee_guarantee}\",\n",
        "    \"collaboration\": f\"{collaboration}\",\n",
        "    \"learning_outcomes\": f\"{learning_outcomes}\",\n",
        "    \"purpose\": f\"{purpose}\",\n",
        "    \"learning_activities\": f\"{learning_activities}\",\n",
        "    \"course_content\": f\"{course_content}\",\n",
        "    \"course_assessments\": f\"{course_assessments}\",\n",
        "    \"course_schedule\": f\"{course_schedule}\",\n",
        "    \"course_sequencing\": f\"{course_sequencing}\",\n",
        "    \"technology_requirements\": f\"{technology_requirements}\",\n",
        "    \"prerequisites\": f\"{prerequisites}\",\n",
        "    \"topic\": f\"{topic}\",\n",
        "    \"field_of_study\": f\"{field_of_study}\",\n",
        "    \"audience\": f\"{audience}\",\n",
        "    \"specific_project\": f\"{specific_project}\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "prompt_course_old = [\n",
        "    f\" As ChatGPT expert in the role of course designing as {role}, suggest one Course Title in less than 15 words, based on This Topic :({TOPIC}) and the description:({PARAGRAPH}).\",\n",
        "\n",
        "    f\"Step 1: As ChatGPT {role} in course designing Identify Situational Factors for {course_design_variables['specific_project']} by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"1. As ChatGPT {role} in course designing Understand the broader context of the {course_design_variables['field_of_study']} course for {course_design_variables['audience']} by the topic of:((( {course_design_variables['topic']} ))  and description of course_design_variables['specific_project'] \",\n",
        "    f\"2. As ChatGPT {role} in course designing Consider factors such as department or discipline, institution expectations, and student backgrounds and needs. Also, consider {course_design_variables['employability']} by the topic of:((( {course_design_variables['topic']} )) of the  {course_design_variables['field_of_study']}  and description of course_design_variables['specific_project'] \",\n",
        "    f\"3. As ChatGPT {role} in course designing Tailor the course content according to these factors to meet the needs of {course_design_variables['audience']}. {course_design_variables['practical_skills']} by the topic of:((( {course_design_variables['topic']} )) and description of course_design_variables['specific_project'] \",\n",
        "    f\"Step 2: As ChatGPT {role} in course designing Define Learning Outcomes by the topic of:((( {course_design_variables['topic']} )) and description of course_design_variables['specific_project'] \",\n",
        "    f\"4. As ChatGPT {role} in course designing Clearly articulate what you want your students to learn at the end of the {course_design_variables['topic']} course. {course_design_variables['learning_outcomes']} by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"5. As ChatGPT {role} in course designing Ensure these outcomes are measurable and directly related to the course content. by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"6. As ChatGPT {role} in course designing Align the learning outcomes with the educational objectives of the institution and the career goals of the students in the {course_design_variables['field_of_study']}. {course_design_variables['purpose']} by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"Step 3: As ChatGPT {role} in course designing Create Assessments by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"7. As ChatGPT {role} in course designing Develop assessments that effectively measure whether students have achieved the learning outcomes. {course_design_variables['course_assessments']} by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"8. As ChatGPT {role} in course designing Include various types of assessments such as exams, projects, presentations, and group work. by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"9. As ChatGPT {role} in course designing Ensure the assessments are fair and accurately reflect the learning outcomes. Also, consider {course_design_variables['collaboration']} and {course_design_variables['fun_and_enjoyment']} by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"Step 4: As ChatGPT {role} in course designing Plan Course Delivery by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"10. As ChatGPT {role} in course designing Decide on how you will deliver the {course_design_variables['field_of_study']} course content. {course_design_variables['learning_activities']} by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"11. As ChatGPT {role} in course designing Consider traditional lectures, discussions, labs, field trips, or a mix of these methods. by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"12. As ChatGPT {role} in course designing Choose the delivery method that best facilitates learning for your students in the {course_design_variables['audience']}. Also, consider {course_design_variables['course_schedule']} and {course_design_variables['course_sequencing']} by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"Step 5: As ChatGPT {role} in course designing Incorporate Universal Design for Learning (UDL) by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"13. As ChatGPT {role} in course designing UDL is a framework for designing instruction that accommodates the wide range of learning preferences and abilities among {course_design_variables['audience']}. by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"14. As ChatGPT {role} in course designing Incorporate multiple modes of representation, expression, action, and engagement within the design of instruction. Also, consider {course_design_variables['technology_requirements']} by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"Step 6: As ChatGPT {role} in course designing Experiential Learning by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"15. As ChatGPT {role} in course designing Tie theoretical knowledge to real-world experiences in the {course_design_variables['field_of_study']}. by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"16. As ChatGPT {role} in course designing For instance, in a {course_design_variables['field_of_study']} course, students could be asked to develop a {course_design_variables['specific_project']} or solve a real-world problem using the concepts they've learned. in the project field of {course_design_variables['specific_project']} by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"Step 7: As ChatGPT {role} in course designing Active Training by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"17. As ChatGPT {role} in course designing Engage students in active learning activities that require them to construct new knowledge through thinking and discussion. {course_design_variables['critical_thinking']} by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"18. As ChatGPT {role} in course designing This could include problem-solving exercises, case studies, simulations, or debates. by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"Step 8: As ChatGPT {role} in course designing Measurable Trainings by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"19. As ChatGPT {role} in course designing Ensure that your course has clear learning objectives and that you have ways to measure whether these objectives have been achieved. Also, consider {course_design_variables['employee_guarantee']} and {course_design_variables['prerequisites']} by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"20. As ChatGPT {role} in course designing This could involve pre-tests and post-tests, assignments, projects\"\n",
        "]\n",
        "\n",
        "prompt_course = [\n",
        "    f\" As ChatGPT expert in the role of course designing as {role}, suggest one Course Title in less than 15 words, based on This Topic :({TOPIC}) and the description:({PARAGRAPH}).\",\n",
        "\n",
        "    f\"Step 1: As ChatGPT {role} in course designing Identify Situational Factors for {course_design_variables['topic']} by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"1. As ChatGPT {role} in course designing Understand the broader context of the {course_design_variables['field_of_study']} course for {course_design_variables['audience']} by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"2. As ChatGPT {role} in course designing Consider factors such as department or discipline, institution expectations, and student backgrounds and needs. Also, consider {course_design_variables['employability']} by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"3. As ChatGPT {role} in course designing Tailor the course content according to these factors to meet the needs of {course_design_variables['audience']}. {course_design_variables['practical_skills']} by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"Step 2: As ChatGPT {role} in course designing Define Learning Outcomes by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"4. As ChatGPT {role} in course designing Clearly articulate what you want your students to learn at the end of the {course_design_variables['topic']} course. {course_design_variables['learning_outcomes']} by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"5. As ChatGPT {role} in course designing Ensure these outcomes are measurable and directly related to the course content. by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"6. As ChatGPT {role} in course designing Align the learning outcomes with the educational objectives of the institution and the career goals of the students in the {course_design_variables['field_of_study']}. {course_design_variables['purpose']} by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"Step 3: As ChatGPT {role} in course designing Create Assessments by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"7. As ChatGPT {role} in course designing Develop assessments that effectively measure whether students have achieved the learning outcomes. {course_design_variables['course_assessments']} by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"8. As ChatGPT {role} in course designing Include various types of assessments such as exams, projects, presentations, and group work. by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"9. As ChatGPT {role} in course designing Ensure the assessments are fair and accurately reflect the learning outcomes. Also, consider {course_design_variables['collaboration']} and {course_design_variables['fun_and_enjoyment']} by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "\n",
        "    f\"Step 4: As ChatGPT {role} in course designing Plan Course Delivery by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"10. As ChatGPT {role} in course designing Decide on how you will deliver the {course_design_variables['field_of_study']} course content. {course_design_variables['learning_activities']} by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"11. As ChatGPT {role} in course designing Consider traditional lectures, discussions, labs, field trips, or a mix of these methods. by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"12. As ChatGPT {role} in course designing Choose the delivery method that best facilitates learning for your students in the {course_design_variables['audience']}. Also, consider {course_design_variables['course_schedule']} and {course_design_variables['course_sequencing']} by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"Step 5:  As ChatGPT {role} in course designing Incorporate multiple modes of representation, expression, action, and engagement within the design of instruction. Also, consider {course_design_variables['technology_requirements']} by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"13. As ChatGPT {role} in course designing Incorporate Universal Design for Learning (UDL) in the {course_design_variables['field_of_study']}. by the topic of:((( {course_design_variables['topic']} )), by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"14. As ChatGPT {role} in course designing Incorporate multiple modes of representation, expression, action, and engagement within the design of instruction. Also, consider {course_design_variables['technology_requirements']} by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "\n",
        "    f\"16. As ChatGPT {role} in course designing Tie theoretical knowledge to real-world experiences in the {course_design_variables['field_of_study']}. by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"Step 6: As ChatGPT {role} in course designing Experiential Learning by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']} in the project field of {course_design_variables['specific_project']}\",\n",
        "    f\"15. As ChatGPT {role} in course designing Tie theoretical knowledge to real-world experiences in the {course_design_variables['field_of_study']}. by the topic of:((( {course_design_variables['topic']} )) in the project field of {course_design_variables['specific_project']}\",\n",
        "    f\"16. As ChatGPT {role} in course designing For instance, in a {course_design_variables['field_of_study']} course, students could be asked to develop a {course_design_variables['specific_project']} or solve a real-world problem using the concepts they've learned. in the project field of {course_design_variables['specific_project']} by the topic of:((( {course_design_variables['topic']} ))\",\n",
        "    f\"17. As ChatGPT {role} in course designing Engage students in active learning activities that require them to construct new knowledge through thinking and discussion. {course_design_variables['critical_thinking']} by the topic of:((( {course_design_variables['topic']} )) in the project field of {course_design_variables['specific_project']}\",\n",
        "    f\"18. As ChatGPT {role} in course designing This could include problem-solving exercises, case studies, simulations, or debates. by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"Step 7: As ChatGPT {role} in course designing Active Training by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"17. As ChatGPT {role} in course designing Engage students in active learning activities that require them to construct new knowledge through thinking and discussion. {course_design_variables['critical_thinking']} by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}\",\n",
        "    f\"18. As ChatGPT {role} in course designing This could include problem-solving exercises, case studies, simulations, or debates. by the topic of:((( {course_design_variables['topic']} )) in the project field of {course_design_variables['specific_project']}\",\n",
        "    f\"Step 8: As ChatGPT {role} in course designing Measurable Trainings by the topic of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\",\n",
        "    f\"19. As ChatGPT {role} in course designing Ensure that your course has clear learning objectives and that you have ways to measure whether these objectives have been achieved. Also, consider {course_design_variables['employee_guarantee']} and {course_design_variables['prerequisites']} by the topic of:((( {course_design_variables['topic']} )) in the project field of {course_design_variables['specific_project']}\",\n",
        "    f\"20. As ChatGPT {role} in course designing This could involve pre-tests and post-tests, assignments, projects or other forms of assessment for topic  of:((( {course_design_variables['topic']} )), in the project field of {course_design_variables['specific_project']}.\"\n",
        "\n",
        "]\n",
        "\n",
        "# Assign the prompts\n",
        "prompt_course_title = [\n",
        "f\" As ChatGPT expert in the role of course designing as {role}, suggest one Course Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "\n",
        " \"Step 1: Identify key factors.\",\n",
        " \"1-1. Understand the course context.\",\n",
        " \"1-2. Consider department, expectations, student needs.\",\n",
        " \"1-3. Tailor content to these factors.\",\n",
        " \"Step 2: Define learning outcomes.\",\n",
        " \"2-1. State student learning objectives.\",\n",
        " \"2-2. Ensure measurable, relevant outcomes.\",\n",
        " \"2-3. Align outcomes with objectives, goals.\",\n",
        " \"Step 3: Develop effective assessments.\",\n",
        " \"3-1. Assessments should measure learning outcomes.\",\n",
        " \"3-2. Use varied types of assessments.\",\n",
        " \"3-3. Ensure fair, accurate assessments.\",\n",
        " \"Step 4: Plan course delivery.\",\n",
        " \"4-1. Decide course content delivery method.\",\n",
        " \"4-2. Consider varied delivery methods.\",\n",
        " \"4-3. Choose best delivery method.\",\n",
        " \"Step 5: Incorporate Universal Design for Learning.\",\n",
        " \"5-1. UDL accommodates diverse learning preferences.\",\n",
        " \"5-2. Incorporate varied instruction design modes.\",\n",
        "\"5-3. Tie knowledge to real-world experiences.\",\n",
        "\"Step 6: Incorporate experiential learning.\",\n",
        " \"6-1. Connect theory to real-world experiences.\",\n",
        " \"6-2. Use field-specific projects for application.\",\n",
        "f\"6-3. Engage students in active learning activities for knowledge construction and discussion.\",\n",
        "f\"6-4. Incorporate problem-solving exercises for interactive learning.\",\n",
        "\"Step 7: Implement active training.\",\n",
        " \"7-1. Engage students in active learning.\",\n",
        " \"7-2. Use exercises, case studies, simulations.\",\n",
        " \"Step 8: Ensure measurable trainings.\",\n",
        " \"8-1. Course should have clear objectives.\",\n",
        " \"8-2. Measure objectives achievement effectively.\"\n",
        "]"
      ],
      "metadata": {
        "id": "NxDofkTSCMRO"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w5efmiQIyG4h"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow #-contrib\n",
        "#!pip uninstall tensorflow -y\n",
        "#!pip3 install tensorflow==1.15.0\n",
        "#!pip3 install tensorflow==1.14.0\n",
        "#!pip3 install tensorflow==1.13.2"
      ],
      "metadata": {
        "id": "xj9xhsV9lN23"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "\n",
        "from newspaper import Article\n",
        "import os\n",
        "import requests\n",
        "import gpt_2_simple as gpt2\n",
        "import tensorflow as tf\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "def extract_course_information(course_design_variables):\n",
        " course_data = {}\n",
        "\n",
        " # Retrieve course information from the web\n",
        " url = course_design_variables[\"url\"]\n",
        " article = Article(url)\n",
        " article.download()\n",
        " article.parse()\n",
        "\n",
        " # Extract course title\n",
        " course_title = article.title if article.title else \"Title not found on the page\"\n",
        " course_data['course_title'] = course_title\n",
        "\n",
        " # Extract course description\n",
        " course_description = article.text if article.text else \"Description not found on the page\"\n",
        " course_data['course_description'] = course_description\n",
        "\n",
        " # Extract authors\n",
        " authors = ', '.join(article.authors) if article.authors else \"Authors not found\"\n",
        " course_data['authors'] = authors\n",
        "\n",
        " # Extract publish date\n",
        " publish_date = article.publish_date if article.publish_date else \"Publish date not found\"\n",
        " course_data['publish_date'] = publish_date\n",
        "\n",
        " # Extract keywords\n",
        " keywords = ', '.join(article.keywords) if article.keywords else \"Keywords not found\"\n",
        " course_data['keywords'] = keywords\n",
        "\n",
        " return course_data, article\n",
        "\n",
        "# Example Usage\n",
        "course_url = \"https://uwex.wisconsin.edu/sustainable-management/masters/\"\n",
        "course_design_variables = {\"url\": course_url}\n",
        "\n",
        "# Extract course information\n",
        "course_data, article = extract_course_information(course_design_variables)\n",
        "\n",
        "if False:\n",
        "   # Print the extracted information\n",
        "   print(\"Course Title: \", course_data['course_title'])\n",
        "   print(\"Course Description: \", course_data['course_description'])\n",
        "   print(\"Authors: \", course_data['authors'])\n",
        "   print(\"Publish Date: \", course_data['publish_date'])\n",
        "   print(\"Keywords: \", course_data['keywords'])\n",
        "\n",
        "# Generate text with Sumy\n",
        "parser = PlaintextParser.from_string(course_data['course_description'], Tokenizer(\"english\"))\n",
        "#summarizer = LsaSummarizer()\n",
        "summary_sumy = summarizer(parser.document, 3)\n",
        "#print(\"\\nSumy Summary and remove the html content from this content :\\n\", summary_sumy)"
      ],
      "metadata": {
        "id": "82qSxXdsrvbL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "fc52397b-d814-4dca-8f9e-7b53df6bbc71"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'summarizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-13c918332591>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlaintextParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcourse_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'course_description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#summarizer = LsaSummarizer()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0msummary_sumy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;31m#print(\"\\nSumy Summary and remove the html content from this content :\\n\", summary_sumy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'summarizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "#from gpt_2_simple import gpt_2 as GPT2\n",
        "#from gpt2_client import GPT2Client\n",
        "#import tf_slim as slim\n",
        "\n",
        "def extract_course_information(course_design_variables,gpt):\n",
        "    #gpt = GPT2()\n",
        "    gpt.generate = gpt.generate_batch_from_prompts()\n",
        "    course_data = {}\n",
        "    course_data['topic'] = gpt.generate(prompt=f\"What is the topic of this course? {course_design_variables['topic']}\", text=course_design_variables['course_description'])\n",
        "    course_data['field_of_study'] = gpt.generate(prompt=f\"What is the field of study of this course? {course_design_variables['field_of_study']}\", text=course_design_variables['course_description'])\n",
        "    course_data['audience'] = gpt.generate(prompt=f\"Who is the target audience for this course? {course_design_variables['audience']}\", text=course_design_variables['course_description'])\n",
        "    course_data['specific_project'] = gpt.generate(prompt=f\"What is the specific project or assignment for this course? {course_design_variables['specific_project']}\", text=course_design_variables['course_description'])\n",
        "    course_data['employability'] = gpt.generate(prompt=f\"What are the employability or career benefits of this course? {course_design_variables['employability']}\", text=course_design_variables['course_description'])\n",
        "    course_data['practical_skills'] = gpt.generate(prompt=f\"What practical skills will students learn in this course? {course_design_variables['practical_skills']}\", text=course_design_variables['course_description'])\n",
        "    course_data['creativity'] = gpt.generate(prompt=f\"How does this course encourage creativity? {course_design_variables['creativity']}\", text=course_design_variables['course_description'])\n",
        "    course_data['critical_thinking'] = gpt.generate(prompt=f\"How does this course develop critical thinking skills? {course_design_variables['critical_thinking']}\", text=course_design_variables['course_description'])\n",
        "    course_data['fun_and_enjoyment'] = gpt.generate(prompt=f\"How does this course make learning engaging and enjoyable? {course_design_variables['fun_and_enjoyment']}\", text=course_design_variables['course_description'])\n",
        "    course_data['employee_guarantee'] = \"\"\n",
        "    course_data['collaboration'] = gpt.generate(prompt=f\"How does this course foster collaboration among students? {course_design_variables['collaboration']}\", text=course_design_variables['course_description'])\n",
        "    course_data['learning_outcomes'] = gpt.generate(prompt=f\"What are the learning outcomes or goals of this course? {course_design_variables['learning_outcomes']}\", text=course_design_variables['course_description'])\n",
        "    course_data['purpose'] = gpt.generate(prompt=f\"What is the purpose or objective of this course? {course_design_variables['purpose']}\", text=course_design_variables['course_description'])\n",
        "    course_data['learning_activities'] = gpt.generate(prompt=f\"What are the learning activities or methods used in this course? {course_design_variables['learning_activities']}\", text=course_design_variables['course_description'])\n",
        "    course_data['course_content'] = gpt.generate(prompt=f\"What are the main topics or subjects covered in this course? {course_design_variables['course_content']}\", text=course_design_variables['course_description'])\n",
        "    course_data['course_assessments'] = gpt.generate(prompt=f\"How are students assessed in this course? {course_design_variables['course_assessments']}\", text=course_design_variables['course_description'])\n",
        "    course_data['course_schedule'] = gpt.generate(prompt=f\"What is the schedule or timeline for this course? {course_design_variables['course_schedule']}\", text=course_design_variables['course_description'])\n",
        "    course_data['course_sequencing'] = gpt.generate(prompt=f\"How is the course content organized or sequenced? {course_design_variables['course_sequencing']}\", text=course_design_variables['course_description'])\n",
        "    course_data['technology_requirements'] = gpt.generate(prompt=f\"What technology or equipment is required for this course? {course_design_variables['technology_requirements']}\", text=course_design_variables['course_description'])\n",
        "    course_data['prerequisites'] = gpt.generate(prompt=f\"What are the prerequisites or prior knowledge required for this course? {course_design_variables['prerequisites']}\", text=course_design_variables['course_description'])\n",
        "\n",
        "    return course_data\n",
        "\n",
        "# Example Usage\n",
        "course_url = \"https://uwex.wisconsin.edu/sustainable-management/masters/\" # @param {type:\"string\"} # Wrap the URL in quotes\n",
        "response = requests.get(course_url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "course_description_element = soup.find('div', class_='course-description__content')\n",
        "\n",
        "if course_description_element:\n",
        "    course_description = course_description_element.text.strip()\n",
        "else:\n",
        "    course_description = \"Description not found on the page\"\n",
        "\n",
        "# Dictionary of course design variables\n",
        "course_design_variables = course_design_variables\n",
        "\n",
        "course_design_variables['course_description'] = summary_sumy\n",
        "\n",
        "#gpt2 = GPT2Client('117M') # This could also be `345M`, `774M`, or `1558M`\n",
        "\n",
        "#text = gpt2.generate_batch_from_prompts(prompts) # returns an array of generated text\n",
        "\n",
        "#course_data = extract_course_information(course_design_variables,gpt2)\n",
        "#prompts = generate_prompts(course_data)\n",
        "#print(prompts)"
      ],
      "metadata": {
        "id": "NDhFuzJhLTwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from newspaper import Article\n",
        "import os\n",
        "import requests\n",
        "import gpt_2_simple as gpt2\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "course_url = \"https://uwex.wisconsin.edu/sustainable-management/masters/\" # @param {type:\"string\"} # Wrap the URL in quotes\n",
        "response = requests.get(course_url)\n",
        "\n",
        "def extract_course_information(course_design_variables):\n",
        " course_data = {}\n",
        "\n",
        " # Retrieve course information from the web\n",
        " url = course_design_variables[\"url\"]\n",
        " article = Article(url)\n",
        " article.download()\n",
        " article.parse()\n",
        "\n",
        " # Extract course title\n",
        " course_title = article.title if article.title else \"Title not found on the page\"\n",
        " course_data['course_title'] = course_title\n",
        "\n",
        " # Extract course description\n",
        " course_description = article.text if article.text else \"Description not found on the page\"\n",
        " course_data['course_description'] = course_description\n",
        "\n",
        " return course_data\n",
        "\n",
        "# Example Usage\n",
        "course_url = \"https://uwex.wisconsin.edu/sustainable-management/masters/\"\n",
        "course_design_variables = {\"url\": course_url}\n",
        "\n",
        "# Extract course information\n",
        "course_data = extract_course_information(course_design_variables)\n",
        "\n",
        "# Print the extracted information\n",
        "print(\"Course Title: \", course_data['course_title'])\n",
        "print(\"Course Description: \", course_data['course_description'])\n",
        "\n",
        "# Download the model if not already present"
      ],
      "metadata": {
        "id": "mRR0xliyRe7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#https://www.phind.com/search?cache=xqbhxgilysl4b8wqweih04eg\n",
        "\n",
        "Based on the search results, it seems you are interested in using Google's Text-to-Speech API to generate a voice for each `.docx` report. Here's how you can do it:\n",
        "\n",
        "First, install the necessary libraries:\n",
        "\n",
        "```python\n",
        "pip install python-docx google-cloud-texttospeech\n",
        "```\n",
        "\n",
        "Then, you can use the following code to read a `.docx` file and convert the text into speech:\n",
        "\n",
        "```python\n",
        "from docx import Document\n",
        "from google.cloud import texttospeech\n",
        "import os\n",
        "import random\n",
        "import slugify\n",
        "\n",
        "folder_path = \"/content/drive/My Drive/ChatGPT_Paper_wrting/All_Reports/\"\n",
        "\n",
        "def extract_course_information(course_design_variables):\n",
        " course_data = {}\n",
        "\n",
        " # Retrieve course information from the .docx file\n",
        " filename = course_design_variables[\"filename\"]\n",
        " doc = Document(filename)\n",
        " full_text = []\n",
        " for para in doc.paragraphs:\n",
        "    full_text.append(para.text)\n",
        " course_description = '\\n'.join(full_text) if full_text else \"Description not found in the file\"\n",
        " course_data['course_description'] = course_description\n",
        "\n",
        " return course_data, doc\n",
        "\n",
        "def generate_voice(course_data, TOPIC):\n",
        " # Convert the Sentence object to a string\n",
        " summary_sumy_str = course_data['course_description']\n",
        "\n",
        " # Initialize the Text-to-Speech client\n",
        " client = texttospeech.TextToSpeechClient()\n",
        "\n",
        " # Set the text input to be synthesized\n",
        " synthesis_input = texttospeech.SynthesisInput(text=summary_sumy_str)\n",
        "\n",
        " # Build the voice request\n",
        " voice = texttospeech.VoiceSelectionParams(\n",
        "    language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.FEMALE\n",
        " )\n",
        "\n",
        " # Select the type of audio file you want returned\n",
        " audio_config = texttospeech.AudioConfig(\n",
        "    audio_encoding=texttospeech.AudioEncoding.MP3\n",
        " )\n",
        "\n",
        " # Perform the text-to-speech request\n",
        " response = client.synthesize_speech(\n",
        "    input=synthesis_input, voice=voice, audio_config=audio_config\n",
        " )\n",
        "\n",
        " # Write the response to the output file.\n",
        " TOPIC_S = slugify(TOPIC)\n",
        " Sound_Folder = folder_path+f\"{TOPIC[:15]}_T/sound_/\"\n",
        " Sound_File = Sound_Folder +str(random.randint (0,1000))+\".mp3\"\n",
        "\n",
        " if not os.path.exists(Sound_Folder):\n",
        "    os.makedirs(Sound_Folder)\n",
        "\n",
        " with open(Sound_File, \"wb\") as out:\n",
        "    out.write(response.audio_content)\n",
        "\n",
        "# Example Usage\n",
        "course_filename = \"path_to_your_file.docx\"\n",
        "course_design_variables = {\"filename\": course_filename}\n",
        "TOPIC = \"Your Topic\"\n",
        "\n",
        "# Extract course information\n",
        "course_data, doc = extract_course_information(course_design_variables)\n",
        "\n",
        "# Generate voice for the course\n",
        "generate_voice(course_data, TOPIC)\n",
        "```\n",
        "\n",
        "In this modified script, `Document(filename)` opens the `.docx` file, and `'\\n'.join(full_text)` combines all the text from the file into a single string. The rest of the script remains the same [Source 2](https://codelabs.developers.google.com/codelabs/cloud-text-speech-python3/), [Source 6](https://cloud.google.com/python/docs/reference/texttospeech/latest/google.cloud.texttospeech_v1.types.VoiceSelectionParams)."
      ],
      "metadata": {
        "id": "H3Z2VpIO0tlr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rtJQMch81CC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "def extract_course_information(course_design_variables):\n",
        " course_data = {}\n",
        "\n",
        " # Retrieve course information from the .docx file\n",
        " filename = course_design_variables[\"filename\"]\n",
        " doc = Document(filename)\n",
        " full_text = []\n",
        " for para in doc.paragraphs:\n",
        "   full_text.append(para.text)\n",
        "   course_description = '\\n'.join(full_text) if full_text else \"Description not found in the file\"\n",
        "   course_data['course_description'] = course_description\n",
        "\n",
        " # Parse the text and generate a summary\n",
        " parser = PlaintextParser.from_string(course_description, Tokenizer(\"english\"))\n",
        " summarizer = LsaSummarizer()\n",
        "\n",
        " # Estimate the number of sentences needed for a 2-minute summary\n",
        " avg_speed = 150 # average words per minute\n",
        " est_num_sentences = int(2 * avg_speed) # 2 minutes in words\n",
        " summary = summarizer(parser.document, est_num_sentences)\n",
        "\n",
        " # Convert the Sentence object to a string\n",
        " summary_str = ' '.join([str(sentence) for sentence in summary])\n",
        "\n",
        " # Split the summary into parts\n",
        " course_parts = summary_str.split('\\n')\n",
        "\n",
        " return course_parts, doc"
      ],
      "metadata": {
        "id": "cQgZSXYl7_iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "from google.cloud import texttospeech\n",
        "import os\n",
        "import random\n",
        "import slugify\n",
        "\n",
        "folder_path = \"/content/drive/My Drive/ChatGPT_Paper_wrting/All_Reports/\"\n",
        "\n",
        "\n",
        "\n",
        "def generate_voice(course_data, TOPIC):\n",
        " # Convert the Sentence object to a string\n",
        " summary_sumy_str = course_data['course_description']\n",
        "\n",
        " # Initialize the Text-to-Speech client\n",
        " client = texttospeech.TextToSpeechClient()\n",
        "\n",
        " # Set the text input to be synthesized\n",
        " synthesis_input = texttospeech.SynthesisInput(text=summary_sumy_str)\n",
        "\n",
        " # Build the voice request\n",
        " voice = texttospeech.VoiceSelectionParams(\n",
        "    language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.FEMALE\n",
        " )\n",
        "\n",
        " # Select the type of audio file you want returned\n",
        " audio_config = texttospeech.AudioConfig(\n",
        "    audio_encoding=texttospeech.AudioEncoding.MP3\n",
        " )\n",
        "\n",
        " # Perform the text-to-speech request\n",
        " response = client.synthesize_speech(\n",
        "    input=synthesis_input, voice=voice, audio_config=audio_config\n",
        " )\n",
        "\n",
        " # Write the response to the output file.\n",
        " TOPIC_S = slugify(TOPIC)\n",
        " Sound_Folder = folder_path+f\"{TOPIC[:15]}_T/sound_/\"\n",
        " Sound_File = Sound_Folder +str(random.randint (0,1000))+\".mp3\"\n",
        "\n",
        " if not os.path.exists(Sound_Folder):\n",
        "    os.makedirs(Sound_Folder)\n",
        "\n",
        " with open(Sound_File, \"wb\") as out:\n",
        "    out.write(response.audio_content)\n",
        "\n",
        "# Example Usage\n",
        "course_filename = \"/content/drive/MyDrive/ChatGPT_Paper_wrting/All_Reports/Climate Change _T/Pitch_Deck/Title/Pitch_Deck_T_climate-change-_t.docx\" # \"path_to_your_file.docx\"\n",
        "course_design_variables = {\"filename\": course_filename}\n",
        "#TOPIC = \"Your Topic\"\n",
        "\n",
        "# Extract course information\n",
        "#course_data, doc = extract_course_information(course_design_variables)\n",
        "\n",
        "# Generate voice for the course\n",
        "#generate_voice(course_data, TOPIC)"
      ],
      "metadata": {
        "id": "-aNw4MOM04gR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "!sudo apt-get install ffmpeg\n",
        "!pip install python-slugify\n",
        "!pip install langdetect"
      ],
      "metadata": {
        "id": "Njd04Vde9ZWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from openai import OpenAI\n",
        "from pydub import AudioSegment\n",
        "from slugify import slugify\n",
        "from langdetect import detect\n",
        "import time\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "client = OpenAI(\n",
        " api_key = openai_api\n",
        ")\n",
        "\n",
        "def retry_with_exponential_backoff(func, initial_delay: float = 1, exponential_base: float = 2, jitter: bool = True, max_retries: int = 15, errors: tuple = (RateLimitError,)):\n",
        " def wrapper(*args, **kwargs):\n",
        "    num_retries = 0\n",
        "    delay = initial_delay\n",
        "    while True:\n",
        "        try:\n",
        "            return func(*args, **kwargs)\n",
        "        except errors as e:\n",
        "            num_retries += 1\n",
        "            if num_retries > max_retries:\n",
        "              raise Exception(f\"Maximum number of retries ({max_retries}) exceeded.\")\n",
        "            delay *= exponential_base * (1 + jitter * random.random())\n",
        "            time.sleep(delay)\n",
        "        except Exception as e:\n",
        "            raise e\n",
        " return wrapper\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_voice_openai(part):\n",
        " if not part:\n",
        "    print(\"Warning: Empty input received.\")\n",
        "    return None\n",
        " response = client.audio.speech.create(\n",
        "    voice=\"alloy\",\n",
        "    model=\"tts-1\",\n",
        "    input=part\n",
        " )\n",
        " return response\n",
        "\n",
        "def sumerizing(doc):\n",
        " content = \"\"\n",
        " for para in doc.paragraphs:\n",
        "    content += para.text + \"\\n\"\n",
        "\n",
        " # Detect the language of the content\n",
        " try:\n",
        "    language = detect(content)\n",
        "    print(f\"Detected language: {language}\")\n",
        " except langdetect.lang_detect_exception.LangDetectException:\n",
        "    print(\"Could not detect language.\")\n",
        "\n",
        " parser = PlaintextParser.from_string(content , Tokenizer(language))\n",
        " summarizer = LsaSummarizer()\n",
        " summary_sumy = summarizer(parser.document, 3)\n",
        " sumerized_content = \" \".join(str(sentence) for sentence in summary_sumy)\n",
        " print(\"\\nSumy Summary and remove the html content from this content :\\n\", sumerized_content)\n",
        " return sumerized_content\n",
        "\n",
        "def extract_course_information(course_design_variables):\n",
        " course_data = {}\n",
        " filename = course_design_variables[\"filename\"]\n",
        " doc = Document(filename)\n",
        " full_text = []\n",
        " for para in doc.paragraphs:\n",
        "  full_text.append(para.text)\n",
        " course_description = '\\n'.join(full_text) if full_text else \"Description not found in the file\"\n",
        " course_data['course_description'] = course_description\n",
        " course_parts = [sent for para in full_text for sent in sent_tokenize(para)]\n",
        " sumerized_content= sumerizing(doc)\n",
        " return course_parts, doc,sumerized_content\n",
        "\n",
        "def generate_voice(course_parts, TOPIC):\n",
        " TOPIC_S = slugify(TOPIC)\n",
        " Sound_Folder = folder_path+f\"{TOPIC[:15]}_T/sound_/\"\n",
        " if not os.path.exists(Sound_Folder):\n",
        "    os.makedirs(Sound_Folder)\n",
        " audio_files = []\n",
        " if True: #for i, part in enumerate(course_parts):\n",
        "    #print (f'\\n The {i}th part of main variable is :',part)\n",
        "    #if not part:\n",
        "       # continue\n",
        "    response = generate_voice_openai(course_parts)\n",
        "    Sound_File = Sound_Folder +str(course_parts[:10])+\".mp3\"\n",
        "    response.stream_to_file(Sound_File)\n",
        "    print ('\\n Response for voice generation is made at : ', Sound_File)\n",
        "    audio_files.append(Sound_File)\n",
        " combined_audio = AudioSegment.empty()\n",
        " for af in audio_files:\n",
        "    combined_audio += AudioSegment.from_file(af)\n",
        " avg_speed = 150\n",
        " total_words = len(' '.join(course_parts).split())\n",
        " est_duration = total_words / avg_speed\n",
        " n = 5\n",
        " if est_duration < n:\n",
        "    num_repetitions = int((n / est_duration) + 1)\n",
        "    empty_audio = AudioSegment.silent(duration=len(combined_audio))\n",
        "    extended_audio = empty_audio.overlay(combined_audio, times=num_repetitions)\n",
        "    extended_audio.export(Sound_Folder+\"extended.mp3\", format='mp3')\n",
        " combined_audio.export(Sound_Folder+\"combined.mp3\", format='mp3')\n",
        "\n",
        "course_filename = \"/content/drive/MyDrive/ChatGPT_Paper_wrting/All_Reports/Climate Change _T/Pitch_Deck/Title/Pitch_Deck_T_climate-change-_t.docx\"\n",
        "course_design_variables = {\"filename\": course_filename}\n",
        "#course_parts, doc,sumerized_content = extract_course_information(course_design_variables)\n",
        "#generate_voice(sumerized_content, TOPIC)"
      ],
      "metadata": {
        "id": "vgQtEAVnfYMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bl5wSWx0nin3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2uaDF7NAu2GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k4EHpU98vgv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dIg4siLIuvdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xF-ZkR6PwUxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y4qxO8WZwBOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Upload posts to linkedin 🔥🌹👇🙏🌀:"
      ],
      "metadata": {
        "id": "evu3izeBUIVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/So-AI-love/chatgpt-prompts-for-academic-writing\n",
        "\n",
        "%cd chatgpt-prompts-for-academic-writing"
      ],
      "metadata": {
        "id": "P7TwfsyaUUB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Topic = TOPIC\n",
        "#TOPIC_0 = f\"Analyze the current situation in the Islamic Republic of Iran and the challenges faced by resistance forces. And Identify effective strategies used by resistance movements to navigate challenging political environments.\"\n",
        "#TOPIC_0 = f\"Could you provide more insights into the challenges faced by the opposition groups in Iran and how they could overcome these challenges to effectively organize resistance against the Islamic Republic?\"\n",
        "\n",
        "Question=Topic\n",
        "#PASSWORD =  # @param {type:\"string\"}\n",
        "if not (Question == \"\"):\n",
        "\n",
        "    TOPIC  = Question\n",
        "\n",
        "else:\n",
        "    TOPIC  = TOPIC_0\n",
        "\n",
        "    print(\"Please Input your Mega IDs.\")\n",
        "# @markdown *After signing\n",
        "print ('Your question is:',TOPIC)# has done successfully\")\n",
        "\n",
        "main_variables_0 = {\n",
        "      'TOPIC': TOPIC,\n",
        "      'RESEARCH_DOMAIN': RESEARCH_DOMAIN,\n",
        "      'PARAGRAPH': PARAGRAPH,\n",
        "      'PARAGRAPHS': PARAGRAPHS,\n",
        "      'TOPIC_SENTENCE': TOPIC_SENTENCE,\n",
        "      'LANGUAGE': LANGUAGE,\n",
        "      'ABSTRACT_PARAGRAPH': ABSTRACT_PARAGRAPH,\n",
        "      'BIBLIOGRAPHY': BIBLIOGRAPHY,\n",
        "      'THEORY1': THEORY1,\n",
        "      'THEORY2': THEORY2,\n",
        "      'RESEARCH_QUESTIONS': RESEARCH_QUESTIONS,\n",
        "      'ACTION': ACTION,\n",
        "      'RESULT_PARAGRAPHS': RESULT_PARAGRAPHS,\n",
        "      'DATE': DATE,\n",
        "      'NUMBER_OF_DAYS_MONTHS_YEARS': NUMBER_OF_DAYS_MONTHS_YEARS,\n",
        "      'role' : role\n",
        "  }\n",
        "\n",
        "# List of prompts for generating academic papers\n",
        "prompts_Academic = [\n",
        "f\" As ChatGPT expert in the role of {role}, suggest one report Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "# Improving Language\n",
        "f\"Write a counterargument to the following claim: '{PARAGRAPH}'\",\n",
        "f\"Rewrite this in an academic voice: '{PARAGRAPH}'\",\n",
        "f\"Expand these notes: '{PARAGRAPH}'\",\n",
        "f\"Provide me a list of words and phrases which were repeatedly / more than 3 times used: '{PARAGRAPHS}'\",\n",
        "f\"Provide me a list of synonyms for '{PARAGRAPH}' and evaluate them in the context of '{PARAGRAPH}'\",\n",
        "f\"Act as a language expert, proofread my paper on '{TOPIC_SENTENCE}' while putting a focus on grammar and punctuation.\",\n",
        "f\"In the context of '{RESEARCH_DOMAIN}' translate '{PARAGRAPH}' into the '{LANGUAGE}' language.\",\n",
        "\n",
        "  # Brainstorming\n",
        "  f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "  f\"Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. '{PARAGRAPH}'\",\n",
        "  f\"Identify gaps in the literature on '{TOPIC_SENTENCE}'\",\n",
        "  f\"Generate 10 academic research questions about '{PARAGRAPHS}'\",\n",
        "  f\"Generate a list of research hypotheses related to '{TOPIC_SENTENCE}'\",\n",
        "  f\"Identify potential areas for future research in the context of this '{TOPIC_SENTENCE}'\",\n",
        "  f\"Suggest novel applications of '{TOPIC_SENTENCE}' within '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "  # Title/Topic Sentence\n",
        "  f\"Suggest 5 titles for the following abstract: '{ABSTRACT_PARAGRAPH}'\",\n",
        "  f\"Write a topic sentence for this paragraph: '{PARAGRAPH}'\",\n",
        "\n",
        "  # Keywords\n",
        "  f\"Provide 5 keywords for this: '{PARAGRAPHS}'\",\n",
        "\n",
        "  # Abstract\n",
        "  f\"Generate an abstract for a scientific paper based on this information for: '{PARAGRAPHS}'\",\n",
        "\n",
        "  # Outline\n",
        "  f\"Generate an outline for '{TOPIC_SENTENCE}'\",\n",
        "  f\"I want to write a journal article about '{TOPIC_SENTENCE}'. Give me an outline for the article that I can use as a starting point.\",\n",
        "\n",
        "  # Introduction\n",
        "  f\"Come up with an introduction for the following research topic: '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "  # Literature Review\n",
        "  f\"Conduct a literature review on '{TOPIC_SENTENCE}' and provide review paper references\",\n",
        "  f\"Provide me with references and links to papers in '{PARAGRAPH}'\",\n",
        "  f\"Summarize the scholarly literature including in-text citations on '{PARAGRAPHS}'\",\n",
        "  f\"Write this in standard Harvard referencing '{PARAGRAPH}'\",\n",
        "  f\"Convert this '{BIBLIOGRAPHY}' from MLA to APA style.\",\n",
        "  f\"Compare and contrast '{THEORY1}' and '{THEORY2}' in the context of '{RESEARCH_DOMAIN}'\",\n",
        "\n",
        "  # Methodology\n",
        "   f\"Create objectives and methodology for '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a detailed methodology for the topic: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Analyze the strengths and weaknesses of this methodology: '{PARAGRAPHS}'\",\n",
        "   f\"Write objectives for this study: '{TOPIC_SENTENCE}'\",\n",
        "   f\"What are the limitations of using '{TOPIC_SENTENCE}' in '{RESEARCH_DOMAIN}'?\",\n",
        "   f\"Create a recipe for the methods used in this '{PARAGRAPHS}'\",\n",
        "   f\"Suggest interdisciplinary approaches to '{TOPIC_SENTENCE}'\",\n",
        "   f\"Explain how qualitative/quantitative research methods can be used to address '{RESEARCH_QUESTIONS}'\",\n",
        "   f\"Recommend best practices for data collection and analysis in '{TOPIC_SENTENCE}'\",\n",
        "\n",
        "   # Experiments\n",
        "   f\"Design an experiment that '{ACTION}'\",\n",
        "\n",
        "   # Results\n",
        "   f\"Write a result section for the following paragraphs. Please write this in the third person. '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Discussion\n",
        "   f\"Discuss this results: '{RESULT_PARAGRAPHS}'\",\n",
        "\n",
        "   # Conclusion\n",
        "   f\"Generate a conclusion for this: '{PARAGRAPHS}'\",\n",
        "   f\"Give recommendations and conclusion for: '{PARAGRAPHS}'\",\n",
        "\n",
        "   # Future Works\n",
        "   f\"Can you suggest 3 directions for future research on this topic: '{PARAGRAPH}'\",\n",
        "\n",
        "   # Plan/Presentation\n",
        "   f\"Develop a research plan for: '{TOPIC_SENTENCE}'\",\n",
        "   f\"Write a schedule for completion in '{TOPIC_SENTENCE}' in NUMBER OF DAYS MONTHS YEARS which is '{NUMBER_OF_DAYS_MONTHS_YEARS}'\",\n",
        "   f\"The deadline for the submission of the first draft is '{DATE}'. Give me a week-by-week breakdown so I can plan my writing better.\",\n",
        "   f\"Write a sensational press release for this research: '{PARAGRAPHS}'\",\n",
        "   f\"Make this more persuasive: '{PARAGRAPH}'\",\n",
        "   f\"Write 3 tweets about this research? '{PARAGRAPHS}'\",\n",
        "]\n",
        "\n",
        "prompt_Word_Topic_Academic = [\n",
        "f\" As ChatGPT expert in the role of {role}, suggest one report Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "\n",
        "  # Improving Language\n",
        "  f\"1. Write a counterargument to the following claim: ''\",\n",
        "  f\"2. Rewrite this in an academic voice: ''\",\n",
        "  f\"3. Expand these notes: ''\",\n",
        "  f\"4. Provide me a list of words and phrases which were repeatedly / more than 3 times used: ''\",\n",
        "  f\"5. Provide me a list of synonyms for '' and evaluate them in the context of ''\",\n",
        "  f\"6. Act as a language expert, proofread my paper on '' while putting a focus on grammar and punctuation.\",\n",
        "  f\"7. In the context of '' translate '' into the '' language.\",\n",
        "\n",
        "  # Brainstorming\n",
        "  f\"8. Find a research topic for a PhD in the area of ''\",\n",
        "  f\"9. Write a detailed proposal on the following research topic. Make sure it is free from plagiarism. ''\",\n",
        "  f\"10. Identify gaps in the literature on ''\",\n",
        "  f\"11. Generate 10 academic research questions about ''\",\n",
        "  f\"12. Generate a list of research hypotheses related to ''\",\n",
        "  f\"13. Identify potential areas for future research in the context of this ''\",\n",
        "  f\"14. Suggest novel applications of '' within ''\",\n",
        "\n",
        "  # Title/Topic Sentence\n",
        "  f\"15. Suggest 5 titles for the following abstract: ''\",\n",
        "  f\"16. Write a topic sentence for this paragraph: ''\",\n",
        "\n",
        "  # Keywords\n",
        "  f\"17. Provide 5 keywords for this: ''\",\n",
        "\n",
        "  # Abstract\n",
        "  f\"18. Generate an abstract for a scientific paper based on this information for: ''\",\n",
        "\n",
        "  # Outline\n",
        "  f\"19. Generate an outline for ''\",\n",
        "  f\"20. I want to write a journal article about ''. Give me an outline for the article that I can use as a starting point.\",\n",
        "\n",
        "  # Introduction\n",
        "  f\"21. Come up with an introduction for the following research topic: ''\",\n",
        "\n",
        "  # Literature Review\n",
        "  f\"22. Conduct a literature review on '' and provide review paper references\",\n",
        "  f\"23. Provide me with references and links to papers in ''\",\n",
        "  f\"24. Summarize the scholarly literature including in-text citations on ''\",\n",
        "  f\"25. Write this in standard Harvard referencing ''\",\n",
        "  f\"26. Convert this '' from MLA to APA style.\",\n",
        "  f\"27. Compare and contrast '' and '' in the context of ''\",\n",
        "\n",
        "  # Methodology\n",
        "  f\"28. Create objectives and methodology for ''\",\n",
        "  f\"29. Write a detailed methodology for the topic: ''\",\n",
        "  f\"30. Analyze the strengths and weaknesses of this methodology: ''\",\n",
        "  f\"31. Write objectives for this study: ''\",\n",
        "  f\"32. What are the limitations of using '' in ''?\",\n",
        "  f\"33. Create a recipe for the methods used in this ''\",\n",
        "  f\"34. Suggest interdisciplinary approaches to ''\",\n",
        "  f\"35. Explain how qualitative/quantitative research methods can be used to address ''\",\n",
        "  f\"36. Recommend best practices for data collection and analysis in ''\",\n",
        "\n",
        "  # Experiments\n",
        "  f\"37. Design an experiment that ''\",\n",
        "\n",
        "  # Results\n",
        "  f\"38. Write a result section for the following paragraphs. Please write this in the third person. ''\",\n",
        "\n",
        "  # Discussion\n",
        "  f\"39. Discuss this results: ''\",\n",
        "\n",
        "  # Conclusion\n",
        "  f\"40. Generate a conclusion for this: ''\",\n",
        "  f\"41. Give recommendations and conclusion for: ''\",\n",
        "\n",
        "  # Future Works\n",
        "  f\"42. Can you suggest 3 directions for future research on this topic: ''\",\n",
        "\n",
        "  # Plan/Presentation\n",
        "  f\"43. Develop a research plan for: ''\",\n",
        "  f\"44. Write a schedule for completion in '' in NUMBER OF DAYS MONTHS YEARS which is ''\",\n",
        "  f\"45. The deadline for the submission of the first draft is ''. Give me a week-by-week breakdown so I can plan my writing better.\",\n",
        "  f\"46. Write a sensational press release for this research: ''\",\n",
        "  f\"47. Make this more persuasive: ''\",\n",
        "  f\"48. Write 3 tweets about this research? ''\",\n",
        "]"
      ],
      "metadata": {
        "id": "ndWVOITXN7Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Goal adding 🙏👇🌸"
      ],
      "metadata": {
        "id": "Jl9PPovDuhlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#TOPIC_0 = f\"Analyze the current situation in the Islamic Republic of Iran and the challenges faced by resistance forces. And Identify effective strategies used by resistance movements to navigate challenging political environments.\"\n",
        "#TOPIC_0 = f\"Could you provide more insights into the challenges faced by the opposition groups in Iran and how they could overcome these challenges to effectively organize resistance against the Islamic Republic?\"\n",
        "\n",
        "Question=Topic\n",
        "#PASSWORD =  # @param {type:\"string\"}\n",
        "if not (Question == \"\"):\n",
        "\n",
        "    TOPIC  = Question\n",
        "\n",
        "else:\n",
        "    TOPIC  = TOPIC_0\n",
        "\n",
        "    print(\"Please Input your Mega IDs.\")\n",
        "# @markdown *After signing\n",
        "print ('Your question is:',TOPIC)# has done successfully\")\n",
        "main_variables_0 = {\n",
        "   'TOPIC': TOPIC,\n",
        "   'PARAGRAPH':PARAGRAPH,\n",
        "    'role':role\n",
        "}\n",
        "\n",
        "prompts = [\n",
        "# Understanding the Issue\n",
        "f\"What are the key aspects of {main_variables_0['TOPIC']} that need to be addressed?\",\n",
        "\n",
        "# Mind Mapping\n",
        "f\"Create a mind map of the main elements of {main_variables_0['TOPIC']} and how they are interconnected.\",\n",
        "\n",
        "# Affinity Diagramming\n",
        "f\"Write down ideas on sticky notes about how to improve {main_variables_0['TOPIC']}. Then, group these ideas based on common themes.\",\n",
        "\n",
        "# Round-Robin Brainstorming\n",
        "f\"Take turns sharing ideas on how to improve {main_variables_0['TOPIC']}. Make sure everyone has a chance to contribute.\",\n",
        "\n",
        "# Reverse Brainstorming\n",
        "f\"Think of ways to create the problem in {main_variables_0['TOPIC']}. This will help you understand how to solve it.\",\n",
        "\n",
        "# SCAMPER\n",
        "f\"Apply the SCAMPER method to existing solutions or situations in {main_variables_0['TOPIC']}. This will spark new ideas.\",\n",
        "\n",
        "# Cross-Functional Brainstorming\n",
        "f\"Assemble a diverse group of people from various backgrounds and disciplines to tackle {main_variables_0['TOPIC']}. This will ensure a more rounded and innovative solution.\",\n",
        "\n",
        "# Future Backwards\n",
        "f\"Envision a future state where {main_variables_0['TOPIC']} has been solved successfully. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.\"\n",
        "]"
      ],
      "metadata": {
        "id": "rmbkC20f6RWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TOPIC_0 = \"task to investigate various gaming groups in Iran, following the Mahsa Movement in the second year. The gaming groups being investigated include the dark solidarity group, the dark trilogy, the dark quadrilogy, the regular people, the bright solidarity group, and the bright trilogy. The aim is to gather information about each group, analyze their characteristics, objectives, and any associated psychological syndromes. This information will then be presented in a table for easier understanding and comparison.\" # Replace this with your topic\n",
        "#RESEARCH_DOMAIN = \"Environmental startup field\" # Replace this with your research domain\n",
        "\n",
        "global docx_path,Pdf_Dir,prompt_Word_Topic\n",
        "\n",
        "if not (Question == \"\"):\n",
        "\n",
        "    TOPIC  = Question\n",
        "\n",
        "else:\n",
        "    TOPIC  = TOPIC_0\n",
        "\n",
        "main_variables_0 = {\n",
        "   'TOPIC': TOPIC,\n",
        "   'RESEARCH_DOMAIN' : RESEARCH_DOMAIN,\n",
        "   'PARAGRAPH':PARAGRAPH\n",
        "}\n",
        "\n",
        "TOPIC = f\"{main_variables_0['TOPIC']}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "\n",
        "prompts_old = [\n",
        "  f\"For the {TOPIC} of Business Overview, provide a detailed description of your business, including its location, legal structure, owners, vision, mission, and history.\",\n",
        "  f\"For the {TOPIC} of Market Analysis, provide information about your target market, market size, growth potential, competitors, market trends, and regulatory environment.\",\n",
        "  f\"For the {TOPIC} of Products and Services, describe your products and services in detail.\",\n",
        "  f\"For the {TOPIC} of Marketing and Sales Strategies, outline your marketing, sales, pricing, and customer retention strategies.\",\n",
        "  f\"For the {TOPIC} of Operations Plan, describe daily business activities, individuals responsible, tools and equipment required, inventory, cost, and any other special requirements.\",\n",
        "  f\"For the {TOPIC} of Management Team, describe the founders, key executives, senior management, their educational and professional background, compensation plan, business hierarchy, and business advisors/consultants.\",\n",
        "  f\"For the {TOPIC} of Financial Plan, provide a thorough understanding of operational costs, net profit, and financing to estimate revenue projections.\",\n",
        "  f\"For the {TOPIC} of Executive Summary, provide an overview of the entire business plan. This is usually written after the entire plan is ready.\",\n",
        "  f\"For the {TOPIC} of Appendix, provide additional information supporting your business plan’s main content.\"\n",
        "]\n",
        "\n",
        "prompts_old_2 = [\n",
        "f\"suggest one Business Plans repost Title based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\"\n",
        " f\"Provide a detailed description of your business, including its location, legal structure, owners, vision, mission, and history. This is for the {TOPIC} of Business Overview. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Provide information about your target market, market size, growth potential, competitors, market trends, and regulatory environment. This is for the {TOPIC} of Market Analysis.More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Describe your products and services in detail. This is for the {TOPIC} of Products and Services.More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Outline your marketing, sales, pricing, and customer retention strategies. This is for the {TOPIC} of Marketing and Sales Strategies.More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Describe daily business activities, individuals responsible, tools and equipment required, inventory, cost, and any other special requirements. This is for the {TOPIC} of Operations Plan.More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Describe the founders, key executives, senior management, their educational and professional background, compensation plan, business hierarchy, and business advisors/consultants. This is for the {TOPIC} of Management Team.More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Provide a thorough understanding of operational costs, net profit, and financing to estimate revenue projections. This is for the {TOPIC} of Financial Plan.More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Provide an overview of the entire business plan. This is usually written after the entire plan is ready. This is for the {TOPIC} of Executive Summary.More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        " f\"Provide additional information supporting your business plan’s main content. This is for the {TOPIC} of Appendix.More Description about the Topic is show at here: {PARAGRAPH}\"\n",
        "f\"Provide additional information about SWOT for supporting your business plan’s main content. This is for the {TOPIC} of Appendix.More Description about the Topic is show at here: {PARAGRAPH}\"\n",
        "\n",
        "]\n",
        "\n",
        "prompt_Word_Topic_old_2 = [\n",
        "   f\"suggest one Business Plans repost Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\"\n",
        "   \"Provide business overview details\",\n",
        "   \"Describe target market information\",\n",
        "   \"Detail products and services\",\n",
        "   \"Outline marketing, sales strategies\",\n",
        "   \"Describe daily business activities\",\n",
        "   \"Detail management team\",\n",
        "   \"Understand operational costs, profit\",\n",
        "   \"Provide business plan overview\",\n",
        "   \"Support business plan with additional info\"\n",
        "   \" SWOT Analysis \"\n",
        "]"
      ],
      "metadata": {
        "id": "kWdIhuI-yhPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.phind.com/search? cache=dmmj0id2em6rm8lo88sqhm6o\n",
        "prompts_old_3 = [\n",
        "  f\"suggest one Business Plans repost Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "\n",
        "  f\"1. **Executive Summary**: Provide a concise summary of the business, its goals, and the market it operates in. This is for the {TOPIC} of Executive Summary. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"2. **Company Description**: Provide a detailed description of the company, its mission, vision, and the problem it aims to solve. This is for the {TOPIC} of Company Description. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"3. **Market Analysis**: Provide a comprehensive PESTEL analysis for the company, including Political, Economic, Sociocultural, Technological, Environmental, and Legal factors. This is for the {TOPIC} of Market Analysis. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"4. **Organization and Management**: Describe the company's organizational structure, its team, and their roles and responsibilities. This is for the {TOPIC} of Organization and Management. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"5. **Service or Product Line**: Describe the services or products offered by the company. This is for the {TOPIC} of Service or Product Line. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"6. **Marketing and Sales Strategy**: Outline the strategies for marketing and sales, including the target audience, user stories, suitable business strategies, and marketing platforms. This is for the {TOPIC} of Marketing and Sales Strategy. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"7. **Funding Request**: Detail the amount of funding needed, how it will be used, and the expected return on investment. This is for the {TOPIC} of Funding Request. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"8. **Financial Projections**: Provide financial forecasts for the next few years, including revenue, costs, and profitability. This is for the {TOPIC} of Financial Projections. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"9. **Appendix**: Include any additional information that supports the business plan, such as legal documents, contracts, or market research data. This is for the {TOPIC} of Appendix. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"10. **Industry Insight**: Provide a detailed industry insight for the business plan. This is for the {TOPIC} of Industry Insight. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"11. **SWOT Analysis**: Conduct a SWOT analysis for the business plan. This is for the {TOPIC} of SWOT Analysis. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"12. **Target Audience and User Stories**: Identify the target audience and user stories for the business plan. This is for the {TOPIC} of Target Audience and User Stories. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"13. **Suitable Business Strategies**: Provide suitable business strategies for the business plan. This is for the {TOPIC} of Suitable Business Strategies. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"14. **Business Frameworks**: Provide business frameworks for the business plan. This is for the {TOPIC} of Business Frameworks. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"15. **Requirements Analysis**: Conduct a requirements analysis for the business plan. This is for the {TOPIC} of Requirements Analysis. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"16. **Additional Revenue Streams**: Identify additional revenue streams for the business plan. This is for the {TOPIC} of Additional Revenue Streams. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"17. **Marketing Strategy and Brand Awareness**: Provide a marketing strategy and brand awareness for the business plan. This is for the {TOPIC} of Marketing Strategy and Brand Awareness. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"18. **Branding Suggestions**: Provide branding suggestions for the business plan. This is for the {TOPIC} of Branding Suggestions. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"19. **Recommended Marketing Platforms**: Recommend marketing platforms for the business plan. This is for the {TOPIC} of Recommended Marketing Platforms. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"20. **Game-Changing Idea**: Provide a game-changing idea for the business plan. This is for the {TOPIC} of Game-Changing Idea. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"21. **Porter's Five Forces Analysis**: Conduct a Porter's Five Forces analysis for the business plan. This is for the {TOPIC} of Porter's Five Forces Analysis. More Description about the Topic is show at here: {PARAGRAPH}\",\n",
        "  f\"22. **CATWOE Analysis**: Provide a CATWOE analysis for the business plan. This is for the {TOPIC} of CATWOE Analysis. More Description about the Topic is show at here: {PARAGRAPH}\"\n",
        "]\n",
        "\n",
        "prompts_business_plan = [\n",
        "    f\"suggest one Business Plans repost Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "    f\"1. **Executive Summary** (As a {role}): In this section, provide a concise summary of the business highlighting its unique value proposition, target market, and projected growth. Describe the company's goals, mission, and the market landscape it operates in. This is for the {TOPIC} of Executive Summary. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"2. **Company Description** (As a {role}): Detail the company's history, its founding principles, values, and the problem it addresses. Explain the company's vision, its core competencies, and how it stands out in the market. This is for the {TOPIC} of Company Description. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"3. **Market Analysis** (As a {role}): Conduct an in-depth PESTEL analysis covering Political, Economic, Sociocultural, Technological, Environmental, and Legal factors. Provide insights into market trends, potential risks, and opportunities. This is for the {TOPIC} of Market Analysis. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"4. **Organization and Management** (As a {role}): Outline the company's organizational structure, key personnel, their roles, and responsibilities. Explain how the team contributes to the company's success. This is for the {TOPIC} of Organization and Management. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"5. **Service or Product Line** (As a {role}): Elaborate on the services or products offered by the company. Highlight their unique features, benefits, and how they fulfill market needs. This is for the {TOPIC} of Service or Product Line. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"6. **Marketing and Sales Strategy** (As a {role}): Explain the strategies for marketing and sales, target audience identification, user stories, and chosen marketing platforms. This is for the {TOPIC} of Marketing and Sales Strategy. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"7. **Funding Request** (As a {role}): Specify the funding amount required, the allocation plan, and the anticipated return on investment. Justify the funding request based on growth projections. This is for the {TOPIC} of Funding Request. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"8. **Financial Projections** (As a {role}): Present detailed financial forecasts covering revenue, costs, and profitability for the upcoming years. Base projections on market analysis and business strategies. This is for the {TOPIC} of Financial Projections. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"9. **Appendix** (As a {role}): Include supporting documents like legal papers, contracts, and additional market research data that strengthen the business plan. This is for the {TOPIC} of Appendix. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"10. **Industry Insight** (As a {role}): Provide a comprehensive analysis of the industry, including current trends, competitive landscape, and future predictions. This is for the {TOPIC} of Industry Insight. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"11. **SWOT Analysis** (As a {role}): Perform a SWOT analysis, highlighting the company's strengths, weaknesses, opportunities, and threats. This is for the {TOPIC} of SWOT Analysis. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"12. **Target Audience and User Stories** (As a {role}): Identify the target audience demographics and behaviors. Create user stories illustrating their needs and experiences. This is for the {TOPIC} of Target Audience and User Stories. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"13. **Suitable Business Strategies** (As a {role}): Present specific business strategies tailored to the company's objectives, market conditions, and competitive positioning. This is for the {TOPIC} of Suitable Business Strategies. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"14. **Business Frameworks** (As a {role}): Propose relevant business frameworks or methodologies to guide the company's operations and decision-making. This is for the {TOPIC} of Business Frameworks. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    # 14-1. **SWOT Analysis**:\n",
        "    f\"Identify strengths, weaknesses, opportunities, and threats affecting the {TOPIC} business plan. This is for the {TOPIC} of SWOT Analysis. More Description about the Topic is shown here: {PARAGRAPH} The role of ChatGPT is to assist in generating insights and strategies.\",\n",
        "    # 14-2. **Porter's Five Forces**:\n",
        "    f\"Analyze industry competitiveness to understand market dynamics and potential competitors in the context of {TOPIC}. This is for the {TOPIC} of Porter's Five Forces Analysis. More Description about the Topic is shown here: {PARAGRAPH} ChatGPT's role is to provide a comprehensive analysis of market forces.\",\n",
        "    # 14-3. **Value Chain Analysis**:\n",
        "    f\"Break down activities to enhance value creation and operational efficiency for the {TOPIC} business plan. This is for the {TOPIC} of Value Chain Analysis. More Description about the Topic is shown here: {PARAGRAPH} ChatGPT will help in identifying areas of value creation and optimization.\",\n",
        "    # 14-4. **Business Model Canvas**:\n",
        "    f\"Visualize and communicate the business model clearly for the {TOPIC} stakeholders. This is for the {TOPIC} of Business Model Canvas. More Description about the Topic is shown here: {PARAGRAPH} ChatGPT's role is to aid in presenting a comprehensive business model.\",\n",
        "    # 14-5. **Ansoff Matrix**:\n",
        "    f\"Determine growth strategies for market penetration, development, and diversification tailored to {TOPIC}. This is for the {TOPIC} of Ansoff Matrix. More Description about the Topic is shown here: {PARAGRAPH} ChatGPT will assist in identifying growth strategies for the business.\",\n",
        "    # 14-6. **PESTEL Analysis**:\n",
        "    f\"Assess political, economic, social, technological, environmental, and legal factors impacting the {TOPIC} business plan. This is for the {TOPIC} of PESTEL Analysis. More Description about the Topic is shown here: {PARAGRAPH} ChatGPT's role is to analyze external factors affecting the business environment.\",\n",
        "    # 14-7. **Balanced Scorecard**:\n",
        "    f\"Monitor performance against strategic objectives and adjust the {TOPIC} business plan accordingly. This is for the {TOPIC} of Balanced Scorecard. More Description about the Topic is shown here: {PARAGRAPH} ChatGPT's role is to assist in monitoring and aligning strategies with objectives.\",\n",
        "    f\"15. **Requirements Analysis** (As a {role}): Detail the requirements necessary for successful implementation of the business plan, including resources, technology, and workforce. This is for the {TOPIC} of Requirements Analysis. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"16. **Additional Revenue Streams** (As a {role}): Identify and explore potential additional revenue streams or business diversification opportunities. This is for the {TOPIC} of Additional Revenue Streams. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"17. **Marketing Strategy and Brand Awareness** (As a {role}): Develop a comprehensive marketing strategy focusing on brand awareness, positioning, and customer acquisition. This is for the {TOPIC} of Marketing Strategy and Brand Awareness. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"18. **Branding Suggestions** (As a {role}): Provide recommendations for branding strategies, including visual elements, messaging, and brand personality. This is for the {TOPIC} of Branding Suggestions. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"19. **Recommended Marketing Platforms** (As a {role}): Recommend specific marketing platforms or channels suitable for the target audience and business objectives. This is for the {TOPIC} of Recommended Marketing Platforms. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"20. **Game-Changing Idea** (As a {role}): Present an innovative idea or strategy that could revolutionize the industry or significantly impact the company's growth. This is for the {TOPIC} of Game-Changing Idea. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"21. **Porter's Five Forces Analysis** (As a {role}): Conduct a thorough Porter's Five Forces analysis to evaluate the competitive forces within the industry. Assess factors affecting profitability and market attractiveness. This is for the {TOPIC} of Porter's Five Forces Analysis. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "    f\"22. **CATWOE Analysis** (As a {role}): Perform a comprehensive CATWOE analysis considering Customers, Actors, Transformation, Worldview, Owners, and Environmental Constraints. Analyze the impacts on the business strategy and operations. This is for the {TOPIC} of CATWOE Analysis. More Description about the Topic is shown here: {PARAGRAPH}\",\n",
        "]\n",
        "\n",
        "\n",
        "prompt_Word_Topic_business_plan = [\n",
        "f\"suggest one Business Plans repost Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "\"1. Executive Summary: Business overview\",\n",
        "\"2. Company Description: Company identity\",\n",
        "\"3. Market Analysis: External factors\",\n",
        "\"4. Organization: Organizational structure\",\n",
        "\"5. Products/Services: Services/Products\",\n",
        "\"6. Marketing Strategy: Marketing strategies\",\n",
        "\"7. Funding: Funding details\",\n",
        "\"8. Financial Projections: Financial forecasts\",\n",
        "\"9. Appendix: Additional information\",\n",
        "\"10. Industry: Industry overview\",\n",
        "\"11. SWOT: Strengths, Weaknesses, Opportunities, Threats\",\n",
        "\"12. Target Audience: Target audience and user stories\",\n",
        "\"13. Business Strategies: Business strategies\",\n",
        "\"14. Frameworks: Business frameworks\",\n",
        "\"14-1. **SWOT Analysis**: Identify strengths, weaknesses, opportunities, and threats. Business insights provided.\",\n",
        "\"14-2. **Porter's Five Forces**: Analyze industry competitiveness, understand potential competitors.\",\n",
        "\"14-3. **Value Chain Analysis**: Enhance value creation, improve operational efficiency.\",\n",
        "\"14-4. **Business Model Canvas**: Visualize and communicate business model clearly.\",\n",
        "\"14-5. **Ansoff Matrix**: Determine growth strategies for market penetration.\",\n",
        "\"14-6. **PESTEL Analysis**: Assess political, economic, social factors impacting.\",\n",
        "\"14-7. **Balanced Scorecard**: Monitor performance, align strategies with objectives.\",\n",
        "\"15. Requirements: Requirements analysis\",\n",
        "\"16. Revenue: Additional revenue\",\n",
        "\"17. Marketing: Marketing and branding\",\n",
        "\"18. Branding: Branding suggestions\",\n",
        "\"19. Marketing Platforms: Recommended marketing platforms\",\n",
        "\"20. Idea: Game-changing idea\",\n",
        "\"21. Porter's Five Forces: Porter's Five Forces analysis\",\n",
        "\"22. CATWOE: CATWOE analysis\"\n",
        "]"
      ],
      "metadata": {
        "id": "OW6pwn7OPpVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#https://www.phind.com/search?cache=mn7fgo273k158vv941hewfxg\n",
        "#TOPIC_0 = \"task to investigate various gaming groups in Iran, following the Mahsa Movement in the second year. The gaming groups being investigated include the dark solidarity group, the dark trilogy, the dark quadrilogy, the regular people, the bright solidarity group, and the bright trilogy. The aim is to gather information about each group, analyze their characteristics, objectives, and any associated psychological syndromes. This information will then be presented in a table for easier understanding and comparison.\" # Replace this with your topic\n",
        "#RESEARCH_DOMAIN = \"Environmental startup field\" # Replace this with your research domain\n",
        "\n",
        "global docx_path,Pdf_Dir\n",
        "\n",
        "if not (Question == \"\"):\n",
        "\n",
        "    TOPIC  = Question\n",
        "\n",
        "else:\n",
        "    TOPIC  = TOPIC_0\n",
        "\n",
        "main_variables_0 = {\n",
        "   'TOPIC': TOPIC,\n",
        "   'RESEARCH_DOMAIN' : RESEARCH_DOMAIN,\n",
        "   'PARAGRAPH':PARAGRAPH,\n",
        "}\n",
        "\n",
        "TOPIC = f\"{main_variables_0['TOPIC']}\"\n",
        "RESEARCH_DOMAIN = \"{RESEARCH_DOMAIN}\"\n",
        "\n",
        "\n",
        "prompts_finantial = [\n",
        "f\"suggest one financial model report Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "f\"1. Do what for the '{TOPIC}' with this description: '{PARAGRAPH}'?, also use word system format as bolding and ...\",\n",
        "f\"1. Critique the business model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"2. Calculate the startup costs for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"2. Critique the startup costs for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"3. Track the revenue for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"3. Critique the revenue tracking for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"4. Review the projections for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"4. Critique the projections for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"5. Generate a detailed financial model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system formats as bolding and ...\",\n",
        "f\"5. Critique the detailed financial model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"6. Analyze the financial model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"6. Critique the financial model analysis for the '{TOPIC}' with this description: '{PARAGRAPH}'.also use word system format as bolding and ...\",\n",
        "f\"7. Adjust the financial model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"7. Critique the adjustments made to the financial model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"8. Finalize the financial model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\",\n",
        "f\"8. Critique the finalized financial model for the '{TOPIC}' with this description: '{PARAGRAPH}'. also use word system format as bolding and ...\"\n",
        "]\n",
        "#https://www.phind.com/search?cache=fbhlj5n08cwpl4y42l99w8sq\n",
        "prompt_Word_Topic_finantial = [\n",
        "  f\"suggest one financial model report Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "  \"1. Determine tasks for topic.\",\n",
        "  \"2. Critique business model.\",\n",
        "  \"3. Calculate startup costs.\",\n",
        "  \"4. Critique startup costs.\",\n",
        "  \"5. Track revenue.\",\n",
        "  \"6. Critique revenue tracking.\",\n",
        "  \"7. Review projections.\",\n",
        "  \"8. Critique projections.\",\n",
        "  \"9. Generate detailed financial model.\",\n",
        "  \"10. Critique financial model.\",\n",
        "  \"11. Analyze financial model.\",\n",
        "  \"12. Critique analysis.\",\n",
        "  \"13. Adjust financial model.\",\n",
        "  \"14. Critique adjustments.\",\n",
        "  \"15. Finalize financial model.\",\n",
        "  \"16. Critique finalized model.\",\n",
        "]"
      ],
      "metadata": {
        "id": "bRdDZr2zPkv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TOPIC_0 = \"task to investigate various gaming groups in Iran, following the Mahsa Movement in the second year. The gaming groups being investigated include the dark solidarity group, the dark trilogy, the dark quadrilogy, the regular people, the bright solidarity group, and the bright trilogy. The aim is to gather information about each group, analyze their characteristics, objectives, and any associated psychological syndromes. This information will then be presented in a table for easier understanding and comparison.\" # Replace this with your topic\n",
        "#RESEARCH_DOMAIN = \"Making Pitch deck file for the TOPIC \"\n",
        "\n",
        "if not (Question == \"\"):\n",
        "   TOPIC = Question\n",
        "else:\n",
        "   TOPIC = TOPIC_0\n",
        "\n",
        "main_variables_0 = {\n",
        "  'TOPIC': TOPIC,\n",
        "  'RESEARCH_DOMAIN' : RESEARCH_DOMAIN,\n",
        "  'PARAGRAPH':PARAGRAPH,\n",
        "}\n",
        "\n",
        "prompts_pitch = [\n",
        "f\"suggest one pitch deck  report Title in less than 15 word, based of This Topic :({main_variables_0['TOPIC']}) and the description:({main_variables_0['PARAGRAPH']}).\",\n",
        "f\"1.What are the key aspects of {main_variables_0['TOPIC']} that need to be addressed in the context of {main_variables_0['PARAGRAPH']}?\",\n",
        "f\"2.Create a mind map of the main elements of {main_variables_0['TOPIC']} and how they are interconnected in the context of {main_variables_0['PARAGRAPH']}.\",\n",
        "f\"3.Write down ideas on sticky notes about how to improve {main_variables_0['TOPIC']} in the context of {main_variables_0['PARAGRAPH']}. Then, group these ideas based on common themes.\",\n",
        "f\"4.Take turns sharing ideas on how to improve {main_variables_0['TOPIC']} in the context of {main_variables_0['PARAGRAPH']}. Make sure everyone has a chance to contribute.\",\n",
        "f\"5.Think of ways to create the problem in {main_variables_0['TOPIC']} in the context of {main_variables_0['PARAGRAPH']}. This will help you understand how to solve it.\",\n",
        "f\"6.Apply the SCAMPER method to existing solutions or situations in {main_variables_0['TOPIC']} in the context of {main_variables_0['PARAGRAPH']}. This will spark new ideas.\",\n",
        "f\"7.Assemble a diverse group of people from various backgrounds and disciplines to tackle {main_variables_0['TOPIC']} in the context of {main_variables_0['PARAGRAPH']}. This will ensure a more rounded and innovative solution.\",\n",
        "f\"8.Envision a future state where {main_variables_0['TOPIC']} has been solved successfully in the context of {main_variables_0['PARAGRAPH']}. Starting from this endpoint, work backward to identify the series of events and decisions that led to that future.\"\n",
        "]\n",
        "\n",
        "prompt_Word_Topic_pitch = [\n",
        "  f\"suggest one pitch deck report Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "  f\"1. Identify key aspects of startup pitch deck.\",\n",
        "  f\"2. Create a mind map of startup elements.\",\n",
        "  f\"3. Brainstorm ideas for startup improvement.\",\n",
        "  f\"4. Share ideas for startup improvement.\",\n",
        "  f\"5. Identify startup problems for solutions.\",\n",
        "  f\"6. Apply SCAMPER method to startup.\",\n",
        "  f\"7. Assemble diverse team for startup.\",\n",
        "  f\"8. Envision successful startup future.\"\n",
        "]"
      ],
      "metadata": {
        "id": "M1anh0IcnFnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#TOPIC_0 = \"task to investigate various gaming groups in Iran, following the Mahsa Movement in the second year. The gaming groups being investigated include the dark solidarity group, the dark trilogy, the dark quadrilogy, the regular people, the bright solidarity group, and the bright trilogy. The aim is to gather information about each group, analyze their characteristics, objectives, and any associated psychological syndromes. This information will then be presented in a table for easier understanding and comparison.\" # Replace this with your topic\n",
        "#RESEARCH_DOMAIN = \"Making Pitch deck file for the TOPIC \"\n",
        "\n",
        "if not (Question == \"\"):\n",
        "   TOPIC = Question\n",
        "else:\n",
        "   TOPIC = TOPIC_0\n",
        "\n",
        "main_variables_0 = {\n",
        "  'TOPIC': TOPIC,\n",
        "  'RESEARCH_DOMAIN' : RESEARCH_DOMAIN,\n",
        "  'PARAGRAPH':PARAGRAPH,\n",
        "}\n",
        "\n",
        "prompts_game_theory_1= [\n",
        "f\"suggest one Game Theory report Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "f\"1. Define the game structure for {TOPIC}: Identify the players, their strategies, and the possible outcomes of the game.\",\n",
        "f\"2. Represent the game for {TOPIC}: This can be done using a matrix or a tree. In the matrix representation, each cell represents a possible outcome of the game.\",\n",
        "f\"3. Analyze the game for {TOPIC}: Determine the best strategies for each player, the Nash equilibrium, and the potential outcomes of the game.\",\n",
        "f\"4. Make decisions based on the analysis for {TOPIC}: Use the results of the analysis to determine the best course of action for each player.\",\n",
        "f\"5. Implement the game for {TOPIC}: Write the code that simulates the game. This could involve creating a payoff matrix or a game tree, and writing functions to determine the best strategies and the Nash equilibrium.\",\n",
        "f\"6. Test the game for {TOPIC}: Run the game simulation and check if the results are as expected. This could involve checking if the Nash equilibrium is correct, or if the best strategies lead to the desired outcomes.\",\n",
        "f\"7. Optimize the game for {TOPIC}: If the results are not as expected, modify the game structure or the strategies, and run the simulation again.\",\n",
        "f\"8. Document the game for {TOPIC}: Write a report or a paper that explains the game, the results, and the conclusions.\",\n",
        "f\"9. Share the game for {TOPIC}: Share the results with others, and get feedback on the game.\",\n",
        "f\"10. Update the game for {TOPIC}: Based on the feedback, update the game structure or the strategies, and run the simulation again.\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "prompt_Word_Topic_game_theory_1 = [\n",
        "  f\"suggest one Game Theory report Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "  \"1.Define the game structure\",\n",
        "  \"2.Represent the game\",\n",
        "  \"3.Analyze the game\",\n",
        "  \"4.Make decisions based on the analysis\",\n",
        "  \"5.Implement the game\",\n",
        "  \"6.Test the game\",\n",
        "  \"7.Optimize the game\",\n",
        "  \"8.Document the game\",\n",
        "  \"9.Share the game\",\n",
        "  \"10.Update the game\"\n",
        "]"
      ],
      "metadata": {
        "id": "m1FFBjbOWkZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of prompts for generating academic papers\n",
        "\n",
        "Previous_CONTENT = '{Previous_CONTENT}'\n",
        "prompts_Academic_proposal_critique= [\n",
        "f\" As ChatGPT expert in the role of {role}, suggest one report Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "  f\"Critically evaluate the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'. Discuss any potential issues, limitations, or controversies in the ideas expressed.\",\n",
        "  f\"Identify the key points in the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Explain the context of the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Summarize the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Identify the research methodology used in the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Analyze the data collection and analysis methods used in the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Identify the research questions in the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Evaluate the conclusions drawn in the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Identify the limitations of the research in the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\",\n",
        "  f\"Identify any controversies or debates related to the research in the following content related to the topic '{TOPIC}': '{Previous_CONTENT}'.\"\n",
        "]\n",
        "\n",
        "prompt_Word_Topic_Academic_proposal_critique = [\n",
        "f\" As ChatGPT expert in the role of {role}, suggest one report Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "f\"1. Critically evaluate the following content related to the topic '': ''. Discuss any potential issues, limitations, or controversies in the ideas expressed.\",\n",
        " f\"2. Identify the key points in the following content related to the topic '': ''.\",\n",
        " f\"3. Explain the context of the following content related to the topic '': ''.\",\n",
        " f\"4. Summarize the following content related to the topic '': ''.\",\n",
        " f\"5. Identify the research methodology used in the following content related to the topic '': ''.\",\n",
        " f\"6. Analyze the data collection and analysis methods used in the following content related to the topic '': ''.\",\n",
        " f\"7. Identify the research questions in the following content related to the topic '': ''.\",\n",
        " f\"8. Evaluate the conclusions drawn in the following content related to the topic '': ''.\",\n",
        " f\"9. Identify the limitations of the research in the following content related to the topic '': ''.\",\n",
        " f\"10. Identify any controversies or debates related to the research in the following content related to the topic '': ''.\",\n",
        "]"
      ],
      "metadata": {
        "id": "RRmk8bTvloSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TOPIC_0 = \"task to investigate various gaming groups in Iran, following the Mahsa Movement in the second year. The gaming groups being investigated include the dark solidarity group, the dark trilogy, the dark quadrilogy, the regular people, the bright solidarity group, and the bright trilogy. The aim is to gather information about each group, analyze their characteristics, objectives, and any associated psychological syndromes. This information will then be presented in a table for easier understanding and comparison.\" # Replace this with your topic\n",
        "#RESEARCH_DOMAIN = \"Game Theory in psychology  field\" # Replace this with your research domain\n",
        "\n",
        "global docx_path,Pdf_Dir\n",
        "\n",
        "if not (Question == \"\"):\n",
        "\n",
        "    TOPIC  = Question\n",
        "\n",
        "else:\n",
        "    TOPIC  = TOPIC_0\n",
        "\n",
        "main_variables_0 = {\n",
        "   'TOPIC': TOPIC,\n",
        "   'RESEARCH_DOMAIN' : RESEARCH_DOMAIN\n",
        "}\n",
        "\n",
        "prompt_6Hat_Brainstorm = [\n",
        "f\"0. Suggest one Title less than 10 word for a report for 6 hat brainstorming game structure for {TOPIC}: Identify the players, their strategies, and the possible outcomes of the game.\",\n",
        "f\"1. Define the game structure for {TOPIC}: Identify the players, their strategies, and the possible outcomes of the game.\",\n",
        "f\"2. Represent the game for {TOPIC}: This can be done using a matrix or a tree. In the matrix representation, each cell represents a possible outcome of the game.\",\n",
        "f\"3. Analyze the game for {TOPIC}: Determine the best strategies for each player, the Nash equilibrium, and the potential outcomes of the game.\",\n",
        "f\"4. Make decisions based on the analysis for {TOPIC}: Use the results of the analysis to determine the best course of action for each player.\",\n",
        "f\"5. Implement the game for {TOPIC}: Write the code that simulates the game. This could involve creating a payoff matrix or a game tree, and writing functions to determine the best strategies and the Nash equilibrium.\",\n",
        "f\"6. Test the game for {TOPIC}: Run the game simulation and check if the results are as expected. This could involve checking if the Nash equilibrium is correct, or if the best strategies lead to the desired outcomes.\",\n",
        "f\"7. Optimize the game for {TOPIC}: If the results are not as expected, modify the game structure or the strategies, and run the simulation again.\",\n",
        "f\"8. Document the game for {TOPIC}: Write a report or a paper that explains the game, the results, and the conclusions.\",\n",
        "f\"9. Share the game for {TOPIC}: Share the results with others, and get feedback on the game.\",\n",
        "f\"10. Update the game for {TOPIC}: Based on the feedback, update the game structure or the strategies, and run the simulation again.\"\n",
        "]\n",
        "\n",
        "prompt_Word_Topic_6Hat_Brainstorm = [\n",
        "f\" Suggest one Title less than 10 word for a report for 6 hat brainstorming game structure for {TOPIC}: Identify the players, their strategies, and the possible outcomes of the game.\",\n",
        "\"1. Define game structure.\",\n",
        "\"2. Represent the game.\",\n",
        "\"3. Analyze the game.\",\n",
        "\"4. Make decisions based on analysis.\",\n",
        "\"5. Implement the game.\",\n",
        "\"6. Test the game.\",\n",
        "\"7. Optimize the game.\",\n",
        "\"8. Document the game.\",\n",
        "\"9. Share the game.\",\n",
        "\"10. Update the game.\"\n",
        "]"
      ],
      "metadata": {
        "id": "RFSHPUyJp-i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_chatdev = [\n",
        "f'0. Suggest one Title less than 10 word for a project tile for the topic which is :({TOPIC}) and description which is :({PARAGRAPH}). so you suggesting to to creat some code for doing this topic snd description as one project',\n",
        "f'if possible consider some ChatGPT project for creating the code for a project like chatdev which is available  at here :( https://github.com/OpenBMB/ChatDev )   to creat one prompt for the topic which is :({TOPIC}) and description  which is :({PARAGRAPH}). so you suggesting to to creat some code for doing this topic and description as one project'\n",
        "]\n",
        "\n",
        "prompts_Topic_chatdev = [\n",
        "f'0. Suggest one Title less than 10 word for a project tile for the topic which is :({TOPIC}) and description  which is :({PARAGRAPH}). so you suggesting to to creat some code for doing this topic snd description as one project',\n",
        "f'Suggested prompt for ChatDev code Writing Project:',\n",
        " ]"
      ],
      "metadata": {
        "id": "W30G7o27kNqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_Psychology = [\n",
        "   f\" 0. As a ChatGP {role}, suggest one report Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}).\",\n",
        "\n",
        "    f\"1. As a ChatGP {role}, Identify the problem in the relationship related to the topic: {TOPIC}.\\nDescription of the situation: {PARAGRAPH}\",\n",
        "    f\"2. As a ChatGP {role}, Define the objective you want to achieve by addressing the problem related to: {TOPIC}.\",\n",
        "    f\"3. As a ChatGP {role}, Gather all relevant information about the problem related to: {TOPIC}.\\nDescription of the situation: {PARAGRAPH}\",\n",
        "    f\"4. As a ChatGP {role}, Analyze the collected data to understand the root cause of the problem related to: {TOPIC}.\\nDescription of the situation: {PARAGRAPH}\",\n",
        "    f\"5. As a ChatGP {role}, Based on the analysis, generate potential solutions to address the problem related to: {TOPIC}.\",\n",
        "    f\"6. As a ChatGP {role}, Create a detailed action plan to implement the chosen solution for the problem related to: {TOPIC}.\",\n",
        "    f\"7. As a ChatGP {role}, Evaluate the effectiveness of the implemented solution for the problem related to: {TOPIC}.\"\n",
        "]\n",
        "\n",
        "prompt_Word_Topic_Psychology = [\n",
        "    f\" 0.As a ChatGP {role}, suggest one report Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}).\",\n",
        "\n",
        "    \"1. Identify the problem in the relationship related to the topic.\",\n",
        "    \"2. Define the objective you want to achieve by addressing the problem.\",\n",
        "    \"3. Gather all relevant information about the problem.\",\n",
        "    \"4. Analyze the collected data to understand the root cause of the problem.\",\n",
        "    \"5. Based on the analysis, generate potential solutions to address the problem.\",\n",
        "    \"6. Create a detailed action plan to implement the chosen solution for the problem.\",\n",
        "    \"7. Evaluate the effectiveness of the implemented solution for the problem.\"\n",
        "]"
      ],
      "metadata": {
        "id": "sfUrAfYzBHNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.phind.com/search?cache=rg4qjuf21n0wdb6i8yq24fsm\n",
        "\n",
        "\n",
        "\n",
        "prompts_story = [\n",
        " f\"0. As ChatGPT role: {role}, suggest a novel title in less than 15 words, based on the topic {TOPIC} and the description:({PARAGRAPH}).\",\n",
        " f\"1. As ChatGPT role: {role}, determine genre and subgenre based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"2. As ChatGPT role: {role}, develop story premise based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"3. As ChatGPT role: {role}, expand premise into blurb based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"4. As ChatGPT role: {role}, create outline from blurb based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"5. As ChatGPT role: {role}, develop style prompt based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"6. As ChatGPT role: {role}, use ChatGPT for introduction based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"7. As ChatGPT role: {role}, write scenes with ChatGPT based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"8. As ChatGPT role: {role}, redirect ChatGPT if needed based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"9. As ChatGPT role: {role}, regenerate content if unsatisfied based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"10. As ChatGPT role: {role}, reuse prompt space for consistency based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"11. As ChatGPT role: {role}, track major story actions based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"12. As ChatGPT role: {role}, review novel for consistency based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"13. As ChatGPT role: {role}, edit novel with ChatGPT based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"14. As ChatGPT role: {role}, write character dramatic life change story based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"15. As ChatGPT role: {role}, start story with character secret based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"16. As ChatGPT role: {role}, write secret reader story based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"17. As ChatGPT role: {role}, write innocent symbolizes darker story based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"18. As ChatGPT role: {role}, write discrimination experience story based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"19. As ChatGPT role: {role}, write cover up mistake story based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"20. As ChatGPT role: {role}, write stormy night story based on the topic {TOPIC} and the description:({PARAGRAPH})\",\n",
        " f\"21. As ChatGPT role: {role}, write villain protagonist story based on the topic {TOPIC} and the description:({PARAGRAPH})\"\n",
        "]\n",
        "\n",
        "prompts_story_topic = [\n",
        "\n",
        "f\"0. As ChatGPT role: {role}, suggest a novel title in less than 15 words, based on the topic {TOPIC} and the description:({PARAGRAPH}).\",\n",
        "\n",
        " \"1. Determine genre and subgenre\",\n",
        " \"2. Develop story premise\",\n",
        " \"3. Expand premise into blurb\",\n",
        " \"4. Create outline from blurb\",\n",
        " \"5. Develop style prompt\",\n",
        " \"6. Use ChatGPT for introduction\",\n",
        " \"7. Write scenes with ChatGPT\",\n",
        " \"8. Redirect ChatGPT if needed\",\n",
        " \"9. Regenerate content if unsatisfied\",\n",
        " \"10. Reuse prompt space for consistency\",\n",
        " \"11. Track major story actions\",\n",
        " \"12. Review novel for consistency\",\n",
        " \"13. Edit novel with ChatGPT\",\n",
        " \"14. Write character dramatic life change story\",\n",
        " \"15. Start story with character secret\",\n",
        " \"16. Write secret reader story\",\n",
        " \"17. Write innocent symbolizes darker story\",\n",
        " \"18. Write discrimination experience story\",\n",
        " \"19. Write cover up mistake story\",\n",
        " \"20. Write stormy night story\",\n",
        " \"21. Write villain protagonist story\"\n",
        "]"
      ],
      "metadata": {
        "id": "k0XR0sbJ4IQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I24Xo1CdBrX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title .\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of changes in the type of violence that continues in the aftermath of violence\"\n",
        "#TOPIC =f\"stop the WarDark Triad and Light Triad in the Middle East: A Critical Examination of their Influence and Impact on Iran\"+TOPIC\n",
        "\n",
        "#TOPIC = f\"If possible read this post ( https://www.geeky-gadgets.com/chatgpt-brainstorming-prompts/ ) and suggest  one python block code 10 prompt in the for on ( prompt=[The suggested prompt based of [var1] ). The prompt must have 10 line and at least three necessary value like TOPIC , FIELD_SUDY,and the third vale is your optional . Also you can have more variable or prompt for doing this post main goal which is brainstorming for one topic based of ChatGPT promptimg. This would be ChatGPT cheat sheet prompting.\"\n",
        "TOPIC = main_variables_0.get('TOPIC', 'Default Value')\n",
        "print ('TOPIC IS :', TOPIC)\n",
        "TOPIC_SENTENCE = Topic\n",
        "LANGUAGE = 'English'\n",
        "main_variables_0 = {\n",
        "      'TOPIC': f\"{Topic}\",\n",
        "      'RESEARCH_DOMAIN': f\"{RESEARCH_DOMAIN}\",\n",
        "      'PARAGRAPH': f\"{PARAGRAPH}\",\n",
        "      'PARAGRAPHS': f\"{PARAGRAPH}\" , # f\"{PARAGRAPHS}\",\n",
        "      'TOPIC_SENTENCE': TOPIC_SENTENCE,\n",
        "      'LANGUAGE': LANGUAGE,\n",
        "      'ABSTRACT_PARAGRAPH': ABSTRACT_PARAGRAPH,\n",
        "      'BIBLIOGRAPHY': BIBLIOGRAPHY,\n",
        "      'THEORY1': THEORY1,\n",
        "      'THEORY2': THEORY2,\n",
        "      'RESEARCH_QUESTIONS': RESEARCH_QUESTIONS,\n",
        "      'ACTION': ACTION,\n",
        "      'RESULT_PARAGRAPHS': RESULT_PARAGRAPHS,\n",
        "      'DATE': DATE,\n",
        "      'NUMBER_OF_DAYS_MONTHS_YEARS': NUMBER_OF_DAYS_MONTHS_YEARS,\n",
        "      'role' : f\"{role}\"\n",
        "  }"
      ],
      "metadata": {
        "id": "I484Df8ONQVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FhppuBUKBFyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0-xBKrKYBJdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "main_variables_0 = {\n",
        "     'TOPIC': f\"{TOPIC}\",\n",
        "     'RESEARCH_DOMAIN': f\"{RESEARCH_DOMAIN}\",\n",
        "     'PARAGRAPH': f\"{PARAGRAPH}\",\n",
        "     'PARAGRAPHS': f\"{PARAGRAPHS}\",\n",
        "     'TOPIC_SENTENCE': f\"{TOPIC_SENTENCE}\",\n",
        "     'LANGUAGE': f\"{LANGUAGE}\",\n",
        "     'ABSTRACT_PARAGRAPH': f\"{ABSTRACT_PARAGRAPH}\",\n",
        "     'BIBLIOGRAPHY': f\"{BIBLIOGRAPHY}\",\n",
        "     'THEORY1': f\"{THEORY1}\",\n",
        "     'THEORY2': f\"{THEORY2}\",\n",
        "     'RESEARCH_QUESTIONS': f\"{RESEARCH_QUESTIONS}\",\n",
        "     'ACTION': f\"{ACTION}\",\n",
        "     'RESULT_PARAGRAPHS': f\"{RESULT_PARAGRAPHS}\",\n",
        "     'DATE': f\"{DATE}\",\n",
        "     'NUMBER_OF_DAYS_MONTHS_YEARS': f\"{NUMBER_OF_DAYS_MONTHS_YEARS}\",\n",
        "     'role': f\"{role}\",\n",
        "     'project_example': f\"{project_example}\",\n",
        "     'context': f\"{context}\",\n",
        "     'instruction': f\"{instruction}\",\n",
        "     'output_format': f\"{output_format}\",\n",
        "     'specific_project_details': f\"{specific_project_details}\",\n",
        "     'X': f\"{X}\",\n",
        "     'project_manager': f\"{project_manager}\",\n",
        "     'report': f\"{report}\",\n",
        "     'important_themes': f\"{important_themes}\",\n",
        "     'project_name': f\"{project_name}\",\n",
        "     'stakeholder': f\"{stakeholder}\",\n",
        "     'resistant_stakeholder': f\"{resistant_stakeholder}\",\n",
        "     'task': f\"{task}\",\n",
        "     'Your_Email': f\"{Your_Email}\"\n",
        "}\n",
        "\n",
        "\n",
        "prompts_project_management = [\n",
        "   f\"0. As ChatGPT role: {role}, suggest a Project Management title in less than 15 words, based on the topic {TOPIC} and the description:({PARAGRAPH}).\",\n",
        "\n",
        "   f\"1. Come up with questions to ask during the meeting to start the project based on the topic {TOPIC} and the description:({PARAGRAPH} and {specific_project_details}).\",\n",
        "   f\"2. I need your assistance in designing a project risk assessment template based on the topic {TOPIC} and the description:({PARAGRAPH} and {specific_project_details}).\",\n",
        "   f\"3. Please provide a handoff and project conclusion checklist based on the topic {TOPIC} and the description:({PARAGRAPH} and {specific_project_details}).\",\n",
        "   f\"4. As a project manager {role}, I am responsible for launching a new e-commerce website {project_example}. The project based on the topic {TOPIC} and the description:({PARAGRAPH} and {specific_project_details}) is planned to span over 6 months and involves multiple departments like design, development, and marketing {context}. Please generate a comprehensive project plan that includes objectives, business case, scope, timeline, stakeholders, and success metrics {instruction} in a table format {output_format}.\",\n",
        "   f\"5. Generate a project timeline with milestones, start dates, end dates, objectives, tasks, and responsible parties for launching X project. Please provide and suggest milestones, their start and end dates, objectives, tasks, and the responsible party for each milestone in a table format.\",\n",
        "   f\"6. Identify potential risks associated with {specific_project_details} and suggest mitigation strategies.\",\n",
        "   f\"7. We are doing a project based on the topic {TOPIC} and the description:({PARAGRAPH} and {specific_project_details}) to do {X} and the below are the risks we have identified, is there anything that we have missed?\",\n",
        "   f\"8. Draft a project update email for stakeholders of {X} highlighting key achievements, current challenges, and next steps.\",\n",
        "   f\"9. Outline the key points from {report}. based on the topic {TOPIC} and the description:({PARAGRAPH} and {specific_project_details}) Focus on any mention of {important_themes} that you would like to specifically have as the main focus.\",\n",
        "   f\"10.based on the topic {TOPIC} and the description:({PARAGRAPH} and {specific_project_details}) Please simulate the dialogue and provide step by step guidance to help me {project_manager} best prepare when dealing with a resistant stakeholder. Context: I want to launch a new project {X} and a key stakeholder fails to see why it's important. Please provide pointers with potential concern and rationale presented in a table format? I want the rationale column to include 2-3 bullets each for talking points.\",\n",
        "   f\"11.based on the topic {TOPIC} and the description:({PARAGRAPH} and {specific_project_details}) What other information do you need to complete this task?\",\n",
        "   f\"12.based on the topic {TOPIC} and the description:({PARAGRAPH} and {specific_project_details}) Can you break that down a little further into more specific, step-by-step assignments?\",\n",
        "   f\"13.based on the topic {TOPIC} and the description:({PARAGRAPH} and {specific_project_details}) Analyze the resource requirements for {project_name} given the current scope and provide recommendations for optimal resource allocation.\"\n",
        "]\n",
        "\n",
        "prompts_project_management_title = [\n",
        "  f\"0. As ChatGPT role: {role}, suggest a Project Management title in less than 15 words, based on the topic {TOPIC} and the description:({PARAGRAPH}).\",\n",
        "\n",
        "  \"1. Come up with questions to ask during the meeting to start the project.\",\n",
        "  \"2. Design a project risk assessment template.\",\n",
        "  \"3. Provide a handoff and project conclusion checklist.\",\n",
        "  \"4. Create a comprehensive project plan for launching a new e-commerce website that spans over 6 months and involves multiple departments.\",\n",
        "  \"5. Generate a project timeline with milestones, start dates, end dates, objectives, tasks, and responsible parties.\",\n",
        "  \"6. Identify potential risks in the project and suggest mitigation strategies.\",\n",
        "  \"7. Review the identified risks in the project and check if any risks have been overlooked.\",\n",
        "  \"8. Draft a project update email for stakeholders highlighting key achievements, current challenges, and next steps.\",\n",
        "  \"9. Outline the key points from a report focusing on certain themes.\",\n",
        "  \"10. Simulate the dialogue and provide step by step guidance to prepare when dealing with a resistant stakeholder.\",\n",
        "  \"11. Ask for additional information required to complete a particular task.\",\n",
        "  \"12. Request a more detailed breakdown of a task into specific, step-by-step assignments.\",\n",
        "  \"13. Analyze the resource requirements for a project given its current scope and provide recommendations for optimal resource allocation.\"\n",
        "]"
      ],
      "metadata": {
        "id": "hGPql56EBVAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('\\n main variable is :', main_variables_0)\n",
        "folder_chatGPT = \"/content/ChatGPT_academic_paper\"\n",
        "#openai_api_0 = \"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\"\n",
        "#openai_api = \"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\"\n",
        "global TOPIC_CLASS,gdrive_fpath\n",
        "\n",
        "\n",
        "class TOPIC_CLASS:\n",
        "    def __init__(self):\n",
        "        self.category = {\n",
        "        \"perviuse_try_numner\" : 0,\n",
        "        \"perviuse_content\" : ['fist step'],\n",
        "        \"topic\" : f\"{TOPIC}\",\n",
        "        \"name\" : \"\",\n",
        "        \"main_variables\" : main_variables_0,\n",
        "        }\n",
        "\n",
        "    def saving(self,topic,category):\n",
        "\n",
        "       self.Topic_Name = topic\n",
        "       self.Topic_Name_abr = self.Topic_Name[:5]\n",
        "       self.save_folder_dest = gdrive_fpath +f\"{Topic_Name_abr}\"+\"_T/\"+category.replace(' ','_')\n",
        "\n",
        "TP= TOPIC_CLASS()\n",
        "#TOPIC = f\" \""
      ],
      "metadata": {
        "id": "QsstPoufBcYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text to image codes:"
      ],
      "metadata": {
        "id": "5DEF-umuDFNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/glide-text2im"
      ],
      "metadata": {
        "id": "GZvsn2_wQesY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qQfAeXC4E_dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "class ImageGenerator:\n",
        "   def __init__(self, prompt=\"\", batch_size=1, guidance_scale=3.0, upsample_temp=0.997):\n",
        "       self.prompt = prompt\n",
        "       self.batch_size = batch_size\n",
        "       self.guidance_scale = guidance_scale\n",
        "       self.upsample_temp = upsample_temp\n",
        "\n",
        "       self.has_cuda = th.cuda.is_available()\n",
        "       self.device = th.device('cpu' if not self.has_cuda else 'cuda')\n",
        "\n",
        "       # Create base model.\n",
        "       self.options = model_and_diffusion_defaults()\n",
        "       self.options['use_fp16'] = self.has_cuda\n",
        "       self.options['timestep_respacing'] = '100' # use 100 diffusion steps for fast sampling\n",
        "       self.model, self.diffusion = create_model_and_diffusion(**self.options)\n",
        "       self.model.eval()\n",
        "       if self.has_cuda:\n",
        "           self.model.convert_to_fp16()\n",
        "       self.model.to(self.device)\n",
        "       self.model.load_state_dict(load_checkpoint('base', self.device))\n",
        "\n",
        "       # Create upsampler model.\n",
        "       self.options_up = model_and_diffusion_defaults_upsampler()\n",
        "       self.options_up['use_fp16'] = self.has_cuda\n",
        "       self.options_up['timestep_respacing'] = 'fast27' # use 27 diffusion steps for very fast sampling\n",
        "       self.model_up, self.diffusion_up = create_model_and_diffusion(**self.options_up)\n",
        "       self.model_up.eval()\n",
        "       if self.has_cuda:\n",
        "           self.model_up.convert_to_fp16()\n",
        "       self.model_up.to(self.device)\n",
        "       self.model_up.load_state_dict(load_checkpoint('upsample', self.device))\n",
        "\n",
        "   def show_images(self, batch: th.Tensor):\n",
        "       \"\"\" Display a batch of images inline. \"\"\"\n",
        "       scaled = ((batch + 1)*127.5).round().clamp(0,255).to(th.uint8).cpu()\n",
        "       reshaped = scaled.permute(2, 0, 3, 1).reshape([batch.shape[2], -1, 3])\n",
        "       display(Image.fromarray(reshaped.numpy()))\n",
        "\n",
        "   def generate_image(self):\n",
        "       # Create the text tokens to feed to the model.\n",
        "       tokens = self.model.tokenizer.encode(self.prompt)\n",
        "       tokens, mask = self.model.tokenizer.padded_tokens_and_mask(\n",
        "           tokens, self.options['text_ctx']\n",
        "       )\n",
        "\n",
        "       # Create the classifier-free guidance tokens (empty)\n",
        "       full_batch_size = self.batch_size * 2\n",
        "       uncond_tokens, uncond_mask = self.model.tokenizer.padded_tokens_and_mask(\n",
        "           [], self.options['text_ctx']\n",
        "       )\n",
        "\n",
        "       # Pack the tokens together into model kwargs.\n",
        "       model_kwargs = dict(\n",
        "           tokens=th.tensor(\n",
        "               [tokens] * self.batch_size + [uncond_tokens] * self.batch_size, device=self.device\n",
        "           ),\n",
        "           mask=th.tensor(\n",
        "               [mask] * self.batch_size + [uncond_mask] * self.batch_size,\n",
        "               dtype=th.bool,\n",
        "               device=self.device,\n",
        "           ),\n",
        "       )\n",
        "\n",
        "       # Create a classifier-free guidance sampling function\n",
        "       def model_fn(x_t, ts, **kwargs):\n",
        "          half = x_t[: len(x_t) // 2]\n",
        "          combined = th.cat([half, half], dim=0)\n",
        "          model_out = self.model(combined, ts, **kwargs)\n",
        "          eps, rest = model_out[:, :3], model_out[:, 3:]\n",
        "          cond_eps, uncond_eps = th.split(eps, len(eps) // 2, dim=0)\n",
        "          half_eps = uncond_eps + self.guidance_scale * (cond_eps - uncond_eps)\n",
        "          eps = th.cat([half_eps, half_eps], dim=0)\n",
        "          return th.cat([eps, rest], dim=1)\n",
        "\n",
        "         # Sample from the base model.\n",
        "       self.model.del_cache()\n",
        "       samples = self.diffusion.p_sample_loop(\n",
        "          model_fn,\n",
        "          (full_batch_size, 3, self.options[\"image_size\"], self.options[\"image_size\"]),\n",
        "          device=self.device,\n",
        "          clip_denoised=True,\n",
        "          progress=True,\n",
        "          model_kwargs=model_kwargs,\n",
        "          cond_fn=None,\n",
        "      )[:self.batch_size]\n",
        "      self.model.del_cache()\n",
        "\n",
        "      # Show the output\n",
        "      self.show_images(samples)\n",
        "      # Upsample the 64x64 samples\n",
        "      tokens = self.model_up.tokenizer.encode(self.prompt)\n",
        "      tokens, mask = self.model_up.tokenizer.padded_tokens_and_mask(\n",
        "           tokens, self.options_up['text_ctx']\n",
        "       )\n",
        "\n",
        "       # Create the model conditioning dict.\n",
        "       model_kwargs = dict(\n",
        "           # Low-res image to upsample.\n",
        "           low_res=((samples+1)*127.5).round()/127.5 - 1,\n",
        "\n",
        "           # Text tokens\n",
        "           tokens=th.tensor(\n",
        "               [tokens] * self.batch_size, device=self.device\n",
        "           ),\n",
        "           mask=th.tensor(\n",
        "               [mask] * self.batch_size,\n",
        "               dtype=th.bool,\n",
        "               device=self.device,\n",
        "           ),\n",
        "       )\n",
        "\n",
        "\n",
        "      # Sample from the base model.\n",
        "       self.model_up.del_cache()\n",
        "      up_shape = (self.batch_size, 3, self.options_up[\"image_size\"], self.options_up[\"image_size\"])\n",
        "      up_samples = self.diffusion_up.ddim_sample_loop(\n",
        "          self.model_up,\n",
        "          up_shape,\n",
        "          noise=th.randn(up_shape, device=self.device) * self.upsample_temp,\n",
        "          device=self.device,\n",
        "          clip_denoised=True,\n",
        "          progress=True,\n",
        "          model_kwargs=model_kwargs,\n",
        "            cond_fn=None,\n",
        "      )[:self.batch_size]\n",
        "      self.model_up.del_cache()\n",
        "\n",
        "      # Show the output\n",
        "      self.show_images(up_samples)\n",
        "generator = ImageGenerator(\"Your prompt here\")\n",
        "generator.generate_image()"
      ],
      "metadata": {
        "id": "RHq5Y1OSOFQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "def text_to_image(content,prompt,doc,p,save_patch):\n",
        "  image_prompt = prompt # f\"creat image for the : prompt ((({prompt})) which made this content :((({content}))) and consider this is the official repost\"\n",
        "  negative_prompt = \"low quality, bad quality, no text in picture and verbal content\"\n",
        "  #image = pipeline(image_prompt).images[0] #\"An image of a squirrel in Picasso style\").images[0]\n",
        "  image = pipeline(prompt = image_prompt, negative_prompt=negative_prompt,prior_guidance_scale =1.0, height=768, width=768).images[0]\n",
        "  print ('\\n image_prompt is: ',image_prompt)\n",
        "  image\n",
        "  path = save_patch+f\"_\"+str(slugify(prompt[:15]))+\".png\"\n",
        "  image.save(path)\n",
        "  p = doc.add_picture(path)\n",
        "  return doc, image\n",
        "#doc = Document()\n",
        "# Add the generated text to the document\n",
        "#p = doc.add_paragraph(\"test\\n\\n\") #prompt_my)\n",
        "\n",
        "#doc,image = text_to_image(doc,f\"Repost_Type_Title For: \"+\"prompt_my\",doc,p,folder_path)\n",
        "#doc.save(folder_path+'/image.docx')\n",
        "#image"
      ],
      "metadata": {
        "id": "sEkW9FJYFfQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "class ImageGenerator:\n",
        "   def __init__(self, prompt=\"\", batch_size=1, guidance_scale=3.0, upsample_temp=0.997):\n",
        "       self.prompt = prompt\n",
        "       self.batch_size = batch_size\n",
        "       self.guidance_scale = guidance_scale\n",
        "       self.upsample_temp = upsample_temp\n",
        "\n",
        "       self.has_cuda = th.cuda.is_available()\n",
        "       self.device = th.device('cpu' if not self.has_cuda else 'cuda')\n",
        "\n",
        "       # Create base model.\n",
        "       self.options = model_and_diffusion_defaults()\n",
        "       self.options['use_fp16'] = self.has_cuda\n",
        "       self.options['timestep_respacing'] = '100' # use 100 diffusion steps for fast sampling\n",
        "       self.model, self.diffusion = create_model_and_diffusion(**self.options)\n",
        "       self.model.eval()\n",
        "       if self.has_cuda:\n",
        "           self.model.convert_to_fp16()\n",
        "       self.model.to(self.device)\n",
        "       self.model.load_state_dict(load_checkpoint('base', self.device))\n",
        "\n",
        "       # Create upsampler model.\n",
        "       self.options_up = model_and_diffusion_defaults_upsampler()\n",
        "       self.options_up['use_fp16'] = self.has_cuda\n",
        "       self.options_up['timestep_respacing'] = 'fast27' # use 27 diffusion steps for very fast sampling\n",
        "       self.model_up, self.diffusion_up = create_model_and_diffusion(**self.options_up)\n",
        "       self.model_up.eval()\n",
        "       if self.has_cuda:\n",
        "           self.model_up.convert_to_fp16()\n",
        "       self.model_up.to(self.device)\n",
        "       self.model_up.load_state_dict(load_checkpoint('upsample', self.device))\n",
        "\n",
        "   def show_images(self, batch: th.Tensor):\n",
        "       \"\"\" Display a batch of images inline. \"\"\"\n",
        "       scaled = ((batch + 1)*127.5).round().clamp(0,255).to(th.uint8).cpu()\n",
        "       reshaped = scaled.permute(2, 0, 3, 1).reshape([batch.shape[2], -1, 3])\n",
        "       display(Image.fromarray(reshaped.numpy()))\n",
        "      \n",
        "   def generate_image(self):\n",
        "      # Create the text tokens to feed to the model.\n",
        "      tokens = self.model.tokenizer.encode(self.prompt)\n",
        "      tokens, mask = self.model.tokenizer.padded_tokens_and_mask(\n",
        "          tokens, self.options['text_ctx']\n",
        "      )\n",
        "\n",
        "      # Create the classifier-free guidance tokens (empty)\n",
        "      full_batch_size = self.batch_size * 2\n",
        "      uncond_tokens, uncond_mask = self.model.tokenizer.padded_tokens_and_mask(\n",
        "          [], self.options['text_ctx']\n",
        "      )\n",
        "\n",
        "      # Pack the tokens together into model kwargs.\n",
        "      model_kwargs = dict(\n",
        "          tokens=th.tensor(\n",
        "              [tokens] * self.batch_size + [uncond_tokens] * self.batch_size, device=self.device\n",
        "          ),\n",
        "          mask=th.tensor(\n",
        "              [mask] * self.batch_size + [uncond_mask] * self.batch_size,\n",
        "              dtype=th.bool,\n",
        "              device=self.device,\n",
        "          ),\n",
        "      )\n",
        "\n",
        "      # Create a classifier-free guidance sampling function\n",
        "   def model_fn(x_t, ts, **kwargs):\n",
        "         half = x_t[: len(x_t) // 2]\n",
        "         combined = th.cat([half, half], dim=0)\n",
        "         model_out = self.model(combined, ts, **kwargs)\n",
        "         eps, rest = model_out[:, :3], model_out[:, 3:]\n",
        "         cond_eps, uncond_eps = th.split(eps, len(eps) // 2, dim=0)\n",
        "         half_eps = uncond_eps + self.guidance_scale * (cond_eps - uncond_eps)\n",
        "         eps = th.cat([half_eps, half_eps], dim=0)\n",
        "         return th.cat([eps, rest], dim=1)\n",
        "\n",
        "        # Sample from the base model.\n",
        "   self.model.del_cache()\n",
        "   samples = self.diffusion.p_sample_loop(\n",
        "         model_fn,\n",
        "         (full_batch_size, 3, self.options [\"image_size\"], self.options [\"image_size\"]),\n",
        "         device=self.device,\n",
        "         clip_denoised=True,\n",
        "         progress=True,\n",
        "         model_kwargs=model_kwargs,\n",
        "         cond_fn=None,\n",
        "   )[:self.batch_size]\n",
        "   self.model.del_cache()\n",
        "\n",
        "   # Show the output\n",
        "   self.show_images(samples)\n",
        "   # Upsample the 64x64 samples\n",
        "   tokens = self.model_up.tokenizer.encode(self.prompt)\n",
        "   tokens, mask = self.model_up.tokenizer.padded_tokens_and_mask(\n",
        "          tokens, self.options_up['text_ctx']\n",
        "   )\n",
        "   \n",
        "       # Create the model conditioning dict.\n",
        "      model_kwargs = dict(\n",
        "           # Low-res image to upsample.\n",
        "           low_res=((samples+1)*127.5).round()/127.5 - 1,\n",
        "\n",
        "           # Text tokens\n",
        "           tokens=th.tensor(\n",
        "               [tokens] * self.batch_size, device=self.device\n",
        "           ),\n",
        "           mask=th.tensor(\n",
        "               [mask] * self.batch_size,\n",
        "               dtype=th.bool,\n",
        "               device=self.device,\n",
        "           ),\n",
        "       )\n",
        "\n",
        "\n",
        "      # Sample from the base model.\n",
        "     self.model_up.del_cache()\n",
        "     up_shape = (self.batch_size, 3, self.options_up[\"image_size\"], self.options_up[\"image_size\"])\n",
        "     up_samples = self.diffusion_up.ddim_sample_loop(\n",
        "          self.model_up,\n",
        "          up_shape,\n",
        "          noise=th.randn(up_shape, device=self.device) * self.upsample_temp,\n",
        "          device=self.device,\n",
        "          clip_denoised=True,\n",
        "          progress=True,\n",
        "          model_kwargs=model_kwargs,\n",
        "            cond_fn=None,\n",
        "     )[:self.batch_size]\n",
        "     self.model_up.del_cache()\n",
        "\n",
        "      # Show the output\n",
        "     self.show_images(up_samples)\n",
        "generator = ImageGenerator(\"Your prompt here\")\n",
        "generator.generate_image()"
      ],
      "metadata": {
        "id": "kwItLBbeON2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Set the max_split_size_mb environment variable\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:8\"\n",
        "\n",
        "def process_data_0(input, output_size=(512, 512), scale_factors=(2, 2)):\n",
        "  if input.ndimension() == 4 and mode == \"nearest\":\n",
        "      output = torch.nn.functional.interpolate(input, size=output_size, mode='nearest')\n",
        "  elif input.ndimension() == 5 and mode == \"nearest\":\n",
        "      output = torch.nn.functional.interpolate(input, size=output_size, mode='nearest')\n",
        "\n",
        "  del input\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  output = output.cpu().numpy()\n",
        "  output = np.transpose(output, (1, 2, 0))\n",
        "  output = output * 255\n",
        "  return output\n",
        "\n",
        "def process_data(input, output_size=(512, 512), scale_factors=(2, 2)):\n",
        "  output = None # Initialize output to None\n",
        "  if input.ndimension() == 4 and mode == \"nearest\":\n",
        "      output = torch.nn.functional.interpolate(input, size=output_size, mode='nearest')\n",
        "  elif input.ndimension() == 5 and mode == \"nearest\":\n",
        "      output = torch.nn.functional.interpolate(input, size=output_size, mode='nearest')\n",
        "\n",
        "  del input\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  if output is not None:\n",
        "      output = output.cpu().numpy() # Move to CPU and convert to numpy\n",
        "      output = np.transpose(output, (1, 2, 0)) # Change the order of dimensions\n",
        "      output = output * 255 # Scale the values to [0, 255]\n",
        "  return output\n",
        "def text_to_image_4(content, prompt, doc, p, save_path):\n",
        "  image_prompt = prompt\n",
        "  negative_prompt = \"low quality, bad quality\"\n",
        "  image = pipeline(prompt=image_prompt, negative_prompt=negative_prompt, prior_guidance_scale=1.0, height=768, width=768).images[0]\n",
        "  print('\\n image_prompt is: ', image_prompt)\n",
        "\n",
        "  # Convert the PIL.Image object to a PyTorch tensor\n",
        "  image = ToTensor()(image)\n",
        "\n",
        "  processed_image = process_data(image)\n",
        "\n",
        "  del image\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  path = save_path + \"_\" + str(slugify(prompt[:15])) + \".png\"\n",
        "  cv2.imwrite(path, processed_image)\n",
        "\n",
        "  p = doc.add_picture(path)\n",
        "  return doc, image\n",
        "\n",
        "#response = Auto_Main().for_each_category(TOPIC_CLASS().category[\"main_variables\"])"
      ],
      "metadata": {
        "id": "jN4TDZUMeLDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_data(input, output_size=(512, 512), scale_factors=(2, 2)):\n",
        "  output = None # Initialize output to None\n",
        "  if input.ndimension() == 4 and mode == \"nearest\":\n",
        "      output = torch.nn.functional.interpolate(input, size=output_size, mode='nearest')\n",
        "  elif input.ndimension() == 5 and mode == \"nearest\":\n",
        "      output = torch.nn.functional.interpolate(input, size=output_size, mode='nearest')\n",
        "\n",
        "  del input\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  if output is not None:\n",
        "      output = output.cpu().numpy() # Move to CPU and convert to numpy\n",
        "      output = np.transpose(output, (1, 2, 0)) # Change the order of dimensions\n",
        "      output = output * 255 # Scale the values to [0, 255]\n",
        "  return output\n",
        "\n",
        "\n",
        "def text_to_image_3(content, prompt, doc, p, save_path):\n",
        " image_prompt = prompt\n",
        " negative_prompt = \"low quality, bad quality\"\n",
        " image = pipeline(prompt=image_prompt, negative_prompt=negative_prompt, prior_guidance_scale=1.0, height=768, width=768).images[0]\n",
        " print('\\n image_prompt is: ', image_prompt)\n",
        "\n",
        " # Convert the PIL.Image object to a PyTorch tensor\n",
        " image = ToTensor()(image)\n",
        "\n",
        " processed_image = process_data(image)\n",
        "\n",
        " # Check if processed_image is not empty\n",
        " if True : #processed_image is not None and not np.all(processed_image == 0):\n",
        "     path = save_path + \"_\" + str(slugify(prompt[:15])) + \".png\"\n",
        "     cv2.imwrite(path, processed_image)\n",
        "\n",
        "     p = doc.add_picture(path)\n",
        " else:\n",
        "     print(\"Warning: processed_image is empty or contains only zeros.\")\n",
        "\n",
        " return doc, image\n",
        "\n",
        "#response = Auto_Main().for_each_category(TOPIC_CLASS().category[\"main_variables\"])"
      ],
      "metadata": {
        "id": "PIFKDG2q2Jq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision.transforms import ToTensor\n",
        "import cv2\n",
        "import numpy as np\n",
        "from urllib.parse import quote\n",
        "\n",
        "def slugify(text):\n",
        "   return quote(text, safe='')\n",
        "\n",
        "\n",
        "def text_to_image_1(content, prompt, doc, p, save_path):\n",
        "   image_prompt = prompt\n",
        "   negative_prompt = \"low quality, bad quality\"\n",
        "   image = pipeline(prompt=image_prompt, negative_prompt=negative_prompt, prior_guidance_scale=1.0, height=768, width=768).images[0]\n",
        "   print('\\n image_prompt is: ', image_prompt)\n",
        "\n",
        "   # Convert the PIL.Image object to a PyTorch tensor\n",
        "   image = ToTensor()(image)\n",
        "\n",
        "   processed_image = process_data(image)\n",
        "\n",
        "   # Check if processed_image is not empty\n",
        "   if processed_image is not None and not np.all(processed_image == 0):\n",
        "       # Ensure the directory exists\n",
        "       os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "       path = save_path + \"_\" + str(slugify(prompt[:15])) + \".png\"\n",
        "       success = cv2.imwrite(path, processed_image)\n",
        "       if not success:\n",
        "           print(\"Failed to save image\")\n",
        "       else:\n",
        "           p = doc.add_picture(path)\n",
        "   else:\n",
        "       print(\"Warning: processed_image is empty or contains only zeros.\")\n",
        "\n",
        "   return doc, image\n",
        "\n",
        "#response = Auto_Main().for_each_category(TOPIC_CLASS().category[\"main_variables\"])"
      ],
      "metadata": {
        "id": "tHtmx8kvE5_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set the max_split_size_mb environment variable\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:1\"\n",
        "def text_to_image_2(content, prompt, doc, p, save_path):\n",
        " image_prompt = prompt\n",
        " negative_prompt = \"low quality, bad quality\"\n",
        " image = pipeline(prompt=image_prompt, negative_prompt=negative_prompt, prior_guidance_scale=1.0, height=768, width=768).images[0]\n",
        " print('\\n image_prompt is: ', image_prompt)\n",
        "\n",
        " # Convert the PIL.Image object to a PyTorch tensor\n",
        " image = ToTensor()(image)\n",
        "\n",
        " processed_image = process_data(image)\n",
        "\n",
        " # Check if processed_image is not empty\n",
        " if processed_image is not None and not np.all(processed_image == 0):\n",
        "     path = save_path + \"_\" + str(slugify(prompt[:15])) + \".png\"\n",
        "     cv2.imwrite(path, processed_image)\n",
        "\n",
        "     p = doc.add_picture(path)\n",
        " else:\n",
        "     print(\"Warning: processed_image is empty or contains only zeros.\")\n",
        "\n",
        " return doc, image\n",
        "\n",
        "#response = Auto_Main().for_each_category(TOPIC_CLASS().category[\"main_variables\"])"
      ],
      "metadata": {
        "id": "NdKgzZ4IHwh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import requests\n",
        "from urllib.request import urlopen\n",
        "from PIL import Image\n",
        "\n",
        "def text_to_image_openai(content, prompt, doc, p, save_path):\n",
        " image_prompt = prompt\n",
        " negative_prompt = \"negative prompts so are low quality, bad quality\"\n",
        " print('\\n image_prompt is: ', image_prompt)\n",
        "\n",
        " # Generate the image using OpenAI API\n",
        " response = client.images.generate(\n",
        "   model=\"dall-e-2\",\n",
        "   prompt= image_prompt+negative_prompt,\n",
        "   size=\"1024x1024\",\n",
        "   quality=\"standard\",\n",
        "   n=1)\n",
        "\n",
        " image_url = response.data[0].url\n",
        "\n",
        " # Download the image from the URL\n",
        " try:\n",
        "   url = urlopen(image_url)\n",
        "   f = Image.open(url)\n",
        "   f.verify() # verify that it is, in fact an image\n",
        " except Exception as e:\n",
        "   print(f\"Failed to open the image: {e}\")\n",
        "   return doc, None\n",
        "\n",
        " # Save the image\n",
        " path = save_path + \"_\" + str(slugify(prompt[:15])) + \".png\"\n",
        " f.save(path)\n",
        "\n",
        " # Display the image\n",
        " f.show()\n",
        "\n",
        " # Add the image to the document\n",
        " p = doc.add_picture(path)\n",
        " return doc, image\n",
        "\n",
        "#response = Auto_Main().for_each_category(TOPIC_CLASS().category[\"main_variables\"])"
      ],
      "metadata": {
        "id": "xkx-k2rkKF_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funstions for saving as PDF and DOCX :\n",
        "👇🌱"
      ],
      "metadata": {
        "id": "lI5PG0BNPrPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!sudo apt-get update\n",
        "#!sudo apt-get install libreoffice\n",
        "#!sudo apt-get install abiword\n",
        "#!sudo apt install libreoffice-writer"
      ],
      "metadata": {
        "id": "CfWk5ZiyJ1Dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2xiQx_camiB"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def convert_docx_to_pdf0(docx_path, pdf_path):\n",
        "  subprocess.call(['abiword', '--to=pdf', docx_path, '--to-dir', pdf_path])\n",
        "\n",
        "def convert_docx_to_pdf(docx_path, pdf_path):\n",
        " command = ['libreoffice', '--headless', '--convert-to', 'pdf', '--outdir', pdf_path, docx_path]\n",
        " subprocess.call(command)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "def add_text_with_bold(paragraph, text,p):\n",
        "   parts = text.split('**')\n",
        "   #doc.style('normal')\n",
        "   #p.style = doc.styles['Normal']\n",
        "\n",
        "   for i in range(len(parts)):\n",
        "       if i % 2 == 0:\n",
        "           p.add_run(parts[i])\n",
        "       else:\n",
        "           run = p.add_run(parts[i])\n",
        "           run.bold = True\n",
        "\n",
        "   return paragraph\n",
        "\n",
        "#add_text_with_bold(doc, 'This is some **bold** text',p)"
      ],
      "metadata": {
        "id": "xWvptzlbCPxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "\n",
        "def save_academic_paper(topic, prompt_my):\n",
        "  global docx_path,Pdf_Dir\n",
        "\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/Bussiness_Plane/\"\n",
        "\n",
        "  # Mount Google Drive\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "  else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "  Pdf_Dir= r\"/content/drive/My Drive/ChatGPT_Paper_wrting/Bussiness_Plane/\"\n",
        "  docx_path= f\"{folder_path}\"+\"FM\"+f\"{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  #doc.add_paragraph(prompt_my)\n",
        "  doc = add_text_with_bold(doc,0,prompt_my)\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "  return docx_path,Pdf_Dir"
      ],
      "metadata": {
        "id": "wTIqVCsP17gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import os , random\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "from docx.shared import Pt\n",
        "\n",
        "  # Mount Google Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "   # If not, mount the drive\n",
        "     drive.mount('/content/drive')\n",
        "else:\n",
        "     print(\"Drive is already mounted.\")\n",
        "\n",
        "\n",
        "def save_academic_paper_with_prompt_Tile(topic, prompt_my,image_prompt,contnet,try_number, category,make_photo,folder_path = \"/content/drive/My Drive/ChatGPT_Paper_wrting/All_Reports/\"):\n",
        "  global docx_path,Pdf_Dir\n",
        "  Repost_Type_Title = category\n",
        "  Repost_Type = category.replace(' ','_')\n",
        "\n",
        "\n",
        "  # Define the path to the folder in Google Drive\n",
        "  #folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+f\"{Repost_Type}/Title/\"\n",
        "  #folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/All_Reports/\"+f\"{topic}/{Repost_Type}/Title/\"\n",
        "  folder_path=folder_path+f\"{topic}/{Repost_Type}/Title/\"\n",
        "\n",
        "  Pdf_Dir = folder_path# r\"/content/drive/My Drive/ChatGPT_Paper_wrting/{Repost_Type}/Title/\"\n",
        "\n",
        "  topic = slugify(topic[:21])\n",
        "\n",
        "  if try_number == 0 :\n",
        "       docx_path= f\"{folder_path}\"+f\"{Repost_Type}_T_\"+f\"{topic}.docx\"\n",
        "       if os.path.isfile(docx_path):\n",
        "          try:\n",
        "             pass #os.remove (docx_path.replace('docx','pdf'))\n",
        "             pass #os.remove (docx_path)#\n",
        "\n",
        "          except:\n",
        "             print (\"the file for saving Exist and some error happened\")\n",
        "\n",
        "       topic = topic+str(random.randint(0,100))#os.remove(docx_path)\n",
        "       docx_path= f\"{folder_path}\"+f\"{Repost_Type}_T_\"+f\"{topic}.docx\"\n",
        "\n",
        "\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  #topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "\n",
        "    if try_number == 0 :\n",
        "\n",
        "       if os.path.isfile(docx_path):\n",
        "          try:\n",
        "             pass #os.remove (docx_path.replace('docx','pdf'))\n",
        "             pass #os.remove (docx_path)#\n",
        "\n",
        "          except:\n",
        "             print (\"the file for saving Exist and some error happened\")\n",
        "\n",
        "       #topic = topic+str(random.randint(0,100))#os.remove(docx_path)\n",
        "       #docx_path= f\"{folder_path}\"+f\"{Repost_Type}_T_\"+f\"{topic}.docx\"\n",
        "\n",
        "       doc = Document()\n",
        "       # Add the generated text to the document\n",
        "       p = doc.add_paragraph() #prompt_my)\n",
        "       # Add the generated text to the document\n",
        "       # Add the generated text to the document\n",
        "       p.style = doc.styles['Title']\n",
        "\n",
        "       p = add_text_with_bold(doc, f\"{Repost_Type_Title} For: \"+prompt_my,p)\n",
        "       p.style = doc.styles['Title']\n",
        "\n",
        "\n",
        "       # Check if CUDA is available\n",
        "       try:\n",
        "          if torch.cuda.is_available() and make_photo:\n",
        "             doc,image = text_to_image(contnet,f\"{Repost_Type_Title} For: \"+image_prompt,doc,p,folder_path)\n",
        "          elif make_photo:\n",
        "\n",
        "             doc,image = text_to_image_openai(doc,f\"{Repost_Type_Title} For: \"+image_prompt,doc,p,folder_path)\n",
        "       except errors as e:\n",
        "\n",
        "          print ('failed in running the Image creating by this error :',e)\n",
        "    else :\n",
        "\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "       doc = Document(docx_path)\n",
        "\n",
        "\n",
        "    # Add the generated text to the document\n",
        "    p = doc.add_paragraph() #prompt_my)\n",
        "    # Add the generated text to the document\n",
        "    # Add the generated text to the document\n",
        "    p.style = doc.styles['Subtitle']\n",
        "\n",
        "    font = p.style.font\n",
        "    font.name = 'Arial'\n",
        "    font.size = Pt(15)\n",
        "    p = add_text_with_bold(doc,prompt_my,p)\n",
        "\n",
        "    # Check if CUDA is available\n",
        "    try:\n",
        "          if torch.cuda.is_available() and make_photo:\n",
        "             doc,image = text_to_image(contnet,f\"{Repost_Type_Title} For: \"+image_prompt,doc,p,folder_path)\n",
        "          elif make_photo:\n",
        "\n",
        "             doc,image = text_to_image_openai(doc,f\"{Repost_Type_Title} For: \"+image_prompt,doc,p,folder_path)\n",
        "    except errors as e:\n",
        "\n",
        "          print ('failed in running the Image creating by this error :',e)\n",
        "\n",
        "    #p.style = doc.styles['Subtitle']\n",
        "\n",
        "  else:\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "    # Add the generated text to the document\n",
        "    p = doc.add_paragraph() #prompt_my)\n",
        "    # Add the generated text to the document\n",
        "    # Add the generated text to the document\n",
        "    p.style = doc.styles['Title']\n",
        "\n",
        "\n",
        "    p = add_text_with_bold(doc, f\"{Repost_Type_Title} For:\"+prompt_my,p)\n",
        "    p.style = doc.styles['Title']\n",
        "    #doc,image = text_to_image(contnet,f\"{Repost_Type_Title} For: \"+prompt_my,doc,p,folder_path)\n",
        "\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p = doc.add_paragraph()#contnet)\n",
        "  p.style = doc.styles['Normal']\n",
        "\n",
        "  p = add_text_with_bold(doc,contnet,p)\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "  return docx_path,Pdf_Dir\n",
        "\n",
        "def save_academic_paper_with_prompt(topic, prompt_my,image_prompt,contnet,try_number,category, make_photo,folder_path = \"/content/drive/My Drive/ChatGPT_Paper_wrting/All_Reports/\"):\n",
        "  global docx_path_prompt,Pdf_Dir\n",
        "\n",
        "  Repost_Type_Title = category\n",
        "  Repost_Type = category.replace(' ','_')\n",
        "\n",
        "  # Define the path to the folder in Google Drive\n",
        "  #folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+f\"{Repost_Type}/Prompt/\"\n",
        "  #folder_path = r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+f\"All_Reports/{topic}/{Repost_Type}/Prompt/\"\n",
        "  folder_path=folder_path+f\"{topic}/{Repost_Type}/Prompt/\"\n",
        "\n",
        "  Pdf_Dir = folder_path# r\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+f\"{Repost_Type}/Prompt/\"\n",
        "  topic = slugify(topic[:21])\n",
        "  docx_path_prompt= f\"{folder_path}\"+f\"{Repost_Type}_PR_\"+f\"{topic}.docx\"\n",
        "\n",
        "\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  #topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "    # If the DOCX file exists, open it\n",
        "  if try_number == 0 :\n",
        "       try:\n",
        "          os.remove(docx_path_prompt)\n",
        "          os.romove (docx_path_prompt.replace('docx','pdf'))\n",
        "       except:\n",
        "          pass\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path_prompt):\n",
        "    # If the DOCX file exists, open it\n",
        "        #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    if try_number == 0 :\n",
        "\n",
        "       topic = topic+str(random.randint(0,100))#os.remove(docx_path)\n",
        "       docx_path_prompt= f\"{folder_path}\"+f\"{Repost_Type}_PR_\"+f\"{topic}.docx\"\n",
        "       if os.path.isfile(docx_path):\n",
        "          try:\n",
        "             os.remove (docx_path_prompt.replace('docx','pdf'))\n",
        "             os.remove (docx_path_prompt)#\n",
        "\n",
        "          except errors as e:\n",
        "\n",
        "             print (\"the file for saving Exist and some error happened\")\n",
        "       doc = Document()\n",
        "       # Add the generated text to the document\n",
        "       p = doc.add_paragraph()#prompt_my)\n",
        "       # Add the generated text to the document\n",
        "       # Add the generated text to the document\n",
        "       p.style = doc.styles['Title']\n",
        "       p = add_text_with_bold(doc,f\"{Repost_Type_Title} For:\"+ prompt_my,p)\n",
        "\n",
        "       p.style = doc.styles['Title']\n",
        "\n",
        "\n",
        "\n",
        "    else :\n",
        "\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "       doc = Document(docx_path_prompt)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Add the generated text to the document\n",
        "    p = doc.add_paragraph(prompt_my)\n",
        "    # Add the generated text to the document\n",
        "    # Add the generated text to the document\n",
        "    p.style = doc.styles['Subtitle']\n",
        "\n",
        "    font = p.style.font\n",
        "    font.name = 'Arial'\n",
        "    font.size = Pt(15)\n",
        "    p = add_text_with_bold(doc,prompt_my,p)\n",
        "    p.style = doc.styles['Subtitle']\n",
        "\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "    # Add the generated text to the document\n",
        "    p = doc.add_paragraph()#prompt_my)\n",
        "    # Add the generated text to the document\n",
        "    # Add the generated text to the document\n",
        "    p.style = doc.styles['Title']\n",
        "    p = add_text_with_bold(doc,f\"{Repost_Type_Title} For:\"+ prompt_my,p)\n",
        "\n",
        "    p.style = doc.styles['Title']\n",
        "\n",
        "  #p = add_text_with_bold(doc,prompt_my,p)  # Save the document\n",
        "  doc.save(docx_path_prompt)\n",
        "\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p = doc.add_paragraph()#contnet)\n",
        "  p.style = doc.styles['Normal']\n",
        "\n",
        "  p = add_text_with_bold(doc,contnet,p) # Save the document\n",
        "  doc.save(docx_path_prompt)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  #convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "  return docx_path,Pdf_Dir\n",
        "\n",
        "#save_academic_paper_with_prompt_Tile('title','**prmpt_mt** is ','contetn',0)\n",
        "#save_academic_paper_with_prompt('title','**prmpt_mt**','content ',0)"
      ],
      "metadata": {
        "id": "FXS5P81E2rId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# @title\n",
        "# conect to [Mega.z](https://mega.nz/) cloud for storage files based ot this page:\n",
        "\n",
        "https://colab.research.google.com/github/sudo-ken/Mega-to-Google-Drive/blob/master/Transfer_files_from_Mega_to_Google_Drive.ipynb#scrollTo=Vgh1xlQYGZCO"
      ],
      "metadata": {
        "id": "x7XWsP_amNqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# %cd '/content/'\n",
        "# !git clone https://github.com/jeroenmeulenaar/python3-mega.git\n",
        "# !(cd python3-mega; pip install urlobject pycrypto)\n",
        "\n",
        "# import os\n",
        "# os.chdir('python3-mega')\n",
        "# from mega import Mega\n",
        "# os.chdir('../')\n",
        "# m = Mega.from_ephemeral()\n",
        "\n",
        "# !git clone https://github.com/odwyersoftware/mega.py\n",
        "# %cd mega.py\n",
        "# !python setup.py install\n",
        "%cd '/content/'\n",
        "\n",
        "!rm -rf '/content/yoloOnGoogleColab'\n",
        "#!git clone https://github.com/CAR-Driving/yoloOnGoogleColab"
      ],
      "metadata": {
        "id": "L436PiVNmQog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# @markdown <center><h3>Input Your Mega ID</h3></center><br>\n",
        "from functools import wraps\n",
        "import errno\n",
        "import os\n",
        "import signal\n",
        "import subprocess\n",
        "import shlex\n",
        "\n",
        "\n",
        "class TimeoutError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def timeout(seconds=10, error_message=os.strerror(errno.ETIME)):\n",
        "    def decorator(func):\n",
        "        def _handle_timeout(signum, frame):\n",
        "            raise TimeoutError(error_message)\n",
        "\n",
        "        def wrapper(*args, **kwargs):\n",
        "            signal.signal(signal.SIGALRM, _handle_timeout)\n",
        "            signal.alarm(seconds)\n",
        "            try:\n",
        "                result = func(*args, **kwargs)\n",
        "            finally:\n",
        "                signal.alarm(0)\n",
        "            return result\n",
        "\n",
        "        return wraps(func)(wrapper)\n",
        "\n",
        "    return decorator\n",
        "\n",
        "\n",
        "if not os.path.exists(\"/root/.ipython/ocr.py\"):\n",
        "    from subprocess import run\n",
        "    from shlex import split\n",
        "\n",
        "    shellCmd = \"wget -qq https://raw.githubusercontent.com/biplobsd/OneClickRun/master/res/ocr.py \\\n",
        "                    -O /root/.ipython/ocr.py\"\n",
        "    run(split(shellCmd))\n",
        "from ocr import runSh\n",
        "\n",
        "@timeout(10)\n",
        "def runShT(args):\n",
        "    return runSh(args, output=True)\n",
        "\n",
        "\n",
        "# MEGAcmd installing\n",
        "if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "    print(\"Installing MEGA ...\")\n",
        "    runSh('sudo apt-get -y update')\n",
        "    runSh('sudo apt-get -y install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https')\n",
        "    runSh('sudo curl -sL -o /var/cache/apt/archives/MEGAcmd.deb https://mega.nz/linux/MEGAsync/Debian_9.0/amd64/megacmd-Debian_9.0_amd64.deb', output=True)\n",
        "    runSh('sudo dpkg -i /var/cache/apt/archives/MEGAcmd.deb', output=True)\n",
        "    print(\"MEGA is installed.\")\n",
        "else:\n",
        "    !pkill mega-cmd\n",
        "\n",
        "# INPUT YOUR MEGA ID\n",
        "\n",
        "USERNAME = 'kayeyoc231@llubed.com'  # @param {type:\"string\"}\n",
        "PASSWORD = \"ss123456\"  # @param {type:\"string\"}\n",
        "if not (USERNAME == \"\" or PASSWORD == \"\"):\n",
        "    try:\n",
        "        runShT(f\"mega-login {USERNAME} {PASSWORD}\")\n",
        "        print (\"megazn login has done successfully\")\n",
        "    except TimeoutError:\n",
        "        runSh('mega-whoami', output=True)\n",
        "else:\n",
        "    print(\"Please Input your Mega IDs.\")\n",
        "# @markdown *After signing in, use the above cell(Main Cell) to transfer files from Mega to GDrive using the transfer quota of your Mega Pro Account*"
      ],
      "metadata": {
        "id": "uqYuzvYFoMIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#!rm -rf '/content/ChatGPT_academic_paper'\n",
        "!mkdir '/content/ChatGPT_academic_paper'\n",
        "%cd '/content/ChatGPT_academic_paper'\n",
        "!echo 't' >> t.txt\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "import errno, os\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "import shlex\n",
        "from ocr import runSh\n",
        "import re\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "# copy subdirectory example\n",
        "fromDirectory = '/content/ChatGPT_academic_paper/'\n",
        "toDirectory = '/content/gdrive/My Drive/yolo_car_database/'\n",
        "\n",
        "runSh('mega-cd /' )\n",
        "runSh(' mega-mkdir ChatGPT_academic_paper ')\n",
        "runSh(' mega-ls ')\n",
        "runSh('mega-cd ChatGPT_academic_paper ')\n",
        "\n",
        "# copy_tree(fromDirectory, toDirectory)\n",
        "def uplaod_mega_nz(root,cloude='mega',title1=''):\n",
        "  if (cloude=='mega'):\n",
        "  #  from mega import Mega\n",
        "  #  mega = Mega()\n",
        "  #  email = 'woraqofa@ivyandmarj.com'\n",
        "  #  password = 'feripas800@wgraj.com'\n",
        "  #  m = mega.login(email, password)\n",
        "  #  # login using a temporary anonymous account\n",
        "  #  m = mega.login()\n",
        "  #  quota = m.get_quota()\n",
        "  #  # specify unit output kilo, mega, gig, else bytes will output\n",
        "  #  space = m.get_storage_space(kilo=True)\n",
        "  #  m.create_folder('yolo_car_database/'+title1+'/')\n",
        "  #  folder = m.find('yolo_car_database/'+title1+'/')\n",
        "   # m.upload('myfile.doc', folder[0])\n",
        "  #  run_command('mega-cd ~ && mega-mkdir Yolo_car_database && mega-cd Yolo_car_database && mega-put '+ root+'/* . ')\n",
        "\n",
        "   runSh('mega-cd ChatGPT_academic_paper' + title1 + '/')\n",
        "   runSh('mega-put '+ root+' . ')\n",
        "   runSh(' mega-ls')\n",
        "\n",
        "   for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        print (files)\n",
        "          # m.upload(os.path.join(path, name), folder[0])\n",
        "   # public_exported_web_link = m.export('myfile.doc')\n",
        "   # public_exported_web_link = m.export('my_mega_folder/my_sub_folder_to_share')\n",
        "\n",
        "  if (cloude=='google_drive'):\n",
        "     run_command('mkdir '+root+'/')\n",
        "     for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        # print ('cp -r \"'+os.path.join(path, name)+'\" '+'\"/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/\"')\n",
        "        # print (os.path.join(path, change_name(name)))\n",
        "        # os.rename(os.path.join(path, name), os.path.join(path, change_name(name)))\n",
        "        run_command('cp -r  \"'+os.path.join(path, name)+'\" '+'\"/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/\"')\n",
        "     try:\n",
        "        copy_tree(root,'/content/gdrive/My Drive/ChatGPT_academic_paper/' + title1 + '/')\n",
        "     except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            # raise #\n",
        "            i=0\n",
        "def change_file_name(root):\n",
        "  for path, subdirs, files in os.walk( root):\n",
        "      for name in files:\n",
        "        print ('filename is: \"'+os.path.join(path, name))\n",
        "        print (os.path.join(path, change_name(name)))\n",
        "        os.rename(os.path.join(path, name), os.path.join(path, change_name(name)))\n",
        "\n",
        "def run_command(cmd):\n",
        "    with Popen(shlex.split(cmd), stdout=PIPE, bufsize=1, universal_newlines=False) as p:\n",
        "        while True:\n",
        "            line = p.stdout.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            print(line)\n",
        "        exit_code = p.poll()\n",
        "    return exit_code\n",
        "def change_name(name):\n",
        "    name_file = ''.join(name)\n",
        "    name_file = name_file.replace(\" \", \"_\")\n",
        "    name_file = name_file.replace(\"'\", \"_\")\n",
        "    name_file = name_file.replace(\"\\n\", \"\")\n",
        "    name_file = name_file.replace(\"\\t\", \"\")\n",
        "    name_file = name_file.replace(\"!\", \"\")\n",
        "    name_file = name_file.replace(\"-\", \"\")\n",
        "    name_file = name_file.replace(\"$\", \"\")\n",
        "    name_file = re.sub(r'[\\\\/*?:\"<>|]',\"\",name_file)\n",
        "    return name_file\n",
        "def MegaZN_upload_file(command):\n",
        "    # command_title=re.split('([^a-zA-Z0-9])',command)\n",
        "    command_title_1 = re.split('([^a-zA-Z0-9])', command)\n",
        "    command_title = ''.join(command_title_1)\n",
        "    command_title=change_name(command_title)\n",
        "\n",
        "\n",
        "    # call_args = ' youtube-dl --match-title ' + ' \"'+command_title_1[0]+ '\" ' + '\"ytsearch10\":'+'\"'+command+ '\" '+\"--external-downloader-args   '-ss 00:00:03 -t 00:03:08' --write-info-json --write-annotation --write-thumbnail --write-sub -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4'\"\n",
        "    #call_args = ' youtube-dl --match-title ' + ' \"'+command_title_1[0]+ '\" ' + '\"ytsearch100\":'+'\"'+command+ '\" '+\"--playlist-end 3  --external-downloader-args   '-ss 00:00:03 -t 00:03:08' --write-info-json --write-annotation --write-thumbnail --write-sub -f 'best[ext=mp4,height<=1080]+best[filesize<100M]' \"\n",
        "\n",
        "    # call_args = call_args.split() # because call takes a list of strings\n",
        "    # print (call_args)\n",
        "    # call(call_args)\n",
        "    # os.chdir(\"/content/yolo_car_database\")\n",
        "    # run_command('cd \"/content/yolo_car_database\"')\n",
        "    # run_command(call_args)\n",
        "    # os.system(\"cp --recursive '/content/yolo_car_database' '/content/gdrive/My Drive/yolo_car_databe\")\n",
        "    # os.system('pwd && ls ')\n",
        "    # copy_tree(fromDirectory, toDirectory)\n",
        "    # p = Popen(shlex.split(call_args), bufsize=1, universal_newlines=True)\n",
        "    run_command('mkdir /content/ChatGPT_academic_paper/'+command_title)\n",
        "\n",
        "    os.chdir( '/content/ChatGPT_academic_paper/'+command_title+'/')\n",
        "    #run_command(call_args)\n",
        "    # copy_tree('/content/yolo_car_database/'+command_title+'/', '/content/gdrive/My Drive/yolo_car_database/'+command_title+'/')\n",
        "    change_file_name('/content/ChatGPT_academic_paper/'+command_title+'/')\n",
        "    uplaod_mega_nz('/content/ChatGPT_academic_paper/'+command_title+'/','mega',command_title)\n",
        "    try:\n",
        "        # call(call_args)\n",
        "        # run_command('mkdir /content/yolo_car_database/'+command_title)\n",
        "        # os.chdir( '/content/yolo_car_database/'+command_title+'/')\n",
        "        # run_command(call_args)\n",
        "        # copy_tree('/content/yolo_car_database/'+command_title+'/', toDirectory)\n",
        "\n",
        "        # print (call_args)\n",
        "        pp=0\n",
        "\n",
        "    except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            raise # re-raise exception if a different error occurred\n",
        "\n",
        "    # return p.poll()\n",
        "\n",
        "# !wget https://github.com/spectrico/car-make-model-classifier-yolo3-python/blob/master/labels.txt\n",
        "\n",
        "i=0\n",
        "#for line in open('/content/yoloOnGoogleColab/car_type_label.txt','r').readlines():\n",
        "    #print (line)\n",
        "    #try:\n",
        "      #Youtube_download_video(line)\n",
        "\n",
        "    #except OSError as e: # this would be \"except OSError, e:\" before Python 2.6\n",
        "        #if e.errno != errno.ENOENT: # errno.ENOENT = no such file or directory\n",
        "            #i=1 # re-raise exception if a different error occurred\n",
        "    #i=i+1\n",
        "# !cp '/content/yolo_car_database' \"gdrive/My Drive/yolo_car_databe\""
      ],
      "metadata": {
        "id": "8Fx5M6zXmTAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pwd\n",
        "%cd '/content/'\n",
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "from docx import Document\n",
        "from django.utils.text import slugify\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "def save_academic_paper_with_prompt_megazn(topic, prompt_my,contnet, category):\n",
        "  # Define the path to the folder in Google Drive\n",
        "  folder_path = r\"/content/ChatGPT_academic_paper/\"\n",
        "\n",
        "  Pdf_Dir= r\"/content/ChatGPT_academic_paper/\"\n",
        "  docx_path= f\"{folder_path}{topic}.docx\"\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "  # If the folder doesn't exist, create it\n",
        "    os.mkdir(folder_path)\n",
        "\n",
        "\n",
        "  # Replace spaces in the topic with underscores\n",
        "  #topic = topic[:12].replace(\" \", \"_\")\n",
        "  topic = slugify(topic)\n",
        "\n",
        "  # Define the path to the DOCX file in the folder\n",
        "\n",
        "\n",
        "  # Check if the DOCX file exists\n",
        "  if os.path.isfile(docx_path):\n",
        "    # If the DOCX file exists, open it\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"#+str(random.randint(0,9))+\".docx\"\n",
        "    doc = Document(docx_path)\n",
        "  else:\n",
        "\n",
        "    #docx_path = f\"{folder_path}{topic}.docx\"\n",
        "    #print(docx_path)\n",
        "     # If the DOCX file doesn't exist, create a new Document object\n",
        "    doc = Document()\n",
        "\n",
        "  # Add the generated text to the document\n",
        "  p = doc.add_paragraph(prompt_my)\n",
        "  # Add the generated text to the document\n",
        "  # Add the generated text to the document\n",
        "  p.style = doc.styles['Heading 2']\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Revert the style of the paragraph back to 'Normal'\n",
        "  p = doc.add_paragraph(contnet)\n",
        "  p.style = doc.styles['Normal']\n",
        "\n",
        "  # Save the document\n",
        "  doc.save(docx_path)\n",
        "\n",
        "  # Convert the DOCX file to a PDF\n",
        "  convert_docx_to_pdf(docx_path,Pdf_Dir)\n",
        "\n",
        "  os.chdir(folder_path)\n",
        "\n",
        "    # copy_tree('/content/yolo_car_database/'+command_title+'/', '/content/gdrive/My Drive/yolo_car_database/'+command_title+'/')\n",
        "\n",
        "  uplaod_mega_nz('/content/ChatGPT_Paper_wrting/')\n",
        "  uplaod_mega_nz('/content/ChatGPT_Paper_wrting/','google_drive')\n",
        "  return docx_path,Pdf_Dir"
      ],
      "metadata": {
        "id": "nv2vAOr8sskq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#save_academic_paper(\"Persian_\"+'topic','\\n**'+'choice_translated_prompt'+'**\\n'+\"choice_translated\")\n",
        "topic = TOPIC[:20].replace(\" \", \"_\")\n",
        "topic = slugify(TOPIC[:-5])\n",
        "docx_path = f\"{topic}.docx\"\n",
        "\n",
        "print(docx_path)"
      ],
      "metadata": {
        "id": "a76qNIRHs_gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running the ChatDev codes based of prompt: 👇🌹🔥🐢🌱"
      ],
      "metadata": {
        "id": "jzbhUax1mMPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib.util\n",
        "import pkg_resources\n",
        "from pkg_resources import DistributionNotFound, VersionConflict\n",
        "import pip\n",
        "import os\n",
        "\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def runSh_(command):\n",
        "   result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, text=True)\n",
        "\n",
        "   if result.returncode != 0:\n",
        "       print(f\"Error: {result.stderr}\")\n",
        "   else:\n",
        "       print(f\"Output: {result.stdout}\")\n",
        "\n",
        "   return result.stdout\n",
        "\n",
        "def runSh(command):\n",
        "  result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, text=True)\n",
        "\n",
        "  if result.returncode != 0:\n",
        "      print(f\"Error: {result.stderr}\")\n",
        "  else:\n",
        "      print(f\"Output: {result.stdout}\")\n",
        "\n",
        "  return result.stdout, result.stderr\n",
        "def check_and_install_requirements(requirements_file_path='', additional_modules=[]):\n",
        "   # If a requirements file path is provided, check and install the requirements\n",
        "   if requirements_file_path:\n",
        "     # Ensure the file exists\n",
        "     if not os.path.isfile(requirements_file_path):\n",
        "         print(f\"The file {requirements_file_path} does not exist.\")\n",
        "         return\n",
        "\n",
        "     # Parse the requirements file\n",
        "     with open(requirements_file_path, 'r') as file:\n",
        "         requirements = file.readlines()\n",
        "\n",
        "     # Iterate over each requirement\n",
        "     for requirement in requirements:\n",
        "         package_name = requirement.strip() # remove leading/trailing white spaces\n",
        "\n",
        "         # Check if the package is installed\n",
        "         package_name_1 = package_name.split('=')\n",
        "         print( '\\n Modules are :',package_name, 'and module_1 is :',f'{package_name_1[0]}' )\n",
        "\n",
        "         spec = importlib.util.find_spec(package_name_1[0])\n",
        "         if spec is None:\n",
        "             print(f\"{package_name} is not installed. Installing...\")\n",
        "\n",
        "             # Install the package\n",
        "             pip.main(['install', package_name])\n",
        "         else:\n",
        "             print(f\"{package_name} is installed.\")\n",
        "\n",
        "   # Iterate over each additional module\n",
        "   for module in additional_modules:\n",
        "     # Check if the module is installed\n",
        "     print( '\\n Modules are :',module)\n",
        "\n",
        "   # Iterate over each additional module\n",
        "   for module in additional_modules:\n",
        "     # Check if the module is installed\n",
        "     module_1 = module.split('=')\n",
        "     print( '\\n Modules are :',module, 'and module_1 is :',f'{module_1[0]}' )\n",
        "     spec = importlib.util.find_spec(f'{module_1[0]} ')\n",
        "     if spec is None:\n",
        "         print(f\"{module} is not installed. Installing...\")\n",
        "\n",
        "         # Install the module\n",
        "         #pip.main(['install', f\"{module}\"])\n",
        "         runSh(f'python3 -m pip install {module} ')\n",
        "     else:\n",
        "         print(f\"{module} is installed.\")\n",
        "\n",
        "#check_and_install_requirements('', ['module1', 'module2'])\n",
        "\n",
        "#check_and_install_requirements('path/to/requirements.txt', ['module1', 'module2'])"
      ],
      "metadata": {
        "id": "uN6Q-cCr8ESc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from subprocess import Popen, PIPE\n",
        "import os, glob, shutil\n",
        "import glob\n",
        "\n",
        "\n",
        "\n",
        "class ChatDev_Run():\n",
        "\n",
        "\n",
        "   def copy_folder_to_destination(self,src_folder, dst_folder,folder_name):\n",
        "      src_folder = os.path.abspath(src_folder)\n",
        "      dst_folder = os.path.abspath(dst_folder)\n",
        "      for folder in glob.glob(f'{src_folder}/*{folder_name}*/**/**/**', recursive=True):\n",
        "         if os.path.isdir(folder):\n",
        "           dst_folder_path = os.path.join(dst_folder, os.path.relpath(folder, src_folder))\n",
        "           shutil.copytree(folder, dst_folder_path,dirs_exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "   def ChatDev_Doit (self,Prompt,Topic_Name,dst,save_results_Dir):\n",
        "\n",
        "       #Current_Dir = os.getcwd()\n",
        "       #dst = '/content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev_projec/'\n",
        "\n",
        "       #Check Chat dev is installed or not\n",
        "       if not os.path.exists(dst):\n",
        "          os.makedirs(dst)\n",
        "\n",
        "       os.chdir(dst)\n",
        "       new_destination = dst+'ChatDev/'\n",
        "       if not os.path.exists(new_destination):\n",
        "          runSh('git clone https://github.com/OpenBMB/ChatDev.git')\n",
        "       os.chdir(new_destination)\n",
        "\n",
        "       #check_and_install_requirements('',[ 'colorama==0.1.6',\"openai==0.28.0\" ,'tiktoken', 'tenacity'])\n",
        "\n",
        "       #check_and_install_requirements(f'{new_destination}/requirements.txt')\n",
        "\n",
        "\n",
        "       runSh('python3 -m pip install colorama==0.1.6 openai==0.28.0 tiktoken tenacity')\n",
        "\n",
        "       runSh('python3 -m pip install -r requirements.txt')\n",
        "\n",
        "       os.environ['OPENAI_API_KEY'] = openai_api\n",
        "       Prompt = Prompt.replace('\\n', ' ')\n",
        "       Topic_Name = Topic_Name.replace('\\n',' ')\n",
        "\n",
        "       os.chdir(new_destination)\n",
        "       print(\"python3 run.py --task \"+ f\"\"\" {Prompt}\"\"\"+\" --name \"+ f'\"\"\"{Topic_Name}\"\"\"')\n",
        "\n",
        "       #runSh(\"python3 run.py --task \"+ f'\"{Prompt}\"'+\" --name \"+ f'\"{Topic_Name}\"')\n",
        "       Result, Error = runSh(\"python3 run.py --task \"+ f\"\"\"'((({Prompt})))'\"\"\"+\" --name \"+ f\"\"\"'((({Topic_Name})))'\"\"\")\n",
        "       print(f\"Result: {Result}\")\n",
        "       print(f\"Error: {Error}\")\n",
        "\n",
        "       root = f'{new_destination}/WareHouse/'\n",
        "\n",
        "       self.copy_folder_to_destination(root,save_results_Dir,Topic_Name)\n",
        "\n",
        "\n",
        "       #runSh(f\"cp -r '{new_destination}/WareHouse/' '{save_results_Dir}'\")\n",
        "\n",
        "       return Result, Error\n",
        "\n",
        "\n",
        "\n",
        "   def run_command_1(self,cmd):\n",
        "      with Popen(shlex.split(cmd), stdout=PIPE, bufsize=1, universal_newlines=False) as p:\n",
        "        while True:\n",
        "            line = p.stdout.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            print(line)\n",
        "        exit_code = p.poll()\n",
        "      return exit_code\n",
        "\n",
        "# ---How to use it :\n",
        "\n",
        "#Current_Dir = os.getcwd()\n",
        "#dst = '/content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev_projec/'\n",
        "\n",
        "#Results , Error = ChatDev_Run().ChatDev_Doit('Prompt gg','Topoc_Name hhh', dst,Current_Dir)\n",
        "#print ( 'Results', Results)"
      ],
      "metadata": {
        "id": "i_cJPo7LmLGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download and upload vidoe form the internet and put it on YouTube 🦋🌹🌀🙏🌺 :"
      ],
      "metadata": {
        "id": "mEIybqas9PXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pillar-youtube-upload"
      ],
      "metadata": {
        "id": "WRtPulC69PDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/pillargg/youtube-upload\n",
        "\n",
        "\n",
        "# Video options\n",
        "options = {\n",
        "    \"title\" : \"Example title\", # The video title\n",
        "    \"description\" : \"Example description\", # The video description\n",
        "    \"tags\" : [\"tag1\", \"tag2\", \"tag3\"],\n",
        "    \"categoryId\" : \"22\",\n",
        "    \"privacyStatus\" : \"private\", # Video privacy. Can either be \"public\", \"private\", or \"unlisted\"\n",
        "    \"kids\" : False, # Specifies if the Video if for kids or not. Defaults to False.\n",
        "    \"thumbnailLink\" : \"https://cdn.havecamerawilltravel.com/photographer/files/2020/01/youtube-logo-new-1068x510.jpg\" # Optional. Specifies video thumbnail.\n",
        "}\n",
        "\n",
        "# upload video\n",
        "#uploader.upload(file_path, options)"
      ],
      "metadata": {
        "id": "SMlH8Ll59vMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#I have tried to update the prompt by ChatGPT itself 👇👇"
      ],
      "metadata": {
        "id": "wxqM4h1fw4fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_main_variables(prompts, variable):\n",
        "   main_variables= main_variables_0\n",
        "   for prompt in prompts:\n",
        "       variables = re.findall(r'\\{(\\w+)\\}', prompt)\n",
        "       for var in variables:\n",
        "           if var == 'TOPIC':\n",
        "               main_variables[var] = variable\n",
        "           else:\n",
        "               main_variables[var] = None\n",
        "\n",
        "   return main_variables"
      ],
      "metadata": {
        "id": "Jd711_MyBgje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_main_variables(prompts, variable_para, var_content):\n",
        "    main_variables = main_variables_0\n",
        "\n",
        "    new_prompt = prompts[:]  # Create a deep copy of prompts\n",
        "\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        for var in variable_para:\n",
        "            if var == variable_para :\n",
        "                main_variables[var] = var_content\n",
        "                new_prompt[i] = prompt.replace(var, var_content)\n",
        "        for var, value in main_variables.items():\n",
        "             if var == variable_para:\n",
        "                main_variables[var] = var_content\n",
        "                new_prompt[i] = new_prompt[i].replace('{'+var+'}', \"{\"+f\"{var}\"+'}'+f\" which is :{var_content}\")#f\"{{{variable}}}\")\n",
        "\n",
        "\n",
        "    return main_variables, new_prompt\n",
        "#TOPIC='my test topic'\n",
        "main_variables, prompt_new = extract_main_variables(prompts, 'TOPIC', TOPIC)\n",
        "print (\" topic is :\", TOPIC)\n",
        "print(\"main variable is :\", main_variables)\n",
        "print(\"new_prompt is :\", prompt_new)\n",
        "prompts= prompt_new\n",
        "print(\"prompt is :\", prompts)"
      ],
      "metadata": {
        "id": "VLFUpVSA2Pbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "def generate_prompt_from_response(previous_response, main_variables):\n",
        "   # Customize this logic based on your needs\n",
        "   # For simplicity, let's use the last 50 characters of the response as the new prompt\n",
        "   new_prompt = previous_response[-50:]\n",
        "\n",
        "   # Replace the main variables in the new prompt\n",
        "   for var, value in main_variables.items():\n",
        "       if value is not None:\n",
        "           new_prompt = new_prompt.replace(value, f\"{{{var}}}\")\n",
        "\n",
        "   return new_prompt\n",
        "\n",
        "# Example usage\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "prompts_1 = [\n",
        "f\"Find a research topic for a PhD in the area of '{TOPIC}'\",\n",
        "\n",
        "]\n",
        "#prompts_2 = [\n",
        "#   \"I need to find information on renewable energy for a research paper that will be 1,500 words and must include eight sources.\",\n",
        "#   \"The research paper should cover the latest advancements in renewable energy technology.\"\n",
        "#]\n",
        "\n",
        "#main_variables,prompt_new = extract_main_variables(prompts,'TOPIC',TOPIC)\n",
        "#print(main_variables)\n",
        "\n",
        "#previous_response = \"Previous GPT response\"\n",
        "#new_prompt = generate_prompt_from_response(previous_response, main_variables)\n",
        "#print(new_prompt)\n",
        "#print ( prompts)"
      ],
      "metadata": {
        "id": "NYegFb6aq_h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Updating the prompt by ChatGPT:👇👇"
      ],
      "metadata": {
        "id": "UgzzXkG9wjbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "num_tokens_from_string(\"tiktoken is great!\", \"cl100k_base\")"
      ],
      "metadata": {
        "id": "oJ1QCUr62rtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_update_0(prompt, previous_content, main_variables):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   # Replace the TOPIC variable in the prompt\n",
        "   for var, value in main_variables.items():\n",
        "       if var == 'TOPIC' and value is not None:\n",
        "           prompt = prompt.replace(f\"{{{var}}}\", value)\n",
        "\n",
        "   # Construct the instruction for updating the prompt\n",
        "   instruction = f\"Given the previous content:\\n\\n{previous_content}\\n\\nUpdate the prompt: {prompt}\"\n",
        "\n",
        "   # Create the completion with the instruction\n",
        "   completion = client.completions.create(\n",
        "       model=model_engine,\n",
        "       prompt=instruction,\n",
        "       max_tokens=max_tokens,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "\n",
        "   # Extract and return the updated prompt from the response\n",
        "   updated_prompt = completion.choices[0].text.strip()\n",
        "   return updated_prompt"
      ],
      "metadata": {
        "id": "QbOCQqCDB8xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_prompt_update_a1(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      #model=\"curie\"\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "WPRw6qJOuaS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import openai\n",
        "from openai import RateLimitError\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api# \"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\",\n",
        ")\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 15,\n",
        "   errors: tuple = (RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_prompt_update(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "   print(f\"{num_tokens_from_string(prompt_my,model)} prompt tokens counted by num_tokens_from_messages().\")\n",
        "\n",
        "   completion = client.completions.create(\n",
        "     model=\"gpt-3.5-turbo-instruct\",\n",
        "     prompt=prompt_my,\n",
        "     max_tokens=500,\n",
        "     temperature=0.1,\n",
        "     n=1,\n",
        "     frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_academic_paper(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "   print(f\"{num_tokens_from_string(prompt_my,model)} prompt tokens counted by num_tokens_from_messages().\")\n",
        "\n",
        "\n",
        "   completion = client.completion.create(\n",
        "     #model=\"gpt-3.5-turbo-instruct\",\n",
        "     model=\"gpt-3.5-turbo-1106\",\n",
        "     prompt=prompt_my,\n",
        "     max_tokens=2048,\n",
        "     temperature=0.3,\n",
        "     n=1,\n",
        "     frequency_penalty=0,\n",
        "   )\n",
        "   return completion"
      ],
      "metadata": {
        "id": "O2TNMQ8eFl8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def generate_content(prompts, variables, TOPIC, perviuse_content=\"\"):\n",
        "  # Generate content for each variable\n",
        "  variable_contents = {}\n",
        "\n",
        "\n",
        "  main_variables = main_variables_0\n",
        "  for prompt in prompts:\n",
        "      for var in variables:\n",
        "          if var in prompt:\n",
        "              print(f\"\\n---prompt is ----\\n{prompt}\")\n",
        "              #prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be in less than 10 words. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "\n",
        "              prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be sumerized and as variable for chatgpt academic phd writer assistance. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "              content = generate_prompt_update_a1(prompt_my)\n",
        "              for choice in content.choices:\n",
        "                print(\"\\n Result is :\"+choice.text)\n",
        "                variable_contents[var] = choice.text\n",
        "              print(f\"variable_contents[{var}] is: {variable_contents[var]}\")\n",
        "\n",
        "              time.sleep(random.randint(22, 40))\n",
        "\n",
        "  # Replace the variables in the prompts with the generated content\n",
        "  prompt_new = []\n",
        "  for prompt in prompts:\n",
        "      for var, content in variable_contents.items():\n",
        "          prompt = prompt.replace(f\"{{{var}}}\", variable_contents[var])\n",
        "      prompt_new.append(prompt)\n",
        "      print(\"\\n --- Updated prompt is :\\n\"+str(prompt_new))\n",
        "  return prompt_new\n",
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# List of prompts\n",
        "#prompts = [\"prompt1\", \"prompt2\", \"prompt3\"] # replace with your actual prompts\n",
        "#perviuse_content= \"test\"\n",
        "# Call the function and store the returned prompts\n",
        "#updated_prompts = generate_content(prompts, variables, TOPIC, perviuse_content)\n",
        "#print(\"Updated Prompts:\", updated_prompts)"
      ],
      "metadata": {
        "id": "uI21enmkhb0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def generate_content_2(prompts, variables, TOPIC, perviuse_content=\"\"):\n",
        "  # Generate content for each variable\n",
        "  variable_contents = {}\n",
        "  main_variables = main_variables_0\n",
        "  for prompt in prompts:\n",
        "      for var in variables:\n",
        "          if var in prompt:\n",
        "              print(f\"\\n---prompt is ----\\n{prompt}\")\n",
        "              prompt_my = f\"Generate content for the variable '{var}' in the context of the topic '{TOPIC}'. Please consider the result must be in less than 10 words. The prompt is '{prompt}'. Also the more information for understanding better content is '{perviuse_content}'\"\n",
        "              content = generate_prompt_update_a1(prompt_my)\n",
        "              for choice in content.choices:\n",
        "                print(\"\\n Result is :\"+choice.text)\n",
        "                variable_contents[var] = choice.text\n",
        "              print(f\"variable_contents[{var}] is: {variable_contents[var]}\")\n",
        "\n",
        "              time.sleep(random.randint(22, 40))\n",
        "\n",
        "  main_variables, prompt_new = extract_main_variables(prompts, var, variable_contents[var])\n",
        "\n",
        "  print(\"main variable is :\", main_variables)\n",
        "  print(\"new_prompt is :\", prompt_new)\n",
        "  prompts= prompt_new\n",
        "\n",
        "  # Replace the variables in the prompts with the generated content\n",
        "  prompt_new = []\n",
        "  for prompt in prompts:\n",
        "      for var, content in variable_contents.items():\n",
        "          prompt = prompt.replace(f\"{{{var}}}\", variable_contents[var])\n",
        "      prompt_new.append(prompt)\n",
        "      print(\"\\n --- Updated prompt is :\\n\"+str(prompt_new))\n",
        "  return prompt_new,main_variables\n",
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# List of prompts\n",
        "#prompts = [\"prompt1\", \"prompt2\", \"prompt3\"] # replace with your actual prompts\n",
        "#perviuse_content= \"test\"\n",
        "# Call the function and store the returned prompts\n",
        "#updated_prompts = generate_content(prompts, variables, TOPIC, perviuse_content)\n",
        "#print(\"Updated Prompts:\", updated_prompts)"
      ],
      "metadata": {
        "id": "-tAXnnAOkagH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\" #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "\n",
        "\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "#client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   #api_key = \"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\",\n",
        "#)\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_academic_paper_a0(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "44bkCJOHtmuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time,random\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "\n",
        "global k\n",
        "k=0\n",
        "\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "#ChatGPT image prompt creating\n",
        "def image_prompting(contnet,prompt):\n",
        "    # Generate text with Sumy\n",
        "    parser = PlaintextParser.from_string(contnet, Tokenizer(\"english\"))\n",
        "    summarizer = LsaSummarizer()\n",
        "    summary_sumy = summarizer(parser.document, 3)\n",
        "    print(\"\\nSumy Summary and remove the html content from this content :\\n\", summary_sumy)\n",
        "    prompt_my = f\"As report logo designer suggest the text to image prompt in the context of the topic '{TOPIC}', in less one paragraph, for the this part of the report :({summary_sumy})\"\n",
        "    image_prompt = generate_prompt_update_a1(prompt_my)\n",
        "    image_prompt = image_prompt.choices[0].text.strip()\n",
        "    print(\"\\n Image Prompt Result is :\",image_prompt)\n",
        "    return image_prompt\n",
        "\n",
        "def update_prompt (prompt, main_variables):\n",
        "        # Replace variables in the prompt with corresponding values from main_variables\n",
        "        for variable, value in main_variables.items():\n",
        "          if variable in prompt:\n",
        "            print ( '\\n variable is :', variable,' \\n and value is :', value)\n",
        "            prompt = prompt.replace(f\"{{{variable}}}\", value)\n",
        "            print ( '\\n Prompt new us :', prompt)\n",
        "        return prompt\n",
        "\n",
        "\n",
        "def generate_papers(prompts, perviuse_content, perviuse_try_numner,prompt_Word_Topic_0, category='First',main_variables= main_variables_0, make_photo = False):\n",
        "  choice_text_all=[]\n",
        "  global prompt_Word_Topic,k\n",
        "  prompt_Word_Topic_1 = prompt_Word_Topic_0\n",
        "  print('prompt_Word_Topic_1 is :',prompt_Word_Topic_1)\n",
        "  k = perviuse_try_numner\n",
        "  for i in range(perviuse_try_numner, len(prompts), 20):\n",
        "     # Slice the prompts list to get the next 20 prompts\n",
        "     print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "\n",
        "     batch = prompts[i:i+20]\n",
        "     print(\"batch is \",batch)\n",
        "\n",
        "\n",
        "     for prompt in batch:\n",
        "\n",
        "         # Print the prompt\n",
        "         print(\"prompt is \",list({prompt}))\n",
        "\n",
        "         #updated_prompts = generate_content(list({prompt}), variables, TOPIC, perviuse_content)\n",
        "\n",
        "         updated_prompts = update_prompt(prompt, main_variables)\n",
        "         print(\"Updated Prompts:\", updated_prompts)\n",
        "\n",
        "         t = 0\n",
        "         while (t == 0):\n",
        "\n",
        "           time.sleep(random.randint(22, 40))\n",
        "           response = generate_academic_paper_a0(updated_prompts)\n",
        "           print(f\"\\n Generated Content in the Field of {category} is: \")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           if not response:\n",
        "             print(\"The response generate_academic_paper_a0 is empty.\")\n",
        "           else:\n",
        "             print(\"\\n The response generate_academic_paper_a0 is not empty and is :\\n\")\n",
        "           t= 1\n",
        "\n",
        "         for choice in response.choices:\n",
        "           print(choice.text)\n",
        "           choice_in_loop = choice.text\n",
        "           choice_text_all.append(choice.text)\n",
        "\n",
        "\n",
        "         #save_academic_paper(topic,'\\n--------**\\n'+updated_prompts+'/n-------**\\n'+choice.text)\n",
        "         if make_photo:\n",
        "            image_prompt = image_prompting(choice.text, updated_prompts)\n",
        "         else:\n",
        "            image_prompt = ''\n",
        "         if k == 0 :\n",
        "            # using string concatenation\n",
        "            new_string = choice.text #+ prompt_Word_Topic_1[1:]\n",
        "            print ('\\n new_string is:',new_string)\n",
        "            prompt_Word_Topic_1[0] = new_string\n",
        "            #prompt_Word_Topic_1[0] = choice.text\n",
        "            prompt_Word_Topic_1[0] = prompt_Word_Topic_1[0].replace ( '\"','')\n",
        "            print ('\\n Prompt for topic is',prompt_Word_Topic_1[0]  )\n",
        "\n",
        "            #ChatGPT image prompt creating\n",
        "            save_academic_paper_with_prompt(TOPIC[:15]+\"_Pr\",prompt_Word_Topic_1[k],image_prompt,\"\",perviuse_try_numner,category,make_photo)\n",
        "            save_academic_paper_with_prompt_Tile(TOPIC[:15]+\"_T\",prompt_Word_Topic_1[k],image_prompt,\"\",perviuse_try_numner,category,make_photo)\n",
        "\n",
        "         else :\n",
        "            save_academic_paper_with_prompt(TOPIC[:15]+\"_Pr\",'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',image_prompt,choice.text,perviuse_try_numner,category,make_photo)\n",
        "            save_academic_paper_with_prompt_Tile(TOPIC[:15]+'_T',prompt_Word_Topic_1[k],image_prompt,choice.text,perviuse_try_numner,category,make_photo)\n",
        "\n",
        "         #save_academic_paper_with_prompt_megazn(TOPIC[:15],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text,category,make_photo)\n",
        "         #save_academic_paper_with_prompt_megazn(TOPIC[:15],'\\n**<<<  ChatGPT Prompt is:\\n'+''.join(updated_prompts)+'\\n>>>**\\n',choice.text, 'google_drive',category,make_photo)\n",
        "         if hasattr(choice, 'choices'):\n",
        "             extract_text(choice)\n",
        "\n",
        "         perviuse_content = choice_in_loop\n",
        "         print(\"\\n end of loop\")\n",
        "         print(\"========================\\n\")\n",
        "\n",
        "         time.sleep(random.randint(22, 40))\n",
        "         perviuse_try_numner = perviuse_try_numner+1\n",
        "         k=k+1\n",
        "  return choice.text,perviuse_try_numner,response\n",
        "\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\" #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\""
      ],
      "metadata": {
        "id": "Uf6RCPBz3aqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Results 👇🌹🌱"
      ],
      "metadata": {
        "id": "xHPMNDjfToIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from django.utils.text import slugify\n",
        "import os\n",
        "prompts_business_plan_test = [\n",
        "    f\"suggest one Business Plans repost Title in less than 15 word, based of This Topic :({TOPIC}) and the description:({PARAGRAPH}.\",\n",
        "  ]\n",
        "class Auto_Main():\n",
        "  def __init__(self):\n",
        "        pass\n",
        "  def prompts_all(self): #, topic, description, main_variables_0):\n",
        "        prompts = {\n",
        "            \"Course Designing\":prompt_course,\n",
        "            \"Pitch Deck\": prompts_pitch,\n",
        "            \"Project Managment Report\" :prompts_project_management,\n",
        "            \"Code For It\" : prompts_chatdev,\n",
        "            \"Financial Model\" : prompts_finantial,\n",
        "            \"Academic Critique Paper\" : prompts_Academic_proposal_critique,\n",
        "            \"Game Theory\" : prompts_game_theory_1,\n",
        "            \"Business Plan\" : prompts_business_plan,\n",
        "            \"6 Hat Brainstorming\" : prompt_6Hat_Brainstorm,\n",
        "            \"Psychology 7 Step\" : prompts_Psychology,\n",
        "            \"Novel Structure\": prompts_story,\n",
        "            \"Academic Proposal\" : prompts_Academic,\n",
        "\n",
        "\n",
        "        }\n",
        "        prompts_topic = {\n",
        "            \"Course Designing\":prompt_course_title,\n",
        "            \"Project Managment Report\" : prompts_project_management_title,\n",
        "            \"Pitch Deck\": prompt_Word_Topic_pitch,\n",
        "            \"Psychology 7 Step\" : prompt_Word_Topic_Psychology,\n",
        "            \"Novel Structure\" : prompts_story_topic,\n",
        "            \"Code For It\":prompts_Topic_chatdev,\n",
        "            \"Financial Model\" : prompt_Word_Topic_finantial,\n",
        "            \"Academic Proposal\" : prompt_Word_Topic_Academic,\n",
        "            \"Academic Critique Paper\" : prompt_Word_Topic_Academic_proposal_critique,\n",
        "            \"Game Theory\" : prompt_Word_Topic_game_theory_1,\n",
        "            \"Pitch Deck\": prompt_Word_Topic_pitch,\n",
        "            \"Business Plan\":prompt_Word_Topic_business_plan,\n",
        "            \"6 Hat Brainstorming\" : prompt_Word_Topic_6Hat_Brainstorm,\n",
        "        }\n",
        "\n",
        "        return prompts,prompts_topic\n",
        "\n",
        "  def for_each_category(self, Main_Variable, prompts = None,prompts_topic= None):\n",
        "\n",
        "     if prompts is None:\n",
        "        prompts,prompts_topic = self.prompts_all()\n",
        "\n",
        "     results = {}\n",
        "     for category, category_prompts in prompts.items():\n",
        "        for category_topic, category_prompts_topic in prompts_topic.items():\n",
        "            if (category==category_topic):\n",
        "            #for prompt in category_prompts:\n",
        "                perviuse_try_numner = 0\n",
        "                # Update the prompt with variables\n",
        "                print ( '\\n category is :',category,'\\n category_prompts is:',category_prompts)\n",
        "                #updated_prompt = self.update_prompt(prompt, main_variables_0)\n",
        "                if category == 'Code For It' :\n",
        "                   #response= 'test'\n",
        "\n",
        "                   last_step_result,perviuse_try_numner,response = self.main(perviuse_try_numner,category_prompts,category_prompts_topic ,category)\n",
        "                   print ('\\n response is :',response)\n",
        "\n",
        "                   Topic_Name = Main_Variable['TOPIC']\n",
        "                   Topic_Name_abr = Topic_Name[:5]\n",
        "                   #Current_Dir = os.getcwd()+'/'+f'{topic}/{category}\"\n",
        "                   #save_folder_dest = \"/content/drive/My Drive/ChatGPT_Paper_wrting/All_Reports/\"+f\"{Topic_Name_abr}/{category}/\"\n",
        "\n",
        "                   save_folder_dest = \"/content/drive/My Drive/ChatGPT_Paper_wrting/All_Reports/\"+f\"{Topic_Name_abr}\"+\"_T/\"+category.replace(' ','_')\n",
        "                   print ( 'save_folder_dest dir is :', save_folder_dest)\n",
        "\n",
        "                   print ( 'save_folder_dest dir is :', save_folder_dest)\n",
        "                   source = '/content/drive/MyDrive/ChatGPT_Paper_wrting/ChatDev_projec/'\n",
        "                   Results = ChatDev_Run().ChatDev_Doit(last_step_result,Topic_Name[:10], source,save_folder_dest)\n",
        "                else:\n",
        "\n",
        "                   perviuse_try_numner = 0\n",
        "                   response = self.main(perviuse_try_numner,category_prompts,category_prompts_topic ,category)\n",
        "                   print ('\\n response is :',response)\n",
        "\n",
        "     return response\n",
        "\n",
        "  def main_generate_papers(self,TOPIC, prompts, perviuse_content, perviuse_try_numner,prompts_topic,category,main_variables):\n",
        "\n",
        "    if not perviuse_try_numner:\n",
        "        perviuse_try_numner = 0\n",
        "        perviuse_content = ['fist step']\n",
        "\n",
        "    elif (perviuse_try_numner == len(prompts)):\n",
        "        perviuse_try_numner = 0\n",
        "        perviuse_content = ['fist step']\n",
        "\n",
        "    last_step_result,perviuse_try_numner_1,results = generate_papers(prompts, perviuse_content, perviuse_try_numner,prompts_topic,category,main_variables)\n",
        "\n",
        "    return last_step_result, perviuse_try_numner_1,results\n",
        "\n",
        "  def main(self,perviuse_try_numner,prompts,prompts_topic,category):\n",
        "     topic = TOPIC_CLASS()\n",
        "     topic.category[\"perviuse_try_numner\"] = perviuse_try_numner\n",
        "     topic.category[\"name\"] = category\n",
        "\n",
        "     if not topic.category[\"perviuse_try_numner\"]:\n",
        "       topic.category[\"perviuse_try_numner\"] = 0\n",
        "       #topic.category[\"perviuse_content\"] = ['fist step']\n",
        "\n",
        "     elif (topic.category[\"perviuse_try_numner\"] == len(prompts)):\n",
        "       topic.category[\"perviuse_try_numner\"] = 0\n",
        "       #topic.category[\"perviuse_content\"] = ['fist step']\n",
        "\n",
        "     topic.topic = TOPIC\n",
        "     last_step_result,topic.category[\"perviuse_try_numner\"],topic.category[\"results\"] = self.main_generate_papers(topic.topic, prompts, topic.category[\"perviuse_content\"], topic.category[\"perviuse_try_numner\"],prompts_topic,category,topic.category[\"main_variables\"])\n",
        "     TOPIC_CLASS() == topic\n",
        "     return last_step_result,topic.category[\"perviuse_try_numner\"],topic.category[\"results\"]\n",
        "\n",
        "response = Auto_Main().for_each_category(TOPIC_CLASS().category[\"main_variables\"]) #prompts,prompts_topic,"
      ],
      "metadata": {
        "id": "-YbWDEd4WzDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the `linkedin-auto-post` library in your Python script, you first need to install it using pip:\n",
        "\n",
        "```python\n",
        "pip install linkedin-auto-post\n",
        "```\n",
        "\n",
        "Then, you can import the necessary functions from the library and use them in your script. Here's how you can modify your `main()` function to use `linkedin-auto-post`:\n",
        "\n",
        "```python\n",
        "from linkedin_auto_post import *\n",
        "\n",
        "def main():\n",
        "   file_path = \"linkedin_topic.txt\" # Replace with the actual file path\n",
        "   current_line = 0\n",
        "   while True:\n",
        "       next_line, current_line = text_getter.get_next_line_from_file(file_path, current_line)\n",
        "\n",
        "       if next_line is not None:\n",
        "           selected_text = next_line\n",
        "           print(selected_text)\n",
        "           print(\"\")\n",
        "           prompt = linkedin_prompts.prompt.format(role_and_target_audience = selected_text)\n",
        "           text_content = text_content_generator.openai_generate(prompt)\n",
        "           print(text_content)\n",
        "           print(\"\")\n",
        "           linkedin.login(username=\"linkedin username\",password=\"linkedin password\")\n",
        "           linkedin.upload_content(content=text_content)\n",
        "           time.sleep(21600)\n",
        "       else:\n",
        "           print(\"All Linkedin posts have been Published.\")\n",
        "           break\n",
        "if __name__ == \"__main__\":\n",
        "   main()\n",
        "```\n",
        "\n",
        "In this modified script, `linkedin.login(username=\"linkedin username\",password=\"linkedin password\")` logs into LinkedIn using your LinkedIn username and password, and `linkedin.upload_content(content=text_content)` uploads the generated content to LinkedIn.\n",
        "\n",
        "Please note that you need to replace `\"linkedin username\"` and `\"linkedin password\"` with your actual LinkedIn username and password. Also, remember to handle your credentials securely, as they will be used for logging into LinkedIn [Source 1](https://pypi.org/project/linkedin-auto-post/)."
      ],
      "metadata": {
        "id": "djlP71rbo1Y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from linkedin_auto_post import *\n",
        "\n",
        "def main():\n",
        "   file_path = \"linkedin_topic.txt\" # Replace with the actual file path\n",
        "   current_line = 0\n",
        "   while True:\n",
        "       next_line, current_line = text_getter.get_next_line_from_file(file_path, current_line)\n",
        "\n",
        "       if next_line is not None:\n",
        "           selected_text = next_line\n",
        "           print(selected_text)\n",
        "           print(\"\")\n",
        "           prompt = linkedin_prompts.prompt.format(role_and_target_audience = selected_text)\n",
        "           text_content = text_content_generator.openai_generate(prompt)\n",
        "           print(text_content)\n",
        "           print(\"\")\n",
        "           linkedin.login(username=\"linkedin username\",password=\"linkedin password\")\n",
        "           linkedin.upload_content(content=text_content)\n",
        "           time.sleep(21600)\n",
        "       else:\n",
        "           print(\"All Linkedin posts have been Published.\")\n",
        "           break\n",
        "if __name__ == \"__main__\":\n",
        "   main()"
      ],
      "metadata": {
        "id": "kY8SELMNpAy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.phind.com/search?cache=xqbhxgilysl4b8wqweih04eg\n",
        "Sure, here's how you can integrate the `linkedin-content-uploader` library into your existing Python code:\n",
        "\n",
        "First, install the library using pip:\n",
        "\n",
        "```python\n",
        "pip install linkedin-content-uploader\n",
        "```\n",
        "\n",
        "Next, import the library and use the `login` function to log into LinkedIn. You can either use your email and password or your cookies. Then, use the `upload_content` function to post content on LinkedIn.\n",
        "\n",
        "Here's an updated version of your `main` function:\n",
        "\n",
        "```python\n",
        "from linkedin_content_uploader import *\n",
        "import linkedin_json_data\n",
        "import text_content_generator\n",
        "import linkedin_prompts\n",
        "import text_getter\n",
        "import time\n",
        "\n",
        "def main():\n",
        "   file_path = \"linkedin_topic.txt\" # Replace with the actual file path\n",
        "   current_line = 0\n",
        "\n",
        "   # Log in to LinkedIn\n",
        "   linkedin.login(email=\"<Your Email>\", password=\"<Your Password>\")\n",
        "   # Or use cookies if you prefer\n",
        "   # linkedin.login_cookie(cookies=<Your Cookies>)\n",
        "\n",
        "   while True:\n",
        "       next_line, current_line = text_getter.get_next_line_from_file(file_path, current_line)\n",
        "\n",
        "       if next_line is not None:\n",
        "           selected_text = next_line\n",
        "           print(selected_text)\n",
        "           print(\"\")\n",
        "           prompt = linkedin_prompts.prompt.format(role_and_target_audience = selected_text)\n",
        "           text_content = text_content_generator.openai_generate(prompt)\n",
        "           print(text_content)\n",
        "           print(\"\")\n",
        "           \n",
        "           # Upload the content to LinkedIn\n",
        "           linkedin.upload_content(content=text_content)\n",
        "           \n",
        "           time.sleep(21600)\n",
        "       else:\n",
        "           print(\"All Linkedin posts have been Published.\")\n",
        "           break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "   main()\n",
        "```\n",
        "\n",
        "In this code, replace `<Your Email>` and `<Your Password>` with your actual LinkedIn email and password. If you choose to use cookies, replace `<Your Cookies>` with your actual cookies [Source 0](https://github.com/datakund/linkedin-post-content-python).\n",
        "\n",
        "Please note that automating LinkedIn posts might violate LinkedIn's terms of service. Always ensure that your actions comply with LinkedIn's rules and regulations."
      ],
      "metadata": {
        "id": "Q3lW7_UWnRJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install linkedin-content-uploader"
      ],
      "metadata": {
        "id": "xQBOBADSnamD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/datakund/linkedin-post-content-python.git\n",
        "\n",
        "!cd linkedin-post-content-python\n",
        "\n",
        "!pip install ."
      ],
      "metadata": {
        "id": "hycjlHzLoFG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from linkedin_content_uploader import *\n",
        "import linkedin_json_data\n",
        "import text_content_generator\n",
        "import linkedin_prompts\n",
        "import text_getter\n",
        "import time\n",
        "\n",
        "def main():\n",
        "   file_path = \"linkedin_topic.txt\" # Replace with the actual file path\n",
        "   current_line = 0\n",
        "\n",
        "   # Log in to LinkedIn\n",
        "   linkedin.login(email=\"<Your Email>\", password=\"<Your Password>\")\n",
        "   # Or use cookies if you prefer\n",
        "   # linkedin.login_cookie(cookies=<Your Cookies>)\n",
        "\n",
        "   while True:\n",
        "       next_line, current_line = text_getter.get_next_line_from_file(file_path, current_line)\n",
        "\n",
        "       if next_line is not None:\n",
        "           selected_text = next_line\n",
        "           print(selected_text)\n",
        "           print(\"\")\n",
        "           prompt = linkedin_prompts.prompt.format(role_and_target_audience = selected_text)\n",
        "           text_content = text_content_generator.openai_generate(prompt)\n",
        "           print(text_content)\n",
        "           print(\"\")\n",
        "\n",
        "           # Upload the content to LinkedIn\n",
        "           linkedin.upload_content(content=text_content)\n",
        "\n",
        "           time.sleep(21600)\n",
        "       else:\n",
        "           print(\"All Linkedin posts have been Published.\")\n",
        "           break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "   main()"
      ],
      "metadata": {
        "id": "gOeeFh1gnU8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the sound by OpenAI: 👇👇\n",
        "\n",
        "https://platform.openai.com/docs/guides/text-to-speech"
      ],
      "metadata": {
        "id": "2ctHZTF6wj0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/ChatGPT_academic_paper\"\n",
        "from openai import OpenAI\n",
        "from django.utils.text import slugify\n",
        "\n",
        "folder_path = \"/content/drive/My Drive/ChatGPT_Paper_wrting/All_Reports/\"\n",
        "\n",
        "\n",
        "client = OpenAI(\n",
        "   # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "   api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "response = client.audio.speech.create(\n",
        "    voice=\"alloy\",\n",
        "    model=\"Kamtera/persian-tts-female-glow_tts\", #model=\"tts-1\",\n",
        "    input=TOPIC #\"Hello world! This is a streaming test.\",\n",
        ")\n",
        "TOPIC_S = slugify(TOPIC)\n",
        "\n",
        "\n",
        "Sound_Folder = folder_path+f\"{TOPIC[:15]}_T/sound_/\"\n",
        "Sound_File = Sound_Folder +str(random.randint (0,1000))+\".mp3\"\n",
        "\n",
        "if not os.path.exists(Sound_Folder):\n",
        "   os.makedirs(Sound_Folder)\n",
        "\n",
        "print (\"save folder is: \",Sound_File)#/content/drive/MyDrive/ChatGPT_Paper_wrting/\"+f\"{TOPIC_S}\"+str(random.randint (0,1000))+\".mp3\") #\"/\"+\"output.mp3\"\n",
        "#response.stream_to_file(\"/content/drive/My Drive/ChatGPT_Paper_wrting/\"+f\"{TOPIC_S}\"+str(random.randint (0,1000))+\".mp3\")#\"/\"+\"output.mp3\")\n",
        "\n",
        "response.stream_to_file(Sound_File)\n",
        "print ( 'topic is:',TOPIC)\n",
        "#print (\"save folder is: /content/drive/MyDrive/ChatGPT_Paper_wrting/\"+f\"{TOPIC[:40]}\"+str(random.randint (0,1000))+\".mp3\") #\"/\"+\"output.mp3\""
      ],
      "metadata": {
        "id": "d2YvDx5DwS7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pydub import AudioSegment\n",
        "from slugify import slugify\n",
        "\n",
        "def extract_course_information(course_design_variables):\n",
        "   course_data = {}\n",
        "\n",
        "   # Retrieve course information from the .docx file\n",
        "   filename = course_design_variables[\"filename\"]\n",
        "   doc = Document(filename)\n",
        "   full_text = []\n",
        "   for para in doc.paragraphs:\n",
        "       full_text.append(para.text)\n",
        "   course_description = '\\n'.join(full_text) if full_text else \"Description not found in the file\"\n",
        "   course_data['course_description'] = course_description\n",
        "\n",
        "   # Split the description into parts\n",
        "   course_parts = course_description.split('\\n')\n",
        "\n",
        "   return course_parts, doc\n",
        "\n",
        "def generate_voice(course_parts, TOPIC):\n",
        "   TOPIC_S = slugify(TOPIC)\n",
        "   Sound_Folder = folder_path+f\"{TOPIC[:15]}_T/sound_/\"\n",
        "\n",
        "   if not os.path.exists(Sound_Folder):\n",
        "       os.makedirs(Sound_Folder)\n",
        "\n",
        "   audio_files = []\n",
        "   @retry_with_exponential_backoff\n",
        "   for i, part in enumerate(course_parts):\n",
        "       # Generate voice from the part\n",
        "       response = client.audio.speech.create(    voice=\"alloy\",\n",
        "         #model=\"Kamtera/persian-tts-female-glow_tts\", #model=\"tts-1\",\n",
        "         model=\"tts-1\",\n",
        "         input=TOPIC #\"Hello world! This is a streaming test.\",\n",
        "       )\n",
        "       # Save the response content (the audio file) to a local file\n",
        "       Sound_File = Sound_Folder +str(i)+\".mp3\"\n",
        "       response.stream_to_file(Sound_File)\n",
        "\n",
        "       # Add the audio file to the list of audio files\n",
        "       audio_files.append(Sound_File)\n",
        "\n",
        "   # Combine all audio files into a single audio file\n",
        "   combined_audio = sum([AudioSegment.from_file(af) for af in audio_files])\n",
        "\n",
        "   # Estimate the duration of the text-to-speech audio\n",
        "   avg_speed = 150 # average words per minute\n",
        "   total_words = len(' '.join(course_parts).split())\n",
        "   est_duration = total_words / avg_speed # in minutes\n",
        "\n",
        "   # If the estimated duration is less than n minutes, extend the audio\n",
        "   n = 5 # desired duration in minutes\n",
        "   if est_duration < n:\n",
        "       extended_audio = combined_audio * int((n / est_duration) + 1)\n",
        "       extended_audio.export(Sound_Folder+\"extended.mp3\", format='mp3')\n",
        "\n",
        "   combined_audio.export(Sound_Folder+\"combined.mp3\", format='mp3')\n",
        "\n",
        "# Example Usage\n",
        "course_filename = \"/content/drive/MyDrive/ChatGPT_Paper_wrting/All_Reports/Climate Change _T/Pitch_Deck/Title/Pitch_Deck_T_climate-change-_t.docx\" # \"path_to_your_file.docx\"\n",
        "course_design_variables = {\"filename\": course_filename}\n",
        "TOPIC = \"Your Topic\"\n",
        "\n",
        "# Extract course information\n",
        "course_parts, doc = extract_course_information(course_design_variables)\n",
        "\n",
        "# Generate voice for each part of the course\n",
        "generate_voice(course_parts, TOPIC)"
      ],
      "metadata": {
        "id": "pPoqYzDHHi57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "from google.cloud import texttospeech\n",
        "import os\n",
        "import random\n",
        "import slugify\n",
        "\n",
        "folder_path = \"/content/drive/My Drive/ChatGPT_Paper_wrting/All_Reports/\"\n",
        "\n",
        "\n",
        "\n",
        "def generate_voice(course_data, TOPIC):\n",
        "# Convert the Sentence object to a string\n",
        " summary_sumy_str = course_data['course_description']\n",
        "\n",
        "# Initialize the Text-to-Speech client\n",
        " client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "# Set the text input to be synthesized\n",
        " synthesis_input = texttospeech.SynthesisInput(text=summary_sumy_str)\n",
        "\n",
        "# Build the voice request\n",
        " voice = texttospeech.VoiceSelectionParams(\n",
        "    language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.FEMALE\n",
        " )\n",
        "\n",
        "# Select the type of audio file you want returned\n",
        " audio_config = texttospeech.AudioConfig(\n",
        "    audio_encoding=texttospeech.AudioEncoding.MP3\n",
        " )\n",
        "\n",
        "# Perform the text-to-speech request\n",
        " response = client.synthesize_speech(\n",
        "    input=synthesis_input, voice=voice, audio_config=audio_config\n",
        " )\n",
        "\n",
        "# Write the response to the output file.\n",
        " TOPIC_S = slugify(TOPIC)\n",
        " Sound_Folder = folder_path+f\"{TOPIC[:15]}_T/sound_/\"\n",
        " Sound_File = Sound_Folder +str(random.randint (0,1000))+\".mp3\"\n",
        "\n",
        "if not os.path.exists(Sound_Folder):\n",
        "    os.makedirs(Sound_Folder)\n",
        "\n",
        "with open(Sound_File, \"wb\") as out:\n",
        "    out.write(response.audio_content)\n",
        "\n",
        "# Example Usage\n",
        "course_filename = \"/content/drive/MyDrive/ChatGPT_Paper_wrting/All_Reports/Climate Change _T/Pitch_Deck/Title/Pitch_Deck_T_climate-change-_t.docx\" # \"path_to_your_file.docx\"\n",
        "course_design_variables = {\"filename\": course_filename}\n",
        "TOPIC = \"Your Topic\"\n",
        "\n",
        "# Extract course information\n",
        "course_data, doc = extract_course_information(course_design_variables)\n",
        "\n",
        "# Generate voice for the course\n",
        "generate_voice(course_data, TOPIC)"
      ],
      "metadata": {
        "id": "MDJ4IOWCHBx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install decencies:\n",
        "\n",
        "https://github.com/karim23657/Persian-tts-coqui/blob/5fffc180b65e4aea9dc3afc370feb5b07c7a6690/recepies/glowtts/test-glowtts-model.ipynb#L4"
      ],
      "metadata": {
        "id": "Y7o-50bDQ4IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -q git+https://github.com/colefranks/coqui-without-japanese\n",
        "!sudo apt-get -y install espeak-ng"
      ],
      "metadata": {
        "id": "zGgTzSnKRDh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install TTS\n",
        "!sudo apt-get -y install espeak-ng"
      ],
      "metadata": {
        "id": "fIeGK4_-KDyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "# @ Download female model\n",
        "!git clone https://huggingface.co/Kamtera/persian-tts-female-glow_tts\n",
        "\n",
        "# Or also you can download male model\n",
        "#!git clone https://huggingface.co/Kamtera/persian-tts-male-glow_tts\n",
        "\n",
        "\n",
        "!wget \"https://huggingface.co/Kamtera/persian-tts-female-Hifigan/resolve/main/config-3.json\" -O \"config.json\"\n",
        "\n",
        "\n",
        "!wget \"https://huggingface.co/Kamtera/persian-tts-female-Hifigan/resolve/main/checkpoint_378000.pth\" -O \"checkpoint_378000.pth\""
      ],
      "metadata": {
        "id": "JGXGql_eSXe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "def extract_course_information_for_farsi_voice(course_design_variables):\n",
        "  course_data = {}\n",
        "\n",
        "# Retrieve course information from the .docx file\n",
        "  filename = course_design_variables[\"filename\"]\n",
        "  doc = Document(filename)\n",
        "  full_text = []\n",
        "  for para in doc.paragraphs:\n",
        "    full_text.append(para.text)\n",
        "    course_description = '\\n'.join(full_text) if full_text else \"Description not found in the file\"\n",
        "    course_data['course_description'] = course_description\n",
        "\n",
        "  # Parse the text and generate a summary\n",
        "  parser = PlaintextParser.from_string(course_description, Tokenizer(\"english\"))\n",
        "  summarizer = LsaSummarizer()\n",
        "\n",
        "  # Estimate the number of sentences needed for a 2-minute summary\n",
        "  avg_speed = 150 # average words per minute\n",
        "  est_num_sentences = int(2 * avg_speed) # 2 minutes in words\n",
        "  summary = summarizer(parser.document, est_num_sentences)\n",
        "\n",
        " # Convert the Sentence object to a string\n",
        "  summary_str = ' '.join([str(sentence) for sentence in summary])\n",
        "\n",
        " # Split the summary into parts\n",
        "  course_parts = summary_str.split('\\n')\n",
        "\n",
        "  return summary_str,course_parts, doc"
      ],
      "metadata": {
        "id": "toH7OEjn_6AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from TTS.config import load_config\n",
        "from TTS.utils.manage import ModelManager\n",
        "from TTS.utils.synthesizer import Synthesizer\n",
        "import IPython\n",
        "\n",
        "basepath=\"/content/persian-tts-female-glow_tts\"\n",
        "vbasepath=\"/content\"\n",
        "model_path =basepath+\"/best_model.pth\" # Absolute path to the model checkpoint.pth\n",
        "config_path =basepath+\"/config.json\" # Absolute path to the model config.json\n",
        "# speakers_file_path = # Absolute path to speakers.pth file\n",
        "vocoder_path=\"/content/checkpoint_378000.pth\"#vbasepath+\"/checkpoint_127000.pth\"\n",
        "vocoder_config_path=\"/content/config.json\"\n",
        "synthesizer = Synthesizer(\n",
        "        model_path,\n",
        "        config_path,\n",
        "        None ,#speakers_file_path,\n",
        "        None ,#language_ids_file_path,\n",
        "        vocoder_path ,#vocoder_path,\n",
        "        vocoder_config_path ,#vocoder_config_path,\n",
        "        None ,#encoder_path,\n",
        "        None ,#encoder_config_path,\n",
        "        None ,#args.use_cuda,\n",
        "    )\n",
        "\n",
        "# Example Usage\n",
        "course_filename = \"/content/drive/MyDrive/ChatGPT_Paper_wrting/All_Reports/Climate Change _T/Pitch_Deck/Title/Pitch_Deck_T_climate-change-_t.docx\" # \"path_to_your_file.docx\"\n",
        "course_design_variables = {\"filename\": course_filename}\n",
        "TOPIC = \"Your Topic\"\n",
        "\n",
        "\n",
        "# Extract course information\n",
        "summary_str,course_data, doc = extract_course_information_for_farsi_voice(course_design_variables)\n",
        "save_folder_dest = \"/content/drive/MyDrive/ChatGPT_Paper_wrting/All_Reports/Climate Change _T/Pitch_Deck/\" # \"path_to_your_file.docx\"\n",
        "text = course_data\n",
        "text=\".زندگی فقط یک بار است؛ از آن به خوبی استفاده کن\"\n",
        "#text = \"test\"\n",
        "print( text)\n",
        "wavs = synthesizer.tts(text)\n",
        "synthesizer.save_wav(wavs, save_folder_dest + 'sp.wav')\n",
        "IPython.display.Audio(save_folder_dest + 'sp.wav')\n",
        "\n",
        "if False : #for category, save_folder_dest in TOPIC_CLASS.items():\n",
        "\n",
        "  text = category[\"results\"]\n",
        "  save_folder=save_folder_dest(category[\"TOPIC\"],category[\"name\"])\n",
        "  #text=\".زندگی فقط یک بار است؛ از آن به خوبی استفاده کن\"\n",
        "\n",
        "  wavs = synthesizer.tts(text)\n",
        "  synthesizer.save_wav(wavs,save_folder_dest+ 'sp.wav')\n",
        "\n",
        "  IPython.display.Audio(save_folder_dest+'sp.wav')\n",
        "\n",
        "IPython.display.Audio(save_folder_dest + 'sp.wav')"
      ],
      "metadata": {
        "id": "3zxpTUwURNj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from TTS.config import load_config\n",
        "from TTS.utils.manage import ModelManager\n",
        "from TTS.utils.synthesizer import Synthesizer\n",
        "\n",
        "config=\"config.json\"\n",
        "model=\"best_model_30824.pth\"\n",
        "\n",
        "model_path =model # Absolute path to the model checkpoint.pth\n",
        "config_path =config # Absolute path to the model config.json\n",
        "\n",
        "for category, save_folder_dest in TOPIC_CLASS.items():\n",
        "\n",
        "  text = category[\"results\"]\n",
        "  save_folder=save_folder_dest(category[\"TOPIC\"],category[\"name\"])\n",
        "  #text=\".زندگی فقط یک بار است؛ از آن به خوبی استفاده کن\"\n",
        "\n",
        "  synthesizer = Synthesizer(\n",
        "    model_path, config_path\n",
        "  )\n",
        "  wavs = synthesizer.tts(text)\n",
        "  synthesizer.save_wav(wavs,save_folder_dest+ 'Describtion.wav')\n",
        "\n",
        "  IPython.display.Audio('sp.wav')"
      ],
      "metadata": {
        "id": "qp_JB8kcKGp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from IPython.display import HTML\n",
        "\n",
        "def upload_files_to_transfer_sh(file_paths):\n",
        "  urls = []\n",
        "  html_content = \"<form>\"\n",
        "  for file_path in file_paths:\n",
        "      with open(file_path, 'rb') as file:\n",
        "          response = requests.post('https://transfer.sh/', files={'file': file})\n",
        "          response.raise_for_status()\n",
        "          urls.append(response.text)\n",
        "          html_content += f\"<p>File: {file_path} <br> And Upload URL is: <a href='{response.text}'>{response.text}</a></p>\"\n",
        "  html_content += \"</form>\"\n",
        "  return urls, html_content\n",
        "\n",
        "file_paths = [Sound_File, docx_path, docx_path.replace('docx','pdf')]\n",
        "urls, html_content = upload_files_to_transfer_sh(file_paths)\n",
        "for url in urls:\n",
        "  print(url)\n",
        "HTML(html_content)"
      ],
      "metadata": {
        "id": "JQVNA0T95rgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Emailing the content 👇🐢🌸"
      ],
      "metadata": {
        "id": "bIYfHcTCp9Qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi-mail"
      ],
      "metadata": {
        "id": "Pku-t3QT_AsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi_mail import FastMail, MessageSchema, ConnectionConfig\n",
        "import os\n",
        "import base64\n",
        "import zipfile\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "conf = ConnectionConfig(\n",
        "  MAIL_USERNAME = \"Your_Email\",\n",
        "  MAIL_PASSWORD = \"Your_Email_Password\",\n",
        "  MAIL_FROM = \"Your_Email\",\n",
        "  MAIL_PORT = 587,\n",
        "  MAIL_SERVER = \"smtp.gmail.com\",\n",
        "  MAIL_TLS = True,\n",
        "  MAIL_SSL = False,\n",
        "  USE_CREDENTIALS = True\n",
        ")\n",
        "\n",
        "@app.post(\"/send_email_summary/\")\n",
        "async def send_email_summary(news_content_summary: str, news_data_with_text_df_1_html: str, attachments: list):\n",
        "  # Create a zip file from the attachments\n",
        "  with zipfile.ZipFile('attachments.zip', 'w') as zipf:\n",
        "      for attachment in attachments:\n",
        "          zipf.write(attachment)\n",
        "\n",
        "  # Prepare attachments\n",
        "  with open('attachments.zip', 'rb') as f:\n",
        "      content = f.read()\n",
        "      encoded_content = base64.b64encode(content).decode()\n",
        "      attachments_data = [\n",
        "          {\n",
        "              'ContentType': 'application/zip',\n",
        "              'Filename': 'attachments.zip',\n",
        "              'Base64Content': encoded_content\n",
        "          }\n",
        "      ]\n",
        "\n",
        "  message = MessageSchema(\n",
        "      subject=\"GPT News Summary of Today\",\n",
        "      recipients=[\"Your_Email\"],\n",
        "      body=\"<h3>Here is the result of our code for today.</h3>{}<br><br> \\\n",
        "            <h3>GPT Gent Summary Sources</h3>{}<br><br> \\\n",
        "            <h4> The PDF,DICX and MP3 file has been added at attachment</h4>\".format(news_content_summary, news_data_with_text_df_1_html),\n",
        "      attachments=attachments_data\n",
        "  )\n",
        "\n",
        "  fm = FastMail(conf)\n",
        "  await fm.send_message(message)\n",
        "  return {\"message\": \"Email Sent\"}"
      ],
      "metadata": {
        "id": "n_r7b-Ud_FKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perviuse_content=''\n",
        "news_content_summary = 'Summary of the news'\n",
        "news_data_with_text_df_1_html = 'HTML table of news sources'\n",
        "attachments = [Sound_File, docx_path, docx_path.replace('docx','pdf')]\n",
        "\n",
        "send_email_summary(news_content_summary, news_data_with_text_df_1_html, attachments)"
      ],
      "metadata": {
        "id": "i4QMJkj8AF6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install mailjet_rest\n",
        "\n",
        "\n",
        "from mailjet_rest import Client\n",
        "import os\n",
        "import base64\n",
        "import zipfile\n",
        "\n",
        "def send_email_summary(api_key, api_secret, news_content_summary, news_data_with_text_df_1_html , attachments):\n",
        "  mailjet = Client(auth=(api_key, api_secret), version='v3.1')\n",
        "\n",
        "  # Create a zip file from the attachments\n",
        "  with zipfile.ZipFile('attachments.zip', 'w') as zipf:\n",
        "      for attachment in attachments:\n",
        "          zipf.write(attachment)\n",
        "\n",
        "  # Prepare attachments\n",
        "  attachments_data = []\n",
        "  with open('attachments.zip', 'rb') as f:\n",
        "      content = f.read()\n",
        "      encoded_content = base64.b64encode(content).decode()\n",
        "      attachments_data.append({\n",
        "          'ContentType': 'application/zip',\n",
        "          'Filename': 'attachments.zip',\n",
        "          'Base64Content': encoded_content\n",
        "      })\n",
        "\n",
        "  data = {\n",
        "    'Messages': [\n",
        "      {\n",
        "        \"From\": {\n",
        "          \"Email\": \"easonlai888@gmail.com\",\n",
        "          \"Name\": \"Eason\"\n",
        "        },\n",
        "        \"To\": [\n",
        "          {\n",
        "            \"Email\": \"Your_Email\",\n",
        "            \"Name\": \"Eason\"\n",
        "          }\n",
        "        ],\n",
        "        \"Subject\": \"GPT News Summary of Today\",\n",
        "        \"HTMLPart\": \"<h3>Here is the result of our code for today.</h3>{}<br><br> \\\n",
        "                  <h3>GPT Gent Summary Sources</h3>{}<br><br> \\\n",
        "                  <h4> The PDF,DICX and MP3 file has been added at attachment</h4>\",#.format(news_content_summary, news_data_with_text_df_1_html),\n",
        "        \"Attachments\": attachments_data\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "  result = mailjet.send.create(data=data)\n",
        "  print(result.status_code)\n",
        "  print(result.json())"
      ],
      "metadata": {
        "id": "lmNpBP9vrrSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = openai_api\n",
        "api_secret = 'PLEASE_ENTER_YOUR_OWNED_MAILJET_API_KEY_SECRET'\n",
        "perviuse_content=''\n",
        "news_content_summary = 'Summary of the news'\n",
        "news_data_with_text_df_1_html = 'HTML table of news sources'\n",
        "attachments = [Sound_File, docx_path, docx_path.replace('docx','pdf')]\n",
        "\n",
        "send_email_summary(api_key, api_secret, perviuse_content, news_data_with_text_df_1_html, attachments)"
      ],
      "metadata": {
        "id": "OZMmRxJyr1QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Only update the Prompt by the help of ChatGPT:👇👇"
      ],
      "metadata": {
        "id": "BAiQz23MlpUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define main variables\n",
        "#TOPIC = \"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"\n",
        "\n",
        "# List of variables\n",
        "variables = [\"RESEARCH_DOMAIN\", \"PARAGRAPH\", \"PARAGRAPHS\", \"TOPIC_SENTENCE\", \"LANGUAGE\", \"ABSTRACT_PARAGRAPH\", \"BIBLIOGRAPHY\", \"THEORY1\", \"THEORY2\", \"RESEARCH_QUESTIONS\", \"ACTION\", \"RESULT_PARAGRAPHS\", \"DATE\", \"NUMBER_OF_DAYS_MONTHS_YEARS\"]\n",
        "\n",
        "# Generate content for each variable\n",
        "variable_contents = {}\n",
        "for prompt in prompts:\n",
        "   for var in variables:\n",
        "       if var in prompt:\n",
        "           prompt = f\"Generate content for the variable '{var}' based on the topic '{TOPIC}'. For this prompt '{prompt}'\"\n",
        "           content= generate_academic_paper(prompt)\n",
        "           for choice in content.choices:\n",
        "               print(choice.text)\n",
        "               variable_contents[var] = choice.text\n",
        "           print(\"variable_contents[var] is: \",variable_contents[var])\n",
        "\n",
        "# Replace the variables in the prompts with the generated content\n",
        "for prompt in prompts:\n",
        "   for var, content in variable_contents.items():\n",
        "       prompt = prompt.replace(f\"{{{var}}}\", content)\n",
        "print(\"Updated Prompt:\", prompt)"
      ],
      "metadata": {
        "id": "kH3LygdiXsPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_update_a3(prompt, previous_content):\n",
        "    model_engine = \"text-davinci-003\"\n",
        "    max_tokens = 2048\n",
        "\n",
        "    # Construct the instruction for updating the prompt\n",
        "    instruction = f\"Given the previous content:\\n\\n{previous_content}\\n\\nUpdate the prompt: {prompt}\"\n",
        "\n",
        "    # Create the completion with the instruction\n",
        "    completion = client.completions.create(\n",
        "        model=model_engine,\n",
        "        prompt=instruction,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0.3,\n",
        "        n=1,\n",
        "        frequency_penalty=0,\n",
        "    )\n",
        "\n",
        "    # Extract and return the updated prompt from the response\n",
        "    updated_prompt = completion.choices[0].text.strip()\n",
        "    return updated_prompt\n",
        "# Inside your loop\n",
        "for prompt in prompts:\n",
        "    print(\"Original Prompt:\", prompt)\n",
        "    response = generate_academic_paper_a2(prompt)\n",
        "    previous_content = response.choices[0].text.strip()\n",
        "    updated_prompt = generate_prompt_update_2(prompt, previous_content)\n",
        "    print(\"Updated Prompt:\", updated_prompt)\n",
        "\n",
        "    # Continue with the rest of your processing\n",
        "    # ..."
      ],
      "metadata": {
        "id": "KviSdMwzwqAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# with no translation for become faster answer:👇👇🙏"
      ],
      "metadata": {
        "id": "iuTPp4YYBg2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#TOPIC = f\"Understanding the Cycle of Domestic Violence against iranian women: The Influence of Economic Power\"\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=20, max_time=600)\n",
        "def generate_academic_paper_a2(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "\n",
        "       batch = prompts[i:i+20]\n",
        "       print(\"batch is \",batch)\n",
        "   #for j in range ( 0, Len(batch)):\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper_a2(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "\n",
        "             # Translate the generated text to Persian\n",
        "         #  choice_translated = translate_to_persian(choice.text) #translator.translate(choice.text, dest='fa')\n",
        "         # choice_translated_prompt = translate_to_persian(prompt)#translator.translate(prompt, dest='fa')\n",
        "\n",
        "         #    print(\"\\n-----\\n Translated is \",choice_translated)\n",
        "         #    save_academic_paper(\"Persian_\"+topic,'\\n**'+choice_translated_prompt+'**\\n'+choice_translated)\n",
        "             save_academic_paper(topic,'\\n--------**\\n'+prompt+'/n-------**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(40)\n",
        "   return choice_text_all#,choice.translated\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts)"
      ],
      "metadata": {
        "id": "rl16DSYABo9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SETUP COLAB for run Streamlit\n",
        "!npm install localtunnel\n",
        "!curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "GRn7OkOUjcdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL Translate\n",
        "A deep learning-based translation library built on Huggingface transformers and Facebook's mBART-Large\n",
        "\n",
        "https://colab.research.google.com/github/xhluca/dl-translate/blob/main/demos/colab_demo.ipynb#scrollTo=qdefSjR_YIiG"
      ],
      "metadata": {
        "id": "_I5yn6CCZdMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q dl-translate"
      ],
      "metadata": {
        "id": "c7-q341UWsr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dl_translate as dlt\n",
        "mt = dlt.TranslationModel('mbart50')"
      ],
      "metadata": {
        "id": "gtQcnXabalaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dl_translate as dlt\n",
        "\n",
        "def translate_to_persian(text):\n",
        "  # Initialize the translation model\n",
        "  #mt = dlt.TranslationModel('mbart50')\n",
        "\n",
        "  # Translate the text\n",
        "  translated = mt.translate(text, source=dlt.lang.ENGLISH, target=dlt.lang.PERSIAN)\n",
        "\n",
        "  return translated"
      ],
      "metadata": {
        "id": "iOX6FGFWaFqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "#topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "#openai.api_key = \"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "# Create a Translator object\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=10, max_time=600)\n",
        "def generate_academic_paper_5(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "              # Translate the generated text to Persian\n",
        "             choice_translated = translate_to_persian(choice.text) #translator.translate(choice.text, dest='fa')\n",
        "             choice_translated_prompt = translate_to_persian(prompt)#translator.translate(prompt, dest='fa')\n",
        "\n",
        "             print(\"\\n-----\\n Translated is \",choice_translated)\n",
        "             save_academic_paper(\"Persian_\"+topic,'\\n**'+choice_translated_prompt+'**\\n'+choice_translated)\n",
        "             save_academic_paper(topic,'\\n**'+prompt+'**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "   return choice_text_all,choice.translated\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ],
      "metadata": {
        "id": "oVldhSpgEVZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For solving queta prompt of Openai API;\n",
        "👇👇🌱"
      ],
      "metadata": {
        "id": "GdTvLhAkKLEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "#import openai\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key = openai_api#\"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\",\n",
        ")\n",
        "\n",
        "def retry_with_exponential_backoff(\n",
        "   func,\n",
        "   initial_delay: float = 1,\n",
        "   exponential_base: float = 2,\n",
        "   jitter: bool = True,\n",
        "   max_retries: int = 10,\n",
        "   errors: tuple = (openai.error.RateLimitError,),\n",
        "):\n",
        "   \"\"\"Retry a function with exponential backoff.\"\"\"\n",
        "   def wrapper(*args, **kwargs):\n",
        "       # Initialize variables\n",
        "       num_retries = 0\n",
        "       delay = initial_delay\n",
        "       # Loop until a successful response or max_retries is hit or an exception is raised\n",
        "       while True:\n",
        "           try:\n",
        "               return func(*args, **kwargs)\n",
        "           # Retry on specified errors\n",
        "           except errors as e:\n",
        "               # Increment retries\n",
        "               num_retries += 1\n",
        "               # Check if max retries has been reached\n",
        "               if num_retries > max_retries:\n",
        "                  raise Exception(\n",
        "                      f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
        "                  )\n",
        "               # Increment the delay\n",
        "               delay *= exponential_base * (1 + jitter * random.random())\n",
        "               # Sleep for the delay\n",
        "               time.sleep(delay)\n",
        "           # Raise exceptions for any errors not specified\n",
        "           except Exception as e:\n",
        "               raise e\n",
        "   return wrapper\n",
        "\n",
        "@retry_with_exponential_backoff\n",
        "def generate_academic_paper_0(prompt_my):\n",
        "  model_engine = \"text-davinci-003\"\n",
        "  max_tokens = 2048\n",
        "\n",
        "  completion = client.completions.create(\n",
        "      model=\"gpt-3.5-turbo-instruct\",\n",
        "      prompt=prompt_my,\n",
        "      max_tokens=2048,\n",
        "      temperature=0.3,\n",
        "      n=1,\n",
        "      frequency_penalty=0,\n",
        "  )\n",
        "  return completion"
      ],
      "metadata": {
        "id": "zLWA8i87KXks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH0Z7EL5LnQc"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries and set up the API key\n",
        "#!pip install openai\n",
        "import json\n",
        "#TOPIC =f\"strategies for increase the compassion in iranian Women movment and ist relationship with the fatigue of compassion in light triad personality\"  #f\" the dark triad in psychology and it's relation with {goal}\"\n",
        "topic = f\"The Importance of Focusing on Waste Collection in a Waste-Filled World\"\n",
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "openai.api_key = openai_api#\"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\"# \"your_openai_api_key\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key= openai_api#\"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\",\n",
        ")\n",
        "#openai.api_key = os.getenv('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')\n",
        "# Define the prompts\n",
        "prompts3 = [\n",
        "f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "f\"Identify gaps in the literature on '{topic}'\",\n",
        "\"Generate 10 academic research questions about Perviuse action\",\n",
        "f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Function to generate an academic paper\n",
        "\n",
        "from openai import RateLimitError\n",
        "from backoff import on_exception, expo\n",
        "\n",
        "@on_exception(expo, RateLimitError, max_tries=10, max_time=600)\n",
        "def generate_academic_paper_6(prompt_my):\n",
        "   model_engine = \"text-davinci-003\"\n",
        "   max_tokens = 2048\n",
        "\n",
        "   completion = client.completions.create(\n",
        "       model=\"gpt-3.5-turbo-instruct\",\n",
        "       prompt=prompt_my,\n",
        "       max_tokens=2048,\n",
        "       temperature=0.3,\n",
        "       n=1,\n",
        "       frequency_penalty=0,\n",
        "   )\n",
        "   return completion\n",
        "\n",
        "choice_text_all=[]\n",
        "\n",
        "import time\n",
        "# Function to generate academic papers for given prompts\n",
        "# Function to generate academic papers for given prompts\n",
        "def generate_papers(prompts):\n",
        "   for i in range(0, len(prompts), 20):\n",
        "       # Slice the prompts list to get the next 20 prompts\n",
        "       print(\"I is \",i,\" Len of prompt Is:\", len(prompts))\n",
        "       batch = prompts[i:i+10]\n",
        "       print(\"batch is \",batch)\n",
        "       # Generate papers for the next 20 prompts\n",
        "       for prompt in batch:\n",
        "      #   for prompt in prompt1:\n",
        "           # Print the prompt\n",
        "           print(\"prompt is \", prompt)\n",
        "           response = generate_academic_paper(prompt)\n",
        "           print(\"\\nGenerated Academic Paper:\")\n",
        "           print(\"========================\\n\")\n",
        "           #print(response)\n",
        "           for choice in response.choices:\n",
        "             print(choice.text)\n",
        "             choice_text_all.append(choice.text)\n",
        "             save_academic_paper(TOPIC,'\\n**'+prompt+'**\\n'+choice.text)\n",
        "             # Recursively call the function for the nested Completion objects\n",
        "             if hasattr(choice, 'choices'):\n",
        "               extract_text(choice)\n",
        "\n",
        "           #generated_text = response.choices[0].text\n",
        "           # Print the generated text\n",
        "           #print(generated_text)\n",
        "           print(\"\\n end of loop\")\n",
        "           print(\"========================\\n\")\n",
        "\n",
        "           #print(\"loop\")\n",
        "       # Wait for a short period of time before sending the next batch of prompts\n",
        "           time.sleep(2)\n",
        "   return choice.text_all\n",
        "\n",
        "# Generate academic papers for the given prompts\n",
        "generate_papers(prompts3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJTgcojthnm7"
      },
      "outputs": [],
      "source": [
        "def render_index_page():\n",
        "   html_content = \"\"\"\n",
        "   <!DOCTYPE html>\n",
        "   <html>\n",
        "   <head>\n",
        "      <title>Generate Academic Papers</title>\n",
        "   </head>\n",
        "   <body>\n",
        "      <h1>Generate Academic Papers</h1>\n",
        "      <form method=\"POST\">\n",
        "          <label for=\"topic\">Topic:</label>\n",
        "          <input type=\"text\" id=\"topic\" name=\"topic\" required>\n",
        "          <input type=\"submit\" value=\"Generate\">\n",
        "      </form>\n",
        "   </body>\n",
        "   </html>\n",
        "   \"\"\"\n",
        "   return render_template_string(html_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKhSXALkhpL7"
      },
      "outputs": [],
      "source": [
        "def render_result_page(topic, docx_file, pdf_file, choice_text_all):\n",
        "   html_content = f\"\"\"\n",
        "   <!DOCTYPE html>\n",
        "   <html>\n",
        "   <head>\n",
        "       <title>Result</title>\n",
        "   </head>\n",
        "   <body>\n",
        "       <h1>Result</h1>\n",
        "       <p>Academic papers have been generated for the topic: {topic}</p>\n",
        "       <a href=\"/download/{docx_file}\">Download DOCX</a>\n",
        "       <a href=\"/download/{pdf_file}\">Download PDF</a>\n",
        "       <h2>Generated Text:</h2>\n",
        "       <p>{choice_text_all}</p>\n",
        "   </body>\n",
        "   </html>\n",
        "   \"\"\"\n",
        "   return render_template_string(html_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuTJlSSGgh4E"
      },
      "outputs": [],
      "source": [
        "# app.py\n",
        "\n",
        "from flask import Flask, request, render_template\n",
        "from academic_paper_generator import generate_papers\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def home():\n",
        "  if request.method == 'POST':\n",
        "      topic = request.form.get('topic')\n",
        "      prompts3 = [\n",
        "          f\"Find a research topic for a PhD in the area of '{topic}'\",\n",
        "          f\"Write a detailed proposal on the following research '{topic}'. Make Sure it is free from plagiarism. \",\n",
        "          f\"Identify gaps in the literature on '{topic}'\",\n",
        "          \"Generate 10 academic research questions about Perviuse action\",\n",
        "          f\"Generate a list of research hypotheses related to '{topic}'\"\n",
        "      ]\n",
        "      generate_papers(prompts3)\n",
        "      return render_template('result.html', topic=topic)\n",
        "  else:\n",
        "      return render_template('index.html')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5a5d686d66df49e1b836374837cd39e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b1acca088e749bcae35dab52c9e7991",
              "IPY_MODEL_415149e1650c45aca03225a671917ddd",
              "IPY_MODEL_f866fa9d7961420da51838a542360d84"
            ],
            "layout": "IPY_MODEL_7b1de52ac7914c6aa39bf9182e17174e"
          }
        },
        "9b1acca088e749bcae35dab52c9e7991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65d2392ae35b4c45acbec4fc98506401",
            "placeholder": "​",
            "style": "IPY_MODEL_a628a3eaad0d4fb3903a9a44aa1aad5b",
            "value": "model_index.json: 100%"
          }
        },
        "415149e1650c45aca03225a671917ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd43be57c7384c1daab427034d3a8711",
            "max": 541,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e76601ee0d314b6e9366b0a9846d5975",
            "value": 541
          }
        },
        "f866fa9d7961420da51838a542360d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f63e225c87f478dbbc82ea1f6e5a40c",
            "placeholder": "​",
            "style": "IPY_MODEL_ad1912297ff9450babd2dce13727084f",
            "value": " 541/541 [00:00&lt;00:00, 26.0kB/s]"
          }
        },
        "7b1de52ac7914c6aa39bf9182e17174e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65d2392ae35b4c45acbec4fc98506401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a628a3eaad0d4fb3903a9a44aa1aad5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd43be57c7384c1daab427034d3a8711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e76601ee0d314b6e9366b0a9846d5975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f63e225c87f478dbbc82ea1f6e5a40c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad1912297ff9450babd2dce13727084f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e806aae5b5454dc3afb1154b00e22855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_316edb0c3d294e6ca627d136e16d7a31",
              "IPY_MODEL_1a990a42347c45b888c694577fe4d491",
              "IPY_MODEL_6fc05178fafb4c988c7a94dc50237a8c"
            ],
            "layout": "IPY_MODEL_6be0f94e5f59490099cb390fc86ee26f"
          }
        },
        "316edb0c3d294e6ca627d136e16d7a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc4f931d14b24d1e8d134e8de10f0e67",
            "placeholder": "​",
            "style": "IPY_MODEL_228377add59340cd924fa6aacc063603",
            "value": "Fetching 15 files: 100%"
          }
        },
        "1a990a42347c45b888c694577fe4d491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4721bc68546408299d0a90b5010cf2b",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b40a4b67378447ff9090ab075f9c2a7b",
            "value": 15
          }
        },
        "6fc05178fafb4c988c7a94dc50237a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_023e4ccf4242485aa85e42f5dfaac155",
            "placeholder": "​",
            "style": "IPY_MODEL_2984641b143e4380a665c523311d9af2",
            "value": " 15/15 [00:58&lt;00:00,  4.52s/it]"
          }
        },
        "6be0f94e5f59490099cb390fc86ee26f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc4f931d14b24d1e8d134e8de10f0e67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228377add59340cd924fa6aacc063603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4721bc68546408299d0a90b5010cf2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40a4b67378447ff9090ab075f9c2a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "023e4ccf4242485aa85e42f5dfaac155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2984641b143e4380a665c523311d9af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d95593e0f52f411d98d4e52fcf3cbf69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_824be7e04a2e4c0e85a895aeaf058fb5",
              "IPY_MODEL_d453e86bf03340ae969d28df004a6d5b",
              "IPY_MODEL_e4938bd57bb24e9ea9e9a15dbb841ce8"
            ],
            "layout": "IPY_MODEL_c9244decf39b474ab5017dc32ec7e08f"
          }
        },
        "824be7e04a2e4c0e85a895aeaf058fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87ca06d6e7d14cf2883c1b4bfe659ee1",
            "placeholder": "​",
            "style": "IPY_MODEL_99c15a97b2014916acf3f4f916bc689b",
            "value": "tokenizer/merges.txt: 100%"
          }
        },
        "d453e86bf03340ae969d28df004a6d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_719dc8e2f4cf442c832dfa0cd7435972",
            "max": 524619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_417e3cff4acb431f997efc354f914aa8",
            "value": 524619
          }
        },
        "e4938bd57bb24e9ea9e9a15dbb841ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05072f32f76149708ecc126aa8f054c1",
            "placeholder": "​",
            "style": "IPY_MODEL_148b0037519a451eaeb2ac2c3cdc1021",
            "value": " 525k/525k [00:00&lt;00:00, 1.78MB/s]"
          }
        },
        "c9244decf39b474ab5017dc32ec7e08f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87ca06d6e7d14cf2883c1b4bfe659ee1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99c15a97b2014916acf3f4f916bc689b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "719dc8e2f4cf442c832dfa0cd7435972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "417e3cff4acb431f997efc354f914aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05072f32f76149708ecc126aa8f054c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "148b0037519a451eaeb2ac2c3cdc1021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bd241a13526413497bbfbefd4c9f47e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcbbfafd968b41b59ce33b6ae46ada6a",
              "IPY_MODEL_fe1cb4ee4b774f088b15682bff8dcaf3",
              "IPY_MODEL_12fe3810f4884deebfe093b9e6fdd476"
            ],
            "layout": "IPY_MODEL_189808ea749e4c70be7e142b927cf553"
          }
        },
        "fcbbfafd968b41b59ce33b6ae46ada6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0644a0961664435a8761a002e4b4976",
            "placeholder": "​",
            "style": "IPY_MODEL_fb58cd4db2d2410b897b349107af5108",
            "value": "scheduler/scheduler_config.json: 100%"
          }
        },
        "fe1cb4ee4b774f088b15682bff8dcaf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5096eab09e844309802fe0766ac9f188",
            "max": 308,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9118e0e0fb940ba836a420115dc9aa2",
            "value": 308
          }
        },
        "12fe3810f4884deebfe093b9e6fdd476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4148961dab248b8accc8da84fb1ecc1",
            "placeholder": "​",
            "style": "IPY_MODEL_fabd3d8cb1074ac0b3a9da74d7eca09e",
            "value": " 308/308 [00:00&lt;00:00, 1.81kB/s]"
          }
        },
        "189808ea749e4c70be7e142b927cf553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0644a0961664435a8761a002e4b4976": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb58cd4db2d2410b897b349107af5108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5096eab09e844309802fe0766ac9f188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9118e0e0fb940ba836a420115dc9aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4148961dab248b8accc8da84fb1ecc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fabd3d8cb1074ac0b3a9da74d7eca09e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76f3373f5abb4f6bb58c6221ef63d5cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ee304704f9c4f0da61bd3111d2cf1e1",
              "IPY_MODEL_039ab76ac3ae4cc5bbd9f70007939e92",
              "IPY_MODEL_b957a5b5ca1a4de9974c11020276fe9a"
            ],
            "layout": "IPY_MODEL_4eb37f88d76f46769dc18a234391270d"
          }
        },
        "5ee304704f9c4f0da61bd3111d2cf1e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3803cb85e41940b79c58556f03d4e00a",
            "placeholder": "​",
            "style": "IPY_MODEL_e56e2a4812cc4eab9524570177dddef8",
            "value": "(…)ature_extractor/preprocessor_config.json: 100%"
          }
        },
        "039ab76ac3ae4cc5bbd9f70007939e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e32da3240d214d1a97800dc0d89c89d2",
            "max": 342,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_454de433eacc4afbb0c888b8b6fa9af9",
            "value": 342
          }
        },
        "b957a5b5ca1a4de9974c11020276fe9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_645007e7760f473c9b2b98ae379ddadf",
            "placeholder": "​",
            "style": "IPY_MODEL_6cb325f37a124a659844a95e8c3816c0",
            "value": " 342/342 [00:00&lt;00:00, 1.80kB/s]"
          }
        },
        "4eb37f88d76f46769dc18a234391270d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3803cb85e41940b79c58556f03d4e00a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e56e2a4812cc4eab9524570177dddef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e32da3240d214d1a97800dc0d89c89d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "454de433eacc4afbb0c888b8b6fa9af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "645007e7760f473c9b2b98ae379ddadf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cb325f37a124a659844a95e8c3816c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6260ef3ee2647ad9ddd32527e8bc731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5397c9e13f61424fabe024670d052ef5",
              "IPY_MODEL_ba3eea41da3146379245875490954e73",
              "IPY_MODEL_fcbe57a1fdd042eb9f3195f0baedf3a2"
            ],
            "layout": "IPY_MODEL_c3139f3c1d894a06a450673288a72d09"
          }
        },
        "5397c9e13f61424fabe024670d052ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d05b0fce91c54985aeeebde659361a31",
            "placeholder": "​",
            "style": "IPY_MODEL_ab78bf4d638946ef9f17ee4b57237d0a",
            "value": "tokenizer/special_tokens_map.json: 100%"
          }
        },
        "ba3eea41da3146379245875490954e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2c9f412babc46a3b247cbb62a6f10d6",
            "max": 472,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83104aa65e6b4e1f84f77b09d7b172b2",
            "value": 472
          }
        },
        "fcbe57a1fdd042eb9f3195f0baedf3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03a72e8ddb02431099af592c370303d5",
            "placeholder": "​",
            "style": "IPY_MODEL_df67f31b511b4dc9a25cb9e0dfd5a9ef",
            "value": " 472/472 [00:00&lt;00:00, 2.47kB/s]"
          }
        },
        "c3139f3c1d894a06a450673288a72d09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d05b0fce91c54985aeeebde659361a31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab78bf4d638946ef9f17ee4b57237d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2c9f412babc46a3b247cbb62a6f10d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83104aa65e6b4e1f84f77b09d7b172b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03a72e8ddb02431099af592c370303d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df67f31b511b4dc9a25cb9e0dfd5a9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68cd281bb05c47709ae5fdeb8e6932c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bf82af4a88347edaf6897e22ba3a109",
              "IPY_MODEL_e40311f72f4d42dea4f9d4bc4ee394a9",
              "IPY_MODEL_95554c35f5ba44168716e63bfa095945"
            ],
            "layout": "IPY_MODEL_f062c507a3664f7781dfeb01086ede4e"
          }
        },
        "5bf82af4a88347edaf6897e22ba3a109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22ea54b39e224df0bd516cdd9b938c14",
            "placeholder": "​",
            "style": "IPY_MODEL_646d44c5a4fa48d6b50abbafe120debb",
            "value": "text_encoder/config.json: 100%"
          }
        },
        "e40311f72f4d42dea4f9d4bc4ee394a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4afe3c9166f4942adcbe781686c9e5e",
            "max": 617,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77c3dc64fec04b52b7e0f6299028366a",
            "value": 617
          }
        },
        "95554c35f5ba44168716e63bfa095945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcff4fd621fa4834a46f0b0caca4bfc5",
            "placeholder": "​",
            "style": "IPY_MODEL_0dfd99ec160340ccaf03be96f36d8856",
            "value": " 617/617 [00:00&lt;00:00, 4.06kB/s]"
          }
        },
        "f062c507a3664f7781dfeb01086ede4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22ea54b39e224df0bd516cdd9b938c14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "646d44c5a4fa48d6b50abbafe120debb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4afe3c9166f4942adcbe781686c9e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77c3dc64fec04b52b7e0f6299028366a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcff4fd621fa4834a46f0b0caca4bfc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dfd99ec160340ccaf03be96f36d8856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8049cccb108243a3ad1a0f24be6dbcbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc8ff5305a4d4eaf97b26129dadee04b",
              "IPY_MODEL_c654f257390a477c9788c6e0c8c13890",
              "IPY_MODEL_62c2888ae649413daa093cf7b30c970c"
            ],
            "layout": "IPY_MODEL_e43c8780ddef4398bf5bb9921bf2eab6"
          }
        },
        "cc8ff5305a4d4eaf97b26129dadee04b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8beb04af98fa45e797e477f04ee32509",
            "placeholder": "​",
            "style": "IPY_MODEL_9efa754a56894de6a3cd9203894ef14c",
            "value": "safety_checker/config.json: 100%"
          }
        },
        "c654f257390a477c9788c6e0c8c13890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f2265a1c482470fa19b6a6159a97200",
            "max": 4723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f75a45e2ed2c4ac0958f4f244ad5d875",
            "value": 4723
          }
        },
        "62c2888ae649413daa093cf7b30c970c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d2a2e023eea468681f4f1e08fa10a67",
            "placeholder": "​",
            "style": "IPY_MODEL_da5f9d431d4140bda3f96f5fcae5f5c7",
            "value": " 4.72k/4.72k [00:00&lt;00:00, 24.9kB/s]"
          }
        },
        "e43c8780ddef4398bf5bb9921bf2eab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8beb04af98fa45e797e477f04ee32509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9efa754a56894de6a3cd9203894ef14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f2265a1c482470fa19b6a6159a97200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f75a45e2ed2c4ac0958f4f244ad5d875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d2a2e023eea468681f4f1e08fa10a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da5f9d431d4140bda3f96f5fcae5f5c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ed38d33bdae4a95ba19a6d22e51e0d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9fe51d985d141119e2016cdec1f8e2a",
              "IPY_MODEL_cb8bb2057aa64005a826d67074caecb0",
              "IPY_MODEL_34ddbd025e9b42d0a2e228dad3986535"
            ],
            "layout": "IPY_MODEL_447ae4761c1349b59257169c1a887f2d"
          }
        },
        "f9fe51d985d141119e2016cdec1f8e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a5659be8157473ea5e9db425d2e31e4",
            "placeholder": "​",
            "style": "IPY_MODEL_5ffc6979b272405ba807fdd74ba90d99",
            "value": "tokenizer/tokenizer_config.json: 100%"
          }
        },
        "cb8bb2057aa64005a826d67074caecb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17986e79d213435f93a6f3636bf53b04",
            "max": 806,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1e9e0a28e2c4c4597587778b9850564",
            "value": 806
          }
        },
        "34ddbd025e9b42d0a2e228dad3986535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b319cfc9320a4f2fb4fe4aef4a57ebb6",
            "placeholder": "​",
            "style": "IPY_MODEL_52d31d1c9b3040ff8314636aebc0766d",
            "value": " 806/806 [00:00&lt;00:00, 4.12kB/s]"
          }
        },
        "447ae4761c1349b59257169c1a887f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5659be8157473ea5e9db425d2e31e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ffc6979b272405ba807fdd74ba90d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17986e79d213435f93a6f3636bf53b04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1e9e0a28e2c4c4597587778b9850564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b319cfc9320a4f2fb4fe4aef4a57ebb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52d31d1c9b3040ff8314636aebc0766d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26551fee300b45059a3507890d6ed081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c52ddf2f937641cab474999fd1021b10",
              "IPY_MODEL_056db4fc725c46b6968899f2985d4564",
              "IPY_MODEL_416e3fdc7c7a4bb6a18eae8432093a51"
            ],
            "layout": "IPY_MODEL_c61ca3e88474415497cde262f66bf8b9"
          }
        },
        "c52ddf2f937641cab474999fd1021b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_047f2a9aa54149faba3bdd638d2d643d",
            "placeholder": "​",
            "style": "IPY_MODEL_53dbefcfce0540ada05effd786333e81",
            "value": "tokenizer/vocab.json: 100%"
          }
        },
        "056db4fc725c46b6968899f2985d4564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d9325c8c85a44fb95acfe037d2622a9",
            "max": 1059962,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_878219683bd84859acc137e54d5cfac0",
            "value": 1059962
          }
        },
        "416e3fdc7c7a4bb6a18eae8432093a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23383869c99748b29f00e850429b9a56",
            "placeholder": "​",
            "style": "IPY_MODEL_0adfec77b17f40569d89f55a27264081",
            "value": " 1.06M/1.06M [00:00&lt;00:00, 2.14MB/s]"
          }
        },
        "c61ca3e88474415497cde262f66bf8b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "047f2a9aa54149faba3bdd638d2d643d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53dbefcfce0540ada05effd786333e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d9325c8c85a44fb95acfe037d2622a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "878219683bd84859acc137e54d5cfac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23383869c99748b29f00e850429b9a56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0adfec77b17f40569d89f55a27264081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66084ce4fca04f728b7c8c782dc2ac72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4317609118444aec9135ea277410bd13",
              "IPY_MODEL_a38d9d8bedc7440194adefdd4be36dab",
              "IPY_MODEL_d87f9110de8f488cb8f58066b152b1f2"
            ],
            "layout": "IPY_MODEL_6335c340917e4430aca2e9b74406aeab"
          }
        },
        "4317609118444aec9135ea277410bd13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55a829725dcc41e695c0b008e60806ad",
            "placeholder": "​",
            "style": "IPY_MODEL_15adc1a82ee940d48e55dcf54a8bfc9a",
            "value": "unet/config.json: 100%"
          }
        },
        "a38d9d8bedc7440194adefdd4be36dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36fec0d5e76b40358f0c702b085aef4a",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41043f77a6a74d4c8faadf00c72376db",
            "value": 743
          }
        },
        "d87f9110de8f488cb8f58066b152b1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ba79a605ec048e3ad663c881db804b3",
            "placeholder": "​",
            "style": "IPY_MODEL_7530b7425fa14e5d8c7c91047e543a9d",
            "value": " 743/743 [00:00&lt;00:00, 4.81kB/s]"
          }
        },
        "6335c340917e4430aca2e9b74406aeab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55a829725dcc41e695c0b008e60806ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15adc1a82ee940d48e55dcf54a8bfc9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36fec0d5e76b40358f0c702b085aef4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41043f77a6a74d4c8faadf00c72376db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ba79a605ec048e3ad663c881db804b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7530b7425fa14e5d8c7c91047e543a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad9bd62fd52444fbb2f9817cec424a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ae3fec928d144bfb5995f94373bdc04",
              "IPY_MODEL_3809e9bcd7a347709f21180359697487",
              "IPY_MODEL_3e13c554e79c43adb5305fc0067fb481"
            ],
            "layout": "IPY_MODEL_d76c1fab7c6f473cb8d6167cf09270f5"
          }
        },
        "5ae3fec928d144bfb5995f94373bdc04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7760f624cd0a45bc9295645b0a3ca7fb",
            "placeholder": "​",
            "style": "IPY_MODEL_3538f0b814e04e75864e97e1397b5175",
            "value": "vae/config.json: 100%"
          }
        },
        "3809e9bcd7a347709f21180359697487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07143968c4f041d7a9e983d1478d4be8",
            "max": 547,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cb7e888a60c47d88bea9b5237009a41",
            "value": 547
          }
        },
        "3e13c554e79c43adb5305fc0067fb481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea248e9876c54250ae9063b94f029e03",
            "placeholder": "​",
            "style": "IPY_MODEL_f00c3a9208414d80903c418482ca4938",
            "value": " 547/547 [00:00&lt;00:00, 3.74kB/s]"
          }
        },
        "d76c1fab7c6f473cb8d6167cf09270f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7760f624cd0a45bc9295645b0a3ca7fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3538f0b814e04e75864e97e1397b5175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07143968c4f041d7a9e983d1478d4be8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cb7e888a60c47d88bea9b5237009a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea248e9876c54250ae9063b94f029e03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f00c3a9208414d80903c418482ca4938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9061f036bc6f4086bec6633baeee0f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76f1681fb4b844e09edb49b075ca5040",
              "IPY_MODEL_9c0dade1375748dd8b199b41d749f842",
              "IPY_MODEL_9ece2cb3279445bd8a6edaac31229634"
            ],
            "layout": "IPY_MODEL_0d97b01828a347e6a9cf5f1bc3b4b12b"
          }
        },
        "76f1681fb4b844e09edb49b075ca5040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85e19bf8456142fe90e0b14a2834d566",
            "placeholder": "​",
            "style": "IPY_MODEL_291fcc5291a64df5a40270ec6a4af5ae",
            "value": "model.safetensors: 100%"
          }
        },
        "9c0dade1375748dd8b199b41d749f842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bfbe982b45e4e37a1afcb147198da8c",
            "max": 1215981830,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c6972d62e3d4b3aa21756f3fda850f6",
            "value": 1215981830
          }
        },
        "9ece2cb3279445bd8a6edaac31229634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4294dffcb984789a7a010b64e75a913",
            "placeholder": "​",
            "style": "IPY_MODEL_a24306084c5c438f891f433a0f4afcec",
            "value": " 1.22G/1.22G [00:27&lt;00:00, 84.3MB/s]"
          }
        },
        "0d97b01828a347e6a9cf5f1bc3b4b12b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85e19bf8456142fe90e0b14a2834d566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "291fcc5291a64df5a40270ec6a4af5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bfbe982b45e4e37a1afcb147198da8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c6972d62e3d4b3aa21756f3fda850f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4294dffcb984789a7a010b64e75a913": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a24306084c5c438f891f433a0f4afcec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "183054e577e74ed09ba210ef03134c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01f7bc4c321340bdba20399c33449eb6",
              "IPY_MODEL_26737b8796884a66afae736313d77902",
              "IPY_MODEL_cde18ac314384b3ea210b54d4e4f6bbc"
            ],
            "layout": "IPY_MODEL_67b4f4db1cc64d598d8f6ec3e4f42c24"
          }
        },
        "01f7bc4c321340bdba20399c33449eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d8600810e5842a59045be019e419807",
            "placeholder": "​",
            "style": "IPY_MODEL_e9306843805744d4a27a828f1de6222a",
            "value": "model.safetensors: 100%"
          }
        },
        "26737b8796884a66afae736313d77902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_909c15ede2d540418ccc1a55e1227248",
            "max": 492265874,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8609e52241cb48d08a6cb38ac5969fbc",
            "value": 492265874
          }
        },
        "cde18ac314384b3ea210b54d4e4f6bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebf2899031134412972148c540209612",
            "placeholder": "​",
            "style": "IPY_MODEL_88adc4904ac94a898d5c4583c7f3631b",
            "value": " 492M/492M [00:17&lt;00:00, 56.5MB/s]"
          }
        },
        "67b4f4db1cc64d598d8f6ec3e4f42c24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d8600810e5842a59045be019e419807": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9306843805744d4a27a828f1de6222a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "909c15ede2d540418ccc1a55e1227248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8609e52241cb48d08a6cb38ac5969fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebf2899031134412972148c540209612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88adc4904ac94a898d5c4583c7f3631b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e2bf5251d7844de829f7f72cfe27744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98240d14aabd4f9eab4603cfe4239360",
              "IPY_MODEL_28206c896dd74e0e8d46fe797027f7d8",
              "IPY_MODEL_1eea8ec1d73348b0a52fa8c779d18cd7"
            ],
            "layout": "IPY_MODEL_3c38a28a3569404cbaed0e7df08963c4"
          }
        },
        "98240d14aabd4f9eab4603cfe4239360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fac1fdc7f2547bb8adb3f2b09a37177",
            "placeholder": "​",
            "style": "IPY_MODEL_772cf02f95d74b78bb54074fdf079c12",
            "value": "diffusion_pytorch_model.safetensors: 100%"
          }
        },
        "28206c896dd74e0e8d46fe797027f7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf5e674a08d247408cfb7f49e345deae",
            "max": 3438167540,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8b06f3762d44dd7826bead24643db3d",
            "value": 3438167540
          }
        },
        "1eea8ec1d73348b0a52fa8c779d18cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34b38c57248f4fc0a1e134a099db7b57",
            "placeholder": "​",
            "style": "IPY_MODEL_8f5ffee32d234aaeb60fab0624189654",
            "value": " 3.44G/3.44G [00:57&lt;00:00, 114MB/s]"
          }
        },
        "3c38a28a3569404cbaed0e7df08963c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fac1fdc7f2547bb8adb3f2b09a37177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "772cf02f95d74b78bb54074fdf079c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf5e674a08d247408cfb7f49e345deae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b06f3762d44dd7826bead24643db3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34b38c57248f4fc0a1e134a099db7b57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f5ffee32d234aaeb60fab0624189654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69f1b43272c743b3b8a68b92752f2547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_faeed76c18bc447f9307a2ef2554373f",
              "IPY_MODEL_0042cc2b46684f828ab576520c00c3d0",
              "IPY_MODEL_58565821e77d45099b0a81e539380247"
            ],
            "layout": "IPY_MODEL_19ae67896c75422496599a08569d7e1d"
          }
        },
        "faeed76c18bc447f9307a2ef2554373f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f7122e0f7c6407e82fa01b9315947fb",
            "placeholder": "​",
            "style": "IPY_MODEL_651d5c4d0f594f1ba64a6e6ee16d552f",
            "value": "diffusion_pytorch_model.safetensors: 100%"
          }
        },
        "0042cc2b46684f828ab576520c00c3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8866d6a3a63c4ea1882c6d3513dee8b7",
            "max": 334643276,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcfc1408185744ad8a3c7e56bd6878df",
            "value": 334643276
          }
        },
        "58565821e77d45099b0a81e539380247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7263c511f084a51bc20f5cff2b9b189",
            "placeholder": "​",
            "style": "IPY_MODEL_e60ebfff739d470098beef49b805c704",
            "value": " 335M/335M [00:14&lt;00:00, 48.7MB/s]"
          }
        },
        "19ae67896c75422496599a08569d7e1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f7122e0f7c6407e82fa01b9315947fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651d5c4d0f594f1ba64a6e6ee16d552f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8866d6a3a63c4ea1882c6d3513dee8b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcfc1408185744ad8a3c7e56bd6878df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7263c511f084a51bc20f5cff2b9b189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e60ebfff739d470098beef49b805c704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "416799817d6a43ccacee1505a2cdc6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ea989b3ff744bee8ad2e5ab5f7a976d",
              "IPY_MODEL_0b6f2fa844624ef0bd6094c3234c0d82",
              "IPY_MODEL_74a3851addf24cb381ed4ee80a657312"
            ],
            "layout": "IPY_MODEL_3631132f19d34547b30d38c54986e82d"
          }
        },
        "3ea989b3ff744bee8ad2e5ab5f7a976d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6650ddfca444314a063f76199c0bf2f",
            "placeholder": "​",
            "style": "IPY_MODEL_f7e8bc976ff44ae9ae83a8c543fa8818",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "0b6f2fa844624ef0bd6094c3234c0d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_defc3382ed864fdca7776b706105fef0",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcee8d8fb34d44cb9b0acbd2e03b4817",
            "value": 7
          }
        },
        "74a3851addf24cb381ed4ee80a657312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c51230ea780840e5818cfbc3e61b2085",
            "placeholder": "​",
            "style": "IPY_MODEL_35a7e139a38c48f2a48b63d4988f33e6",
            "value": " 7/7 [00:02&lt;00:00,  3.67it/s]"
          }
        },
        "3631132f19d34547b30d38c54986e82d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6650ddfca444314a063f76199c0bf2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7e8bc976ff44ae9ae83a8c543fa8818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "defc3382ed864fdca7776b706105fef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcee8d8fb34d44cb9b0acbd2e03b4817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c51230ea780840e5818cfbc3e61b2085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35a7e139a38c48f2a48b63d4988f33e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}