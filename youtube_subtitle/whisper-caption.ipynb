{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soheilpaper/-tft-2.4-ili9341-STM32/blob/master/youtube_subtitle/whisper-caption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "783e4589",
      "metadata": {
        "id": "783e4589"
      },
      "source": [
        "# Setup\n",
        "Here we install the required packages for this application. Additionally, we will remove a single line from the ImageMagick policy that would have prevented this code from running, create our experiments directory, and restart the kernel.\n",
        "\n",
        "> Note: We need to restart the kernel due to an odd behavior from MoviePy that stops this from working in the same session as the install.\n",
        "\n",
        "> Just move onto the next section of this notebook after running the install cell below.\n",
        "\n",
        "> We should be especially wary of this if we intend to 'Run All' cells, as it will catch here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "global gdrive_fpath\n",
        "drive_mounted = False\n",
        "gdrive_fpath = '.'\n",
        "local_path = '/content/'\n",
        "\n",
        "mount_gdrive = True # @param{type:\"boolean\"}\n",
        "if mount_gdrive : # and not drive_mounted:\n",
        "    from google.colab import drive\n",
        "\n",
        "    gdrive_mountpoint = '/content/drive/' #@param{type:\"string\"}\n",
        "    gdrive_subdirectory = 'MyDrive/YouTube_Auto_Subtitle' #@param{type:\"string\"}\n",
        "    gdrive_fpath = str(Path(gdrive_mountpoint) / gdrive_subdirectory)\n",
        "    print (\"gdrive path is :\",gdrive_fpath)\n",
        "   # Mount Google Drive\n",
        "    if not os.path.isdir(gdrive_mountpoint):\n",
        "     # If not, mount the drive\n",
        "       drive.mount(gdrive_mountpoint)\n",
        "       if not os.path.exists(gdrive_fpath):\n",
        "          os.makedirs(gdrive_fpath)\n",
        "          os.chdir(gdrive_fpath)\n",
        "    else:\n",
        "          print(\"Drive is already mounted.\")\n",
        "else:\n",
        "   Folder_fpath ='/content/' #@param{type:\"string\"}\n",
        "   #gdrive_subdirectory = 'MyDrive/ChatGPT_Paper_wrting' #@param{type:\"string\"}\n",
        "   gdrive_fpath = Folder_fpath\n",
        "   os.chdir(gdrive_fpath)\n",
        "folder_path = gdrive_fpath"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_pC5ZXOfK7f",
        "outputId": "94e492c8-6073-4715-e63e-68fd4ad5a1f4"
      },
      "id": "V_pC5ZXOfK7f",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive path is : /content/drive/MyDrive/YouTube_Auto_Subtitle\n",
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d06587d3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T15:58:15.069487Z",
          "iopub.status.busy": "2023-12-14T15:58:15.069013Z"
        },
        "id": "d06587d3",
        "outputId": "97f81475-9e3b-492a-c9ae-cc86806bded0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Whisper-AutoCaption'...\n",
            "remote: Enumerating objects: 352, done.\u001b[K\n",
            "remote: Counting objects: 100% (129/129), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 352 (delta 58), reused 89 (delta 26), pack-reused 223\u001b[K\n",
            "Receiving objects: 100% (352/352), 3.20 MiB | 23.40 MiB/s, done.\n",
            "Resolving deltas: 100% (157/157), done.\n",
            "/content/Whisper-AutoCaption\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (10.1.0)\n",
            "Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.35.2)\n",
            "Collecting ffmpeg-python==0.2.0 (from -r requirements.txt (line 6))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->-r requirements.txt (line 6)) (0.18.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (0.20.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r requirements.txt (line 5)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r requirements.txt (line 5)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r requirements.txt (line 5)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r requirements.txt (line 5)) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 2)) (1.3.0)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-p_s6czmg\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-p_s6czmg\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=2c5963b021f92e904a6576e21a3f8c45653576d7295770ac593fcb98be26adae\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t5g7kg9x/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.5.2\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-_h0mr5dq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-_h0mr5dq\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.5.2)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2023.12.30-py2.py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2023.11.17)\n",
            "Requirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Collecting websockets>=12.0 (from yt-dlp)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.6)\n",
            "Installing collected packages: brotli, websockets, pycryptodomex, mutagen, yt-dlp\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/gradient-ai/Whisper-AutoCaption\n",
        "\n",
        "%cd Whisper-AutoCaption\n",
        "import os\n",
        "!pip install -r requirements.txt\n",
        "!pip install --upgrade git+https://github.com/openai/whisper.git\n",
        "\n",
        "!pip install yt-dlp\n",
        "!pip install moviepy --upgrade\n",
        "!apt-get update\n",
        "!apt install imagemagick -y\n",
        "# remove line 88 of vim ~/../etc/ImageMagick-6/policy.xml to run MoviePy\n",
        "!sed -i '88d' ~/../etc/ImageMagick-6/policy.xml\n",
        "!mkdir experiments\n",
        "#os._exit(00)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd9b2695",
      "metadata": {
        "id": "dd9b2695"
      },
      "source": [
        "# The function\n",
        "\n",
        "The `subtitle_video` function does all the work for us to autocaption our supplied video with the generated text captions from Whisper at the correct time stamps.\n",
        "\n",
        "This works for both youtube links and videos uploaded directly to this Notebook, and will automatically scale the size of the captions to the video size.\n",
        "\n",
        "See the params notes section of the start of the function and the function call below for more details on the arguments for this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffedc8a2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T16:01:24.820153Z",
          "iopub.status.busy": "2023-12-14T16:01:24.819481Z",
          "iopub.status.idle": "2023-12-14T16:01:27.566764Z",
          "shell.execute_reply": "2023-12-14T16:01:27.566129Z",
          "shell.execute_reply.started": "2023-12-14T16:01:24.820129Z"
        },
        "id": "ffedc8a2"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "from __future__ import unicode_literals\n",
        "from yt_dlp import YoutubeDL\n",
        "import yt_dlp\n",
        "from IPython.display import Video\n",
        "import whisper\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from moviepy.editor import VideoFileClip\n",
        "import moviepy.editor as mp\n",
        "from IPython.display import display, Markdown\n",
        "from moviepy.editor import *\n",
        "from moviepy.video.tools.subtitles import SubtitlesClip\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import subprocess\n",
        "import json\n",
        "\n",
        "import yt_dlp\n",
        "from whisper.utils import get_writer\n",
        "\n",
        "\n",
        "\n",
        "def get_video_title(url):\n",
        "    ydl_opts = {\n",
        "        'skip_download': True, # We don't want to download the video\n",
        "        'quiet': True, # We don't want to print everything to the console\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        info = ydl.extract_info(url, download=False)\n",
        "        return info.get('title', None)\n",
        "\n",
        "def subtitle_video(download, url, aud_opts, vid_opts, model_type, name, audio_file, input_file, output, lang, uploaded_vid = None):\n",
        "# ------------------------------------------------------------------------------------------------------------------------------\n",
        "#     Params:\n",
        "# ------------------------------------------------------------------------------------------------------------------------------\n",
        "#     download:      bool, this tells your function if you are downloading a youtube video\n",
        "#     url: str,      str, the URL of youtube video to download if download is True\n",
        "#     aud_opts:      dict, audio file youtube-dl options\n",
        "#     vid_opts:      dict, video file youtube-dl options\n",
        "#     model_type:    str, which pretrained model to download. Options are:\n",
        "#                    ['tiny', 'small', 'base', 'medium','large','tiny.en', 'small.en', 'base.en', 'medium.en']\n",
        "#                    More details about model_types can be found in table in original repo here:\n",
        "#                    https://github.com/openai/whisper#Available-models-and-languages\n",
        "#.    name:          str, name of directory to store files in in experiments folder\n",
        "#     audio_file:    str, path to extracted audio file for Whisper\n",
        "#     input_file:    str, path to video file for MoviePy to caption\n",
        "#     output:        str, destination of final output video file\n",
        "#     uploaded_vid:  str, path to uploaded video file if download is False\n",
        "#\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "#     Returns:       An annotated video with translated captions into english, saved to name/output\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    ## First, this checks if your expermiment name is taken. If not, it will create the directory.\n",
        "    ## Otherwise, we will be prompted to retry with a new name\n",
        "    try:\n",
        "        os.mkdir(f'{name}')\n",
        "        print('Starting AutoCaptioning...')\n",
        "        print(f'Results will be stored in :{name}')\n",
        "\n",
        "    except:\n",
        "       pass #print('Choose another folder name! This one already has files in it.')\n",
        "\n",
        "    ## Use audio and video options for youtube-dl if downloading from youtube\n",
        "    vid_opts['outtmpl'] = f'{name}/{input_file}'\n",
        "    aud_opts['outtmpl'] = f'{name}/{audio_file}'\n",
        "\n",
        "    URLS = [url]\n",
        "    if download:\n",
        "        with YoutubeDL(aud_opts) as ydl:\n",
        "            ydl.download(url)\n",
        "            title = get_video_title(url)\n",
        "        with YoutubeDL(vid_opts) as ydl:\n",
        "            ydl.download(URLS)\n",
        "\n",
        "    else:\n",
        "        # Use local clip if not downloading from youtube\n",
        "        my_clip = mp.VideoFileClip(uploaded_vid)\n",
        "        my_clip.write_videofile(f'{name}/{input_file}')\n",
        "        my_clip.audio.write_audiofile(f'{name}/{audio_file}')\n",
        "\n",
        "\n",
        "\n",
        "    title  = \"\".join(c if c.isalnum() else \"_\" for c in title).rstrip(\"_\")\n",
        "    output = f'{name}/{title}.mp4'\n",
        "    # Instantiate whisper model using model_type variable\n",
        "    model = whisper.load_model(model_type)\n",
        "\n",
        "    # Get text from speech for subtitles from audio file\n",
        "    result = model.transcribe(f'''{name}/{audio_file}''', task = 'translate', language = lang)\n",
        "    srt_writer = get_writer(\"srt\", f\"{name}/{audio_file}\")\n",
        "    srt_writer(result, f'{name}/{title}.str')\n",
        "\n",
        "    # create Subtitle dataframe, and save it\n",
        "    dict1 = {'start':[], 'end':[], 'text':[]}\n",
        "    for i in result['segments']:\n",
        "        dict1['start'].append(int(i['start']))\n",
        "        dict1['end'].append(int(i['end']))\n",
        "        dict1['text'].append(i['text'])\n",
        "    df = pd.DataFrame.from_dict(dict1)\n",
        "    df.to_csv(f'{name}/subs.csv')\n",
        "    vidcap = cv2.VideoCapture(f'''{name}/{input_file}''')\n",
        "    success,image = vidcap.read()\n",
        "    height = image.shape[0]\n",
        "    width =image.shape[1]\n",
        "\n",
        "    # Instantiate MoviePy subtitle generator with TextClip, subtitles, and SubtitlesClip\n",
        "    generator = lambda txt: TextClip(\n",
        "        txt,\n",
        "        font='P052-Bold',\n",
        "        fontsize=width / 30, # Adjust font size (increase for larger text)\n",
        "        stroke_width=2, # Adjust stroke width\n",
        "        color='yellow', # Change text color to yellow\n",
        "        bg_color='transparent', # Set background color to transparent\n",
        "        size=(width, height * 0.25),\n",
        "        method='caption'\n",
        "    )\n",
        "    subs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\n",
        "    subtitles = SubtitlesClip(subs, generator)\n",
        "\n",
        "    # Ff the file was on youtube, add the captions to the downloaded video\n",
        "    if download:\n",
        "        video = VideoFileClip(f'{name}/{input_file}')\n",
        "        final = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\n",
        "        final.write_videofile(f'{output}', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n",
        "    else:\n",
        "        # If the file was a local upload:\n",
        "        video = VideoFileClip(uploaded_vid)\n",
        "        final = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\n",
        "        final.write_videofile(f'{output}', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n",
        "\n",
        "    return f'{output}'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe41bec9",
      "metadata": {
        "id": "fe41bec9"
      },
      "source": [
        "## Declare relevant variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52afb830",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T16:01:27.568394Z",
          "iopub.status.busy": "2023-12-14T16:01:27.567872Z",
          "iopub.status.idle": "2023-12-14T16:01:27.571778Z",
          "shell.execute_reply": "2023-12-14T16:01:27.571316Z",
          "shell.execute_reply.started": "2023-12-14T16:01:27.568371Z"
        },
        "id": "52afb830"
      },
      "outputs": [],
      "source": [
        "# Options for youtube download to ensure we get a high quality audio file extraction.\n",
        "# This is key, as extracting from the video in the same download seemed to significantly affect caption Word Error Rate in our experiments.\n",
        "# Only modify these if needed. Lowered audio quality may inhibit the transcription's word error rate.\n",
        "opts_aud = {\n",
        "    'format': 'mp3/bestaudio/best',\n",
        "    'keep-video':True}\n",
        "\n",
        "# Options for youtube video to get right video file for final output\n",
        "opts_vid = {'format': 'mp4/bestvideo/best'}\n",
        "\n",
        "# Youtube URL\n",
        "URL = 'https://m.youtube.com/watch?v=I5gPddBRHjU&pp=ygUd2LPYrdixINmF2LfZhNio24wg2LHYp9iv24zZiCA%3D'# @param{type:'string'}\n",
        "# The Hobbit Smaug in many languages\n",
        "\n",
        "#URL = 'https://youtu.be/C-WFK7iKPb0?feature=shared' # steamed hams in many languages, sample link"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "187a443f",
      "metadata": {
        "id": "187a443f"
      },
      "source": [
        "# Generate subtitles\n",
        "\n",
        "To autocaption our video, we just simply fill in the fields below with the relevant values.\n",
        "\n",
        "The only required change is to the URL value if we would like that to be a different video from the sample.\n",
        "\n",
        "> Note: If we run into an error, we can try restarting the kernel and running these 3 code cells again. It is unclear why this happens, but MoviePy seems to require a restart to the kernel occasionally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f315ad30",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T16:01:29.519176Z",
          "iopub.status.busy": "2023-12-14T16:01:29.518322Z"
        },
        "id": "f315ad30"
      },
      "outputs": [],
      "source": [
        "name = 'run2'\n",
        "Video_patch = subtitle_video(\n",
        "    download=True,\n",
        "    #uploaded_vid='dune.mp4',     # path to local file\n",
        "    url = URL,\n",
        "    name = folder_path , #name,\n",
        "    aud_opts = opts_aud,\n",
        "    vid_opts = opts_vid,   # Video download settings\n",
        "    model_type = 'large', # change to 'large' if you want more accurate results,\n",
        "                           #change to 'medium.en' or 'large.en' for all english language tasks,\n",
        "                           #and change to 'small' or 'base' for faster inference\n",
        "    audio_file = \"audio.mp3\",\n",
        "    input_file = 'dune.mp4',\n",
        "    output = 'output.mp4',\n",
        "    lang = 'en')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d06b43f1",
      "metadata": {
        "id": "d06b43f1"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Video\n",
        "Video(f'{Video_patch}',embed=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bac7273e-539a-4364-a20d-a2928d5d8639",
      "metadata": {
        "id": "bac7273e-539a-4364-a20d-a2928d5d8639"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}