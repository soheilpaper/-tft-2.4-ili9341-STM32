{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soheilpaper/-tft-2.4-ili9341-STM32/blob/master/youtube_subtitle/whisper-caption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "783e4589",
      "metadata": {
        "id": "783e4589"
      },
      "source": [
        "# Setup\n",
        "Here we install the required packages for this application. Additionally, we will remove a single line from the ImageMagick policy that would have prevented this code from running, create our experiments directory, and restart the kernel.\n",
        "\n",
        "> Note: We need to restart the kernel due to an odd behavior from MoviePy that stops this from working in the same session as the install.\n",
        "\n",
        "> Just move onto the next section of this notebook after running the install cell below.\n",
        "\n",
        "> We should be especially wary of this if we intend to 'Run All' cells, as it will catch here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "global gdrive_fpath\n",
        "drive_mounted = False\n",
        "gdrive_fpath = '.'\n",
        "local_path = '/content/'\n",
        "\n",
        "mount_gdrive = True # @param{type:\"boolean\"}\n",
        "if mount_gdrive : # and not drive_mounted:\n",
        "    from google.colab import drive\n",
        "\n",
        "    gdrive_mountpoint = '/content/drive/' #@param{type:\"string\"}\n",
        "    gdrive_subdirectory = 'MyDrive/YouTube_Auto_Subtitle' #@param{type:\"string\"}\n",
        "    gdrive_fpath = str(Path(gdrive_mountpoint) / gdrive_subdirectory)\n",
        "    print (\"gdrive path is :\",gdrive_fpath)\n",
        "   # Mount Google Drive\n",
        "    if not os.path.isdir(gdrive_mountpoint):\n",
        "     # If not, mount the drive\n",
        "       drive.mount(gdrive_mountpoint)\n",
        "       if not os.path.exists(gdrive_fpath):\n",
        "          os.makedirs(gdrive_fpath)\n",
        "          os.chdir(gdrive_fpath)\n",
        "    else:\n",
        "          print(\"Drive is already mounted.\")\n",
        "else:\n",
        "   Folder_fpath ='/content/' #@param{type:\"string\"}\n",
        "   #gdrive_subdirectory = 'MyDrive/ChatGPT_Paper_wrting' #@param{type:\"string\"}\n",
        "   gdrive_fpath = Folder_fpath\n",
        "   os.chdir(gdrive_fpath)\n",
        "folder_path = gdrive_fpath"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_pC5ZXOfK7f",
        "outputId": "bb38106d-d636-4bdd-8d14-f8d3ed9e9890"
      },
      "id": "V_pC5ZXOfK7f",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive path is : /content/drive/MyDrive/YouTube_Auto_Subtitle\n",
            "Drive is already mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d06587d3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T15:58:15.069487Z",
          "iopub.status.busy": "2023-12-14T15:58:15.069013Z"
        },
        "id": "d06587d3",
        "outputId": "cee9c6f7-ebfa-4060-cae1-0ceb4f038b47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Whisper-AutoCaption'...\n",
            "remote: Enumerating objects: 352, done.\u001b[K\n",
            "remote: Counting objects: 100% (129/129), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 352 (delta 58), reused 89 (delta 26), pack-reused 223\u001b[K\n",
            "Receiving objects: 100% (352/352), 3.20 MiB | 9.28 MiB/s, done.\n",
            "Resolving deltas: 100% (157/157), done.\n",
            "/content/Whisper-AutoCaption/Whisper-AutoCaption\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (10.1.0)\n",
            "Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.35.2)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->-r requirements.txt (line 6)) (0.18.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (0.20.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r requirements.txt (line 5)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r requirements.txt (line 5)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r requirements.txt (line 5)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r requirements.txt (line 5)) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 2)) (1.3.0)\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-w76r6cy8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-w76r6cy8\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 73, in resolve\n",
            "    collected = self.factory.collect_root_requirements(root_reqs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 491, in collect_root_requirements\n",
            "    req = self._make_requirement_from_install_req(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 453, in _make_requirement_from_install_req\n",
            "    cand = self._make_candidate_from_link(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 206, in _make_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 293, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 156, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 225, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 304, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 516, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 631, in _prepare_linked_requirement\n",
            "    dist = _get_prepared_distribution(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 69, in _get_prepared_distribution\n",
            "    abstract_dist.prepare_distribution_metadata(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/distributions/sdist.py\", line 38, in prepare_distribution_metadata\n",
            "    self._prepare_build_backend(finder)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/distributions/sdist.py\", line 70, in _prepare_build_backend\n",
            "    self.req.build_env.install_requirements(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 217, in install_requirements\n",
            "    self._install_requirements(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 275, in _install_requirements\n",
            "    call_subprocess(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 207, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-t8vd3yix\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-t8vd3yix\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.5.2)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.23.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2023.11.17)\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 229 kB in 1s (162 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "imagemagick is already the newest version (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/gradient-ai/Whisper-AutoCaption\n",
        "\n",
        "%cd Whisper-AutoCaption\n",
        "import os\n",
        "!pip install -r requirements.txt\n",
        "!pip install --upgrade git+https://github.com/openai/whisper.git\n",
        "\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install yt-dlp\n",
        "!pip install moviepy --upgrade\n",
        "!apt-get update\n",
        "!apt install imagemagick -y\n",
        "# remove line 88 of vim ~/../etc/ImageMagick-6/policy.xml to run MoviePy\n",
        "!sed -i '88d' ~/../etc/ImageMagick-6/policy.xml\n",
        "!mkdir experiments\n",
        "#os._exit(00)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd9b2695",
      "metadata": {
        "id": "dd9b2695"
      },
      "source": [
        "# The function\n",
        "\n",
        "The `subtitle_video` function does all the work for us to autocaption our supplied video with the generated text captions from Whisper at the correct time stamps.\n",
        "\n",
        "This works for both youtube links and videos uploaded directly to this Notebook, and will automatically scale the size of the captions to the video size.\n",
        "\n",
        "See the params notes section of the start of the function and the function call below for more details on the arguments for this function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "id": "8RMS9DD-pUAZ",
        "outputId": "9a74284e-4c58-4e96-b90c-f2b046d6b248",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8RMS9DD-pUAZ",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-omzyhc84\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-omzyhc84\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.5.2)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ffedc8a2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T16:01:24.820153Z",
          "iopub.status.busy": "2023-12-14T16:01:24.819481Z",
          "iopub.status.idle": "2023-12-14T16:01:27.566764Z",
          "shell.execute_reply": "2023-12-14T16:01:27.566129Z",
          "shell.execute_reply.started": "2023-12-14T16:01:24.820129Z"
        },
        "id": "ffedc8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "1a0097cf-8079-4e33-da16-97ed19c67742"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'get_writer' from 'whisper.utils' (/content/Whisper-AutoCaption/whisper/utils.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f88f2b659eab>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myt_dlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_writer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_writer' from 'whisper.utils' (/content/Whisper-AutoCaption/whisper/utils.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "## Imports\n",
        "from __future__ import unicode_literals\n",
        "from yt_dlp import YoutubeDL\n",
        "import yt_dlp\n",
        "from IPython.display import Video\n",
        "import whisper\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from moviepy.editor import VideoFileClip\n",
        "import moviepy.editor as mp\n",
        "from IPython.display import display, Markdown\n",
        "from moviepy.editor import *\n",
        "from moviepy.video.tools.subtitles import SubtitlesClip\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import subprocess\n",
        "import json\n",
        "\n",
        "import yt_dlp\n",
        "from whisper.utils import get_writer\n",
        "\n",
        "\n",
        "\n",
        "def get_video_title(url):\n",
        "    ydl_opts = {\n",
        "        'skip_download': True, # We don't want to download the video\n",
        "        'quiet': True, # We don't want to print everything to the console\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        info = ydl.extract_info(url, download=False)\n",
        "        return info.get('title', None)\n",
        "\n",
        "def subtitle_video(download, url, aud_opts, vid_opts, model_type, name, audio_file, input_file, output, lang, uploaded_vid = None):\n",
        "# ------------------------------------------------------------------------------------------------------------------------------\n",
        "#     Params:\n",
        "# ------------------------------------------------------------------------------------------------------------------------------\n",
        "#     download:      bool, this tells your function if you are downloading a youtube video\n",
        "#     url: str,      str, the URL of youtube video to download if download is True\n",
        "#     aud_opts:      dict, audio file youtube-dl options\n",
        "#     vid_opts:      dict, video file youtube-dl options\n",
        "#     model_type:    str, which pretrained model to download. Options are:\n",
        "#                    ['tiny', 'small', 'base', 'medium','large','tiny.en', 'small.en', 'base.en', 'medium.en']\n",
        "#                    More details about model_types can be found in table in original repo here:\n",
        "#                    https://github.com/openai/whisper#Available-models-and-languages\n",
        "#.    name:          str, name of directory to store files in in experiments folder\n",
        "#     audio_file:    str, path to extracted audio file for Whisper\n",
        "#     input_file:    str, path to video file for MoviePy to caption\n",
        "#     output:        str, destination of final output video file\n",
        "#     uploaded_vid:  str, path to uploaded video file if download is False\n",
        "#\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "#     Returns:       An annotated video with translated captions into english, saved to name/output\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    ## First, this checks if your expermiment name is taken. If not, it will create the directory.\n",
        "    ## Otherwise, we will be prompted to retry with a new name\n",
        "    try:\n",
        "        os.mkdir(f'{name}')\n",
        "        print('Starting AutoCaptioning...')\n",
        "        print(f'Results will be stored in :{name}')\n",
        "\n",
        "    except:\n",
        "       pass #print('Choose another folder name! This one already has files in it.')\n",
        "\n",
        "    ## Use audio and video options for youtube-dl if downloading from youtube\n",
        "    vid_opts['outtmpl'] = f'{name}/{input_file}'\n",
        "    aud_opts['outtmpl'] = f'{name}/{audio_file}'\n",
        "\n",
        "    URLS = [url]\n",
        "    if download:\n",
        "        with YoutubeDL(aud_opts) as ydl:\n",
        "            ydl.download(url)\n",
        "            title = get_video_title(url)\n",
        "        with YoutubeDL(vid_opts) as ydl:\n",
        "            ydl.download(URLS)\n",
        "\n",
        "    else:\n",
        "        # Use local clip if not downloading from youtube\n",
        "        my_clip = mp.VideoFileClip(uploaded_vid)\n",
        "        my_clip.write_videofile(f'{name}/{input_file}')\n",
        "        my_clip.audio.write_audiofile(f'{name}/{audio_file}')\n",
        "\n",
        "\n",
        "\n",
        "    title  = \"\".join(c if c.isalnum() else \"_\" for c in title).rstrip(\"_\")\n",
        "    output = f'{name}/{title}.mp4'\n",
        "    # Instantiate whisper model using model_type variable\n",
        "    model = whisper.load_model(model_type)\n",
        "\n",
        "    # Get text from speech for subtitles from audio file\n",
        "    result = model.transcribe(f'''{name}/{audio_file}''', task = 'translate', language = lang)\n",
        "    srt_writer = get_writer(\"srt\", f\"{name}/{audio_file}\")\n",
        "    srt_writer(result, f'{name}/{title}.str')\n",
        "\n",
        "    # create Subtitle dataframe, and save it\n",
        "    dict1 = {'start':[], 'end':[], 'text':[]}\n",
        "    for i in result['segments']:\n",
        "        dict1['start'].append(int(i['start']))\n",
        "        dict1['end'].append(int(i['end']))\n",
        "        dict1['text'].append(i['text'])\n",
        "    df = pd.DataFrame.from_dict(dict1)\n",
        "    df.to_csv(f'{name}/subs.csv')\n",
        "    vidcap = cv2.VideoCapture(f'''{name}/{input_file}''')\n",
        "    success,image = vidcap.read()\n",
        "    height = image.shape[0]\n",
        "    width =image.shape[1]\n",
        "\n",
        "    # Instantiate MoviePy subtitle generator with TextClip, subtitles, and SubtitlesClip\n",
        "    generator = lambda txt: TextClip(\n",
        "        txt,\n",
        "        font='P052-Bold',\n",
        "        fontsize=width / 30, # Adjust font size (increase for larger text)\n",
        "        stroke_width=2, # Adjust stroke width\n",
        "        color='yellow', # Change text color to yellow\n",
        "        bg_color='transparent', # Set background color to transparent\n",
        "        size=(width, height * 0.25),\n",
        "        method='caption'\n",
        "    )\n",
        "    subs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\n",
        "    subtitles = SubtitlesClip(subs, generator)\n",
        "\n",
        "    # Ff the file was on youtube, add the captions to the downloaded video\n",
        "    if download:\n",
        "        video = VideoFileClip(f'{name}/{input_file}')\n",
        "        final = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\n",
        "        final.write_videofile(f'{output}', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n",
        "    else:\n",
        "        # If the file was a local upload:\n",
        "        video = VideoFileClip(uploaded_vid)\n",
        "        final = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\n",
        "        final.write_videofile(f'{output}', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n",
        "\n",
        "    return f'{output}'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe41bec9",
      "metadata": {
        "id": "fe41bec9"
      },
      "source": [
        "## Declare relevant variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "52afb830",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T16:01:27.568394Z",
          "iopub.status.busy": "2023-12-14T16:01:27.567872Z",
          "iopub.status.idle": "2023-12-14T16:01:27.571778Z",
          "shell.execute_reply": "2023-12-14T16:01:27.571316Z",
          "shell.execute_reply.started": "2023-12-14T16:01:27.568371Z"
        },
        "id": "52afb830"
      },
      "outputs": [],
      "source": [
        "# Options for youtube download to ensure we get a high quality audio file extraction.\n",
        "# This is key, as extracting from the video in the same download seemed to significantly affect caption Word Error Rate in our experiments.\n",
        "# Only modify these if needed. Lowered audio quality may inhibit the transcription's word error rate.\n",
        "opts_aud = {\n",
        "    'format': 'mp3/bestaudio/best',\n",
        "    'keep-video':True}\n",
        "\n",
        "# Options for youtube video to get right video file for final output\n",
        "opts_vid = {'format': 'mp4/bestvideo/best'}\n",
        "\n",
        "# Youtube URL\n",
        "URL = 'https://m.youtube.com/watch?v=I5gPddBRHjU&pp=ygUd2LPYrdixINmF2LfZhNio24wg2LHYp9iv24zZiCA%3D'# @param{type:'string'}\n",
        "# The Hobbit Smaug in many languages\n",
        "\n",
        "#URL = 'https://youtu.be/C-WFK7iKPb0?feature=shared' # steamed hams in many languages, sample link"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "187a443f",
      "metadata": {
        "id": "187a443f"
      },
      "source": [
        "# Generate subtitles\n",
        "\n",
        "To autocaption our video, we just simply fill in the fields below with the relevant values.\n",
        "\n",
        "The only required change is to the URL value if we would like that to be a different video from the sample.\n",
        "\n",
        "> Note: If we run into an error, we can try restarting the kernel and running these 3 code cells again. It is unclear why this happens, but MoviePy seems to require a restart to the kernel occasionally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f315ad30",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T16:01:29.519176Z",
          "iopub.status.busy": "2023-12-14T16:01:29.518322Z"
        },
        "id": "f315ad30",
        "outputId": "f1942fd3-0e01-4d2c-faf2-0e642894eb00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://m.youtube.com/watch?v=I5gPddBRHjU&pp=ygUd2LPYrdixINmF2LfZhNio24wg2LHYp9iv24zZiCA%3D\n",
            "[youtube] I5gPddBRHjU: Downloading webpage\n",
            "[youtube] I5gPddBRHjU: Downloading ios player API JSON\n",
            "[youtube] I5gPddBRHjU: Downloading android player API JSON\n",
            "[youtube] I5gPddBRHjU: Downloading m3u8 information\n",
            "[info] I5gPddBRHjU: Downloading 1 format(s): 251\n",
            "[download] /content/drive/MyDrive/YouTube_Auto_Subtitle/audio.mp3 has already been downloaded\n",
            "[download] 100% of   12.22MiB\n",
            "[youtube] Extracting URL: https://m.youtube.com/watch?v=I5gPddBRHjU&pp=ygUd2LPYrdixINmF2LfZhNio24wg2LHYp9iv24zZiCA%3D\n",
            "[youtube] I5gPddBRHjU: Downloading webpage\n",
            "[youtube] I5gPddBRHjU: Downloading ios player API JSON\n",
            "[youtube] I5gPddBRHjU: Downloading android player API JSON\n",
            "[youtube] I5gPddBRHjU: Downloading m3u8 information\n",
            "[info] I5gPddBRHjU: Downloading 1 format(s): 22\n",
            "[download] Destination: /content/drive/MyDrive/YouTube_Auto_Subtitle/dune.mp4\n",
            "[download] 100% of   54.01MiB in 00:00:06 at 8.97MiB/s   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.87G/2.87G [09:35<00:00, 5.36MiB/s]\n",
            "WARNING:py.warnings:/content/Whisper-AutoCaption/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "tuple.index(x): x not in tuple",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0da354868ed5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'run2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m subtitle_video(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#uploaded_vid='dune.mp4',     # path to local file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-42cb4f10da5b>\u001b[0m in \u001b[0;36msubtitle_video\u001b[0;34m(download, url, aud_opts, vid_opts, model_type, name, audio_file, input_file, output, lang, uploaded_vid)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# Get text from speech for subtitles from audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'''{name}/{audio_file}'''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'translate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# create Subtitle dataframe, and save it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Whisper-AutoCaption/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, **decode_options)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Whisper-AutoCaption/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beam_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# no beam search for t > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Whisper-AutoCaption/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Whisper-AutoCaption/whisper/decoding.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, options)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_tokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_initial_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_begin\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msot_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;31m# inference: implements the forward pass through the decoder, including kv caching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: tuple.index(x): x not in tuple"
          ]
        }
      ],
      "source": [
        "name = 'run2'\n",
        "Video_patch = subtitle_video(\n",
        "    download=True,\n",
        "    #uploaded_vid='dune.mp4',     # path to local file\n",
        "    url = URL,\n",
        "    name = folder_path , #name,\n",
        "    aud_opts = opts_aud,\n",
        "    vid_opts = opts_vid,   # Video download settings\n",
        "    model_type = 'large', # change to 'large' if you want more accurate results,\n",
        "                           #change to 'medium.en' or 'large.en' for all english language tasks,\n",
        "                           #and change to 'small' or 'base' for faster inference\n",
        "    audio_file = \"audio.mp3\",\n",
        "    input_file = 'dune.mp4',\n",
        "    output = 'output.mp4',\n",
        "    lang = 'en')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d06b43f1",
      "metadata": {
        "id": "d06b43f1"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Video\n",
        "Video(f'{Video_patch}',embed=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bac7273e-539a-4364-a20d-a2928d5d8639",
      "metadata": {
        "id": "bac7273e-539a-4364-a20d-a2928d5d8639"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}