{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soheilpaper/-tft-2.4-ili9341-STM32/blob/master/youtube_subtitle/whisper-caption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "783e4589",
      "metadata": {
        "id": "783e4589"
      },
      "source": [
        "# Setup\n",
        "Here we install the required packages for this application. Additionally, we will remove a single line from the ImageMagick policy that would have prevented this code from running, create our experiments directory, and restart the kernel.\n",
        "\n",
        "> Note: We need to restart the kernel due to an odd behavior from MoviePy that stops this from working in the same session as the install.\n",
        "\n",
        "> Just move onto the next section of this notebook after running the install cell below.\n",
        "\n",
        "> We should be especially wary of this if we intend to 'Run All' cells, as it will catch here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "global gdrive_fpath\n",
        "drive_mounted = False\n",
        "gdrive_fpath = '.'\n",
        "local_path = '/content/'\n",
        "\n",
        "mount_gdrive = False # @param{type:\"boolean\"}\n",
        "if mount_gdrive : # and not drive_mounted:\n",
        "    from google.colab import drive\n",
        "\n",
        "    gdrive_mountpoint = '/content/drive/' #@param{type:\"string\"}\n",
        "    gdrive_subdirectory = 'MyDrive/YouTube_Auto_Subtitle' #@param{type:\"string\"}\n",
        "    gdrive_fpath = str(Path(gdrive_mountpoint) / gdrive_subdirectory)\n",
        "    print (\"gdrive path is :\",gdrive_fpath)\n",
        "   # Mount Google Drive\n",
        "    if not os.path.isdir(gdrive_mountpoint):\n",
        "     # If not, mount the drive\n",
        "       drive.mount(gdrive_mountpoint)\n",
        "       if not os.path.exists(gdrive_fpath):\n",
        "          os.makedirs(gdrive_fpath)\n",
        "          os.chdir(gdrive_fpath)\n",
        "    else:\n",
        "          print(\"Drive is already mounted.\")\n",
        "else:\n",
        "   Folder_fpath ='/content/' #@param{type:\"string\"}\n",
        "   #gdrive_subdirectory = 'MyDrive/ChatGPT_Paper_wrting' #@param{type:\"string\"}\n",
        "   gdrive_fpath = Folder_fpath\n",
        "   os.chdir(gdrive_fpath)\n",
        "folder_path = gdrive_fpath"
      ],
      "metadata": {
        "id": "V_pC5ZXOfK7f"
      },
      "id": "V_pC5ZXOfK7f",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d06587d3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T15:58:15.069487Z",
          "iopub.status.busy": "2023-12-14T15:58:15.069013Z"
        },
        "id": "d06587d3",
        "outputId": "7c471938-e371-48b1-d948-e02791357f7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Whisper-AutoCaption' already exists and is not an empty directory.\n",
            "/content/Whisper-AutoCaption\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (10.1.0)\n",
            "Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.35.2)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->-r requirements.txt (line 6)) (0.18.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r requirements.txt (line 5)) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r requirements.txt (line 5)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r requirements.txt (line 5)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r requirements.txt (line 5)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r requirements.txt (line 5)) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 2)) (1.3.0)\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-q97xzqko\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-q97xzqko\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!git clone https://github.com/gradient-ai/Whisper-AutoCaption\n",
        "\n",
        "%cd Whisper-AutoCaption\n",
        "import os\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install yt-dlp\n",
        "!pip install moviepy --upgrade\n",
        "!apt-get update\n",
        "!apt install imagemagick -y\n",
        "# remove line 88 of vim ~/../etc/ImageMagick-6/policy.xml to run MoviePy\n",
        "!sed -i '88d' ~/../etc/ImageMagick-6/policy.xml\n",
        "!mkdir experiments\n",
        "#os._exit(00)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd9b2695",
      "metadata": {
        "id": "dd9b2695"
      },
      "source": [
        "# The function\n",
        "\n",
        "The `subtitle_video` function does all the work for us to autocaption our supplied video with the generated text captions from Whisper at the correct time stamps.\n",
        "\n",
        "This works for both youtube links and videos uploaded directly to this Notebook, and will automatically scale the size of the captions to the video size.\n",
        "\n",
        "See the params notes section of the start of the function and the function call below for more details on the arguments for this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffedc8a2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T16:01:24.820153Z",
          "iopub.status.busy": "2023-12-14T16:01:24.819481Z",
          "iopub.status.idle": "2023-12-14T16:01:27.566764Z",
          "shell.execute_reply": "2023-12-14T16:01:27.566129Z",
          "shell.execute_reply.started": "2023-12-14T16:01:24.820129Z"
        },
        "id": "ffedc8a2"
      },
      "outputs": [],
      "source": [
        "## Imports\n",
        "from __future__ import unicode_literals\n",
        "from yt_dlp import YoutubeDL\n",
        "import yt_dlp\n",
        "from IPython.display import Video\n",
        "import whisper\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from moviepy.editor import VideoFileClip\n",
        "import moviepy.editor as mp\n",
        "from IPython.display import display, Markdown\n",
        "from moviepy.editor import *\n",
        "from moviepy.video.tools.subtitles import SubtitlesClip\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import subprocess\n",
        "import json\n",
        "\n",
        "import yt_dlp\n",
        "\n",
        "def get_video_title(url):\n",
        "    ydl_opts = {\n",
        "        'skip_download': True, # We don't want to download the video\n",
        "        'quiet': True, # We don't want to print everything to the console\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        info = ydl.extract_info(url, download=False)\n",
        "        return info.get('title', None)\n",
        "\n",
        "def subtitle_video(download, url, aud_opts, vid_opts, model_type, name, audio_file, input_file, output, lang, uploaded_vid = None):\n",
        "# ------------------------------------------------------------------------------------------------------------------------------\n",
        "#     Params:\n",
        "# ------------------------------------------------------------------------------------------------------------------------------\n",
        "#     download:      bool, this tells your function if you are downloading a youtube video\n",
        "#     url: str,      str, the URL of youtube video to download if download is True\n",
        "#     aud_opts:      dict, audio file youtube-dl options\n",
        "#     vid_opts:      dict, video file youtube-dl options\n",
        "#     model_type:    str, which pretrained model to download. Options are:\n",
        "#                    ['tiny', 'small', 'base', 'medium','large','tiny.en', 'small.en', 'base.en', 'medium.en']\n",
        "#                    More details about model_types can be found in table in original repo here:\n",
        "#                    https://github.com/openai/whisper#Available-models-and-languages\n",
        "#.    name:          str, name of directory to store files in in experiments folder\n",
        "#     audio_file:    str, path to extracted audio file for Whisper\n",
        "#     input_file:    str, path to video file for MoviePy to caption\n",
        "#     output:        str, destination of final output video file\n",
        "#     uploaded_vid:  str, path to uploaded video file if download is False\n",
        "#\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "#     Returns:       An annotated video with translated captions into english, saved to name/output\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    ## First, this checks if your expermiment name is taken. If not, it will create the directory.\n",
        "    ## Otherwise, we will be prompted to retry with a new name\n",
        "    try:\n",
        "        os.mkdir(f'{name}')\n",
        "        print('Starting AutoCaptioning...')\n",
        "        print(f'Results will be stored in :{name}')\n",
        "\n",
        "    except:\n",
        "       pass #print('Choose another folder name! This one already has files in it.')\n",
        "\n",
        "    ## Use audio and video options for youtube-dl if downloading from youtube\n",
        "    vid_opts['outtmpl'] = f'{name}/{input_file}'\n",
        "    aud_opts['outtmpl'] = f'{name}/{audio_file}'\n",
        "\n",
        "    URLS = [url]\n",
        "    if download:\n",
        "        with YoutubeDL(aud_opts) as ydl:\n",
        "            ydl.download(url)\n",
        "            title = get_video_title(url)\n",
        "        with YoutubeDL(vid_opts) as ydl:\n",
        "            ydl.download(URLS)\n",
        "\n",
        "    else:\n",
        "        # Use local clip if not downloading from youtube\n",
        "        my_clip = mp.VideoFileClip(uploaded_vid)\n",
        "        my_clip.write_videofile(f'{name}/{input_file}')\n",
        "        my_clip.audio.write_audiofile(f'{name}/{audio_file}')\n",
        "\n",
        "\n",
        "\n",
        "    title  = \"\".join(c if c.isalnum() else \"_\" for c in title).rstrip(\"_\")\n",
        "    output = title+'mp4'\n",
        "    # Instantiate whisper model using model_type variable\n",
        "    model = whisper.load_model(model_type)\n",
        "\n",
        "    # Get text from speech for subtitles from audio file\n",
        "    result = model.transcribe(f'''{name}/{audio_file}''', task = 'translate', language = lang)\n",
        "\n",
        "    # create Subtitle dataframe, and save it\n",
        "    dict1 = {'start':[], 'end':[], 'text':[]}\n",
        "    for i in result['segments']:\n",
        "        dict1['start'].append(int(i['start']))\n",
        "        dict1['end'].append(int(i['end']))\n",
        "        dict1['text'].append(i['text'])\n",
        "    df = pd.DataFrame.from_dict(dict1)\n",
        "    df.to_csv(f'{name}/subs.csv')\n",
        "    vidcap = cv2.VideoCapture(f'''{name}/{input_file}''')\n",
        "    success,image = vidcap.read()\n",
        "    height = image.shape[0]\n",
        "    width =image.shape[1]\n",
        "\n",
        "    # Instantiate MoviePy subtitle generator with TextClip, subtitles, and SubtitlesClip\n",
        "    generator = lambda txt: TextClip(\n",
        "        txt,\n",
        "        font='P052-Bold',\n",
        "        fontsize=width / 30, # Adjust font size (increase for larger text)\n",
        "        stroke_width=2, # Adjust stroke width\n",
        "        color='yellow', # Change text color to yellow\n",
        "        bg_color='transparent', # Set background color to transparent\n",
        "        size=(width, height * 0.25),\n",
        "        method='caption'\n",
        "    )\n",
        "    subs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\n",
        "    subtitles = SubtitlesClip(subs, generator)\n",
        "\n",
        "    # Ff the file was on youtube, add the captions to the downloaded video\n",
        "    if download:\n",
        "        video = VideoFileClip(f'{name}/{input_file}')\n",
        "        final = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\n",
        "        final.write_videofile(f'{name}/{output}', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n",
        "    else:\n",
        "        # If the file was a local upload:\n",
        "        video = VideoFileClip(uploaded_vid)\n",
        "        final = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\n",
        "        final.write_videofile(f'{name}/{output}', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n",
        "\n",
        "    return f'{name}/{output}'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe41bec9",
      "metadata": {
        "id": "fe41bec9"
      },
      "source": [
        "## Declare relevant variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52afb830",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T16:01:27.568394Z",
          "iopub.status.busy": "2023-12-14T16:01:27.567872Z",
          "iopub.status.idle": "2023-12-14T16:01:27.571778Z",
          "shell.execute_reply": "2023-12-14T16:01:27.571316Z",
          "shell.execute_reply.started": "2023-12-14T16:01:27.568371Z"
        },
        "id": "52afb830"
      },
      "outputs": [],
      "source": [
        "# Options for youtube download to ensure we get a high quality audio file extraction.\n",
        "# This is key, as extracting from the video in the same download seemed to significantly affect caption Word Error Rate in our experiments.\n",
        "# Only modify these if needed. Lowered audio quality may inhibit the transcription's word error rate.\n",
        "opts_aud = {\n",
        "    'format': 'mp3/bestaudio/best',\n",
        "    'keep-video':True}\n",
        "\n",
        "# Options for youtube video to get right video file for final output\n",
        "opts_vid = {'format': 'mp4/bestvideo/best'}\n",
        "\n",
        "# Youtube URL\n",
        "URL = 'https://m.youtube.com/watch?v=I5gPddBRHjU&pp=ygUd2LPYrdixINmF2LfZhNio24wg2LHYp9iv24zZiCA%3D'# @param{type:'string'}\n",
        "# The Hobbit Smaug in many languages\n",
        "\n",
        "#URL = 'https://youtu.be/C-WFK7iKPb0?feature=shared' # steamed hams in many languages, sample link"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "187a443f",
      "metadata": {
        "id": "187a443f"
      },
      "source": [
        "# Generate subtitles\n",
        "\n",
        "To autocaption our video, we just simply fill in the fields below with the relevant values.\n",
        "\n",
        "The only required change is to the URL value if we would like that to be a different video from the sample.\n",
        "\n",
        "> Note: If we run into an error, we can try restarting the kernel and running these 3 code cells again. It is unclear why this happens, but MoviePy seems to require a restart to the kernel occasionally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f315ad30",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-14T16:01:29.519176Z",
          "iopub.status.busy": "2023-12-14T16:01:29.518322Z"
        },
        "id": "f315ad30"
      },
      "outputs": [],
      "source": [
        "name = 'run2'\n",
        "subtitle_video(\n",
        "    download=True,\n",
        "    #uploaded_vid='dune.mp4',     # path to local file\n",
        "    url = URL,\n",
        "    name = folder_path , #name,\n",
        "    aud_opts = opts_aud,\n",
        "    vid_opts = opts_vid,   # Video download settings\n",
        "    model_type = 'large', # change to 'large' if you want more accurate results,\n",
        "                           #change to 'medium.en' or 'large.en' for all english language tasks,\n",
        "                           #and change to 'small' or 'base' for faster inference\n",
        "    audio_file = \"audio.mp3\",\n",
        "    input_file = 'dune.mp4',\n",
        "    output = 'output.mp4',\n",
        "    lang = 'en')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall whisper-openai\n",
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "id": "e2TDY3sLiPkM"
      },
      "id": "e2TDY3sLiPkM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d06b43f1",
      "metadata": {
        "id": "d06b43f1"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Video\n",
        "Video(f'e{name}/output.mp4',embed=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bac7273e-539a-4364-a20d-a2928d5d8639",
      "metadata": {
        "id": "bac7273e-539a-4364-a20d-a2928d5d8639"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}