{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soheilpaper/-tft-2.4-ili9341-STM32/blob/master/youtube_subtitle/whisper_podcast_subtitles_with_speakers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ç”ŸæˆApple PodCastå­—å¹•\n",
        "\n"
      ],
      "metadata": {
        "id": "73JHCOCS99hl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mBUm1pmC90Mk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13401ce8-e6d6-4340-aaa1-2ae9c04274af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Check GPU type** ðŸ•µï¸\n",
        "\n",
        "#@markdown The type of GPU you get assigned in your Colab session defined the speed at which the video will be transcribed.\n",
        "#@markdown The higher the number of floating point operations per second (FLOPS), the faster the transcription.\n",
        "#@markdown But even the least powerful GPU available in Colab is able to run any Whisper model.\n",
        "#@markdown Make sure you've selected `GPU` as hardware accelerator for the Notebook (Runtime â†’ Change runtime type â†’ Hardware accelerator).\n",
        "\n",
        "#@markdown |  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "#@markdown |:------:|:----------:|:--------------:|:------------------:|\n",
        "#@markdown |  T4    |    16 GB   |       8.1      |         Free       |\n",
        "#@markdown | P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "#@markdown | V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Factory reset your Notebook's runtime if you want to get assigned a new GPU.**\n",
        "\n",
        "!nvidia-smi -L\n",
        "\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **é…ç½®Whisper/Setup Whisper** ðŸ—ï¸\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!pip install git+https://github.com/yinruiqing/pyannote-whisper.git\n",
        "!pip install requests beautifulsoup4 pyannote.audio pydub\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "import whisper\n",
        "import numpy as np\n",
        "import warnings\n",
        "import shutil\n",
        "from IPython.display import Markdown\n",
        "import os\n",
        "import requests\n",
        "import re\n",
        "from pydub import AudioSegment\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "from pathlib import Path\n",
        "from pyannote.audio import Pipeline\n",
        "from pyannote_whisper.utils import diarize_text\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "\n",
        "print('Whisper installedï¼Œplease execute next cell')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMRtV2Lw_BHU",
        "outputId": "747362bb-1613-418d-f32f-37d7c36d707f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/yinruiqing/pyannote-whisper.git\n",
            "  Cloning https://github.com/yinruiqing/pyannote-whisper.git to /tmp/pip-req-build-3710r4p2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/yinruiqing/pyannote-whisper.git /tmp/pip-req-build-3710r4p2\n",
            "  Resolved https://github.com/yinruiqing/pyannote-whisper.git to commit bb55b6547d611de04f07fafc6c149f51ae3ca5a3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setuptools==59.5.0 (from pyannote-whisper==1.0)\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyannote-whisper==1.0) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pyannote-whisper==1.0) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from pyannote-whisper==1.0) (0.17.1+cu121)\n",
            "Collecting openai-whisper (from pyannote-whisper==1.0)\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests #beautifulsoup\n",
        "\n",
        "!sudo apt-get install python-beautifulsoup"
      ],
      "metadata": {
        "id": "Xt3SX8edQH0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "3cVLD--WgYRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Apple Podcast selection** ðŸŽ™ï¸\n",
        "\n",
        "#@markdown Enter the URL of the Apple Podcast you want to transcribe.\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### **Apple Podcast**\n",
        "URL = \"https://pro-arpit-69-f899161164e6.herokuapp.com/548299/4_5771510420242174755.wav\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the video.**\n",
        "import requests,re,os\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "from pydub import AudioSegment\n",
        "def convert_audio_to_wav(input_file: str):\n",
        "    # Determine the output file name by replacing the input file extension with .wav\n",
        "    output_file = os.path.splitext(input_file)[0] + \".wav\"\n",
        "\n",
        "    # Check the input file extension and load the audio accordingly\n",
        "    if input_file.lower().endswith(\".mp3\"):\n",
        "        audio = AudioSegment.from_mp3(input_file)\n",
        "    elif input_file.lower().endswith(\".m4a\"):\n",
        "        audio = AudioSegment.from_file(input_file, \"m4a\")\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported audio format. Please provide an MP3 or M4A file.\")\n",
        "\n",
        "    # Export the audio as a WAV file\n",
        "    audio.export(output_file, format=\"wav\")\n",
        "\n",
        "    return output_file\n",
        "\n",
        "\n",
        "def find_audio_url(html: str) -> str:\n",
        "    # Find all .mp3 and .m4a URLs in the HTML content\n",
        "    audio_urls = re.findall(r'https://[^\\s^\"]+(?:\\.mp3|\\.m4a)', html)\n",
        "\n",
        "    # If there's at least one URL, return the first one\n",
        "    if audio_urls:\n",
        "        return audio_urls[-1]\n",
        "\n",
        "    # Otherwise, return None\n",
        "    return None\n",
        "\n",
        "def get_file_extension(url: str) -> str:\n",
        "    # Parse the URL to get the path\n",
        "    parsed_url = urlparse(url)\n",
        "    path = parsed_url.path\n",
        "\n",
        "    # Extract the file extension using os.path.splitext\n",
        "    _, file_extension = os.path.splitext(path)\n",
        "\n",
        "    # Return the file extension\n",
        "    return file_extension\n",
        "\n",
        "def download_apple_podcast(url: str, output_folder: str = 'downloads'):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(\n",
        "            f\"Error: Unable to fetch the podcast page. Status code: {response.status_code}\")\n",
        "        return\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    audio_url = find_audio_url(response.text)\n",
        "\n",
        "    if not audio_url:\n",
        "        print(\"Error: Unable to find the podcast audio url.\")\n",
        "        return\n",
        "\n",
        "    episode_title = soup.find('span', {'class': 'product-header__title'})\n",
        "\n",
        "    if not episode_title:\n",
        "        print(\"Error: Unable to find the podcast title.\")\n",
        "        return\n",
        "\n",
        "    episode_title = episode_title.text.strip().replace('/', '-')\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    output_file = os.path.join(output_folder, f\"{episode_title}{get_file_extension(audio_url)}\")\n",
        "\n",
        "    with requests.get(audio_url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(output_file, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "    output_file = convert_audio_to_wav(output_file)\n",
        "\n",
        "    return episode_title, output_file\n",
        "\n",
        "\n",
        "result = download_apple_podcast(URL)\n",
        "if not result:\n",
        "  print(\"Error: Unable to download podcast.\")\n",
        "else:\n",
        "  (title, filepath) = result\n",
        "  print(f\"Downloaded podcast episode '{title}' to '{filepath}'\")"
      ],
      "metadata": {
        "id": "h2AL0Hw-Bow2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "spUB1xPHmywD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "#@markdown #### **Download Podcast from URL**\n",
        "URL = \"https://fileiran.net/Download/File/DitjzXY11B/20636_4_5771510420242174755.mp3\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Function to download a file from a URL\n",
        "def download_file_from_url(url: str, output_filename: str = None):\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        if not output_filename:\n",
        "            output_filename = url.split(\"/\")[-1]\n",
        "        with open(output_filename, 'wb') as file:\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                if chunk:\n",
        "                    file.write(chunk)\n",
        "        return output_filename\n",
        "    else:\n",
        "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "# Function to convert audio to WAV format\n",
        "def convert_audio_to_wav(input_file: str):\n",
        "    output_file = os.path.splitext(input_file)[0] + \".wav\"\n",
        "    if input_file.lower().endswith(\".mp3\"):\n",
        "        audio = AudioSegment.from_mp3(input_file)\n",
        "    elif input_file.lower().endswith(\".m4a\"):\n",
        "        audio = AudioSegment.from_file(input_file, \"m4a\")\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported audio format. Please provide an MP3 or M4A file.\")\n",
        "    audio.export(output_file, format=\"wav\")\n",
        "    return output_file\n",
        "\n",
        "# Function to find the audio URL in the HTML content\n",
        "def find_audio_url(html: str) -> str:\n",
        "    audio_urls = re.findall(r'https://[^\\s^\"]+(?:\\.mp3|\\.m4a)', html)\n",
        "    if audio_urls:\n",
        "        return audio_urls[-1]\n",
        "    return None\n",
        "\n",
        "# Function to get the file extension from a URL\n",
        "def get_file_extension(url: str) -> str:\n",
        "    parsed_url = urlparse(url)\n",
        "    _, file_extension = os.path.splitext(parsed_url.path)\n",
        "    return file_extension\n",
        "\n",
        "# Function to download and convert an audio file from a URL\n",
        "def download_and_convert_audio(url: str, output_folder: str = 'downloads'):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error: Unable to fetch the page. Status code: {response.status_code}\")\n",
        "        return\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    audio_url = find_audio_url(response.text)\n",
        "    if not audio_url:\n",
        "        print(\"Error: Unable to find the audio URL.\")\n",
        "        return\n",
        "    episode_title = soup.find('span', {'class': 'product-header__title'})\n",
        "    if not episode_title:\n",
        "        print(\"Error: Unable to find the title.\")\n",
        "        return\n",
        "    episode_title = episode_title.text.strip().replace('/', '-')\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    output_file = os.path.join(output_folder, f\"{episode_title}{get_file_extension(audio_url)}\")\n",
        "    downloaded_file = download_file_from_url(audio_url, output_file)\n",
        "    if not downloaded_file:\n",
        "        print(\"Error: Unable to download the file.\")\n",
        "        return\n",
        "    output_file = convert_audio_to_wav(downloaded_file)\n",
        "    return episode_title, output_file\n",
        "\n",
        "# Example usage\n",
        "result = download_and_convert_audio(URL)\n",
        "if not result:\n",
        "    print(\"Error: Unable to download podcast.\")\n",
        "else:\n",
        "    (title, filepath) = result\n",
        "    print(f\"Downloaded podcast episode '{title}' to '{filepath}'\")"
      ],
      "metadata": {
        "id": "PWKcY05fjrAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "from pydub import AudioSegment\n",
        "from tqdm import tqdm # Import tqdm for progress bars\n",
        "\n",
        "# Function to download a file from a URL with a progress bar\n",
        "def download_file_from_url(url: str, output_filename: str = None):\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        if not output_filename:\n",
        "            output_filename = url.split(\"/\")[-1]\n",
        "        with open(output_filename, 'wb') as file:\n",
        "            # Use tqdm to create a progress bar\n",
        "            for chunk in tqdm(response.iter_content(chunk_size=1024),\n",
        "                              unit='KB', unit_scale=True, desc=f\"Downloading {output_filename}\"):\n",
        "                if chunk:\n",
        "                    file.write(chunk)\n",
        "        return output_filename\n",
        "    else:\n",
        "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "def convert_audio_to_wav(input_file: str):\n",
        "    output_file = os.path.splitext(input_file)[0] + \".wav\"\n",
        "    if input_file.lower().endswith(\".mp3\"):\n",
        "        audio = AudioSegment.from_mp3(input_file)\n",
        "    elif input_file.lower().endswith(\".m4a\"):\n",
        "        audio = AudioSegment.from_file(input_file, \"m4a\")\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported audio format. Please provide an MP3 or M4A file.\")\n",
        "\n",
        "    # Export the audio without using a progress_hook\n",
        "    audio.export(output_file, format=\"wav\", codec=\"pcm_s16le\", parameters=[\"-q:a\", \"0\"])\n",
        "    return output_file\n",
        "\n",
        "# Example usage\n",
        "URL = \"https://fileiran.net/Download/File/DitjzXY11B/20636_4_5771510420242174755.mp3\"\n",
        "result = download_file_from_url(URL)\n",
        "if not result:\n",
        "    print(\"Error: Unable to download file.\")\n",
        "else:\n",
        "    print(f\"Downloaded file to '{result}'\")\n",
        "    wav_file = convert_audio_to_wav(result)\n",
        "    print(f\"Converted file to WAV format and saved as '{wav_file}'\")\n",
        "(title, filepath) = 'Title','/content/'+wav_file\n",
        "print(title, filepath)"
      ],
      "metadata": {
        "id": "MJgO7QPzm0bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0AenMXRyDTXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import whisper\n",
        "\n",
        "# Function to load a tiny Whisper model\n",
        "def load_tiny_whisper_model():\n",
        "    # Load a tiny Whisper model\n",
        "    # This is a placeholder; replace with actual code to load a tiny model\n",
        "    tiny_model = whisper.load_model(\"tiny\")\n",
        "    return tiny_model\n",
        "\n",
        "# Function to detect the language from a transcription\n",
        "def detect_language(transcription):\n",
        "    # Placeholder for language detection logic\n",
        "    # This should return the detected language\n",
        "    # For simplicity, let's assume the language is always English\n",
        "    return \"English\"\n",
        "\n",
        "# Function to load the appropriate large Whisper model based on the detected language\n",
        "def load_large_whisper_model(language):\n",
        "    # Load the large Whisper model for the detected language\n",
        "    # This is a placeholder; replace with actual code to load a large model\n",
        "    large_model = whisper.load_model(\"large\")\n",
        "    return large_model\n",
        "# Clear the CUDA cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Load the tiny Whisper model\n",
        "tiny_model = load_tiny_whisper_model()\n",
        "\n",
        "# Transcribe a short segment of the audio to detect the language\n",
        "# This is a placeholder; replace with actual code to transcribe a short segment\n",
        "transcription = tiny_model.transcribe(filepath) #\"path/to/short/audio/segment.wav\")\n",
        "\n",
        "# Detect the language from the transcription\n",
        "detected_language = detect_language(transcription)\n",
        "\n",
        "# Load the appropriate large Whisper model based on the detected language\n",
        "large_model = load_large_whisper_model(detected_language)\n",
        "\n",
        "# Now you can use the large_model for further processing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "X9G3c-zDCEGA",
        "outputId": "c1e0fd35-f445-4b9d-8303-1bc674f068b9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 1.06 MiB is free. Process 111550 has 14.74 GiB memory in use. Of the allocated memory 14.13 GiB is allocated by PyTorch, and 484.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-bb191e587661>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Load the tiny Whisper model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtiny_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tiny_whisper_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Transcribe a short segment of the audio to detect the language\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-bb191e587661>\u001b[0m in \u001b[0;36mload_tiny_whisper_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Load a tiny Whisper model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# This is a placeholder; replace with actual code to load a tiny model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtiny_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tiny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtiny_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0min_memory\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     ) as fp:\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1024\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                 return _load(opened_zipfile,\n\u001b[0m\u001b[1;32m   1027\u001b[0m                              \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                              \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m         typed_storage = torch.storage.TypedStorage(\n\u001b[0;32m-> 1382\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m             _internal=True)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mrestore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m   1306\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             untyped_storage = torch.UntypedStorage(\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 1.06 MiB is free. Process 111550 has 14.74 GiB memory in use. Of the allocated memory 14.13 GiB is allocated by PyTorch, and 484.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Model selection** ðŸ§ \n",
        "\n",
        "#@markdown As of the first public release, there are 4 pre-trained options to play with:\n",
        "\n",
        "#@markdown |  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "#@markdown |:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "#@markdown |  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "#@markdown |  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "#@markdown | small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "#@markdown | medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "#@markdown | large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Model = 'tiny' #@param ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large', 'large-v2','large-v3']\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the model.**\n",
        "\n",
        "# load pyannote speaker-diarization\n",
        "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\",\n",
        "                                            use_auth_token=\"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\")\n",
        "\n",
        "whisper_model = whisper.load_model(Model)\n",
        "\n",
        "if Model in whisper.available_models():\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is selected.**\"\n",
        "    ))\n",
        "else:\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is no longer available.** Please select one of the following: - {' - '.join(whisper.available_models())}\"\n",
        "    ))"
      ],
      "metadata": {
        "id": "HaDJa6vYCrSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Run the model** ðŸš€\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** âš™ï¸\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"Auto detection\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "language = (None if language == \"Auto detection\" else language)\n",
        "verbose = verbose_lut[verbose]\n",
        "\n",
        "\n",
        "if Model.endswith(\".en\") and language not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{language}'; using English instead.\")\n",
        "    language = \"en\"\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(filepath)[0] + \".txt\"\n",
        "print(\"audio local path:\", audio_path_local)\n",
        "\n",
        "import time\n",
        "\n",
        "#Transcribe\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper.transcribe(\n",
        "    model=whisper_model,\n",
        "    audio = str(audio_path_local),\n",
        "    verbose=verbose,\n",
        "    task=task,\n",
        "    language=language\n",
        ")\n",
        "#Time comsumed\n",
        "toc = time.time()\n",
        "print(f'Time consumpution {toc-tic}s for transcribing')\n",
        "\n",
        "#Write SRT file\n",
        "from whisper.utils import WriteSRT\n",
        "with open(subtitle_file, \"w\", encoding=\"utf-8\") as srt:\n",
        "    writer = WriteSRT(audio_path_local.parent)\n",
        "    writer.write_result(transcription, srt)\n",
        "print(f\"Write SRT file to '{subtitle_file}'\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "diarization_result = pipeline(audio_path_local)\n",
        "final_result = diarize_text(transcription, diarization_result)\n",
        "\n",
        "lines = list()\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    print(f\"{line}\")\n",
        "    lines.append(line)\n",
        "\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "display(Markdown(f\"**Transcript file created: {transcript_with_speakers_file}**\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lOnyZpK2EsVe",
        "outputId": "7c7d801e-1259-47ae-e695-2de79deb329d"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "### /content/20636_4_5771510420242174755.wav",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio local path: /content/20636_4_5771510420242174755.wav\n",
            "Transcribe in progress...\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Persian\n",
            "[00:00.000 --> 00:03.200]  Ø¯Ú©ØªØ± Ø³Ù…Ø§ÛŒÙ‡ ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ù†Ø§Ø³ Ù…ÛŒÚ¯ÙˆÛŒØ¯\n",
            "[00:03.200 --> 00:05.600]  Ø¬Ø§ÛŒÚ¯Ø§Ù‡ Ø²Ù†Ø§Ù† Ø¯Ø± Ø¬Ø§Ù…Ø¹Ù‡ Ø§ÛŒØ±Ø§Ù†ÛŒ\n",
            "[00:05.600 --> 00:10.080]  Ø¨Ø¹Ø¯ Ø§Ø² Ø¬Ù†Ø¨Ø´ Ù‡Ø§ÛŒ Ø³Ø§Ù„Ù‡ 1400 Ùˆ 1ØŒ 2ØŒ 4 ØªØºÛŒÛŒØ± Ùˆ ØªØºÙˆÙ„ Ø´Ø¯Ù‡\n",
            "[00:16.240 --> 00:20.080]  Ø³Ù„Ø§Ù… Ù…Ù† Ø¨ÛŒØª Ø¢Ø°Ø±ÛŒ Ø¨Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¯ÛŒØ¯Ú©Ø§ Ù‡Ù…Ø±Ø§Ù‡ Ø´Ù…Ø§ Ù‡Ø³ØªÙ…\n",
            "[00:22.200 --> 00:25.480]  Ø®Ø§Ù†Ù… ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¨Ù‡ Ø®Ø¨Ø± Ø¢Ù†Ù„Ø§ÛŒÙ† Ú¯ÙØªÙ‡ Ø§Ø² Ø¯Ù‡Ù‡ Ù‡ÙØªØ§Ø¯\n",
            "[00:25.480 --> 00:28.000]  Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡\n",
            "[00:28.000 --> 00:32.000]  Ù…Ø§ ÛŒÚ© Ø¬Ø§Ù…Ø¹Ù‡ Ù…Ø±Ø¯ Ø³Ø§Ù„Ø§Ø± Ø±Ø§ Ø¯Ø§Ø´ØªÛŒÙ… Ú©Ù‡ Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø´Ú©Ù„ Ù…Ø´Ø®ØµÛŒ\n",
            "[00:32.000 --> 00:34.240]  Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø²Ù†Ø§Ù† Ù…ÛŒØ±Ø³ÛŒØ¯\n",
            "[00:34.240 --> 00:38.320]  Ø§Ù…Ø§ Ø¯Ø± Ø³Ø§Ù„ 1400 Ùˆ 2 ÛŒÚ© Ø¨Ø§Ø±Ù‡ Ø¨Ø§ Ø¬Ù…Ø¹ÛŒØªÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒØ´ÙˆÛŒÙ…\n",
            "[00:38.320 --> 00:41.680]  Ú©Ù‡ Ø¨Ù‡ Ø¹Ø±Øµ Ø¨Ø±Ø¯Ù† ÛŒÚ© Ø³Ø§Ù† Ø²Ù† Ùˆ Ù…Ø±Ø¯ Ø¨Ø§ÙˆØ±Ø¯Ø§Ø±Ù†Ø¯\n",
            "[00:41.680 --> 00:45.040]  Ø­Ù‚ ØªÙ„Ø§Ù‚ Ø¨Ø±Ø§ÛŒ Ø²Ù†Ø§Ù† Ù…ÙˆØ±Ø¯ Ù¾Ø°ÛŒØ±Ø´ Ù‚Ø±Ø§Ø± Ù…ÛŒÚ¯ÛŒØ±Ø¯\n",
            "[00:45.040 --> 00:47.480]  Ùˆ Ù¾Ø°ÛŒØ±Ø´ Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ ÙˆØ§Ù„Ø¯ÛŒÙ†\n",
            "[00:47.480 --> 00:50.200]  Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ±Ø§Øª ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø¨Ø§Ù„Ø§ Ø±ÙØªØ³Øª\n",
            "[00:50.240 --> 00:52.720]  Ø¨Ù‡ Ø§Ø¹ØªÙ‚Ø§Ø¯ ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø§ÛŒÙ† ØªØºÛŒÛŒØ±Ø§Øª Ù†Ø´Ø§Ù†Ø¯Ù‡Ù†Ø¯Ù‡\n",
            "[00:52.720 --> 00:57.120]  ØªØ³Ø§Ù‡Ù„ Ø¨ÛŒÙ†Ú¯Ø±ÙˆÙ‡ÛŒ Ùˆ Ø¨ÛŒÙ† Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ Ø¯Ø±Ù…ÛŒØ§Ù† Ù…Ø±Ø¯Ù… Ø§Ø³Øª\n",
            "[00:57.120 --> 01:01.040]  Ø¯Ø± Ø¯ÛŒØ¯Ú¯Ø§Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¬Ø²ÛŒØ§Øª Ú¯ÙØªÚ¯ÙˆÛŒ Ø³Ù…ÛŒØª ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ\n",
            "[01:01.040 --> 01:06.680]  Ø¨Ø§ Ø³Ù‡Ø± Ù…ØªÙ„Ø¨ÛŒ Ù¾Ø¬ÙˆÙ‡Ø´Ú©Ø± Ø¨Ù‡Ø¯Ø§Ø´Øª Ø¬Ù…Ø¹ÛŒØª Ø¨ÛŒÙ† Ø§Ù„Ù…Ù„Ù„ Ø§Ø² Ø³ÙˆØ¦Ø¯ Ù‡Ù…Ø±Ø§Ù‡ Ù…ÛŒØ´ÙˆÛŒÙ…\n",
            "[01:11.680 --> 01:14.720]  Ø®Ø§Ù† Ù…ØªÙ„Ø¨ÛŒ Ù¾ÛŒØ´ Ø§Ø² Ø§ÛŒÙ† Ú©Ù‡ Ù…Ù† Ù¾Ø±Ø³Ø´Ùˆ Ù‡Ù… Ù…Ø·Ø±Ø­ Ú©Ù†Ù…\n",
            "[01:14.720 --> 01:19.200]  Ø®ÙˆØ§Ù‡Ø´ Ù…ÛŒÚ©Ù†Ù… Ø®Ù„Ø§ØµÙ‡ Ø§ÛŒ Ø§Ø² Ø¹Ø±Ø¶ÛŒØ§Ø¨ÛŒ Ù‡Ø§ÛŒ Ø¯Ú©ØªØ± Ø³Ù…ÛŒØª ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ\n",
            "[01:19.200 --> 01:24.600]  Ø§Ø² ØªØ­ÙˆÙ„Ø§Øª Ø¬Ø§Ù…Ø¹Ù‡ Ø§ÛŒØ±Ø§Ù† Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ø¹ØªØ±Ø§Ø²Ø§Øª 1401 Ø±Ùˆ Ø¨Ø±Ù…ÙˆÙ† Ù…Ø±ÙˆØ± Ú©Ù†ÛŒØ¯\n",
            "[01:24.600 --> 01:26.360]  Ø¨Ø¹Ø¯ ÙˆØ§Ø±Ø¯ Ùˆ Ø¬Ø²ÛŒØ§Øª Ø¨Ø´ÛŒÙ…\n",
            "[01:26.360 --> 01:28.680]  Ø¨Ø§ ØµØ¯Ø§ ÙÙ‚Ø· Ø®Ø¯Ù…Øª Ø´Ù…Ø§ Ø¨Ø¨ÛŒÙ†ÛŒØ¯\n",
            "[01:28.680 --> 01:31.720]  Ø§ÛŒÙ† Ø¨ØºØ§Ù„Ø§ Ø¨Ù‡ Ù†Ø¸Ø±Ù…Øª ÙÙ‚Ø· Ù†ÙØ¹Ù‡ Ø®ÛŒÙ„ÛŒ Ø¬Ø§Ù„Ø¨ÛŒ Ø¯Ø§Ø´Øª\n",
            "[01:31.720 --> 01:34.120]  Ø¨Ù‡ Ø·ÙˆÙ„ Ù…Ø´Ø§Ù‚ØµÙ… Ù…Ù‡Ù…ØªØ±ÛŒÙ† Ú†ÛŒØ²ÛŒ Ú©Ù‡\n",
            "[01:34.120 --> 01:37.560]  ØªØºÛŒÛŒØ±Ø§Øª Ú©Ù‡ Ø¯Ø± ÙˆÙ‚Øª Ø§ÛŒØ´ÙˆÙ† Ø§Ø´Ø§Ø±Ù‡ Ú©Ø±Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ø¨Ù‡Ø´\n",
            "[01:37.560 --> 01:41.600]  Ø§ÛŒÙ†ÛŒ Ú©Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø¯Ø± ÙˆÙ‚Øª ØªØ¹Ø§Ù…Ù„ Ú¯Ø±ÙˆÙ‡ Ù‡Ø§ Ùˆ Ø¨Ù‚Ø´ Ùˆ Ø¨Ù‚Ø´ Ùˆ Ù…Ø®ØªÙ„Ù\n",
            "[01:41.600 --> 01:43.800]  Ø¨Ù‡ Ø§ÛŒÚ© ØªØ³Ø§Ù‡Ù„ÛŒ Ø±Ùˆ ØªØ¬Ø±Ø¨Ù‡ Ù…ÛŒÚ©Ù†Ù‡\n",
            "[01:43.840 --> 01:45.760]  Ú©Ù‡ Ù…Ø«Ù„Ø§ Ø¯Ø± Ø²Ù…Ø§Ù†Ù‡ÙˆÙ‚ Ø²Ù†Ø§Ù†\n",
            "[01:45.760 --> 01:49.600]  Ø®ÛŒÙ„ÛŒ Ù…ÙˆØ§Ø¯ Ø¯ÛŒØ¯Ù‡ Ù…ÛŒØ´Ù‡ Ú©Ù‡ Ø­Ù‚ ØªÙ„Ø§Ù‚Ù‡ Ø³ÛŒÙ‡ Ø¨Ø±Ø§Ø¨Ø± Ø¯Ø§Ø±Ù‡\n",
            "[01:49.600 --> 01:52.800]  Ø¨ÛŒØ´ØªØ± Ù¾Ø°Ø±ÙˆÙØªÙ‡ Ù…ÛŒØ´Ù‡ ØªÙˆÛŒ Ø¬Ø§Ù…Ø¹Ù‡\n",
            "[01:52.800 --> 01:55.920]  Ùˆ Ù‡Ù…ÛŒÙ†Ø·ÙˆØ± Ù…Ø¯Ø§Ø±Ø§ÛŒ ÙˆØ§Ù„Ø¯ÛŒÙ† Ø¨Ø§ Ø®ÙˆØ§Ø³ØªØ§ÛŒ Ù¾Ø±Ø²Ù†Ø¯Ø§Ù†Ø´ÙˆÙ†\n",
            "[01:55.920 --> 02:00.200]  Ú©Ù‡ Ù…Ù…Ú©Ù†Ù‡ Ú©Ù‡ Ø¨Ù‡ Ù„Ø­Ø§Ø¸ Ø¹Ù‚ÛŒØ¯ØªÛŒ Ø¨Ø§ Ø®ÙˆØ§Ø³ØªØ§ÛŒ Ø®ÙˆØ¯Ø´ÙˆÙ† Ù…ØªÙØ§Ø¨Ø· Ø¨Ø§Ø´Ù‡\n",
            "[02:00.200 --> 02:04.360]  Ùˆ Ø§ÛŒÙ† ØªØ³Ø§Ø±Ù„ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¨ÛŒÙ† Ú¯Ø±ÙˆÙ‡ÛŒ Ùˆ Ø¨ÛŒÙ† Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ Ù‡Ù… Ø¯Ø§Ø±Ù‡ Ø´Ú©Ù„ Ù…ÛŒÚ¯ÛŒØ¯\n",
            "[02:04.360 --> 02:07.960]  Ù…Ø«Ù„Ø§ Ø¨ÛŒÙ† Ø¹Ù‚Ù„ÛŒØªÙ‡Ø§ÛŒ Ù…Ø±Ø«Ù‡ÙˆÛŒ Ù…Ø®ØªÙ„Ù Ø¨ÛŒØ´ØªØ± Ù¾Ø°Ø±ÙˆÙØªÙ‡ Ù…ÛŒØ´Ù†\n",
            "[02:07.960 --> 02:10.920]  Ùˆ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø³Ø§Ø¨Ù‚ Ø¨ÛŒØ´ØªØ± Ø¯ÛŒØ¯Ù‡ Ù…ÛŒØ´Ù† Ùˆ Ø´Ø§ÛŒØ¯ Ù¾Ø°Ø±ÛŒØ´ÙˆÙ† Ø²ÛŒØ§Ø¯ Ø´Ø¯Ù‡\n",
            "[02:10.920 --> 02:12.960]  Ø¯ÛŒÚ¯Ù‡ Ù†Ú©ØªÙ‡ ÛŒÚ©ÛŒ Ú©Ù‡ Ú¯ÙØªÙ† Ø§ÛŒÙ†Ù‡ Ú©Ù‡\n",
            "[02:12.960 --> 02:17.440]  ÙˆÙ‚ØªÛŒ Ù†Ø§Ø±Ø¶ÛŒØ§ØªÛŒ Ø¬Ù…Ø¹ÛŒ Ù†Ø§Ø´ÛŒ Ø§Ø² Ø¹Ø¯Ù…ÛŒ Ø±Ø³ÛŒØ¯Ù† Ø¨Ù‡ Ø®ÙˆØ§Ø³ØªØ§Ù‡Ø§ Ø¨Ù‡ ÙˆØ¬ÙˆØ¯ Ø¨ÛŒØ§Ø¯\n",
            "[02:17.440 --> 02:20.080]  Ø§Ù†ØªØ¸Ø§Ø± Ù…ÛŒÚ©Ù†Ù‡ Ú©Ù‡ Ø¯Ùˆ ØªØ§ Ù†ØªÛŒØ¬Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù‡\n",
            "[02:20.080 --> 02:23.320]  ÛŒØ§ Ø§ÛŒÙ† Ú©Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ú©Ø±Ø®Øª Ùˆ Ù„Ù…Ø³ Ùˆ Ø¨ÛŒØªÙØ§ÙˆØª Ù…ÛŒØ´Ù‡\n",
            "[02:23.320 --> 02:26.960]  Ùˆ ÛŒØ§ Ø§ÛŒÙ†ÛŒ Ú©Ù‡ Ø§ØªÙØ§Ù‚Ø§ Ø¨Ø§ Ú©Ø§Ù†Ø´Ù‡Ø§ÛŒ Ø±Ø§Ø¯ÛŒÚ©Ø§Ù„ Ø¹Ù‚Øµ Ø§Ø´Ø´Ø§ÙØªÛŒ Ø¯Ø§Ø±Ù‡\n",
            "[02:26.960 --> 02:31.800]  Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù‡Ø± Ø¯Ùˆ ÛŒÚ© Ø¨Ø§ Ú©Ø§Ù†Ø´ Ø§ÙØ±Ø§Ø¯ÛŒÙ‡ Ú©Ù‡ Ø§ÛŒÙ† Ø¨Ø§Ø¹Ø«Ù…Ø´ Ú©Ù‡ Ú©Ù†Ø´Ú¯Ø±ÛŒ Ø³Ø®Øª Ù‡Ø± Ø¨Ø´Ù‡\n",
            "[02:31.800 --> 02:34.640]  Ø¨Ø¹Ø¯ Ù†Ú©ØªÙ‡ Ø¯ÛŒÚ¯Ù‡ Ú©Ù‡ Ú¯ÙØªÙ‡ Ø¨ÙˆØ¯Ù† Ø§ÛŒÙ† Ø¨ÙˆØ¯Ù‡ Ú©Ù‡\n",
            "[02:34.640 --> 02:37.520]  Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø·Ø¨Ù‚Ù‡ Ù¾Ø§ÛŒÙ†Ø¯ Ø±ÙˆÛŒ ÙÙ‚Ù‚ ÙˆØ§Ù‚Ø¹ÛŒ Ù…ÙˆÙ†Ø¯Ù‡\n",
            "[02:37.520 --> 02:39.720]  Ùˆ Ø·Ø¨Ù‚Ù‡ Ù…ØªÙˆØ³Ø· Ø¯Ø§Ø±Ù‡ Ù…Ø²Ù…Ø­Ù„ Ù…ÛŒØ´Ù‡\n",
            "[02:39.720 --> 02:43.000]  Ùˆ Ø§Ø´Ø¹Ø§Ù„ÛŒ Ú©Ø±Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ú©Ù‡ Ø¢Ù…Ø§Ø± Ø¨ÛŒÚ©Ø§Ø±ÛŒ Ú©Ù‡ 75% Ø§Ø¹Ù„Ø§Ù… Ø´Ø¯Ù‡\n",
            "[02:43.000 --> 02:44.200]  Ø§ÛŒ Ø®Ø¨ Ù…Ø§Ù„Ø§ Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø³Øª\n",
            "[02:44.200 --> 02:49.360]  Ø¬Ø§Ù†Ø¯Ù‡ ÛŒÚ© Ø¨Ø®Ø´ÛŒ Ø§Ø² Ø¨ÛŒÚ©Ø§Ø±Ø§Ù† Ú©Ù‡ Ø¨Ù‡ Ø³Ø±Ø²Ø¯Ù‡ Ø´Ù‚Ø§ÛŒ Ù¾Ø§Ø±ÙˆØ§Ø®ØªÛŒ Ù‡Ø³ØªÙ†\n",
            "[02:49.360 --> 02:53.360]  Ùˆ ÛŒØ§ Ø¨Ø±Ø·Ù…Ù‡ ÙˆØ§Ù‚Ø¹ Ø´Ø§ØºÙ„ Ù‡Ø³ØªÙ† Ø§ÛŒÙ†Ù‡Ø§ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¬Ø² Ø¢Ù…Ø§Ø± Ø´Ø§ØºÙ„ Ù…ÛŒÙ‡Ù†Ù‡\n",
            "[02:53.360 --> 02:56.760]  Ø³Ø¨Ø´ØªÙ‡ Ú©Ù‡ Ø¯Ø± Ø³Ø±Ø²Ø¯Ù‡ Ú©Ù‡ Ø¹Ù„Ø§Ù‚Ù‡ Ø§ÛŒÙ†Ù‡Ø§ Ø¨Ø§ Ø¬Ø² Ø¢Ù…Ø§Ø± Ø¨ÛŒÚ©Ø§Ø±Ø§Ù† Ø­Ø³Ø§Ø¨ Ú©Ø´Ù†Ø¯\n",
            "[02:56.760 --> 03:02.480]  Ùˆ Ù†Ú©ØªÙ‡ Ø¯ÛŒÚ¯Ù‡ Ø§ÛŒÙ†ÛŒ Ú©Ù‡ 40% Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¨ÛŒÚ©Ø§Ø±Ø§Ù† ØªØ­ØµÛŒÙ„ Ú©Ø±Ø¯Ù‡ Ù‡Ø³ØªÙ†\n",
            "[03:02.480 --> 03:04.840]  Ùˆ 71% Ø§ÙˆÙ†Ù‡Ø§ Ù‡Ù… Ø²Ù†Ø§Ù† Ù‡Ø³ØªÙ†\n",
            "[03:04.840 --> 03:08.640]  Ù†Ú©ØªÙ‡ Ú©Ù‡ Ú¯ÙØªÙ‡ Ø¨ÙˆØ¯Ù† Ø§ÛŒÙ† Ø¨ÙˆØ¯Ù‡ Ú©Ù‡ Ø¨ÛŒØ´ØªØ±ÛŒ Ù…ÛŒØ²Ø§Ù† Ú©Ù†Ø´Ú¯Ø±ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ\n",
            "[03:08.640 --> 03:10.560]  Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø§Ø² Ø·Ø¨Ù‚Ù‡ Ù…ØªÙˆØ³Ø· Ø´Ø¯Ù‡ Ù…ÛŒØ´Ù‡\n",
            "[03:10.560 --> 03:13.760]  Ùˆ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…Ø®ØªØµÙ… ÙˆÙ‚ØªÛŒ Ø·Ø¨Ù‚Ù‡ Ù…ØªÙˆØ³Ø· Ú©Ù„Ø§Ù…Øª Ùˆ Ø¬Ø§ÛŒÚ¯Ø§Ù‡ Ø§Ù†Ø³Ø§Ù†ÛŒÙ‡\n",
            "[03:13.760 --> 03:18.040]  Ø§Ø² Ø¯Ø³Øª Ù†ÛŒØ¯Ù‡ Ùˆ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù„Ú†Ø§Ø±Ù‡ Ø®Ø´Ù… Ù‡Ù… Ø¨Ø§Ø´Ù‡ Ù†ÛŒÙ…ÛŒØ´Ù‡\n",
            "[03:18.040 --> 03:23.680]  Ø²ÛŒØ± Ù‚ØµØ¯ Ø¬Ø§Ù…Ø¹Ù‡ ØªÙØ§Ù‡Ù…ÛŒ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø­Ù‚ÙˆÙ‚ Ø²Ù†Ø§Ù† Ø¯Ø± Ø­Ø§Ù„ Ø´Ú©Ù„ Ú¯Ø±ÙØªÙ†\n",
            "[03:23.680 --> 03:29.920]  Ø§Ú¯Ø±Ú†Ù‡ Ø­Ø§Ú©Ù…ÛŒØª Ù…Ø§ Ù†Ù¾Ø°ÛŒØ±ÙØªÙ‡ ÙˆÙ„ÛŒ Ú©Ù‡ Ø¨Ù†Ø¸Ø± Ù…ÛŒØ±Ø³Ø¯ Ú©Ù‡ Ø§ÛŒÙ† Ù†Ø´Ø§Ù†Ù‡ Ù‡Ø§Ø´ Ø¯Ø± ÙˆØ§Ù‚Ø¹\n",
            "[03:29.920 --> 03:35.920]  Ù…Ø«Ù„Ø§Ù‹ Ø¨Ø³Ø±Ø§Øª Ø§ÛŒÙ†Ù‡ Ú©Ù‡ Ø±Ø³Ø§Ù†Ù‡ Ù‡Ø§ Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ Ù¾ÙˆØ´Ø´ Ø²Ù†Ø§Ù† ØªØ³Ø§Ø­Ù„ Ø¯Ø§Ø±Ù†Ø¯ Ø¯ÛŒØ¯Ù‡ Ù…ÛŒØ´Ù‡\n",
            "[03:35.960 --> 03:41.080]  Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù…Ù‡Ø§Ø¬Ø±Øª Ù‡Ù… Ø§ÛŒØ´ÙˆÙ† Ø¨Ú©Ù†Ù† Ú©Ù‡ Ø§ÛŒØ±Ø§Ù† Ù‡ÙØªÙ‡ Ù…Ù† Ú©Ø´ÙˆØ±Ù‡ Ù…Ù‡Ø§Ø¬Ø±Øª Ø¨Ø±Ø³ØªÙ‡\n",
            "[03:41.080 --> 03:45.160]  Ú©Ù‡ Ø¨Ù†Ø¸Ø± Ù…ÛŒØ±Ø³ØªÙ‡ Ú©Ù‡ Ø§Ù†Ú¯ÛŒØ²Ù‡ Ù‡Ø§ÛŒ Ù…Ù‡Ø§Ø¬Ø±Øª Ø§ÛŒ Ú©Ù‡ Ù…Ù‚Ø§ÛŒÛŒ ØªÙ‚Ø±ÛŒØ± Ú©Ø±Ø¯Ù‡\n",
            "[03:45.160 --> 03:48.960]  Ù…Ø«Ù„Ø§Ù‹ Ø¨Ù‡ Ù¾Ø´Ø§Ø±Ù‡ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ù…ÛŒÙ†Ù‡ Ø­ØªÛŒ Ø¯Ø± Ø¨ÛŒÙ† Ú¯Ø±ÙˆÙ‡ Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø®ÙˆØ¯Ø´ÙˆÙ†\n",
            "[03:48.960 --> 03:54.280]  Ø§Ø¯ÙˆÛŒØ² Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ùˆ ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ØªØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯ ÙˆÙ„ÛŒ Ú©Ù‡ Ù‡ÙØªÙ‡ Ù¾Ø´Ø§Ø± Ù‡Ù… Ù†Ø³Ù„Ù‡ Ù‡Ø§Ø´ÙˆÙ† Ø¯Ø§Ø±Ù†Ø¯\n",
            "[03:54.280 --> 04:00.040]  Ø³Ø¹ÛŒ Ù…ÛŒ Ú©Ù†Ù†Ø¯ Ú©Ù‡ Ù…Ù‡Ø§Ø¬Ø±Øª Ø¨Ú©Ù†Ù†Ø¯ Ùˆ Ù…Ù…Ú©Ù†Ù‡ Ø¯Ù„ÛŒÙ„ Ø§ØµÙ„Ø´ Ø§ÛŒÙ† Ø¨ÙˆØ¯Ù‡ Ú©Ù‡ Ø¯Ø± Ø®ÙˆÙ†Ø¯ Ú†Ø´Ù…Ø§Ù†Ø¯Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ù‡\n",
            "[04:00.040 --> 04:06.720]  Ø®Ø§Ù†Ù… ØªØ¹Ù„ÛŒØ¨ÛŒ Ø§Ø² ÛŒÚ© Ø·Ø±Ù Ù†Ú¯Ø§Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø¨Ù‡ Ù…Ø³Ø¦Ù„Ù‡ Ø²Ù†Ø§Ù† Ø¯ÙˆÚ†Ø§Ø± ØªØ­ÙˆÙ„ Ù…Ø¹Ù†Ø§Ø¯Ø§Ø± Ø´Ø¯Ù‡\n",
            "[04:06.720 --> 04:11.280]  Ø§Ø² Ø·Ø±Ù Ø¯ÛŒÚ¯Ù‡ Ø¨Ù‡ Ø´Ù‡Ø§Ø¯Øª Ù‡Ù…ÛŒÙ† Ú¯ÙØªÚ¯Ùˆ Ø¨Ø§ Ø®Ø§Ù†Ù… ØªÙˆØ­ÛŒØ¯Ù„Ùˆ\n",
            "[04:11.280 --> 04:17.240]  Ù¾Ø´Ø§Ø±Ø§ÛŒ Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ù‚Ø´Ø± Ù…ØªÙˆØ³Ø· Ø±Ùˆ Ú†Ù†Ø§Ù† Ø²Ø¹ÛŒÙ Ú©Ø±Ø¯Ù‡ Ú©Ù‡ Ø§Ø² Ú©Ø§Ø±Ú©Ø±Ø¯ Ø§Ù†Ø¯Ø§Ø®ØªÙ‡\n",
            "[04:17.240 --> 04:24.840]  Ø³ÙˆØ§Ù„ Ù…Ù† Ø§ÛŒÙ†Ù‡ Ú©Ù‡ Ø§Ø² Ù†Ø¸Ø± Ø´Ù…Ø§ ÙˆØ²Ù† Ù¾Ø´Ø§Ø±Ø§ÛŒ Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ø¯Ø± ØªØ­ÙˆÙ„Ø§Øª Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ø³Ù‡Ù… Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù‡ØŸ\n",
            "[04:24.840 --> 04:28.480]  ÛŒØ§ Ø­Ù‚ÙˆÙ‚ Ø²Ù†Ø§Ù† Ú©Ù‡ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ØªØ§Ù„Ø¨Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ø¯Ù‡ØŸ\n",
            "[04:28.480 --> 04:36.440]  Ø¨Ù‡ Ù†Ø¸Ø± Ø´Ø®ØµÛŒ Ù…Ù† Ø§ÛŒÙ†Ø·ÙˆØ± Ù†ÛŒØ§Ø¯Ø´ Ú©Ù‡ Ù…Ø±Ù‚Ø¬ Ù…Ø´ØªØ±Ú© Ù…ØªØ§Ù„Ø¨Ø§Øª Ø¬Ø§Ù…Ø¹ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø§Ù„Ø§Ù† Ù…ØªØ§Ù„Ø¨Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÛŒÙ‡\n",
            "[04:36.440 --> 04:43.120]  ÙˆÙ‚ØªØ§Ù† Ø§Ø² Ù„Ø§Ø³Ù‡ Ø¢Ù…Ø§Ø±ÛŒ Ú©Ù‡ Ù…ÛŒ Ø®ÙˆØ§Ù‡ÛŒÙ… Ø¨Ø±Ø³ÛŒØ¨ Ú©Ù†ÛŒÙ… Ù…ÛŒ Ø¨ÛŒÙ†ÛŒÙ… Ú©Ù‡ Ø¨ÛŒÙ† Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ø§Ú©Ø± Ù…Ø«Ù„Ø§ Ø³Ø§Ù„ 1378-18\n",
            "[04:43.120 --> 04:46.880]  ØªÙˆØ§Ù‚Ø¹ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø¢Ø²Ø§Ø¯ÛŒ Ù…Ø¯Øª Ø¨ÙˆØ¯ØŒ Ø³Ø§Ù„ 828 Ø­Ù‚ Ø±Ø¹ÛŒ Ø¨ÙˆØ¯\n",
            "[04:46.880 --> 04:55.000]  ÙˆÙ„ÛŒ Ø§Ø² Ø¯Ø± ÙˆØ§Ù‚Ø¹ ÛŒÚ© Ø¯Ù‡Ù‡ Ø§Ø®ÛŒØ±ØŒ Ø³Ø§Ù„ 96-98-1401 Ù…ØªØ§Ù„Ø¨Ø§Øª Ø¨Ù‡ Ø·ÙˆØ± Ù…Ø´Ø®Øµ\n",
            "[04:55.000 --> 05:00.360]  Ù…ØªØ§Ù„Ø¨Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ùˆ Ø±ÙØ¹ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ùˆ ØªÙˆØ§Ù‚Ø¹ Ú©Ø±ÙˆØ¯Ø³Øª Ø¨ÛŒØ´ØªØ± Ù…Ø´Ø§Ø±Ú©Øª Ú©Ø±Ø¯Ù†\n",
            "[05:00.360 --> 05:08.880]  Ùˆ ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ú¯Ø±ÙˆÙ‡ Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ø´Ø§Ø±Ú©Øª Ú©Ø±Ø¯Ù† Ù‡Ù… Ù…Ø«Ù„Ø§ Ø¯Ø± Ù…ØµØ¯Ø± Ø´Ø¹Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø¨Ø®ÙˆØ§ÛŒÛŒÙ… Ø¯Ø± Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ±ÛŒÙ… Ø®ÛŒÙ„ÛŒ Ø¨ÛŒØ´ØªØ± Ø´Ø¯Ù‡\n",
            "[05:08.880 --> 05:18.840]  Ùˆ Ø¯ÛŒÚ¯Ù‡ Ø§ÛŒÙ† Ú©Ù‡ Ù…Ø«Ù„Ø§ Ø§Ú¯Ø± Ø¨Ø®ÙˆØ§ÛŒÛŒÙ… Ø­ØªÛŒ Ø§ÙˆÙ† Ø¯Ùˆ ØªØ§ Ù†Ù‚Ø´Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¯Ø±Ù…ÙˆÙ…Ø¯Ù‡ Ú©Ù‡ Ù†Ù‚Ø´ ØªÙˆØ¶ÛŒØ­ Ø¨ÙˆØ¬Ù‡ÛŒ Ø³Ø§Ù„ 1401 Ú©Ù‡ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¢Ù†Ù„Ø§ÛŒÙ† Ù…Ù†ØªØ´Ø± Ú©Ø±Ø¯Ù‡\n",
            "[05:18.840 --> 05:24.000]  Ø§ÙˆÙ† Ø±Ùˆ Ù…Ù‚Ø§Ø±ÛŒØ³Ù‡ Ø¨Ú©Ù†ÛŒÙ… Ø¨Ø§ Ù†Ù‚Ø´Ù‡ Ø¢Ø³ÛŒØ¯ Ø¨ÛŒØ¯Ú¯Ø§Ù† Ø¬Ù†Ø¨Ø´ØŒ Ø®ÛŒÙ„ÛŒ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù‡Ù…Ú©ÙˆØ´Ø§Ù†ÛŒ Ø¬Ø§Ù„Ø¨ÛŒ Ø¯Ø§Ø±Ù‡\n",
            "[05:24.000 --> 05:34.600]  Ø§ÙˆÙ† Ø§Ø³ØªØ§Ù†Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¨ÙˆØ¬Ù‡ÛŒ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù† Ú©Ù…ØªØ±ÛŒÙ† Ù…ÛŒØ²Ø§Ù† Ù…Ø´Ø§Ø±Ú©Øª Ø±Ùˆ Ø¯Ø± Ø¬Ù†Ø¨Ø´ Ø§Ø² Ù„Ø§Ø²Ù… Ø¢Ù…Ø§Ø± Ø¢Ø³ÛŒØ¯ Ø¨ÛŒØ¯Ú¯Ø§Ù† Ùˆ Ú©Ø´Øª Ø´Ø¯Ú¯Ø§Ù† Ùˆ Ø¨Ø§Ø²Ø´ Ø´Ø¯Ú¯Ø§Ù† Ø¯Ø§Ø±Ù†\n",
            "[05:34.600 --> 05:43.640]  Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Ø§Ø³ØªØ§Ù†Ù‡Ø§ÛŒÛŒ Ø­Ø§Ø´ÛŒÙ‡ Ú©Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ú©Ù…ØªØ±ÛŒÙ† Ù…ÛŒØ²Ø§Ù† Ø¨Ù‡ Ø¨ÙˆØ¬Ù‡ Ø±Ùˆ ÙˆØ§Ø³Ø§Ø³ Ø³Ø±Ø§Ù†Ù‡ Ø¯Ø§Ø±Ù† Ø¨ÛŒØ´ØªØ±ÛŒ Ù…ÛŒØ²Ø§Ù† Ø¢Ø³ÛŒØ¯ Ø¨ÛŒØ¯Ú¯Ø§Ù† Ø¬Ù†Ø¨Ø´ Ø¯Ø§Ø±Ù†\n",
            "[05:43.640 --> 05:54.400]  Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù†Ø´ÙˆÙ†Ø¯Ù‡ Ú©Ù‡ Ø§ÛŒÙ† Ù‡Ø§ Ù…Ø´Ø§Ø±Ú©Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ú©Ø±Ø¯Ù† ÛŒØ¹Ù†ÛŒ Ø¨Ø§ Ø§ÛŒÙ† Ø­Ø§Ù„ Ù‡Ù…ÛŒØ² Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒØ§Ø¯ Ú©Ù‡ Ù…ØªØ¹Ù„Ù‚Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÛŒØŒ Ù…ØªØ¹Ù„Ù‚Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ ØªÙ„ÛŒÙ‡ Ùˆ ÙˆØ²Ù† Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù‡\n",
            "[05:54.400 --> 06:06.560]  Ø§Ù…Ø§ Ù†Ú©ØªÙ‡ Ú©Ù‡ Ø¨ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù‡ Ø§ÛŒÙ†Ù‡ Ú©Ù‡ 10.401 Ø§ÛŒÚ© ØªÙ‚Ø§Ø¨Ù„ Ø¯ÛŒÚ¯Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯ØŒ Ø§ÙˆÙ† Ù‡Ù…ÙˆÙ†ÛŒ Ú©Ù‡ Ù†ÛŒÙ…ÛŒ Ø§Ø² Ø¬Ø§Ù…Ø¹Ù‡ Ú©Ù‡ Ø²Ù†Ø§Ù† Ø¨ÙˆØ¯Ù† Ú©Ù‡ Ø¨Ù‡ Ø·ÙˆØ± ØµÙ†Ø¯ØªÛŒ Ø¯Ø± Ø¬Ø§Ù…Ø¹Ù‡ Ù…Ø±Ø³Ø§Ù„Ù‡ Ø±ÛŒØ¶Ø§Ù† Ù‚ÛŒØ± Ø¢Ù…Ù„ Ø¨Ø±Ø²Ù† Ø´Ø¯Ù†\n",
            "[06:06.560 --> 06:16.160]  Ø§Ù…Ø§ Ø§ÛŒÙ† Ù‡Ø§ Ø¢Ù…Ù„ÛŒØª Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ùˆ Ø¢Ù…Ù„ÛŒØª Ø´Ø¯Ù† Ùˆ Ø¢Ù…Ù„Ù‡Ø§ÛŒ Ø§ÛŒÙ† Ø¬Ù…Ø¨Ø´ ÛŒÚ© Ø¬Ø§ Ø¨Ù‡ Ø¬Ø§ÛŒÛŒ Ø¯Ø±Ø´ÙˆÙ† Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡ Ù‡Ø³ØªÙ†Ø¯\n",
            "[06:16.160 --> 06:20.440]  Ø§Ø² Ø¬Ø§Ù…Ø¹Ù‡ Ù…Ø±Ø¯Ø§Ù† ÙˆÙØªÙ‡ Ø¯Ø± Ø¬Ø§Ù…Ø¹Ù‡ Ø²Ù†Ø§Ù† Ùˆ Ù…Ø±Ø¯Ù‡Ø§ Ù‡Ù… Ø§Ù…Ø±ÙˆØ² Ø²Ù†Ø§Ù† Ø´Ø¯Ù†Ø¯\n",
            "[06:20.440 --> 06:27.480]  Ù†Ú©ØªÙ‡ Ú©Ù‡ Ø¨ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù‡ Ø§ÛŒÙ†Ù‡ Ú©Ù‡ Ø¨Ù‡ Ù„Ø­Ø§Ø¸ Ø·Ø¨ÛŒØ¹ÛŒ Ø¨Ù‡ Ù†Ø¸Ø± Ù…Ù† Ø²Ù†Ø§Ù† Ø¨Ù‡ Ø®Ø§Ø·Ø± Ø·Ø¨ÛŒØ¹Øª Ù…Ø§Ø¯Ø±Ú¯ÙˆÙ†Ù‡\n",
            "[06:27.480 --> 06:32.640]  Ø§ÛŒÙ† Ù‡Ø§ Ù…Ù‡Ù…ÙˆÙ†Ø§Ù† Ú¯Ø±Ø§ÛŒØ´ Ø¨Ù‡ Ù‡Ù…Ù‡ Ø´Ù…ÙˆÙ„ÛŒÙ‡ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù†\n",
            "[06:32.640 --> 06:36.200]  Ù‡Ù…ÙˆÙ†Ø·ÙˆØ± Ú©Ù‡ Ù…ÛŒØ¨ÛŒÙ†ÛŒØ¯ Ø¨ÛŒØ´ØªØ±ÛŒ Ù…ÛŒØ²Ø§Ù† Ø®ÛŒØ±ÛŒ Ù‡Ø§ Ù‡Ù… Ø·Ø¨Ø¹Ø§ Ø§Ø² Ú©Ù‡ Ø²Ù†Ø§Ù† Ø§Ø¯Ø§Ø±Ù‡ Ù…ÛŒØ´Ù‡\n",
            "[06:36.200 --> 06:42.680]  Ø§ÛŒÙ† Ù‡Ø§ Ø¨Ø§ Ø§Ù‚Ø´Ø§Ø± Ø¨Ù‡ØªØ± Ú©Ù… Ø¨Ù‡ØªØ± Ù…Ù†ØªÙ‚Ù„ Ø¨ÛŒØ´ØªØ± Ø¯Ø±ØªÙ…Ø§Ø³ Ù‡Ø³ØªÙ† Ùˆ Ú©Ù¾ Ø¬Ø§Ù…Ø¹Ù‡ ØªÙ…Ø§Ø³ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù†\n",
            "[06:42.680 --> 06:47.480]  Ùˆ Ù…ØªØ¹Ù„Ø¨Ø§ØªØ´ÙˆÙ† ÙÙ‚Ø· Ù…ØªØ¹Ù„Ø¨Ø§Øª Ø®ÙˆØ¯Ø´ÙˆÙ† Ù†ÛŒØ³ØªØŒ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…ØªØ¹Ù„Ø¨Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ Ùˆ Ø¬Ù…Ø¹ÛŒ Ù†ÛŒØ³Øª\n",
            "[06:47.480 --> 06:53.480]  Ù…ØªØ­Ø§Ù„ Ù‚Ø¶ÛŒÙ‡ Ù‡Ø¬Ø§Ø¨ Ø¨Ù‡ Ù†Ø¸Ø± Ù…Ù† Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¨Ø³Ø±Ø§Øª ÛŒÚ© Ø³Ù…Ø¨ÙˆÙ„ Ù…Ù‚Ø§Ø¨Ù„Ù‡ Ø¨Ú©Ù†Ù‡\n",
            "[06:53.480 --> 07:00.480]  Ú†ÙˆÙ† Ø§ÛŒÙ† Ø±Ùˆ Ù†Ù‡ ØªÙ†Ù‡Ø§ Ø§ÛŒØ±Ø§Ù† ØªÙˆÛŒ Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ù„Ú©Ù‡ Ø¯Ø± Ú©Ø´ÙˆØ±Ù‡Ø§ÛŒ Ø¯ÛŒÚ¯Ù‡ Ù‡Ù… Ù…ÛŒØ¨ÛŒÙ†ÛŒØ¯\n",
            "[07:00.480 --> 07:05.480]  Ù…Ø«Ù„Ø§ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ù†Ù‚Ù„Ø§Ø¨ ÛŒÚ© Ú¯Ø±Ø§ÛŒØ´ÛŒ Ø¨Ù‡ Ù‡Ø¬Ø§Ø¨ Ø¨ÙˆØ¬ÙˆØ¯ Ø§ÙˆÙ…Ø¯Ù‡ Ø¨ÙˆØ¯\n",
            "[07:05.480 --> 07:11.480]  Ø§ÙˆÙ† Ù‡Ù… Ø¨ÛŒÙ† Ú¯Ø±ÙˆÙ‡ Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ø«Ù„Ø§ Ù…ÙˆØªØ±Ø²ÛŒÙ† Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø´Ø§Ù‡ Ø¨Ù‡ Ù‡Ø¬Ø§Ø¨ Ù…ÛŒØ¯ÙˆØ´ØªÙ†\n",
            "[07:11.480 --> 07:15.480]  Ø¨Ù‡ Ø®Ø§Ø·Ø± Ø§ÛŒÙ† Ú©Ù‡ Ø´Ø§Ù‡ Ø³Ù…Ø¨ÙˆÙ„ Ù…Ø¯Ø±Ù†ÛŒØ³Øª Ø¨ÙˆØ¯ Ùˆ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…ÛŒØ®ÙˆØ§Ø³ØªÙ† Ø¨Ù‡ Ø§ÙˆÙ† Ù…Ù‚Ø§Ø¨Ù„Ù‡ Ø¨Ú©Ù†Ù†\n",
            "[07:15.480 --> 07:23.480]  Ùˆ Ø§ÛŒÙ† Ø§ØªÙØ§Ù‚ Ø¯Ù‚ÛŒÙ‚Ø§ ØªÙˆÛŒ Ù…ØµØ± Ù‡Ù… Ø§ÙØªØ§Ø¯ Ú©Ù‡ Ù…Ø«Ù„Ø§ Ú¯ÙØªÙ‡ Ù…ÛŒØ´ÙˆØ¯ Ú©Ù‡ 70% Ø¬Ù…Ø¹ÛŒØª Ù…ØµØ± Ø²Ù…Ø§Ù† Ù…Ø¨Ø§Ø±Ú© Ú¯Ø±Ø§ÛŒØ´ Ø¨Ù‡ Ù‡Ø¬Ø§Ø¨ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù†\n",
            "[07:23.480 --> 07:29.480]  Ø³Ø§Ù„Ù‡Ø§ÛŒ Ø¢Ø®Ø± Ù…Ø¨Ø§Ø±Ú© Ø§ÙˆÙ† Ù‡Ù… ÙˆÙ‚ØªÛŒ Ù…Ù† Ú†Ù‚ØµØ§ Ù¾Ø±Ø³ÛŒØ¯Ù… Ø§Ø² Ú©Ù†Ø´Ú¯Ø±Ø§Ù† Ù…ØµØ±ÛŒ Ú©ÙØªÙ†\n",
            "[07:29.480 --> 07:34.480]  ÛŒÚ©ÛŒ Ø¯Ù„Ù„Ø´ Ø§ÛŒÙ†Ù‡ Ú©Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ÛŒ Ø³Ù…Ø¨ÙˆÙ„ Ù…Ù‚Ø§Ø¨Ù„Ù‡ Ø¨Ø± Ø¹Ù„ÛŒÙ‡ Ù…Ø¨Ø§Ø±Ú©ÛŒ Ú©Ù‡ Ø³Ù…Ø¨ÙˆÙ„ Ù…Ø¯Ø±Ù†ÛŒØ³ØªÛŒÙ…\n",
            "[07:34.480 --> 07:39.480]  Ùˆ Ø¨Ø®Ø§Ø·Ø± Ù‡Ù…ÛŒÙ† Ø¨Ø§Ø²Ú¯Ø´Øª ØµØ§Ù†ØªÙˆ Ù‡Ù…ÛŒØ®ÙˆØ§Ø³ØªÙ† ÙØ§ØµÙ„Ù‡ Ø®ÙˆØ¯Ø´ÙˆÙ† Ø±Ùˆ Ø¨Ø§ Ù…Ø¨Ø§Ø±Ú© Ù†Ø´ÙˆÙ† Ø¯Ø§Ø±Ø¯\n",
            "[07:39.480 --> 07:47.480]  Ùˆ Ø§ÛŒÙ† Ø­Ø§Ù„Ùˆ Ù…Ø§ Ø§Ù„Ø§Ù† ØªÙˆ Ø§ÛŒÙ† Ø²Ù…Ø§Ù† Ø¯Ù‚ÛŒÙ‚Ø§ Ù…ÛŒØ¨ÛŒÙ†ÛŒÙ… Ú©Ù‡ Ø¨Ø§ Ú©Ø´Ù Ù‡Ø¬Ø§Ø¨ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø²Ù†Ø¯Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø¯Ø§Ø±Ù‡\n",
            "[07:47.480 --> 07:52.480]  ÙØ§ØµÙ„Ù‡ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù‡ Ø¨Ø§ Ø­Ú©Ù…ÛŒØª Ø±Ùˆ Ø§Ø² Ù„Ø§Ø²Ù… Ø§ÛŒØ¯ÙˆÙ„ÙˆØ¬ÛŒ Ù†Ø´ÙˆÙ† Ø¯ÛŒØ¯Ù‡\n",
            "[07:52.480 --> 07:58.480]  Ù…Ø«Ù„Ø§ ÛŒÚ© Ú©Ø³Ø§Ù†ÛŒ Ù…Ø«Ù„ Ø®Ø§Ù†Ù… Ú¯ÙˆÙ‡Ø± Ø§Ø´Ù‚ÛŒ ÛŒØ§ Ø®Ø§Ù†Ù… ÙØ³ÙÙ‚ÛŒ Ú©Ù‡ Ù…ÛŒØ¨ÛŒÙ†ÛŒÙ… Ø§ÛŒÙ†Ù‡Ø§ Ø¨Ù‡ Ù‡Ø¬Ø§Ø¨ Ø§Ø¹ØªÙ…Ø§Ù„Ø§Ù† Ø§Ø¹ØªÙ‚Ø§Ø¯ Ø¯Ø§Ø±Ù†\n",
            "[07:58.480 --> 08:04.480]  Ø¯Ø§Ø´ØªÙ† Ùˆ Ø³Ø§Ù„Ù‡Ø§ Ù…Ø­Ø¬Ø¨ Ø¨ÙˆØ¯Ù† ÙˆÙ„ÛŒ Ø¨Ù‡ Ù†Ø´Ø§Ù†Ù‡ Ù…Ù‚Ø§ÙˆÙ…Øª Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù‡Ø¬Ø§Ø¨ Ø±Ùˆ Ø¨Ø±Ø§Ù…ÛŒ Ø¯Ø§Ø±Ù†\n",
            "[08:04.480 --> 08:12.480]  Ùˆ Ù‡Ù…ÛŒÙ† Ø·Ø±ÛŒÙ‚Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…ØªØ§Ù„Ø¨Ø§Øª Ø²Ù…Ø§Ù† ÛŒÚ© ÙˆØ³ÛŒÙ„Ù‡ Ù‚Ø¯ÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÙˆÙ† Ù…ØªØ§Ù„Ø¨Ø§Øª Ø¬Ù…Ø¹ÛŒ Ùˆ Ø¹Ù…ÙˆÙ…ÛŒ\n",
            "[08:12.480 --> 08:18.480]  Ú©Ù‡ Ù…Ø±Ú©Ø²Ø´ Ø§ÙˆÙ† Ø±Ø§Ù†Ù‡ Ù‡Ø§ÛŒ Ø§Ù‚ØªØµØ§Ø¯ÛŒÙ‡ Ù…Ù†ØªÙ‚Ù„Ù‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø³Ù…Ø¨ÙˆÙ„ Ø§Ø²Ø´ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒØ´Ù‡\n",
            "[08:18.480 --> 08:24.480]  Ú©Ù‡ Ù…Ø¹Ø«Ø±Ù‡ Ùˆ Ú†ÙˆÙ† Ø´Ø¯Øª Ø§ÛŒØ¯ÙˆÙ„ÙˆØ¬ÛŒ Ù‡Ø§Ú©Ù…ÛŒØª Ø¯Ø± ØªØ¹Ø²Ø§Ø¯Ù‡ Ø¨ÛŒØ´ØªØ± Ø¨Ù‡ Ú†Ø´Ù…ÛŒ Ø¢Ø¯\n",
            "[08:24.480 --> 08:27.480]  Ùˆ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…ÛŒØªÙˆÙ†Ù‡ Ø¢Ø³ÛŒØ¨ Ø´Ø¯ÛŒØ¯ ØªØ§ÛŒÛŒ Ø±Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ùˆ\n",
            "[08:27.480 --> 08:33.480]  Ø®Ø§Ù†Ù… Ù…ØªØ§Ù„Ø¨ÛŒ Ø´Ù…Ø§ ÙÚ©Ø± Ù…ÛŒÚ©Ù†ÛŒØ¯ Ø§Ø² Ø¨ÛŒÙ† Ø±ÙØ¶Ù† Ù‚Ø´Ø± Ù…ØªÙˆØ³Ø· Ø¨Ù‡ Ø®Ø§Ø·Ø± Ø¨Ø­Ø±Ø§Ù† Ù‡Ø§ÛŒ Ø§Ù‚ØªØµØ§Ø¯ÛŒ\n",
            "[08:33.480 --> 08:37.480]  Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ Ø§ÛŒÙ† Ù…Ù†ÛŒÙ‡ Ú©Ù‡ Ù…ØªØ§Ù„Ø¨Ø§Øª Ø§ÛŒÙ† Ù‚Ø´Ø± Ù‡Ù… Ø±Ù†Ú¯ Ù…ÛŒØ¨Ø§Ø²Ù‡ØŸ\n",
            "[08:37.480 --> 08:41.480]  Ø¨Ù‡ Ù†Ø¸Ø± Ù…Ù† Ù…ØªØ§Ù„Ø¨Ø§Øª Ù‚Ø´Ø± Ø¯Ø± ÙˆØ§Ù‚Ø¹ ÛŒÙ‡ ØªØºÛŒÛŒØ± Ù…Ø§Ø­ÛŒØªÛŒ Ù…ÛŒØ¯Ù‡\n",
            "[08:41.480 --> 08:45.480]  ÛŒØ¹Ù†ÛŒ Ø§ÛŒÙ† Ú©Ù‡ ÛŒÚ© Ù…ØªØ§Ù„Ø¨Ø§ØªÛŒ Ú©Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…ØªØ§Ù„Ø¨Ø§Øª Ø¢Ø²Ø§Ø¯ÛŒÛŒ ÛŒØ§ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒÛŒ Ø¨ÙˆØ¯Ù‡\n",
            "[08:45.480 --> 08:51.480]  Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ù‚Ø´Ø± Ù…ØªÙˆØ³Ø· ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù‡ Ùˆ Ø¨Ø¹Ø¯ ÙˆÙ‚ØªÛŒ Ú©Ù‡ Ø·Ø¨Ù‚Ù‡ Ø§Ù‚ØªØµØ§Ø¯ÛŒØ´ ØªØºÛŒÛŒØ± Ù…ÛŒÚ©Ù†Ù‡ Ùˆ Ø³Ù‚ÙˆØ· Ù…ÛŒÚ©Ù†Ù‡\n",
            "[08:51.480 --> 08:54.480]  ÙˆÙ‚ØªÛŒ Ù…ØªØ§Ù„Ø¨Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ù‡Ù… Ø¨Ù‡Ø´ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒØ´Ù‡\n",
            "[08:54.480 --> 09:01.480]  ÛŒØ¹Ù†ÛŒ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¨Ø®ÙˆØ§ÛŒÛŒØ¯ Ø±ÙˆÛŒ Ø§ÛŒÙ† Ø§Ø±Ù‡Ù† Ù…ÙˆØ² Ø±Ùˆ Ù†Ú¯Ø§Ù‡ Ø¨Ú©Ù†ÛŒØ¯ Ù…ØªØ§Ù„Ø¨Ø§ØªØ´ Ù…ÛŒØ±Ù‡ Ø¨Ù‡ Ø³Ù…Øª Ú©Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…Ø´Ø±ÙˆÛŒØªØ´ Ø§ØªÙØ§Ù‚Ø§ Ø¨ÛŒØ´ØªØ± Ù…ÛŒØ´Ù‡\n",
            "[09:01.480 --> 09:07.480]  ØªÙ†Ø´Ù…ÙˆÙ„ÛŒØ´ Ø¨ÛŒØ´ØªØ± Ù…ÛŒØ´Ù‡ Ùˆ Ø­ÛŒØ§ØªÛŒ ØªØ± Ø¨ÙˆØ¯Ù†Ø´ Ø§Ø­Ù†ÛŒØªØ´ Ø¨ÛŒØ´ØªØ± Ù…ÛŒØ´Ù‡ Ùˆ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒØ´Ù‡\n",
            "[09:07.480 --> 09:10.480]  Ø¨Ù‡ Ù…ØªØ§Ù„Ø¨Ø§ØªØ´ Ú©Ù…ØªØ± Ù†Ù…ÛŒØ´Ù‡\n",
            "[09:10.480 --> 09:16.480]  Ø§Ø² Ø·Ø±ÙÛŒ Ø¨Ù‡ Ø®Ø§Ø·Ø± Ø§ÛŒÙ† Ú©Ù‡ Ø¬Ø§ÛŒÚ¯Ø§Ù‡ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ùˆ Ú©Ø±Ø§Ù…Øª Ø§ÙˆÙ† Ø·Ø¨Ù‚Ù‡ Ù…Ø§ ØªÙˆØ³Ø· ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡\n",
            "[09:16.480 --> 09:21.480]  Ø¯ÙˆÚ†Ø§Ø± ØªØºÛŒÛŒØ± Ù‡Ù… Ø´Ø¯Ù‡ Ùˆ Ø§ÛŒÙ† Ù…Ù†Ø¬Ø±Ø¯ Ø§Ù†Ø¨Ø§Ø´Øª Ø´Ø¯Ù† Ø®Ø´Ù…ÛŒ Ù…ÛŒØ´Ù‡\n",
            "[09:21.480 --> 09:28.480]  Ú©Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø§Ù…Ú©Ø§Ù† Ø¯Ø§Ø±Ù‡ Ú©Ù‡ Ø­ØªÛŒ Ø§Ù†Ú¯ÛŒØ²Ù‡ Ù‡Ø§ÛŒ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¬Ø§Ù…Ø¹Ù‡ Ø±Ùˆ ØªØ´Ø¯ÛŒØ¯ Ø¨Ú©Ù†Ù‡\n",
            "[09:28.480 --> 09:33.480]  Ú†ÙˆÙ† Ù‚Ø¨Ù„Ø§ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…ØªØ§Ù„Ø¨Ø§Øª ÛŒÚ© Ø³Ø·Ø­ Ø¨Ø§Ù„Ø§Ø¯Ø±Ù‡ Ø±ÙˆØ´Ù† ÙÚ©Ø± Ø¯Ø§Ø±Ø¯\n",
            "[09:33.480 --> 09:41.480]  Ø­Ù‚ÙˆÙ‚ Ø§Ù†Ø³Ø§Ù†ÛŒ Ùˆ Ø¢Ø²Ø§Ø¯ÛŒ Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ø¯Ø§Ø±Ø¯ Ùˆ Ø¨Ø¹Ø¯Ø´ Ø¯Ø±Ø³ÛŒØ¯Ù‡ Ø¨Ù‡ Ù…ØªØ§Ù„Ø¨Ø§Øª Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù…ØªØ±ÛŒ Ø­ÛŒØ§ØªÛŒ ØªØ± Ø§Ù‚ØªØµØ§Ø¯ÛŒ\n",
            "[09:41.480 --> 09:45.480]  Ùˆ Ø¯Ø± Ø§ÛŒÙ† Ø­Ø§Ù„ Ú©Ø±Ø§Ù…ØªØ´ Ù‡Ù… Ø§Ø² Ø¨Ù‡ Ø§ÛŒÙ† ÙˆÙ‚ØªÙ‡ Ù‡Ø³ØªÙ‡\n",
            "[09:45.480 --> 09:56.480]  Ø¯ÙˆÚ†Ø§Ø± Ø¨ØºØ±Ø§Ù† Ø­Ù‚ÙˆÙ‚ÛŒØªÛŒ Ù‡Ù… Ø´Ø¯Ù‡ Ùˆ Ø§ÛŒÙ† Ø§Ø­ØªÙ…Ø§Ù„Ø§ Ù…Ù…Ú©Ù†Ù‡ Ú©Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª Ø§Ù†ØªØ¬Ø§Ø±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø®ÛŒÙ„ÛŒ Ù†ÛŒØ±ÙˆÛŒ Ø´Ø¯ÛŒØ¯ ØªØ±ÛŒ Ø¯Ø§Ø±Ù‡ Ú¯Ø±Ø³ Ø¨Ú©Ù†Ù‡\n",
            "[09:56.480 --> 10:00.480]  ÛŒÚ© Ù†Ú©ØªÙ‡ Ø¯ÛŒÚ¯Ù‡ÛŒ Ú©Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ú¯ÙØªÚ¯Ùˆ ØªÙˆØ¬Ù‡ Ø¬Ø±Ø¨ Ù…ÛŒ Ú©Ù†Ù‡\n",
            "[10:00.480 --> 10:06.480]  Ø§ÙØ¶Ø§Ø¹Ø´ Ù…Ø­Ø§Ø¬Ø±Øª Ùˆ ØªØºÛŒÛŒØ± Ø¬Ø§Ù…Ø¹Ù‡ Ù…Ø­Ø§Ø¬Ø± Ø§ÛŒØ±Ø§Ù†ÛŒ Ø®Ø§Ø±Ø¬ Ø§Ø² Ú©Ø´ÙˆØ±Ù‡ Ú©Ù‡ Ø´Ù…Ø§ Ø¨Ù‡Ø´ Ø§Ø´Ø§Ø±Ù‡ Ú©Ø±Ø¯ÛŒØ¯\n",
            "[10:06.480 --> 10:15.480]  Ø§ÛŒØ±Ø§Ù†ÛŒØ§Ù† Ù…Ø­Ø§Ø¬Ø± Ú©Ù‡ Ø¬Ù…Ø¹ÛŒØªØ´ÙˆÙ† Ø¨Ù‡ Ø´Ú©Ù„ Ú†Ø´Ù…Ú¯ÛŒØ±ÛŒ Ø²ÛŒØ§Ø¯ Ø´Ø¯Ù‡ Ùˆ Ø±ÙˆÙ†Ø¯ ØªØ­ÙˆÙ„Ø§Øª Ø¯Ø§Ø®Ù„ Ø§ÛŒØ±Ø§Ù† ÙÚ©Ø± Ù…ÛŒÚ©Ù†ÛŒØ¯ Ú†Ù‡ ØªØ£Ø«ÛŒØ± Ø®ÙˆØ§Ù‡Ù†Ø¯ Ø¯Ø§Ø´ØªØŸ\n",
            "[10:15.480 --> 10:22.480]  Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø§ÛŒÙ† Ù…Ø³Ø¦Ù„Ù‡ Ù¾ÛŒÙ…Ù‚Ø± Ø¨Ø§Ù‚ÛŒÙ… Ù‡Ø±Ú©ÛŒØ² Ø¨Ù‡ Ù…ØªØ¹Ù„Ù‚Ø§Øª Ø§Ù…Ø±ÙŠÚ©Ø§ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±ÛŒ Ù…Ø§ Ù„Ø§Ø²Ù… Ø¯Ø§Ø±ÛŒÙ…\n",
            "[10:22.480 --> 10:34.480]  Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒ Ø±Ø³Ø¯ Ú©Ù‡ Ø¯Ø± Ø¬Ù…Ø¹Ù‡ Ø¯ÛŒØ§Ø³ÙØ§Ø±Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ ØªÙˆÙ†Ø³Øª Ø¯Ø± ÛŒÚ© ÙˆÙ‚Øª ØªØ®Ù†Ú¯ÙˆÛŒ Ø®ÙˆØ¨ÛŒ Ø¨Ø±Ø§ÛŒ ØµØ¯Ø§ÛŒ Ø¬Ø§Ù…Ø¹ÛŒ Ø¯Ø§Ø®Ù„ Ø§ÛŒØ±Ø§Ù† Ø±Ùˆ Ø¨Ø±Ø³Ù†Ù‡ Ø¨Ù‡ Ø®Ø§Ø±Ø¬ Ø§ÛŒØ±Ø§Ù†\n",
            "[10:34.480 --> 10:44.480]  Ùˆ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¬Ø±Ù… ØªÙˆØ¬Ù‡ Ú©Ø§ÙÛŒ Ø¨Ú©Ù†Ù‡ Ø¯Ø± Ø¬Ø§Ù…Ø¹ÛŒ Ø¬Ø§Ù…Ø¹ÛŒ Ùˆ Ø­ØªÛŒ Ú©Ù‡ ØªÚ©Ø§Ù†Ù‡Ø§ÛŒÛŒ Ø±Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ú©Ù†Ù‡ Ùˆ Ø§ÛŒÙ† Ú©Ù‡ ØªØ±Ø¯ÛŒØ¯ Ø¨Ú©Ù†Ù† Ø¯ÙˆÙ„ØªÛŒ\n",
            "[10:44.480 --> 11:14.480]  Ø§ÛŒÙ† Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒ\n",
            "[11:14.480 --> 11:19.880]  Ø¨ØªÙˆÙ†Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø¯ÛŒØ§Ø³ØªØ§Ø± Ø¨ÛŒÙ‡ Ú©Ù‡ Ø§ÙˆÙ†Ø¬Ø§ Ù¾ÛŒ ÙˆØ§Ø­Ø¯ÛŒ Ø±Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ú©Ù†Ù‡ Ùˆ Ø¨ØªÙˆÙ†Ù‡ Ù‚Ù„Ø¨Ù‡ Ø¨Ú©Ù†Ù‡\n",
            "[11:19.880 --> 11:27.480]  Ùˆ Ù…Ú©Ø§Ù†ÛŒØ³Ù… Ù‡Ø§ÛŒ Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ø¹Ø¨Ù‚Ø§Ø± Ø§Ù…ÙˆÙ…ÛŒ Ø³ÛŒØ³ØªÙ… Ù‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ø­Ø§Ú©Ù…ÛŒØª Ú©Ù‡ Ø¯Ø±ÙˆÙ‚Øª Ø­ÙØ±Ù‚Ù‡ Ø±Ø§ ØªØ´Ú©ÛŒÙ„ Ù…ÛŒ Ú©Ù†Ù‡\n",
            "[11:27.480 --> 11:31.680]  Ùˆ Ø¨ØªÙˆÙ†Ù‡ Ø§Ø² Ø§ÛŒÙ† Ù…Ù†Ø¹ Ø§Ø¨ÙˆØ± Ø¨Ú©Ù†Ù‡ Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ø²ÛŒØ§Ø¯ Ù…ÛŒØªÙˆÙ†Ù‡ ØªØ£Ø«ÛŒØ± Ú¯Ø°Ø§Ø± Ø¨Ø§Ø´Ù‡\n",
            "[11:31.680 --> 11:38.480]  Ø¨Ø³ÛŒØ§Ø± Ø³Ù¾Ø§Ø³ Ú¯Ø°Ø§Ø±Ù… Ø§Ø² Ø´Ù…Ø§ Ø³Ù‡Ø± Ù…Ø·Ù„Ø¨ÛŒ Ù¾Ø¬ÙˆÛŒØ´Ú¯Ø± Ø¨Ù‡ Ø§Ø®ØªÛŒØ§Ø± Ø¬Ù…Ø¹ÛŒØª Ø¨ÛŒÙ† Ø§Ù„Ù…Ù„Ù„ Ø§Ø² Ù…Ø§Ù„Ù…Ùˆ Ø³ÙˆØ¦Ø¯\n",
            "[11:38.480 --> 11:44.480]  Ø§Ø² Ø·Ø±Ù Ø®ÙˆØ¯Ù… Ùˆ Ø¹Ù„ÛŒ Ø±Ø²Ø§ Ø±ÙˆØ´Ù† ØªÙ‡ÛŒÛŒ Ú©Ù†Ù†Ø¯Ù‡ Ø§ÛŒÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø² Ù‡Ù…Ø±Ø§Ù‡ÛŒ Ø´Ù…Ø§ ØªØ´Ú©Ø± Ù…ÛŒÚ©Ù†Ù…\n",
            "Time consumpution 323.9818706512451s for transcribing\n",
            "Write SRT file to '/content/20636_4_5771510420242174755.srt'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-cd8ca7ae6b75>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mdiarization_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mfinal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiarize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiarization_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from whisper.utils import WriteSRT\n",
        "from whisper import Whisper\n",
        "\n",
        "# Assuming you have a function to extract audio segments and features\n",
        "def extract_features(audio_segment):\n",
        "    # Placeholder for feature extraction logic\n",
        "    # This should return a feature vector for the audio segment\n",
        "    return np.random.rand(10) # Example feature vector\n",
        "\n",
        "# Assuming you have a function to perform clustering\n",
        "def perform_clustering(features, num_speakers):\n",
        "    # Placeholder for clustering logic\n",
        "    # This should return the speaker ID for each audio segment\n",
        "    return [0] * len(features) # Example clustering result\n",
        "\n",
        "# Assuming you have a function to align diarization results with the transcript\n",
        "def diarize_text(transcription, diarization_result):\n",
        "    # Placeholder for diarization result processing\n",
        "    # This should align the diarization results with the transcript\n",
        "    return [] # Example diarization result\n",
        "\n",
        "#@markdown # **Run the model** ðŸš€\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** âš™ï¸\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"Auto detection\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "language = (None if language == \"Auto detection\" else language)\n",
        "verbose = verbose_lut[verbose]\n",
        "\n",
        "\n",
        "if Model.endswith(\".en\") and language not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{language}'; using English instead.\")\n",
        "    language = \"en\"\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(audio_path_local)[0] + \".txt\"\n",
        "\n",
        "# Transcribe the audio\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper.transcribe(\n",
        "    model=whisper_model,\n",
        "    audio=str(audio_path_local),\n",
        "    verbose=True,\n",
        "    task='transcribe',\n",
        "    language=None\n",
        ")\n",
        "toc = time.time()\n",
        "print(f'Time consumed: {toc-tic}s for transcribing')\n",
        "\n",
        "# Extract audio segments and features\n",
        "audio_segments = [] # Placeholder for extracted audio segments\n",
        "features = [extract_features(segment) for segment in audio_segments]\n",
        "\n",
        "# Perform clustering to identify speakers\n",
        "num_speakers = 2 # Example number of speakers\n",
        "clusters = perform_clustering(features, num_speakers)\n",
        "\n",
        "# Align diarization results with the transcript\n",
        "final_result = diarize_text(transcription, clusters)\n",
        "\n",
        "# Write the transcript with speakers to a file\n",
        "lines = []\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    lines.append(line)\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "print(\"Transcript with speakers saved to\", transcript_with_speakers_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "Dw-cx9hNqf2L",
        "outputId": "9356f6dc-f2ff-4646-fddd-45e1a87905da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### /content/20636_4_5771510420242174755.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribe in progress...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'device'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0fe2cffbd25c>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transcribe in progress...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m transcription = whisper.transcribe(\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhisper_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \"\"\"\n\u001b[1;32m    110\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdecode_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fp16\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Performing inference on CPU when CUDA is available\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'device'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from whisper.utils import WriteSRT\n",
        "from whisper import Whisper\n",
        "\n",
        "# Load the Whisper model\n",
        "\n",
        "# Assuming you have a function to extract audio segments and features\n",
        "def extract_features(audio_segment):\n",
        "    # Placeholder for feature extraction logic\n",
        "    # This should return a feature vector for the audio segment\n",
        "    return np.random.rand(10) # Example feature vector\n",
        "\n",
        "# Assuming you have a function to perform clustering\n",
        "def perform_clustering(features, num_speakers):\n",
        "    # Placeholder for clustering logic\n",
        "    # This should return the speaker ID for each audio segment\n",
        "    return [0] * len(features) # Example clustering result\n",
        "\n",
        "# Assuming you have a function to align diarization results with the transcript\n",
        "def diarize_text(transcription, diarization_result):\n",
        "    # Placeholder for diarization result processing\n",
        "    # This should align the diarization results with the transcript\n",
        "    return [] # Example diarization result\n",
        "#@markdown # **Run the model** ðŸš€\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** âš™ï¸\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"Auto detection\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "language = (None if language == \"Auto detection\" else language)\n",
        "verbose = verbose_lut[verbose]\n",
        "\n",
        "\n",
        "if Model.endswith(\".en\") and language not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{language}'; using English instead.\")\n",
        "    language = \"en\"\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "# Your existing code for transcribing with Whisper\n",
        "\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(audio_path_local)[0] + \".txt\"\n",
        "\n",
        "# Transcribe the audio\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper.transcribe(\n",
        "    model=whisper_model,\n",
        "    audio=str(audio_path_local),\n",
        "    verbose=True,\n",
        "    task='transcribe',\n",
        "    language=None\n",
        ")\n",
        "toc = time.time()\n",
        "print(f'Time consumed: {toc-tic}s for transcribing')\n",
        "\n",
        "# Extract audio segments and features\n",
        "audio_segments = [] # Placeholder for extracted audio segments\n",
        "features = [extract_features(segment) for segment in audio_segments]\n",
        "\n",
        "# Perform clustering to identify speakers\n",
        "num_speakers = 2 # Example number of speakers\n",
        "clusters = perform_clustering(features, num_speakers)\n",
        "\n",
        "# Align diarization results with the transcript\n",
        "final_result = diarize_text(transcription, clusters)\n",
        "\n",
        "# Write the transcript with speakers to a file\n",
        "lines = []\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    lines.append(line)\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "print(\"Transcript with speakers saved to\", transcript_with_speakers_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "uL8jCIC4r0hD",
        "outputId": "dee89c04-be30-4020-bb1f-2559edbe0ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### /content/20636_4_5771510420242174755.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### /content/20636_4_5771510420242174755.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribe in progress...\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Persian\n",
            "[00:00.000 --> 00:03.200]  Ø¯Ú©ØªØ± Ø³Ù…Ø§ÛŒÙ‡ ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ù†Ø§Ø³ Ù…ÛŒÚ¯ÙˆÛŒØ¯\n",
            "[00:03.200 --> 00:05.600]  Ø¬Ø§ÛŒÚ¯Ø§Ù‡ Ø²Ù†Ø§Ù† Ø¯Ø± Ø¬Ø§Ù…Ø¹Ù‡ Ø§ÛŒØ±Ø§Ù†ÛŒ\n",
            "[00:05.600 --> 00:10.080]  Ø¨Ø¹Ø¯ Ø§Ø² Ø¬Ù†Ø¨Ø´ Ù‡Ø§ÛŒ Ø³Ø§Ù„Ù‡ 1400 Ùˆ 1ØŒ 2ØŒ 4 ØªØºÛŒÛŒØ± Ùˆ ØªØºÙˆÙ„ Ø´Ø¯Ù‡\n",
            "[00:16.240 --> 00:20.080]  Ø³Ù„Ø§Ù… Ù…Ù† Ø¨ÛŒØª Ø¢Ø°Ø±ÛŒ Ø¨Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¯ÛŒØ¯Ú©Ø§ Ù‡Ù…Ø±Ø§Ù‡ Ø´Ù…Ø§ Ù‡Ø³ØªÙ…\n",
            "[00:22.200 --> 00:25.480]  Ø®Ø§Ù†Ù… ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¨Ù‡ Ø®Ø¨Ø± Ø¢Ù†Ù„Ø§ÛŒÙ† Ú¯ÙØªÙ‡ Ø§Ø² Ø¯Ù‡Ù‡ Ù‡ÙØªØ§Ø¯\n",
            "[00:25.480 --> 00:28.000]  Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡\n",
            "[00:28.000 --> 00:32.000]  Ù…Ø§ ÛŒÚ© Ø¬Ø§Ù…Ø¹Ù‡ Ù…Ø±Ø¯ Ø³Ø§Ù„Ø§Ø± Ø±Ø§ Ø¯Ø§Ø´ØªÛŒÙ… Ú©Ù‡ Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø´Ú©Ù„ Ù…Ø´Ø®ØµÛŒ\n",
            "[00:32.000 --> 00:34.240]  Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø²Ù†Ø§Ù† Ù…ÛŒØ±Ø³ÛŒØ¯\n",
            "[00:34.240 --> 00:38.320]  Ø§Ù…Ø§ Ø¯Ø± Ø³Ø§Ù„ 1400 Ùˆ 2 ÛŒÚ© Ø¨Ø§Ø±Ù‡ Ø¨Ø§ Ø¬Ù…Ø¹ÛŒØªÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒØ´ÙˆÛŒÙ…\n",
            "[00:38.320 --> 00:41.680]  Ú©Ù‡ Ø¨Ù‡ Ø¹Ø±Øµ Ø¨Ø±Ø¯Ù† ÛŒÚ© Ø³Ø§Ù† Ø²Ù† Ùˆ Ù…Ø±Ø¯ Ø¨Ø§ÙˆØ±Ø¯Ø§Ø±Ù†Ø¯\n",
            "[00:41.680 --> 00:45.040]  Ø­Ù‚ ØªÙ„Ø§Ù‚ Ø¨Ø±Ø§ÛŒ Ø²Ù†Ø§Ù† Ù…ÙˆØ±Ø¯ Ù¾Ø°ÛŒØ±Ø´ Ù‚Ø±Ø§Ø± Ù…ÛŒÚ¯ÛŒØ±Ø¯\n",
            "[00:45.040 --> 00:47.480]  Ùˆ Ù¾Ø°ÛŒØ±Ø´ Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ ÙˆØ§Ù„Ø¯ÛŒÙ†\n",
            "[00:47.480 --> 00:50.200]  Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ±Ø§Øª ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø¨Ø§Ù„Ø§ Ø±ÙØªØ³Øª\n",
            "[00:50.240 --> 00:52.720]  Ø¨Ù‡ Ø§Ø¹ØªÙ‚Ø§Ø¯ ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø§ÛŒÙ† ØªØºÛŒÛŒØ±Ø§Øª Ù†Ø´Ø§Ù†Ø¯Ù‡Ù†Ø¯Ù‡\n",
            "[00:52.720 --> 00:57.120]  ØªØ³Ø§Ù‡Ù„ Ø¨ÛŒÙ†Ú¯Ø±ÙˆÙ‡ÛŒ Ùˆ Ø¨ÛŒÙ† Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ Ø¯Ø±Ù…ÛŒØ§Ù† Ù…Ø±Ø¯Ù… Ø§Ø³Øª\n",
            "[00:57.120 --> 01:01.040]  Ø¯Ø± Ø¯ÛŒØ¯Ú¯Ø§Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¬Ø²ÛŒØ§Øª Ú¯ÙØªÚ¯ÙˆÛŒ Ø³Ù…ÛŒØª ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ\n",
            "[01:01.040 --> 01:06.680]  Ø¨Ø§ Ø³Ù‡Ø± Ù…ØªÙ„Ø¨ÛŒ Ù¾Ø¬ÙˆÙ‡Ø´Ú©Ø± Ø¨Ù‡Ø¯Ø§Ø´Øª Ø¬Ù…Ø¹ÛŒØª Ø¨ÛŒÙ† Ø§Ù„Ù…Ù„Ù„ Ø§Ø² Ø³ÙˆØ¦Ø¯ Ù‡Ù…Ø±Ø§Ù‡ Ù…ÛŒØ´ÙˆÛŒÙ…\n",
            "[01:11.680 --> 01:14.720]  Ø®Ø§Ù† Ù…ØªÙ„Ø¨ÛŒ Ù¾ÛŒØ´ Ø§Ø² Ø§ÛŒÙ† Ú©Ù‡ Ù…Ù† Ù¾Ø±Ø³Ø´Ùˆ Ù‡Ù… Ù…Ø·Ø±Ø­ Ú©Ù†Ù…\n",
            "[01:14.720 --> 01:19.200]  Ø®ÙˆØ§Ù‡Ø´ Ù…ÛŒÚ©Ù†Ù… Ø®Ù„Ø§ØµÙ‡ Ø§ÛŒ Ø§Ø² Ø¹Ø±Ø¶ÛŒØ§Ø¨ÛŒ Ù‡Ø§ÛŒ Ø¯Ú©ØªØ± Ø³Ù…ÛŒØª ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ\n",
            "[01:19.200 --> 01:24.600]  Ø§Ø² ØªØ­ÙˆÙ„Ø§Øª Ø¬Ø§Ù…Ø¹Ù‡ Ø§ÛŒØ±Ø§Ù† Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ø¹ØªØ±Ø§Ø²Ø§Øª 1401 Ø±Ùˆ Ø¨Ø±Ù…ÙˆÙ† Ù…Ø±ÙˆØ± Ú©Ù†ÛŒØ¯\n",
            "[01:24.600 --> 01:26.360]  Ø¨Ø¹Ø¯ ÙˆØ§Ø±Ø¯ Ùˆ Ø¬Ø²ÛŒØ§Øª Ø¨Ø´ÛŒÙ…\n",
            "[01:26.360 --> 01:28.680]  Ø¨Ø§ ØµØ¯Ø§ ÙÙ‚Ø· Ø®Ø¯Ù…Øª Ø´Ù…Ø§ Ø¨Ø¨ÛŒÙ†ÛŒØ¯\n",
            "[01:28.680 --> 01:31.720]  Ø§ÛŒÙ† Ø¨ØºØ§Ù„Ø§ Ø¨Ù‡ Ù†Ø¸Ø±Ù…Øª ÙÙ‚Ø· Ù†ÙØ¹Ù‡ Ø®ÛŒÙ„ÛŒ Ø¬Ø§Ù„Ø¨ÛŒ Ø¯Ø§Ø´Øª\n",
            "[01:31.720 --> 01:34.120]  Ø¨Ù‡ Ø·ÙˆÙ„ Ù…Ø´Ø§Ù‚ØµÙ… Ù…Ù‡Ù…ØªØ±ÛŒÙ† Ú†ÛŒØ²ÛŒ Ú©Ù‡\n",
            "[01:34.120 --> 01:37.560]  ØªØºÛŒÛŒØ±Ø§Øª Ú©Ù‡ Ø¯Ø± ÙˆÙ‚Øª Ø§ÛŒØ´ÙˆÙ† Ø§Ø´Ø§Ø±Ù‡ Ú©Ø±Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ø¨Ù‡Ø´\n",
            "[01:37.560 --> 01:41.600]  Ø§ÛŒÙ†ÛŒ Ú©Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø¯Ø± ÙˆÙ‚Øª ØªØ¹Ø§Ù…Ù„ Ú¯Ø±ÙˆÙ‡ Ù‡Ø§ Ùˆ Ø¨Ù‚Ø´ Ùˆ Ø¨Ù‚Ø´ Ùˆ Ù…Ø®ØªÙ„Ù\n",
            "[01:41.600 --> 01:43.800]  Ø¨Ù‡ Ø§ÛŒÚ© ØªØ³Ø§Ù‡Ù„ÛŒ Ø±Ùˆ ØªØ¬Ø±Ø¨Ù‡ Ù…ÛŒÚ©Ù†Ù‡\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming necessary imports are done at the beginning of your script\n",
        "# For example:\n",
        "# from some_library import pipeline, diarize_text\n",
        "\n",
        "# Your existing code for setting parameters and paths\n",
        "# Your existing code for setting parameters and paths\n",
        "language = (None if language == \"Auto detection\" else language)\n",
        "\n",
        "# Safely access the verbose_lut dictionary using .get()\n",
        "verbose = verbose_lut.get(verbose, verbose)\n",
        "\n",
        "if Model.endswith(\".en\") and language not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{language}'; using English instead.\")\n",
        "    language = \"en\"\n",
        "\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(filepath)[0] + \".txt\"\n",
        "print(\"audio local path:\", audio_path_local)\n",
        "\n",
        "import time\n",
        "\n",
        "# Transcribe\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper.transcribe(\n",
        "    model=whisper_model,\n",
        "    audio=str(audio_path_local),\n",
        "    verbose=verbose,\n",
        "    task=task,\n",
        "    language=language\n",
        ")\n",
        "# Time consumed\n",
        "toc = time.time()\n",
        "print(f'Time consumed {toc-tic}s for transcribing')\n",
        "\n",
        "# Write SRT file\n",
        "from whisper.utils import WriteSRT\n",
        "with open(subtitle_file, \"w\", encoding=\"utf-8\") as srt:\n",
        "    writer = WriteSRT(audio_path_local.parent)\n",
        "    writer.write_result(transcription, srt)\n",
        "print(f\"Write SRT file to '{subtitle_file}'\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Check if pipeline is callable before using it\n",
        "if callable(pipeline):\n",
        "    diarization_result = pipeline(audio_path_local)\n",
        "    final_result = diarize_text(transcription, diarization_result)\n",
        "else:\n",
        "    print(\"Error: pipeline is not callable. Please ensure it is correctly defined and initialized.\")\n",
        "    # Handle the error appropriately, e.g., by exiting the script or skipping the diarization step\n",
        "\n",
        "lines = list()\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    print(f\"{line}\")\n",
        "    lines.append(line)\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "display(Markdown(f\"**Transcript file created: {transcript_with_speakers_file}**\"))"
      ],
      "metadata": {
        "id": "Un2zHXulsxQm",
        "outputId": "896a33cd-c811-49c0-9874-c144f64dcf55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### /content/20636_4_5771510420242174755.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio local path: /content/20636_4_5771510420242174755.wav\n",
            "Transcribe in progress...\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Persian\n",
            "[00:00.000 --> 00:03.200]  Ø¯Ú©ØªØ± Ø³Ù…Ø§ÛŒÙ‡ ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ù†Ø§Ø³ Ù…ÛŒÚ¯ÙˆÛŒØ¯\n",
            "[00:03.200 --> 00:05.600]  Ø¬Ø§ÛŒÚ¯Ø§Ù‡ Ø²Ù†Ø§Ù† Ø¯Ø± Ø¬Ø§Ù…Ø¹Ù‡ Ø§ÛŒØ±Ø§Ù†ÛŒ\n",
            "[00:05.600 --> 00:10.080]  Ø¨Ø¹Ø¯ Ø§Ø² Ø¬Ù†Ø¨Ø´ Ù‡Ø§ÛŒ Ø³Ø§Ù„Ù‡ 1400 Ùˆ 1ØŒ 2ØŒ 4 ØªØºÛŒÛŒØ± Ùˆ ØªØºÙˆÙ„ Ø´Ø¯Ù‡\n",
            "[00:16.240 --> 00:20.080]  Ø³Ù„Ø§Ù… Ù…Ù† Ø¨ÛŒØª Ø¢Ø°Ø±ÛŒ Ø¨Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¯ÛŒØ¯Ú©Ø§ Ù‡Ù…Ø±Ø§Ù‡ Ø´Ù…Ø§ Ù‡Ø³ØªÙ…\n",
            "[00:22.200 --> 00:25.480]  Ø®Ø§Ù†Ù… ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¨Ù‡ Ø®Ø¨Ø± Ø¢Ù†Ù„Ø§ÛŒÙ† Ú¯ÙØªÙ‡ Ø§Ø² Ø¯Ù‡Ù‡ Ù‡ÙØªØ§Ø¯\n",
            "[00:25.480 --> 00:28.000]  Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡\n",
            "[00:28.000 --> 00:32.000]  Ù…Ø§ ÛŒÚ© Ø¬Ø§Ù…Ø¹Ù‡ Ù…Ø±Ø¯ Ø³Ø§Ù„Ø§Ø± Ø±Ø§ Ø¯Ø§Ø´ØªÛŒÙ… Ú©Ù‡ Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø´Ú©Ù„ Ù…Ø´Ø®ØµÛŒ\n",
            "[00:32.000 --> 00:34.240]  Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø²Ù†Ø§Ù† Ù…ÛŒØ±Ø³ÛŒØ¯\n",
            "[00:34.240 --> 00:38.320]  Ø§Ù…Ø§ Ø¯Ø± Ø³Ø§Ù„ 1400 Ùˆ 2 ÛŒÚ© Ø¨Ø§Ø±Ù‡ Ø¨Ø§ Ø¬Ù…Ø¹ÛŒØªÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒØ´ÙˆÛŒÙ…\n",
            "[00:38.320 --> 00:41.680]  Ú©Ù‡ Ø¨Ù‡ Ø¹Ø±Øµ Ø¨Ø±Ø¯Ù† ÛŒÚ© Ø³Ø§Ù† Ø²Ù† Ùˆ Ù…Ø±Ø¯ Ø¨Ø§ÙˆØ±Ø¯Ø§Ø±Ù†Ø¯\n",
            "[00:41.680 --> 00:45.040]  Ø­Ù‚ ØªÙ„Ø§Ù‚ Ø¨Ø±Ø§ÛŒ Ø²Ù†Ø§Ù† Ù…ÙˆØ±Ø¯ Ù¾Ø°ÛŒØ±Ø´ Ù‚Ø±Ø§Ø± Ù…ÛŒÚ¯ÛŒØ±Ø¯\n",
            "[00:45.040 --> 00:47.480]  Ùˆ Ù¾Ø°ÛŒØ±Ø´ Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ ÙˆØ§Ù„Ø¯ÛŒÙ†\n",
            "[00:47.480 --> 00:50.200]  Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ±Ø§Øª ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø¨Ø§Ù„Ø§ Ø±ÙØªØ³Øª\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-fd77d6136fd5>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transcribe in progress...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m transcription = whisper.transcribe(\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhisper_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mneeds_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;31m# call the main sampling loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_speech_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mlogits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    202\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2544\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m         )\n\u001b[0;32m-> 2546\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from whisper.utils import WriteSRT\n",
        "import whisper\n",
        "\n",
        "# Load the Whisper model\n",
        "\n",
        "# Assuming you have a function to extract audio segments and features\n",
        "def extract_features(audio_segment):\n",
        "    # Placeholder for feature extraction logic\n",
        "    # This should return a feature vector for the audio segment\n",
        "    return np.random.rand(10) # Example feature vector\n",
        "\n",
        "# Assuming you have a function to perform clustering\n",
        "def perform_clustering(features, num_speakers):\n",
        "    # Placeholder for clustering logic\n",
        "    # This should return the speaker ID for each audio segment\n",
        "    return [0] * len(features) # Example clustering result\n",
        "\n",
        "# Assuming you have a function to align diarization results with the transcript\n",
        "def diarize_text(transcription, diarization_result):\n",
        "    # Placeholder for diarization result processing\n",
        "    # This should align the diarization results with the transcript\n",
        "    return [] # Example diarization result\n",
        "\n",
        "# Your existing code for transcribing with Whisper\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(filepath)[0] + \".txt\"\n",
        "print(\"audio local path:\", audio_path_local)\n",
        "\n",
        "# Transcribe the audio\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper_model.transcribe(\n",
        "    audio=str(audio_path_local),\n",
        "    verbose=True,\n",
        "    task='transcribe',\n",
        "    language=None\n",
        ")\n",
        "toc = time.time()\n",
        "print(f'Time consumed: {toc-tic}s for transcribing')\n",
        "\n",
        "# Extract audio segments and features\n",
        "audio_segments = [] # Placeholder for extracted audio segments\n",
        "features = [extract_features(segment) for segment in audio_segments]\n",
        "\n",
        "# Perform clustering to identify speakers\n",
        "num_speakers = 2 # Example number of speakers\n",
        "clusters = perform_clustering(features, num_speakers)\n",
        "\n",
        "# Align diarization results with the transcript\n",
        "final_result = diarize_text(transcription, clusters)\n",
        "\n",
        "# Write the transcript with speakers to a file\n",
        "lines = []\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    lines.append(line)\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "print(\"Transcript with speakers saved to\", transcript_with_speakers_file)"
      ],
      "metadata": {
        "id": "bo3Bd07ztRA6",
        "outputId": "89e2c5f0-5d59-449c-d3ba-a38f9387ec4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio local path: /content/20636_4_5771510420242174755.wav\n",
            "Transcribe in progress...\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Persian\n",
            "[00:00.000 --> 00:03.200]  Ø¯Ú©ØªØ± Ø³Ù…Ø§ÛŒÙ‡ ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ù†Ø§Ø³ Ù…ÛŒÚ¯ÙˆÛŒØ¯\n",
            "[00:03.200 --> 00:05.600]  Ø¬Ø§ÛŒÚ¯Ø§Ù‡ Ø²Ù†Ø§Ù† Ø¯Ø± Ø¬Ø§Ù…Ø¹Ù‡ Ø§ÛŒØ±Ø§Ù†ÛŒ\n",
            "[00:05.600 --> 00:10.080]  Ø¨Ø¹Ø¯ Ø§Ø² Ø¬Ù†Ø¨Ø´ Ù‡Ø§ÛŒ Ø³Ø§Ù„Ù‡ 1400 Ùˆ 1ØŒ 2ØŒ 4 ØªØºÛŒÛŒØ± Ùˆ ØªØºÙˆÙ„ Ø´Ø¯Ù‡\n",
            "[00:16.240 --> 00:20.080]  Ø³Ù„Ø§Ù… Ù…Ù† Ø¨ÛŒØª Ø¢Ø°Ø±ÛŒ Ø¨Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¯ÛŒØ¯Ú©Ø§ Ù‡Ù…Ø±Ø§Ù‡ Ø´Ù…Ø§ Ù‡Ø³ØªÙ…\n",
            "[00:22.200 --> 00:25.480]  Ø®Ø§Ù†Ù… ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¨Ù‡ Ø®Ø¨Ø± Ø¢Ù†Ù„Ø§ÛŒÙ† Ú¯ÙØªÙ‡ Ø§Ø² Ø¯Ù‡Ù‡ Ù‡ÙØªØ§Ø¯\n",
            "[00:25.480 --> 00:28.000]  Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡\n",
            "[00:28.000 --> 00:32.000]  Ù…Ø§ ÛŒÚ© Ø¬Ø§Ù…Ø¹Ù‡ Ù…Ø±Ø¯ Ø³Ø§Ù„Ø§Ø± Ø±Ø§ Ø¯Ø§Ø´ØªÛŒÙ… Ú©Ù‡ Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø´Ú©Ù„ Ù…Ø´Ø®ØµÛŒ\n",
            "[00:32.000 --> 00:34.240]  Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø²Ù†Ø§Ù† Ù…ÛŒØ±Ø³ÛŒØ¯\n",
            "[00:34.240 --> 00:38.320]  Ø§Ù…Ø§ Ø¯Ø± Ø³Ø§Ù„ 1400 Ùˆ 2 ÛŒÚ© Ø¨Ø§Ø±Ù‡ Ø¨Ø§ Ø¬Ù…Ø¹ÛŒØªÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒØ´ÙˆÛŒÙ…\n",
            "[00:38.320 --> 00:41.680]  Ú©Ù‡ Ø¨Ù‡ Ø¹Ø±Øµ Ø¨Ø±Ø¯Ù† ÛŒÚ© Ø³Ø§Ù† Ø²Ù† Ùˆ Ù…Ø±Ø¯ Ø¨Ø§ÙˆØ±Ø¯Ø§Ø±Ù†Ø¯\n",
            "[00:41.680 --> 00:45.040]  Ø­Ù‚ ØªÙ„Ø§Ù‚ Ø¨Ø±Ø§ÛŒ Ø²Ù†Ø§Ù† Ù…ÙˆØ±Ø¯ Ù¾Ø°ÛŒØ±Ø´ Ù‚Ø±Ø§Ø± Ù…ÛŒÚ¯ÛŒØ±Ø¯\n",
            "[00:45.040 --> 00:47.480]  Ùˆ Ù¾Ø°ÛŒØ±Ø´ Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ ÙˆØ§Ù„Ø¯ÛŒÙ†\n",
            "[00:47.480 --> 00:50.200]  Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ±Ø§Øª ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø¨Ø§Ù„Ø§ Ø±ÙØªØ³Øª\n",
            "[00:50.240 --> 00:52.720]  Ø¨Ù‡ Ø§Ø¹ØªÙ‚Ø§Ø¯ ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø§ÛŒÙ† ØªØºÛŒÛŒØ±Ø§Øª Ù†Ø´Ø§Ù†Ø¯Ù‡Ù†Ø¯Ù‡\n",
            "[00:52.720 --> 00:57.120]  ØªØ³Ø§Ù‡Ù„ Ø¨ÛŒÙ†Ú¯Ø±ÙˆÙ‡ÛŒ Ùˆ Ø¨ÛŒÙ† Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ Ø¯Ø±Ù…ÛŒØ§Ù† Ù…Ø±Ø¯Ù… Ø§Ø³Øª\n",
            "[00:57.120 --> 01:01.040]  Ø¯Ø± Ø¯ÛŒØ¯Ú¯Ø§Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¬Ø²ÛŒØ§Øª Ú¯ÙØªÚ¯ÙˆÛŒ Ø³Ù…ÛŒØª ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ\n",
            "[01:01.040 --> 01:06.680]  Ø¨Ø§ Ø³Ù‡Ø± Ù…ØªÙ„Ø¨ÛŒ Ù¾Ø¬ÙˆÙ‡Ø´Ú©Ø± Ø¨Ù‡Ø¯Ø§Ø´Øª Ø¬Ù…Ø¹ÛŒØª Ø¨ÛŒÙ† Ø§Ù„Ù…Ù„Ù„ Ø§Ø² Ø³ÙˆØ¦Ø¯ Ù‡Ù…Ø±Ø§Ù‡ Ù…ÛŒØ´ÙˆÛŒÙ…\n",
            "[01:11.680 --> 01:14.720]  Ø®Ø§Ù† Ù…ØªÙ„Ø¨ÛŒ Ù¾ÛŒØ´ Ø§Ø² Ø§ÛŒÙ† Ú©Ù‡ Ù…Ù† Ù¾Ø±Ø³Ø´Ùˆ Ù‡Ù… Ù…Ø·Ø±Ø­ Ú©Ù†Ù…\n",
            "[01:14.720 --> 01:19.200]  Ø®ÙˆØ§Ù‡Ø´ Ù…ÛŒÚ©Ù†Ù… Ø®Ù„Ø§ØµÙ‡ Ø§ÛŒ Ø§Ø² Ø¹Ø±Ø¶ÛŒØ§Ø¨ÛŒ Ù‡Ø§ÛŒ Ø¯Ú©ØªØ± Ø³Ù…ÛŒØª ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-b5b8ad649751>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transcribe in progress...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m transcription = whisper_model.transcribe(\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mneeds_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;31m# call the main sampling loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_speech_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mlogits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mqkv_attention\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_ctx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Download the subtitle file** ðŸŽ†\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "display(Markdown(f\"**Download Subtitle: {subtitle_file}**\"))\n",
        "files.download(subtitle_file)\n",
        "\n",
        "display(Markdown(f\"**Download Transcript With Speakers: {transcript_with_speakers_file}**\"))\n",
        "files.download(transcript_with_speakers_file)\n",
        "\n",
        "display(Markdown(f\"**Download Audio: {filepath}**\"))\n",
        "files.download(filepath)"
      ],
      "metadata": {
        "id": "yBGKpOjFHLTx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "outputId": "fec6f886-ec7e-4f92-d11c-de20a1c90586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Download Subtitle: /content/20636_4_5771510420242174755.srt**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d0ed7327-4471-45e3-a102-2da9ad11111f\", \"20636_4_5771510420242174755.srt\", 19617)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Download Transcript With Speakers: /content/20636_4_5771510420242174755.txt**"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: /content/20636_4_5771510420242174755.txt",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ded2a3815ba0>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"**Download Transcript With Speakers: {transcript_with_speakers_file}**\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript_with_speakers_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"**Download Audio: {filepath}**\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/20636_4_5771510420242174755.txt"
          ]
        }
      ]
    }
  ]
}