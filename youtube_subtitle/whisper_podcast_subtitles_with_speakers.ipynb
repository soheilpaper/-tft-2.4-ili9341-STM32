{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soheilpaper/-tft-2.4-ili9341-STM32/blob/master/youtube_subtitle/whisper_podcast_subtitles_with_speakers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ç”ŸæˆApple PodCastå­—å¹•\n",
        "\n"
      ],
      "metadata": {
        "id": "73JHCOCS99hl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBUm1pmC90Mk"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Check GPU type** ğŸ•µï¸\n",
        "\n",
        "#@markdown The type of GPU you get assigned in your Colab session defined the speed at which the video will be transcribed.\n",
        "#@markdown The higher the number of floating point operations per second (FLOPS), the faster the transcription.\n",
        "#@markdown But even the least powerful GPU available in Colab is able to run any Whisper model.\n",
        "#@markdown Make sure you've selected `GPU` as hardware accelerator for the Notebook (Runtime â†’ Change runtime type â†’ Hardware accelerator).\n",
        "\n",
        "#@markdown |  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "#@markdown |:------:|:----------:|:--------------:|:------------------:|\n",
        "#@markdown |  T4    |    16 GB   |       8.1      |         Free       |\n",
        "#@markdown | P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "#@markdown | V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Factory reset your Notebook's runtime if you want to get assigned a new GPU.**\n",
        "\n",
        "!nvidia-smi -L\n",
        "\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **é…ç½®Whisper/Setup Whisper** ğŸ—ï¸\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!pip install git+https://github.com/yinruiqing/pyannote-whisper.git\n",
        "!pip install requests beautifulsoup4 pyannote.audio pydub\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "import whisper\n",
        "import numpy as np\n",
        "import warnings\n",
        "import shutil\n",
        "from IPython.display import Markdown\n",
        "import os\n",
        "import requests\n",
        "import re\n",
        "from pydub import AudioSegment\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "from pathlib import Path\n",
        "from pyannote.audio import Pipeline\n",
        "from pyannote_whisper.utils import diarize_text\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "\n",
        "print('Whisper installedï¼Œplease execute next cell')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZMRtV2Lw_BHU",
        "outputId": "5109e44f-f8bf-4d48-c595-095e21a77ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/yinruiqing/pyannote-whisper.git\n",
            "  Cloning https://github.com/yinruiqing/pyannote-whisper.git to /tmp/pip-req-build-f3bbcn3p\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/yinruiqing/pyannote-whisper.git /tmp/pip-req-build-f3bbcn3p\n",
            "  Resolved https://github.com/yinruiqing/pyannote-whisper.git to commit bb55b6547d611de04f07fafc6c149f51ae3ca5a3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setuptools==59.5.0 (from pyannote-whisper==1.0)\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyannote-whisper==1.0) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pyannote-whisper==1.0) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from pyannote-whisper==1.0) (0.17.1+cu121)\n",
            "Collecting openai-whisper (from pyannote-whisper==1.0)\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyannote.audio (from pyannote-whisper==1.0)\n",
            "  Downloading pyannote.audio-3.1.1-py2.py3-none-any.whl (208 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.7/208.7 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from pyannote-whisper==1.0) (0.12.1)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper->pyannote-whisper==1.0) (2.2.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper->pyannote-whisper==1.0) (0.58.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper->pyannote-whisper==1.0) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper->pyannote-whisper==1.0) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper->pyannote-whisper==1.0)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asteroid-filterbanks>=0.4 (from pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
            "Collecting einops>=0.6.0 (from pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (0.20.3)\n",
            "Collecting lightning>=2.0.1 (from pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading lightning-2.2.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<3.0,>=2.1 (from pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyannote.core>=5.0.0 (from pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyannote.database>=5.0.1 (from pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading pyannote.database-5.1.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyannote.metrics>=3.2 (from pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyannote.pipeline>=3.0.1 (from pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
            "Collecting pytorch-metric-learning>=2.1.0 (from pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading pytorch_metric_learning-2.5.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.1/119.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (13.7.1)\n",
            "Collecting semver>=3.0.0 (from pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Collecting speechbrain>=0.5.14 (from pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading speechbrain-1.0.0-py3-none-any.whl (760 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m760.1/760.1 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX>=2.6 (from pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-audiomentations>=0.11.0 (from pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading torch_audiomentations-0.11.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (2.2.1+cu121)\n",
            "Collecting torchmetrics>=0.11.0 (from pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->pyannote-whisper==1.0) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->pyannote-whisper==1.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->pyannote-whisper==1.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->pyannote-whisper==1.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->pyannote-whisper==1.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->pyannote-whisper==1.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->pyannote-whisper==1.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->pyannote-whisper==1.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->pyannote-whisper==1.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->pyannote-whisper==1.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->pyannote-whisper==1.0)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->pyannote-whisper==1.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->pyannote-whisper==1.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->pyannote-whisper==1.0) (9.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->pyannote-whisper==1.0) (2.22)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio->pyannote-whisper==1.0) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio->pyannote-whisper==1.0) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio->pyannote-whisper==1.0) (24.0)\n",
            "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning>=2.0.1->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading pytorch_lightning-2.2.2-py3-none-any.whl (801 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m801.9/801.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from omegaconf<3.0,>=2.1->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio->pyannote-whisper==1.0) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio->pyannote-whisper==1.0) (1.11.4)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote.audio->pyannote-whisper==1.0) (2.0.3)\n",
            "Collecting typer>=0.12.1 (from pyannote.database>=5.0.1->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (1.2.2)\n",
            "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (3.7.1)\n",
            "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio->pyannote-whisper==1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio->pyannote-whisper==1.0) (2.16.1)\n",
            "Collecting hyperpyyaml (from speechbrain>=0.5.14->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio->pyannote-whisper==1.0) (1.4.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio->pyannote-whisper==1.0) (0.1.99)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pyannote-whisper==1.0) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.6->pyannote.audio->pyannote-whisper==1.0) (3.20.3)\n",
            "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (0.10.1)\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading torch_pitch_shift-1.2.4-py3-none-any.whl (4.9 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pyannote-whisper==1.0) (2.1.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper->pyannote-whisper==1.0) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper->pyannote-whisper==1.0) (2023.12.25)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->torch->pyannote-whisper==1.0) (3.9.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (3.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (1.0.8)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio->pyannote-whisper==1.0) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (2.8.2)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->pyannote-whisper==1.0) (2.0.29)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio->pyannote-whisper==1.0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio->pyannote-whisper==1.0) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio->pyannote-whisper==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio->pyannote-whisper==1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio->pyannote-whisper==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio->pyannote-whisper==1.0) (2024.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (3.4.0)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio->pyannote-whisper==1.0) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=0.5.14->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->pyannote-whisper==1.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->pyannote-whisper==1.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->pyannote-whisper==1.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->pyannote-whisper==1.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->pyannote-whisper==1.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->pyannote-whisper==1.0) (4.0.3)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (1.16.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=0.5.14->pyannote.audio->pyannote-whisper==1.0)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->pyannote-whisper==1.0) (3.0.3)\n",
            "Building wheels for collected packages: pyannote-whisper, openai-whisper, antlr4-python3-runtime, docopt, julius\n",
            "  Building wheel for pyannote-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyannote-whisper: filename=pyannote_whisper-1.0-py3-none-any.whl size=5212 sha256=ba6bdc9580ff56f57d873923838feb783f725c1ba4edd46e640acee2a906f9c2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-60zeflpe/wheels/01/b3/21/695432ee1c7da9637387a7efec322b8a4b072e04f5a6ad081f\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801358 sha256=4badf825c2e2f3822fade0816fd344ec29de38c7143449531abb08c4523733e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=fe28403dbcfcfc5f228f52ff8c319f4e5325009eae4b2458b234e11e3f230da4\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=81db45375a97d196e23bdd42f20396679a99948d2b6142514f152ab27333a220\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=055f90a973ce14693e84037c55fd273fd1046301d10b4461345c9670fc2c638b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/b2/05/f883527ffcb7f2ead5438a2c23439aa0c881eaa9a4c80256f4\n",
            "Successfully built pyannote-whisper openai-whisper antlr4-python3-runtime docopt julius\n",
            "Installing collected packages: primePy, docopt, antlr4-python3-runtime, tensorboardX, shellingham, setuptools, semver, ruamel.yaml.clib, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, einops, colorlog, tiktoken, ruamel.yaml, pyannote.core, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lightning-utilities, alembic, typer, optuna, nvidia-cusolver-cu12, hyperpyyaml, pyannote.database, torchmetrics, pytorch-metric-learning, pyannote.pipeline, pyannote.metrics, openai-whisper, julius, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, torch-audiomentations, lightning, pyannote.audio, pyannote-whisper\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "arviz 0.15.1 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\n",
            "cvxpy 1.3.3 requires setuptools>65.5.1, but you have setuptools 59.5.0 which is incompatible.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.3 alembic-1.13.1 antlr4-python3-runtime-4.9.3 asteroid-filterbanks-0.4.0 colorlog-6.8.2 docopt-0.6.2 einops-0.7.0 hyperpyyaml-1.2.2 julius-0.2.7 lightning-2.2.2 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 openai-whisper-20231117 optuna-3.6.1 primePy-1.3 pyannote-whisper-1.0 pyannote.audio-3.1.1 pyannote.core-5.0.0 pyannote.database-5.1.0 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pytorch-lightning-2.2.2 pytorch-metric-learning-2.5.0 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 semver-3.0.2 setuptools-59.5.0 shellingham-1.5.4 speechbrain-1.0.0 tensorboardX-2.6.2.2 tiktoken-0.6.0 torch-audiomentations-0.11.1 torch-pitch-shift-1.2.4 torchmetrics-1.3.2 typer-0.12.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "43fef17477914e78ac8d2d50ba19fae6",
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "pydevd_plugins",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pyannote.audio in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: asteroid-filterbanks>=0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (0.4.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (0.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (0.20.3)\n",
            "Requirement already satisfied: lightning>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (2.2.2)\n",
            "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (2.3.0)\n",
            "Requirement already satisfied: pyannote.core>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (5.0.0)\n",
            "Requirement already satisfied: pyannote.database>=5.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (5.1.0)\n",
            "Requirement already satisfied: pyannote.metrics>=3.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (3.2.1)\n",
            "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (3.0.1)\n",
            "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (2.5.0)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (13.7.1)\n",
            "Requirement already satisfied: semver>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (3.0.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (0.12.1)\n",
            "Requirement already satisfied: speechbrain>=0.5.14 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (1.0.0)\n",
            "Requirement already satisfied: tensorboardX>=2.6 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (2.6.2.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (2.2.1+cu121)\n",
            "Requirement already satisfied: torch-audiomentations>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (0.11.1)\n",
            "Requirement already satisfied: torchaudio>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (1.25.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (24.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote.audio) (0.11.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote.audio) (2.2.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.11.4)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.0.3)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.12.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.2.2)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.6.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.7.1)\n",
            "Requirement already satisfied: sympy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.12)\n",
            "Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.pipeline>=3.0.1->pyannote.audio) (3.6.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio) (2.16.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->pyannote.audio) (1.16.0)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio) (1.4.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio) (0.1.99)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.6->pyannote.audio) (3.20.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.2.7)\n",
            "Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.10.1)\n",
            "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (1.2.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (3.9.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (3.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.58.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.8.0->lightning>=2.0.1->pyannote.audio) (59.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.8.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.29)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.4.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio) (1.3.0)\n",
            "Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.10/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio) (1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml->speechbrain>=0.5.14->pyannote.audio) (0.18.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->pyannote.audio) (2.1.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (4.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.3.3)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.16.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=0.5.14->pyannote.audio) (0.2.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.0.3)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-dedlx4an\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-dedlx4an\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.6.0)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.4)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Whisper installedï¼Œplease execute next cell\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Model selection** ğŸ§ \n",
        "\n",
        "#@markdown As of the first public release, there are 4 pre-trained options to play with:\n",
        "\n",
        "#@markdown |  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "#@markdown |:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "#@markdown |  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "#@markdown |  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "#@markdown | small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "#@markdown | medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "#@markdown | large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Model = 'large-v3' #@param ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large', 'large-v2','large-v3']\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the model.**\n",
        "\n",
        "# load pyannote speaker-diarization\n",
        "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\",\n",
        "                                            use_auth_token=\"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\")\n",
        "\n",
        "whisper_model = whisper.load_model(Model)\n",
        "\n",
        "if Model in whisper.available_models():\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is selected.**\"\n",
        "    ))\n",
        "else:\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is no longer available.** Please select one of the following: - {' - '.join(whisper.available_models())}\"\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPV9yHeqARiK",
        "outputId": "d8a903d3-f024-47cf-9371-0af311c61c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Could not download 'pyannote/speaker-diarization' pipeline.\n",
            "It might be because the pipeline is private or gated so make\n",
            "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
            "create your access token and retry with:\n",
            "\n",
            "   >>> Pipeline.from_pretrained('pyannote/speaker-diarization',\n",
            "   ...                          use_auth_token=YOUR_AUTH_TOKEN)\n",
            "\n",
            "If this still does not work, it might be because the pipeline is gated:\n",
            "visit https://hf.co/pyannote/speaker-diarization to accept the user conditions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 1.23G/2.88G [00:11<00:12, 146MiB/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests #beautifulsoup\n",
        "\n",
        "!sudo apt-get install python-beautifulsoup"
      ],
      "metadata": {
        "id": "Xt3SX8edQH0s",
        "outputId": "f2b081eb-8bdb-4820-f8f5-0e69f45c99bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python-beautifulsoup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "3cVLD--WgYRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Apple Podcast selection** ğŸ™ï¸\n",
        "\n",
        "#@markdown Enter the URL of the Apple Podcast you want to transcribe.\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### **Apple Podcast**\n",
        "URL = \"https://pro-arpit-69-f899161164e6.herokuapp.com/548299/4_5771510420242174755.wav\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the video.**\n",
        "import requests,re,os\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "from pydub import AudioSegment\n",
        "def convert_audio_to_wav(input_file: str):\n",
        "    # Determine the output file name by replacing the input file extension with .wav\n",
        "    output_file = os.path.splitext(input_file)[0] + \".wav\"\n",
        "\n",
        "    # Check the input file extension and load the audio accordingly\n",
        "    if input_file.lower().endswith(\".mp3\"):\n",
        "        audio = AudioSegment.from_mp3(input_file)\n",
        "    elif input_file.lower().endswith(\".m4a\"):\n",
        "        audio = AudioSegment.from_file(input_file, \"m4a\")\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported audio format. Please provide an MP3 or M4A file.\")\n",
        "\n",
        "    # Export the audio as a WAV file\n",
        "    audio.export(output_file, format=\"wav\")\n",
        "\n",
        "    return output_file\n",
        "\n",
        "\n",
        "def find_audio_url(html: str) -> str:\n",
        "    # Find all .mp3 and .m4a URLs in the HTML content\n",
        "    audio_urls = re.findall(r'https://[^\\s^\"]+(?:\\.mp3|\\.m4a)', html)\n",
        "\n",
        "    # If there's at least one URL, return the first one\n",
        "    if audio_urls:\n",
        "        return audio_urls[-1]\n",
        "\n",
        "    # Otherwise, return None\n",
        "    return None\n",
        "\n",
        "def get_file_extension(url: str) -> str:\n",
        "    # Parse the URL to get the path\n",
        "    parsed_url = urlparse(url)\n",
        "    path = parsed_url.path\n",
        "\n",
        "    # Extract the file extension using os.path.splitext\n",
        "    _, file_extension = os.path.splitext(path)\n",
        "\n",
        "    # Return the file extension\n",
        "    return file_extension\n",
        "\n",
        "def download_apple_podcast(url: str, output_folder: str = 'downloads'):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(\n",
        "            f\"Error: Unable to fetch the podcast page. Status code: {response.status_code}\")\n",
        "        return\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    audio_url = find_audio_url(response.text)\n",
        "\n",
        "    if not audio_url:\n",
        "        print(\"Error: Unable to find the podcast audio url.\")\n",
        "        return\n",
        "\n",
        "    episode_title = soup.find('span', {'class': 'product-header__title'})\n",
        "\n",
        "    if not episode_title:\n",
        "        print(\"Error: Unable to find the podcast title.\")\n",
        "        return\n",
        "\n",
        "    episode_title = episode_title.text.strip().replace('/', '-')\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    output_file = os.path.join(output_folder, f\"{episode_title}{get_file_extension(audio_url)}\")\n",
        "\n",
        "    with requests.get(audio_url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(output_file, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "    output_file = convert_audio_to_wav(output_file)\n",
        "\n",
        "    return episode_title, output_file\n",
        "\n",
        "\n",
        "result = download_apple_podcast(URL)\n",
        "if not result:\n",
        "  print(\"Error: Unable to download podcast.\")\n",
        "else:\n",
        "  (title, filepath) = result\n",
        "  print(f\"Downloaded podcast episode '{title}' to '{filepath}'\")"
      ],
      "metadata": {
        "id": "h2AL0Hw-Bow2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "#@markdown #### **Download Podcast from URL**\n",
        "URL = \"https://fileiran.net/Download/File/DitjzXY11B/20636_4_5771510420242174755.mp3\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Function to download a file from a URL\n",
        "def download_file_from_url(url: str, output_filename: str = None):\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        if not output_filename:\n",
        "            output_filename = url.split(\"/\")[-1]\n",
        "        with open(output_filename, 'wb') as file:\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                if chunk:\n",
        "                    file.write(chunk)\n",
        "        return output_filename\n",
        "    else:\n",
        "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "# Function to convert audio to WAV format\n",
        "def convert_audio_to_wav(input_file: str):\n",
        "    output_file = os.path.splitext(input_file)[0] + \".wav\"\n",
        "    if input_file.lower().endswith(\".mp3\"):\n",
        "        audio = AudioSegment.from_mp3(input_file)\n",
        "    elif input_file.lower().endswith(\".m4a\"):\n",
        "        audio = AudioSegment.from_file(input_file, \"m4a\")\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported audio format. Please provide an MP3 or M4A file.\")\n",
        "    audio.export(output_file, format=\"wav\")\n",
        "    return output_file\n",
        "\n",
        "# Function to find the audio URL in the HTML content\n",
        "def find_audio_url(html: str) -> str:\n",
        "    audio_urls = re.findall(r'https://[^\\s^\"]+(?:\\.mp3|\\.m4a)', html)\n",
        "    if audio_urls:\n",
        "        return audio_urls[-1]\n",
        "    return None\n",
        "\n",
        "# Function to get the file extension from a URL\n",
        "def get_file_extension(url: str) -> str:\n",
        "    parsed_url = urlparse(url)\n",
        "    _, file_extension = os.path.splitext(parsed_url.path)\n",
        "    return file_extension\n",
        "\n",
        "# Function to download and convert an audio file from a URL\n",
        "def download_and_convert_audio(url: str, output_folder: str = 'downloads'):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error: Unable to fetch the page. Status code: {response.status_code}\")\n",
        "        return\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    audio_url = find_audio_url(response.text)\n",
        "    if not audio_url:\n",
        "        print(\"Error: Unable to find the audio URL.\")\n",
        "        return\n",
        "    episode_title = soup.find('span', {'class': 'product-header__title'})\n",
        "    if not episode_title:\n",
        "        print(\"Error: Unable to find the title.\")\n",
        "        return\n",
        "    episode_title = episode_title.text.strip().replace('/', '-')\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    output_file = os.path.join(output_folder, f\"{episode_title}{get_file_extension(audio_url)}\")\n",
        "    downloaded_file = download_file_from_url(audio_url, output_file)\n",
        "    if not downloaded_file:\n",
        "        print(\"Error: Unable to download the file.\")\n",
        "        return\n",
        "    output_file = convert_audio_to_wav(downloaded_file)\n",
        "    return episode_title, output_file\n",
        "\n",
        "# Example usage\n",
        "result = download_and_convert_audio(URL)\n",
        "if not result:\n",
        "    print(\"Error: Unable to download podcast.\")\n",
        "else:\n",
        "    (title, filepath) = result\n",
        "    print(f\"Downloaded podcast episode '{title}' to '{filepath}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWKcY05fjrAw",
        "outputId": "09ffe931-40cf-49cf-cfa3-9839a9345a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Unable to find the audio URL.\n",
            "Error: Unable to download podcast.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "spUB1xPHmywD",
        "outputId": "2944c54d-3cc1-45e9-d09a-cdedc27d72c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "from pydub import AudioSegment\n",
        "from tqdm import tqdm # Import tqdm for progress bars\n",
        "\n",
        "# Function to download a file from a URL with a progress bar\n",
        "def download_file_from_url(url: str, output_filename: str = None):\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        if not output_filename:\n",
        "            output_filename = url.split(\"/\")[-1]\n",
        "        with open(output_filename, 'wb') as file:\n",
        "            # Use tqdm to create a progress bar\n",
        "            for chunk in tqdm(response.iter_content(chunk_size=1024),\n",
        "                              unit='KB', unit_scale=True, desc=f\"Downloading {output_filename}\"):\n",
        "                if chunk:\n",
        "                    file.write(chunk)\n",
        "        return output_filename\n",
        "    else:\n",
        "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "def convert_audio_to_wav(input_file: str):\n",
        "    output_file = os.path.splitext(input_file)[0] + \".wav\"\n",
        "    if input_file.lower().endswith(\".mp3\"):\n",
        "        audio = AudioSegment.from_mp3(input_file)\n",
        "    elif input_file.lower().endswith(\".m4a\"):\n",
        "        audio = AudioSegment.from_file(input_file, \"m4a\")\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported audio format. Please provide an MP3 or M4A file.\")\n",
        "\n",
        "    # Export the audio without using a progress_hook\n",
        "    audio.export(output_file, format=\"wav\", codec=\"pcm_s16le\", parameters=[\"-q:a\", \"0\"])\n",
        "    return output_file\n",
        "\n",
        "# Example usage\n",
        "URL = \"https://fileiran.net/Download/File/DitjzXY11B/20636_4_5771510420242174755.mp3\"\n",
        "result = download_file_from_url(URL)\n",
        "if not result:\n",
        "    print(\"Error: Unable to download file.\")\n",
        "else:\n",
        "    print(f\"Downloaded file to '{result}'\")\n",
        "    wav_file = convert_audio_to_wav(result)\n",
        "    print(f\"Converted file to WAV format and saved as '{wav_file}'\")\n",
        "(title, filepath) = 'Title','/content/'+wav_file\n",
        "print(title, filepath)"
      ],
      "metadata": {
        "id": "MJgO7QPzm0bP",
        "outputId": "0da1434a-1eca-404d-a62d-c88021c8d094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading 20636_4_5771510420242174755.mp3: 8.44kKB [00:01, 8.21kKB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded file to '20636_4_5771510420242174755.mp3'\n",
            "Converted file to WAV format and saved as '20636_4_5771510420242174755.wav'\n",
            "Title /content/20636_4_5771510420242174755.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Run the model** ğŸš€\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** âš™ï¸\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"Auto detection\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "language = (None if language == \"Auto detection\" else language)\n",
        "verbose = verbose_lut[verbose]\n",
        "\n",
        "\n",
        "if Model.endswith(\".en\") and language not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{language}'; using English instead.\")\n",
        "    language = \"en\"\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(filepath)[0] + \".txt\"\n",
        "print(\"audio local path:\", audio_path_local)\n",
        "\n",
        "import time\n",
        "\n",
        "#Transcribe\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper.transcribe(\n",
        "    model=whisper_model,\n",
        "    audio = str(audio_path_local),\n",
        "    verbose=verbose,\n",
        "    task=task,\n",
        "    language=language\n",
        ")\n",
        "#Time comsumed\n",
        "toc = time.time()\n",
        "print(f'Time consumpution {toc-tic}s for transcribing')\n",
        "\n",
        "#Write SRT file\n",
        "from whisper.utils import WriteSRT\n",
        "with open(subtitle_file, \"w\", encoding=\"utf-8\") as srt:\n",
        "    writer = WriteSRT(audio_path_local.parent)\n",
        "    writer.write_result(transcription, srt)\n",
        "print(f\"Write SRT file to '{subtitle_file}'\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "diarization_result = pipeline(audio_path_local)\n",
        "final_result = diarize_text(transcription, diarization_result)\n",
        "\n",
        "lines = list()\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    print(f\"{line}\")\n",
        "    lines.append(line)\n",
        "\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "display(Markdown(f\"**Transcript file created: {transcript_with_speakers_file}**\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lOnyZpK2EsVe",
        "outputId": "7c7d801e-1259-47ae-e695-2de79deb329d"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "### /content/20636_4_5771510420242174755.wav",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio local path: /content/20636_4_5771510420242174755.wav\n",
            "Transcribe in progress...\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Persian\n",
            "[00:00.000 --> 00:03.200]  Ø¯Ú©ØªØ± Ø³Ù…Ø§ÛŒÙ‡ ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ù†Ø§Ø³ Ù…ÛŒÚ¯ÙˆÛŒØ¯\n",
            "[00:03.200 --> 00:05.600]  Ø¬Ø§ÛŒÚ¯Ø§Ù‡ Ø²Ù†Ø§Ù† Ø¯Ø± Ø¬Ø§Ù…Ø¹Ù‡ Ø§ÛŒØ±Ø§Ù†ÛŒ\n",
            "[00:05.600 --> 00:10.080]  Ø¨Ø¹Ø¯ Ø§Ø² Ø¬Ù†Ø¨Ø´ Ù‡Ø§ÛŒ Ø³Ø§Ù„Ù‡ 1400 Ùˆ 1ØŒ 2ØŒ 4 ØªØºÛŒÛŒØ± Ùˆ ØªØºÙˆÙ„ Ø´Ø¯Ù‡\n",
            "[00:16.240 --> 00:20.080]  Ø³Ù„Ø§Ù… Ù…Ù† Ø¨ÛŒØª Ø¢Ø°Ø±ÛŒ Ø¨Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¯ÛŒØ¯Ú©Ø§ Ù‡Ù…Ø±Ø§Ù‡ Ø´Ù…Ø§ Ù‡Ø³ØªÙ…\n",
            "[00:22.200 --> 00:25.480]  Ø®Ø§Ù†Ù… ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¨Ù‡ Ø®Ø¨Ø± Ø¢Ù†Ù„Ø§ÛŒÙ† Ú¯ÙØªÙ‡ Ø§Ø² Ø¯Ù‡Ù‡ Ù‡ÙØªØ§Ø¯\n",
            "[00:25.480 --> 00:28.000]  Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡\n",
            "[00:28.000 --> 00:32.000]  Ù…Ø§ ÛŒÚ© Ø¬Ø§Ù…Ø¹Ù‡ Ù…Ø±Ø¯ Ø³Ø§Ù„Ø§Ø± Ø±Ø§ Ø¯Ø§Ø´ØªÛŒÙ… Ú©Ù‡ Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø´Ú©Ù„ Ù…Ø´Ø®ØµÛŒ\n",
            "[00:32.000 --> 00:34.240]  Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø²Ù†Ø§Ù† Ù…ÛŒØ±Ø³ÛŒØ¯\n",
            "[00:34.240 --> 00:38.320]  Ø§Ù…Ø§ Ø¯Ø± Ø³Ø§Ù„ 1400 Ùˆ 2 ÛŒÚ© Ø¨Ø§Ø±Ù‡ Ø¨Ø§ Ø¬Ù…Ø¹ÛŒØªÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒØ´ÙˆÛŒÙ…\n",
            "[00:38.320 --> 00:41.680]  Ú©Ù‡ Ø¨Ù‡ Ø¹Ø±Øµ Ø¨Ø±Ø¯Ù† ÛŒÚ© Ø³Ø§Ù† Ø²Ù† Ùˆ Ù…Ø±Ø¯ Ø¨Ø§ÙˆØ±Ø¯Ø§Ø±Ù†Ø¯\n",
            "[00:41.680 --> 00:45.040]  Ø­Ù‚ ØªÙ„Ø§Ù‚ Ø¨Ø±Ø§ÛŒ Ø²Ù†Ø§Ù† Ù…ÙˆØ±Ø¯ Ù¾Ø°ÛŒØ±Ø´ Ù‚Ø±Ø§Ø± Ù…ÛŒÚ¯ÛŒØ±Ø¯\n",
            "[00:45.040 --> 00:47.480]  Ùˆ Ù¾Ø°ÛŒØ±Ø´ Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ ÙˆØ§Ù„Ø¯ÛŒÙ†\n",
            "[00:47.480 --> 00:50.200]  Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ±Ø§Øª ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø¨Ø§Ù„Ø§ Ø±ÙØªØ³Øª\n",
            "[00:50.240 --> 00:52.720]  Ø¨Ù‡ Ø§Ø¹ØªÙ‚Ø§Ø¯ ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø§ÛŒÙ† ØªØºÛŒÛŒØ±Ø§Øª Ù†Ø´Ø§Ù†Ø¯Ù‡Ù†Ø¯Ù‡\n",
            "[00:52.720 --> 00:57.120]  ØªØ³Ø§Ù‡Ù„ Ø¨ÛŒÙ†Ú¯Ø±ÙˆÙ‡ÛŒ Ùˆ Ø¨ÛŒÙ† Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ Ø¯Ø±Ù…ÛŒØ§Ù† Ù…Ø±Ø¯Ù… Ø§Ø³Øª\n",
            "[00:57.120 --> 01:01.040]  Ø¯Ø± Ø¯ÛŒØ¯Ú¯Ø§Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¬Ø²ÛŒØ§Øª Ú¯ÙØªÚ¯ÙˆÛŒ Ø³Ù…ÛŒØª ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ\n",
            "[01:01.040 --> 01:06.680]  Ø¨Ø§ Ø³Ù‡Ø± Ù…ØªÙ„Ø¨ÛŒ Ù¾Ø¬ÙˆÙ‡Ø´Ú©Ø± Ø¨Ù‡Ø¯Ø§Ø´Øª Ø¬Ù…Ø¹ÛŒØª Ø¨ÛŒÙ† Ø§Ù„Ù…Ù„Ù„ Ø§Ø² Ø³ÙˆØ¦Ø¯ Ù‡Ù…Ø±Ø§Ù‡ Ù…ÛŒØ´ÙˆÛŒÙ…\n",
            "[01:11.680 --> 01:14.720]  Ø®Ø§Ù† Ù…ØªÙ„Ø¨ÛŒ Ù¾ÛŒØ´ Ø§Ø² Ø§ÛŒÙ† Ú©Ù‡ Ù…Ù† Ù¾Ø±Ø³Ø´Ùˆ Ù‡Ù… Ù…Ø·Ø±Ø­ Ú©Ù†Ù…\n",
            "[01:14.720 --> 01:19.200]  Ø®ÙˆØ§Ù‡Ø´ Ù…ÛŒÚ©Ù†Ù… Ø®Ù„Ø§ØµÙ‡ Ø§ÛŒ Ø§Ø² Ø¹Ø±Ø¶ÛŒØ§Ø¨ÛŒ Ù‡Ø§ÛŒ Ø¯Ú©ØªØ± Ø³Ù…ÛŒØª ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ\n",
            "[01:19.200 --> 01:24.600]  Ø§Ø² ØªØ­ÙˆÙ„Ø§Øª Ø¬Ø§Ù…Ø¹Ù‡ Ø§ÛŒØ±Ø§Ù† Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ø¹ØªØ±Ø§Ø²Ø§Øª 1401 Ø±Ùˆ Ø¨Ø±Ù…ÙˆÙ† Ù…Ø±ÙˆØ± Ú©Ù†ÛŒØ¯\n",
            "[01:24.600 --> 01:26.360]  Ø¨Ø¹Ø¯ ÙˆØ§Ø±Ø¯ Ùˆ Ø¬Ø²ÛŒØ§Øª Ø¨Ø´ÛŒÙ…\n",
            "[01:26.360 --> 01:28.680]  Ø¨Ø§ ØµØ¯Ø§ ÙÙ‚Ø· Ø®Ø¯Ù…Øª Ø´Ù…Ø§ Ø¨Ø¨ÛŒÙ†ÛŒØ¯\n",
            "[01:28.680 --> 01:31.720]  Ø§ÛŒÙ† Ø¨ØºØ§Ù„Ø§ Ø¨Ù‡ Ù†Ø¸Ø±Ù…Øª ÙÙ‚Ø· Ù†ÙØ¹Ù‡ Ø®ÛŒÙ„ÛŒ Ø¬Ø§Ù„Ø¨ÛŒ Ø¯Ø§Ø´Øª\n",
            "[01:31.720 --> 01:34.120]  Ø¨Ù‡ Ø·ÙˆÙ„ Ù…Ø´Ø§Ù‚ØµÙ… Ù…Ù‡Ù…ØªØ±ÛŒÙ† Ú†ÛŒØ²ÛŒ Ú©Ù‡\n",
            "[01:34.120 --> 01:37.560]  ØªØºÛŒÛŒØ±Ø§Øª Ú©Ù‡ Ø¯Ø± ÙˆÙ‚Øª Ø§ÛŒØ´ÙˆÙ† Ø§Ø´Ø§Ø±Ù‡ Ú©Ø±Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ø¨Ù‡Ø´\n",
            "[01:37.560 --> 01:41.600]  Ø§ÛŒÙ†ÛŒ Ú©Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø¯Ø± ÙˆÙ‚Øª ØªØ¹Ø§Ù…Ù„ Ú¯Ø±ÙˆÙ‡ Ù‡Ø§ Ùˆ Ø¨Ù‚Ø´ Ùˆ Ø¨Ù‚Ø´ Ùˆ Ù…Ø®ØªÙ„Ù\n",
            "[01:41.600 --> 01:43.800]  Ø¨Ù‡ Ø§ÛŒÚ© ØªØ³Ø§Ù‡Ù„ÛŒ Ø±Ùˆ ØªØ¬Ø±Ø¨Ù‡ Ù…ÛŒÚ©Ù†Ù‡\n",
            "[01:43.840 --> 01:45.760]  Ú©Ù‡ Ù…Ø«Ù„Ø§ Ø¯Ø± Ø²Ù…Ø§Ù†Ù‡ÙˆÙ‚ Ø²Ù†Ø§Ù†\n",
            "[01:45.760 --> 01:49.600]  Ø®ÛŒÙ„ÛŒ Ù…ÙˆØ§Ø¯ Ø¯ÛŒØ¯Ù‡ Ù…ÛŒØ´Ù‡ Ú©Ù‡ Ø­Ù‚ ØªÙ„Ø§Ù‚Ù‡ Ø³ÛŒÙ‡ Ø¨Ø±Ø§Ø¨Ø± Ø¯Ø§Ø±Ù‡\n",
            "[01:49.600 --> 01:52.800]  Ø¨ÛŒØ´ØªØ± Ù¾Ø°Ø±ÙˆÙØªÙ‡ Ù…ÛŒØ´Ù‡ ØªÙˆÛŒ Ø¬Ø§Ù…Ø¹Ù‡\n",
            "[01:52.800 --> 01:55.920]  Ùˆ Ù‡Ù…ÛŒÙ†Ø·ÙˆØ± Ù…Ø¯Ø§Ø±Ø§ÛŒ ÙˆØ§Ù„Ø¯ÛŒÙ† Ø¨Ø§ Ø®ÙˆØ§Ø³ØªØ§ÛŒ Ù¾Ø±Ø²Ù†Ø¯Ø§Ù†Ø´ÙˆÙ†\n",
            "[01:55.920 --> 02:00.200]  Ú©Ù‡ Ù…Ù…Ú©Ù†Ù‡ Ú©Ù‡ Ø¨Ù‡ Ù„Ø­Ø§Ø¸ Ø¹Ù‚ÛŒØ¯ØªÛŒ Ø¨Ø§ Ø®ÙˆØ§Ø³ØªØ§ÛŒ Ø®ÙˆØ¯Ø´ÙˆÙ† Ù…ØªÙØ§Ø¨Ø· Ø¨Ø§Ø´Ù‡\n",
            "[02:00.200 --> 02:04.360]  Ùˆ Ø§ÛŒÙ† ØªØ³Ø§Ø±Ù„ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¨ÛŒÙ† Ú¯Ø±ÙˆÙ‡ÛŒ Ùˆ Ø¨ÛŒÙ† Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ Ù‡Ù… Ø¯Ø§Ø±Ù‡ Ø´Ú©Ù„ Ù…ÛŒÚ¯ÛŒØ¯\n",
            "[02:04.360 --> 02:07.960]  Ù…Ø«Ù„Ø§ Ø¨ÛŒÙ† Ø¹Ù‚Ù„ÛŒØªÙ‡Ø§ÛŒ Ù…Ø±Ø«Ù‡ÙˆÛŒ Ù…Ø®ØªÙ„Ù Ø¨ÛŒØ´ØªØ± Ù¾Ø°Ø±ÙˆÙØªÙ‡ Ù…ÛŒØ´Ù†\n",
            "[02:07.960 --> 02:10.920]  Ùˆ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø³Ø§Ø¨Ù‚ Ø¨ÛŒØ´ØªØ± Ø¯ÛŒØ¯Ù‡ Ù…ÛŒØ´Ù† Ùˆ Ø´Ø§ÛŒØ¯ Ù¾Ø°Ø±ÛŒØ´ÙˆÙ† Ø²ÛŒØ§Ø¯ Ø´Ø¯Ù‡\n",
            "[02:10.920 --> 02:12.960]  Ø¯ÛŒÚ¯Ù‡ Ù†Ú©ØªÙ‡ ÛŒÚ©ÛŒ Ú©Ù‡ Ú¯ÙØªÙ† Ø§ÛŒÙ†Ù‡ Ú©Ù‡\n",
            "[02:12.960 --> 02:17.440]  ÙˆÙ‚ØªÛŒ Ù†Ø§Ø±Ø¶ÛŒØ§ØªÛŒ Ø¬Ù…Ø¹ÛŒ Ù†Ø§Ø´ÛŒ Ø§Ø² Ø¹Ø¯Ù…ÛŒ Ø±Ø³ÛŒØ¯Ù† Ø¨Ù‡ Ø®ÙˆØ§Ø³ØªØ§Ù‡Ø§ Ø¨Ù‡ ÙˆØ¬ÙˆØ¯ Ø¨ÛŒØ§Ø¯\n",
            "[02:17.440 --> 02:20.080]  Ø§Ù†ØªØ¸Ø§Ø± Ù…ÛŒÚ©Ù†Ù‡ Ú©Ù‡ Ø¯Ùˆ ØªØ§ Ù†ØªÛŒØ¬Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù‡\n",
            "[02:20.080 --> 02:23.320]  ÛŒØ§ Ø§ÛŒÙ† Ú©Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ú©Ø±Ø®Øª Ùˆ Ù„Ù…Ø³ Ùˆ Ø¨ÛŒØªÙØ§ÙˆØª Ù…ÛŒØ´Ù‡\n",
            "[02:23.320 --> 02:26.960]  Ùˆ ÛŒØ§ Ø§ÛŒÙ†ÛŒ Ú©Ù‡ Ø§ØªÙØ§Ù‚Ø§ Ø¨Ø§ Ú©Ø§Ù†Ø´Ù‡Ø§ÛŒ Ø±Ø§Ø¯ÛŒÚ©Ø§Ù„ Ø¹Ù‚Øµ Ø§Ø´Ø´Ø§ÙØªÛŒ Ø¯Ø§Ø±Ù‡\n",
            "[02:26.960 --> 02:31.800]  Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù‡Ø± Ø¯Ùˆ ÛŒÚ© Ø¨Ø§ Ú©Ø§Ù†Ø´ Ø§ÙØ±Ø§Ø¯ÛŒÙ‡ Ú©Ù‡ Ø§ÛŒÙ† Ø¨Ø§Ø¹Ø«Ù…Ø´ Ú©Ù‡ Ú©Ù†Ø´Ú¯Ø±ÛŒ Ø³Ø®Øª Ù‡Ø± Ø¨Ø´Ù‡\n",
            "[02:31.800 --> 02:34.640]  Ø¨Ø¹Ø¯ Ù†Ú©ØªÙ‡ Ø¯ÛŒÚ¯Ù‡ Ú©Ù‡ Ú¯ÙØªÙ‡ Ø¨ÙˆØ¯Ù† Ø§ÛŒÙ† Ø¨ÙˆØ¯Ù‡ Ú©Ù‡\n",
            "[02:34.640 --> 02:37.520]  Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø·Ø¨Ù‚Ù‡ Ù¾Ø§ÛŒÙ†Ø¯ Ø±ÙˆÛŒ ÙÙ‚Ù‚ ÙˆØ§Ù‚Ø¹ÛŒ Ù…ÙˆÙ†Ø¯Ù‡\n",
            "[02:37.520 --> 02:39.720]  Ùˆ Ø·Ø¨Ù‚Ù‡ Ù…ØªÙˆØ³Ø· Ø¯Ø§Ø±Ù‡ Ù…Ø²Ù…Ø­Ù„ Ù…ÛŒØ´Ù‡\n",
            "[02:39.720 --> 02:43.000]  Ùˆ Ø§Ø´Ø¹Ø§Ù„ÛŒ Ú©Ø±Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ú©Ù‡ Ø¢Ù…Ø§Ø± Ø¨ÛŒÚ©Ø§Ø±ÛŒ Ú©Ù‡ 75% Ø§Ø¹Ù„Ø§Ù… Ø´Ø¯Ù‡\n",
            "[02:43.000 --> 02:44.200]  Ø§ÛŒ Ø®Ø¨ Ù…Ø§Ù„Ø§ Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø³Øª\n",
            "[02:44.200 --> 02:49.360]  Ø¬Ø§Ù†Ø¯Ù‡ ÛŒÚ© Ø¨Ø®Ø´ÛŒ Ø§Ø² Ø¨ÛŒÚ©Ø§Ø±Ø§Ù† Ú©Ù‡ Ø¨Ù‡ Ø³Ø±Ø²Ø¯Ù‡ Ø´Ù‚Ø§ÛŒ Ù¾Ø§Ø±ÙˆØ§Ø®ØªÛŒ Ù‡Ø³ØªÙ†\n",
            "[02:49.360 --> 02:53.360]  Ùˆ ÛŒØ§ Ø¨Ø±Ø·Ù…Ù‡ ÙˆØ§Ù‚Ø¹ Ø´Ø§ØºÙ„ Ù‡Ø³ØªÙ† Ø§ÛŒÙ†Ù‡Ø§ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¬Ø² Ø¢Ù…Ø§Ø± Ø´Ø§ØºÙ„ Ù…ÛŒÙ‡Ù†Ù‡\n",
            "[02:53.360 --> 02:56.760]  Ø³Ø¨Ø´ØªÙ‡ Ú©Ù‡ Ø¯Ø± Ø³Ø±Ø²Ø¯Ù‡ Ú©Ù‡ Ø¹Ù„Ø§Ù‚Ù‡ Ø§ÛŒÙ†Ù‡Ø§ Ø¨Ø§ Ø¬Ø² Ø¢Ù…Ø§Ø± Ø¨ÛŒÚ©Ø§Ø±Ø§Ù† Ø­Ø³Ø§Ø¨ Ú©Ø´Ù†Ø¯\n",
            "[02:56.760 --> 03:02.480]  Ùˆ Ù†Ú©ØªÙ‡ Ø¯ÛŒÚ¯Ù‡ Ø§ÛŒÙ†ÛŒ Ú©Ù‡ 40% Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¨ÛŒÚ©Ø§Ø±Ø§Ù† ØªØ­ØµÛŒÙ„ Ú©Ø±Ø¯Ù‡ Ù‡Ø³ØªÙ†\n",
            "[03:02.480 --> 03:04.840]  Ùˆ 71% Ø§ÙˆÙ†Ù‡Ø§ Ù‡Ù… Ø²Ù†Ø§Ù† Ù‡Ø³ØªÙ†\n",
            "[03:04.840 --> 03:08.640]  Ù†Ú©ØªÙ‡ Ú©Ù‡ Ú¯ÙØªÙ‡ Ø¨ÙˆØ¯Ù† Ø§ÛŒÙ† Ø¨ÙˆØ¯Ù‡ Ú©Ù‡ Ø¨ÛŒØ´ØªØ±ÛŒ Ù…ÛŒØ²Ø§Ù† Ú©Ù†Ø´Ú¯Ø±ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ\n",
            "[03:08.640 --> 03:10.560]  Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø§Ø² Ø·Ø¨Ù‚Ù‡ Ù…ØªÙˆØ³Ø· Ø´Ø¯Ù‡ Ù…ÛŒØ´Ù‡\n",
            "[03:10.560 --> 03:13.760]  Ùˆ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…Ø®ØªØµÙ… ÙˆÙ‚ØªÛŒ Ø·Ø¨Ù‚Ù‡ Ù…ØªÙˆØ³Ø· Ú©Ù„Ø§Ù…Øª Ùˆ Ø¬Ø§ÛŒÚ¯Ø§Ù‡ Ø§Ù†Ø³Ø§Ù†ÛŒÙ‡\n",
            "[03:13.760 --> 03:18.040]  Ø§Ø² Ø¯Ø³Øª Ù†ÛŒØ¯Ù‡ Ùˆ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù„Ú†Ø§Ø±Ù‡ Ø®Ø´Ù… Ù‡Ù… Ø¨Ø§Ø´Ù‡ Ù†ÛŒÙ…ÛŒØ´Ù‡\n",
            "[03:18.040 --> 03:23.680]  Ø²ÛŒØ± Ù‚ØµØ¯ Ø¬Ø§Ù…Ø¹Ù‡ ØªÙØ§Ù‡Ù…ÛŒ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø­Ù‚ÙˆÙ‚ Ø²Ù†Ø§Ù† Ø¯Ø± Ø­Ø§Ù„ Ø´Ú©Ù„ Ú¯Ø±ÙØªÙ†\n",
            "[03:23.680 --> 03:29.920]  Ø§Ú¯Ø±Ú†Ù‡ Ø­Ø§Ú©Ù…ÛŒØª Ù…Ø§ Ù†Ù¾Ø°ÛŒØ±ÙØªÙ‡ ÙˆÙ„ÛŒ Ú©Ù‡ Ø¨Ù†Ø¸Ø± Ù…ÛŒØ±Ø³Ø¯ Ú©Ù‡ Ø§ÛŒÙ† Ù†Ø´Ø§Ù†Ù‡ Ù‡Ø§Ø´ Ø¯Ø± ÙˆØ§Ù‚Ø¹\n",
            "[03:29.920 --> 03:35.920]  Ù…Ø«Ù„Ø§Ù‹ Ø¨Ø³Ø±Ø§Øª Ø§ÛŒÙ†Ù‡ Ú©Ù‡ Ø±Ø³Ø§Ù†Ù‡ Ù‡Ø§ Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ Ù¾ÙˆØ´Ø´ Ø²Ù†Ø§Ù† ØªØ³Ø§Ø­Ù„ Ø¯Ø§Ø±Ù†Ø¯ Ø¯ÛŒØ¯Ù‡ Ù…ÛŒØ´Ù‡\n",
            "[03:35.960 --> 03:41.080]  Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù…Ù‡Ø§Ø¬Ø±Øª Ù‡Ù… Ø§ÛŒØ´ÙˆÙ† Ø¨Ú©Ù†Ù† Ú©Ù‡ Ø§ÛŒØ±Ø§Ù† Ù‡ÙØªÙ‡ Ù…Ù† Ú©Ø´ÙˆØ±Ù‡ Ù…Ù‡Ø§Ø¬Ø±Øª Ø¨Ø±Ø³ØªÙ‡\n",
            "[03:41.080 --> 03:45.160]  Ú©Ù‡ Ø¨Ù†Ø¸Ø± Ù…ÛŒØ±Ø³ØªÙ‡ Ú©Ù‡ Ø§Ù†Ú¯ÛŒØ²Ù‡ Ù‡Ø§ÛŒ Ù…Ù‡Ø§Ø¬Ø±Øª Ø§ÛŒ Ú©Ù‡ Ù…Ù‚Ø§ÛŒÛŒ ØªÙ‚Ø±ÛŒØ± Ú©Ø±Ø¯Ù‡\n",
            "[03:45.160 --> 03:48.960]  Ù…Ø«Ù„Ø§Ù‹ Ø¨Ù‡ Ù¾Ø´Ø§Ø±Ù‡ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ù…ÛŒÙ†Ù‡ Ø­ØªÛŒ Ø¯Ø± Ø¨ÛŒÙ† Ú¯Ø±ÙˆÙ‡ Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø®ÙˆØ¯Ø´ÙˆÙ†\n",
            "[03:48.960 --> 03:54.280]  Ø§Ø¯ÙˆÛŒØ² Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ùˆ ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ØªØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯ ÙˆÙ„ÛŒ Ú©Ù‡ Ù‡ÙØªÙ‡ Ù¾Ø´Ø§Ø± Ù‡Ù… Ù†Ø³Ù„Ù‡ Ù‡Ø§Ø´ÙˆÙ† Ø¯Ø§Ø±Ù†Ø¯\n",
            "[03:54.280 --> 04:00.040]  Ø³Ø¹ÛŒ Ù…ÛŒ Ú©Ù†Ù†Ø¯ Ú©Ù‡ Ù…Ù‡Ø§Ø¬Ø±Øª Ø¨Ú©Ù†Ù†Ø¯ Ùˆ Ù…Ù…Ú©Ù†Ù‡ Ø¯Ù„ÛŒÙ„ Ø§ØµÙ„Ø´ Ø§ÛŒÙ† Ø¨ÙˆØ¯Ù‡ Ú©Ù‡ Ø¯Ø± Ø®ÙˆÙ†Ø¯ Ú†Ø´Ù…Ø§Ù†Ø¯Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ù‡\n",
            "[04:00.040 --> 04:06.720]  Ø®Ø§Ù†Ù… ØªØ¹Ù„ÛŒØ¨ÛŒ Ø§Ø² ÛŒÚ© Ø·Ø±Ù Ù†Ú¯Ø§Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø¨Ù‡ Ù…Ø³Ø¦Ù„Ù‡ Ø²Ù†Ø§Ù† Ø¯ÙˆÚ†Ø§Ø± ØªØ­ÙˆÙ„ Ù…Ø¹Ù†Ø§Ø¯Ø§Ø± Ø´Ø¯Ù‡\n",
            "[04:06.720 --> 04:11.280]  Ø§Ø² Ø·Ø±Ù Ø¯ÛŒÚ¯Ù‡ Ø¨Ù‡ Ø´Ù‡Ø§Ø¯Øª Ù‡Ù…ÛŒÙ† Ú¯ÙØªÚ¯Ùˆ Ø¨Ø§ Ø®Ø§Ù†Ù… ØªÙˆØ­ÛŒØ¯Ù„Ùˆ\n",
            "[04:11.280 --> 04:17.240]  Ù¾Ø´Ø§Ø±Ø§ÛŒ Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ù‚Ø´Ø± Ù…ØªÙˆØ³Ø· Ø±Ùˆ Ú†Ù†Ø§Ù† Ø²Ø¹ÛŒÙ Ú©Ø±Ø¯Ù‡ Ú©Ù‡ Ø§Ø² Ú©Ø§Ø±Ú©Ø±Ø¯ Ø§Ù†Ø¯Ø§Ø®ØªÙ‡\n",
            "[04:17.240 --> 04:24.840]  Ø³ÙˆØ§Ù„ Ù…Ù† Ø§ÛŒÙ†Ù‡ Ú©Ù‡ Ø§Ø² Ù†Ø¸Ø± Ø´Ù…Ø§ ÙˆØ²Ù† Ù¾Ø´Ø§Ø±Ø§ÛŒ Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ø¯Ø± ØªØ­ÙˆÙ„Ø§Øª Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ø³Ù‡Ù… Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù‡ØŸ\n",
            "[04:24.840 --> 04:28.480]  ÛŒØ§ Ø­Ù‚ÙˆÙ‚ Ø²Ù†Ø§Ù† Ú©Ù‡ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ØªØ§Ù„Ø¨Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ø¯Ù‡ØŸ\n",
            "[04:28.480 --> 04:36.440]  Ø¨Ù‡ Ù†Ø¸Ø± Ø´Ø®ØµÛŒ Ù…Ù† Ø§ÛŒÙ†Ø·ÙˆØ± Ù†ÛŒØ§Ø¯Ø´ Ú©Ù‡ Ù…Ø±Ù‚Ø¬ Ù…Ø´ØªØ±Ú© Ù…ØªØ§Ù„Ø¨Ø§Øª Ø¬Ø§Ù…Ø¹ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø§Ù„Ø§Ù† Ù…ØªØ§Ù„Ø¨Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÛŒÙ‡\n",
            "[04:36.440 --> 04:43.120]  ÙˆÙ‚ØªØ§Ù† Ø§Ø² Ù„Ø§Ø³Ù‡ Ø¢Ù…Ø§Ø±ÛŒ Ú©Ù‡ Ù…ÛŒ Ø®ÙˆØ§Ù‡ÛŒÙ… Ø¨Ø±Ø³ÛŒØ¨ Ú©Ù†ÛŒÙ… Ù…ÛŒ Ø¨ÛŒÙ†ÛŒÙ… Ú©Ù‡ Ø¨ÛŒÙ† Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ø§Ú©Ø± Ù…Ø«Ù„Ø§ Ø³Ø§Ù„ 1378-18\n",
            "[04:43.120 --> 04:46.880]  ØªÙˆØ§Ù‚Ø¹ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø¢Ø²Ø§Ø¯ÛŒ Ù…Ø¯Øª Ø¨ÙˆØ¯ØŒ Ø³Ø§Ù„ 828 Ø­Ù‚ Ø±Ø¹ÛŒ Ø¨ÙˆØ¯\n",
            "[04:46.880 --> 04:55.000]  ÙˆÙ„ÛŒ Ø§Ø² Ø¯Ø± ÙˆØ§Ù‚Ø¹ ÛŒÚ© Ø¯Ù‡Ù‡ Ø§Ø®ÛŒØ±ØŒ Ø³Ø§Ù„ 96-98-1401 Ù…ØªØ§Ù„Ø¨Ø§Øª Ø¨Ù‡ Ø·ÙˆØ± Ù…Ø´Ø®Øµ\n",
            "[04:55.000 --> 05:00.360]  Ù…ØªØ§Ù„Ø¨Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ùˆ Ø±ÙØ¹ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ùˆ ØªÙˆØ§Ù‚Ø¹ Ú©Ø±ÙˆØ¯Ø³Øª Ø¨ÛŒØ´ØªØ± Ù…Ø´Ø§Ø±Ú©Øª Ú©Ø±Ø¯Ù†\n",
            "[05:00.360 --> 05:08.880]  Ùˆ ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ú¯Ø±ÙˆÙ‡ Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ø´Ø§Ø±Ú©Øª Ú©Ø±Ø¯Ù† Ù‡Ù… Ù…Ø«Ù„Ø§ Ø¯Ø± Ù…ØµØ¯Ø± Ø´Ø¹Ø±Ù‡Ø§ Ø§Ú¯Ø± Ø¨Ø®ÙˆØ§ÛŒÛŒÙ… Ø¯Ø± Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ±ÛŒÙ… Ø®ÛŒÙ„ÛŒ Ø¨ÛŒØ´ØªØ± Ø´Ø¯Ù‡\n",
            "[05:08.880 --> 05:18.840]  Ùˆ Ø¯ÛŒÚ¯Ù‡ Ø§ÛŒÙ† Ú©Ù‡ Ù…Ø«Ù„Ø§ Ø§Ú¯Ø± Ø¨Ø®ÙˆØ§ÛŒÛŒÙ… Ø­ØªÛŒ Ø§ÙˆÙ† Ø¯Ùˆ ØªØ§ Ù†Ù‚Ø´Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¯Ø±Ù…ÙˆÙ…Ø¯Ù‡ Ú©Ù‡ Ù†Ù‚Ø´ ØªÙˆØ¶ÛŒØ­ Ø¨ÙˆØ¬Ù‡ÛŒ Ø³Ø§Ù„ 1401 Ú©Ù‡ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¢Ù†Ù„Ø§ÛŒÙ† Ù…Ù†ØªØ´Ø± Ú©Ø±Ø¯Ù‡\n",
            "[05:18.840 --> 05:24.000]  Ø§ÙˆÙ† Ø±Ùˆ Ù…Ù‚Ø§Ø±ÛŒØ³Ù‡ Ø¨Ú©Ù†ÛŒÙ… Ø¨Ø§ Ù†Ù‚Ø´Ù‡ Ø¢Ø³ÛŒØ¯ Ø¨ÛŒØ¯Ú¯Ø§Ù† Ø¬Ù†Ø¨Ø´ØŒ Ø®ÛŒÙ„ÛŒ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù‡Ù…Ú©ÙˆØ´Ø§Ù†ÛŒ Ø¬Ø§Ù„Ø¨ÛŒ Ø¯Ø§Ø±Ù‡\n",
            "[05:24.000 --> 05:34.600]  Ø§ÙˆÙ† Ø§Ø³ØªØ§Ù†Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¨ÙˆØ¬Ù‡ÛŒ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù† Ú©Ù…ØªØ±ÛŒÙ† Ù…ÛŒØ²Ø§Ù† Ù…Ø´Ø§Ø±Ú©Øª Ø±Ùˆ Ø¯Ø± Ø¬Ù†Ø¨Ø´ Ø§Ø² Ù„Ø§Ø²Ù… Ø¢Ù…Ø§Ø± Ø¢Ø³ÛŒØ¯ Ø¨ÛŒØ¯Ú¯Ø§Ù† Ùˆ Ú©Ø´Øª Ø´Ø¯Ú¯Ø§Ù† Ùˆ Ø¨Ø§Ø²Ø´ Ø´Ø¯Ú¯Ø§Ù† Ø¯Ø§Ø±Ù†\n",
            "[05:34.600 --> 05:43.640]  Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Ø§Ø³ØªØ§Ù†Ù‡Ø§ÛŒÛŒ Ø­Ø§Ø´ÛŒÙ‡ Ú©Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ú©Ù…ØªØ±ÛŒÙ† Ù…ÛŒØ²Ø§Ù† Ø¨Ù‡ Ø¨ÙˆØ¬Ù‡ Ø±Ùˆ ÙˆØ§Ø³Ø§Ø³ Ø³Ø±Ø§Ù†Ù‡ Ø¯Ø§Ø±Ù† Ø¨ÛŒØ´ØªØ±ÛŒ Ù…ÛŒØ²Ø§Ù† Ø¢Ø³ÛŒØ¯ Ø¨ÛŒØ¯Ú¯Ø§Ù† Ø¬Ù†Ø¨Ø´ Ø¯Ø§Ø±Ù†\n",
            "[05:43.640 --> 05:54.400]  Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù†Ø´ÙˆÙ†Ø¯Ù‡ Ú©Ù‡ Ø§ÛŒÙ† Ù‡Ø§ Ù…Ø´Ø§Ø±Ú©Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ú©Ø±Ø¯Ù† ÛŒØ¹Ù†ÛŒ Ø¨Ø§ Ø§ÛŒÙ† Ø­Ø§Ù„ Ù‡Ù…ÛŒØ² Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒØ§Ø¯ Ú©Ù‡ Ù…ØªØ¹Ù„Ù‚Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÛŒØŒ Ù…ØªØ¹Ù„Ù‚Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ ØªÙ„ÛŒÙ‡ Ùˆ ÙˆØ²Ù† Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù‡\n",
            "[05:54.400 --> 06:06.560]  Ø§Ù…Ø§ Ù†Ú©ØªÙ‡ Ú©Ù‡ Ø¨ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù‡ Ø§ÛŒÙ†Ù‡ Ú©Ù‡ 10.401 Ø§ÛŒÚ© ØªÙ‚Ø§Ø¨Ù„ Ø¯ÛŒÚ¯Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯ØŒ Ø§ÙˆÙ† Ù‡Ù…ÙˆÙ†ÛŒ Ú©Ù‡ Ù†ÛŒÙ…ÛŒ Ø§Ø² Ø¬Ø§Ù…Ø¹Ù‡ Ú©Ù‡ Ø²Ù†Ø§Ù† Ø¨ÙˆØ¯Ù† Ú©Ù‡ Ø¨Ù‡ Ø·ÙˆØ± ØµÙ†Ø¯ØªÛŒ Ø¯Ø± Ø¬Ø§Ù…Ø¹Ù‡ Ù…Ø±Ø³Ø§Ù„Ù‡ Ø±ÛŒØ¶Ø§Ù† Ù‚ÛŒØ± Ø¢Ù…Ù„ Ø¨Ø±Ø²Ù† Ø´Ø¯Ù†\n",
            "[06:06.560 --> 06:16.160]  Ø§Ù…Ø§ Ø§ÛŒÙ† Ù‡Ø§ Ø¢Ù…Ù„ÛŒØª Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ùˆ Ø¢Ù…Ù„ÛŒØª Ø´Ø¯Ù† Ùˆ Ø¢Ù…Ù„Ù‡Ø§ÛŒ Ø§ÛŒÙ† Ø¬Ù…Ø¨Ø´ ÛŒÚ© Ø¬Ø§ Ø¨Ù‡ Ø¬Ø§ÛŒÛŒ Ø¯Ø±Ø´ÙˆÙ† Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡ Ù‡Ø³ØªÙ†Ø¯\n",
            "[06:16.160 --> 06:20.440]  Ø§Ø² Ø¬Ø§Ù…Ø¹Ù‡ Ù…Ø±Ø¯Ø§Ù† ÙˆÙØªÙ‡ Ø¯Ø± Ø¬Ø§Ù…Ø¹Ù‡ Ø²Ù†Ø§Ù† Ùˆ Ù…Ø±Ø¯Ù‡Ø§ Ù‡Ù… Ø§Ù…Ø±ÙˆØ² Ø²Ù†Ø§Ù† Ø´Ø¯Ù†Ø¯\n",
            "[06:20.440 --> 06:27.480]  Ù†Ú©ØªÙ‡ Ú©Ù‡ Ø¨ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù‡ Ø§ÛŒÙ†Ù‡ Ú©Ù‡ Ø¨Ù‡ Ù„Ø­Ø§Ø¸ Ø·Ø¨ÛŒØ¹ÛŒ Ø¨Ù‡ Ù†Ø¸Ø± Ù…Ù† Ø²Ù†Ø§Ù† Ø¨Ù‡ Ø®Ø§Ø·Ø± Ø·Ø¨ÛŒØ¹Øª Ù…Ø§Ø¯Ø±Ú¯ÙˆÙ†Ù‡\n",
            "[06:27.480 --> 06:32.640]  Ø§ÛŒÙ† Ù‡Ø§ Ù…Ù‡Ù…ÙˆÙ†Ø§Ù† Ú¯Ø±Ø§ÛŒØ´ Ø¨Ù‡ Ù‡Ù…Ù‡ Ø´Ù…ÙˆÙ„ÛŒÙ‡ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù†\n",
            "[06:32.640 --> 06:36.200]  Ù‡Ù…ÙˆÙ†Ø·ÙˆØ± Ú©Ù‡ Ù…ÛŒØ¨ÛŒÙ†ÛŒØ¯ Ø¨ÛŒØ´ØªØ±ÛŒ Ù…ÛŒØ²Ø§Ù† Ø®ÛŒØ±ÛŒ Ù‡Ø§ Ù‡Ù… Ø·Ø¨Ø¹Ø§ Ø§Ø² Ú©Ù‡ Ø²Ù†Ø§Ù† Ø§Ø¯Ø§Ø±Ù‡ Ù…ÛŒØ´Ù‡\n",
            "[06:36.200 --> 06:42.680]  Ø§ÛŒÙ† Ù‡Ø§ Ø¨Ø§ Ø§Ù‚Ø´Ø§Ø± Ø¨Ù‡ØªØ± Ú©Ù… Ø¨Ù‡ØªØ± Ù…Ù†ØªÙ‚Ù„ Ø¨ÛŒØ´ØªØ± Ø¯Ø±ØªÙ…Ø§Ø³ Ù‡Ø³ØªÙ† Ùˆ Ú©Ù¾ Ø¬Ø§Ù…Ø¹Ù‡ ØªÙ…Ø§Ø³ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù†\n",
            "[06:42.680 --> 06:47.480]  Ùˆ Ù…ØªØ¹Ù„Ø¨Ø§ØªØ´ÙˆÙ† ÙÙ‚Ø· Ù…ØªØ¹Ù„Ø¨Ø§Øª Ø®ÙˆØ¯Ø´ÙˆÙ† Ù†ÛŒØ³ØªØŒ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…ØªØ¹Ù„Ø¨Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ Ùˆ Ø¬Ù…Ø¹ÛŒ Ù†ÛŒØ³Øª\n",
            "[06:47.480 --> 06:53.480]  Ù…ØªØ­Ø§Ù„ Ù‚Ø¶ÛŒÙ‡ Ù‡Ø¬Ø§Ø¨ Ø¨Ù‡ Ù†Ø¸Ø± Ù…Ù† Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¨Ø³Ø±Ø§Øª ÛŒÚ© Ø³Ù…Ø¨ÙˆÙ„ Ù…Ù‚Ø§Ø¨Ù„Ù‡ Ø¨Ú©Ù†Ù‡\n",
            "[06:53.480 --> 07:00.480]  Ú†ÙˆÙ† Ø§ÛŒÙ† Ø±Ùˆ Ù†Ù‡ ØªÙ†Ù‡Ø§ Ø§ÛŒØ±Ø§Ù† ØªÙˆÛŒ Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ù„Ú©Ù‡ Ø¯Ø± Ú©Ø´ÙˆØ±Ù‡Ø§ÛŒ Ø¯ÛŒÚ¯Ù‡ Ù‡Ù… Ù…ÛŒØ¨ÛŒÙ†ÛŒØ¯\n",
            "[07:00.480 --> 07:05.480]  Ù…Ø«Ù„Ø§ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ù†Ù‚Ù„Ø§Ø¨ ÛŒÚ© Ú¯Ø±Ø§ÛŒØ´ÛŒ Ø¨Ù‡ Ù‡Ø¬Ø§Ø¨ Ø¨ÙˆØ¬ÙˆØ¯ Ø§ÙˆÙ…Ø¯Ù‡ Ø¨ÙˆØ¯\n",
            "[07:05.480 --> 07:11.480]  Ø§ÙˆÙ† Ù‡Ù… Ø¨ÛŒÙ† Ú¯Ø±ÙˆÙ‡ Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ø«Ù„Ø§ Ù…ÙˆØªØ±Ø²ÛŒÙ† Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø´Ø§Ù‡ Ø¨Ù‡ Ù‡Ø¬Ø§Ø¨ Ù…ÛŒØ¯ÙˆØ´ØªÙ†\n",
            "[07:11.480 --> 07:15.480]  Ø¨Ù‡ Ø®Ø§Ø·Ø± Ø§ÛŒÙ† Ú©Ù‡ Ø´Ø§Ù‡ Ø³Ù…Ø¨ÙˆÙ„ Ù…Ø¯Ø±Ù†ÛŒØ³Øª Ø¨ÙˆØ¯ Ùˆ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…ÛŒØ®ÙˆØ§Ø³ØªÙ† Ø¨Ù‡ Ø§ÙˆÙ† Ù…Ù‚Ø§Ø¨Ù„Ù‡ Ø¨Ú©Ù†Ù†\n",
            "[07:15.480 --> 07:23.480]  Ùˆ Ø§ÛŒÙ† Ø§ØªÙØ§Ù‚ Ø¯Ù‚ÛŒÙ‚Ø§ ØªÙˆÛŒ Ù…ØµØ± Ù‡Ù… Ø§ÙØªØ§Ø¯ Ú©Ù‡ Ù…Ø«Ù„Ø§ Ú¯ÙØªÙ‡ Ù…ÛŒØ´ÙˆØ¯ Ú©Ù‡ 70% Ø¬Ù…Ø¹ÛŒØª Ù…ØµØ± Ø²Ù…Ø§Ù† Ù…Ø¨Ø§Ø±Ú© Ú¯Ø±Ø§ÛŒØ´ Ø¨Ù‡ Ù‡Ø¬Ø§Ø¨ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù†\n",
            "[07:23.480 --> 07:29.480]  Ø³Ø§Ù„Ù‡Ø§ÛŒ Ø¢Ø®Ø± Ù…Ø¨Ø§Ø±Ú© Ø§ÙˆÙ† Ù‡Ù… ÙˆÙ‚ØªÛŒ Ù…Ù† Ú†Ù‚ØµØ§ Ù¾Ø±Ø³ÛŒØ¯Ù… Ø§Ø² Ú©Ù†Ø´Ú¯Ø±Ø§Ù† Ù…ØµØ±ÛŒ Ú©ÙØªÙ†\n",
            "[07:29.480 --> 07:34.480]  ÛŒÚ©ÛŒ Ø¯Ù„Ù„Ø´ Ø§ÛŒÙ†Ù‡ Ú©Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ÛŒ Ø³Ù…Ø¨ÙˆÙ„ Ù…Ù‚Ø§Ø¨Ù„Ù‡ Ø¨Ø± Ø¹Ù„ÛŒÙ‡ Ù…Ø¨Ø§Ø±Ú©ÛŒ Ú©Ù‡ Ø³Ù…Ø¨ÙˆÙ„ Ù…Ø¯Ø±Ù†ÛŒØ³ØªÛŒÙ…\n",
            "[07:34.480 --> 07:39.480]  Ùˆ Ø¨Ø®Ø§Ø·Ø± Ù‡Ù…ÛŒÙ† Ø¨Ø§Ø²Ú¯Ø´Øª ØµØ§Ù†ØªÙˆ Ù‡Ù…ÛŒØ®ÙˆØ§Ø³ØªÙ† ÙØ§ØµÙ„Ù‡ Ø®ÙˆØ¯Ø´ÙˆÙ† Ø±Ùˆ Ø¨Ø§ Ù…Ø¨Ø§Ø±Ú© Ù†Ø´ÙˆÙ† Ø¯Ø§Ø±Ø¯\n",
            "[07:39.480 --> 07:47.480]  Ùˆ Ø§ÛŒÙ† Ø­Ø§Ù„Ùˆ Ù…Ø§ Ø§Ù„Ø§Ù† ØªÙˆ Ø§ÛŒÙ† Ø²Ù…Ø§Ù† Ø¯Ù‚ÛŒÙ‚Ø§ Ù…ÛŒØ¨ÛŒÙ†ÛŒÙ… Ú©Ù‡ Ø¨Ø§ Ú©Ø´Ù Ù‡Ø¬Ø§Ø¨ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø²Ù†Ø¯Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø¯Ø§Ø±Ù‡\n",
            "[07:47.480 --> 07:52.480]  ÙØ§ØµÙ„Ù‡ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù‡ Ø¨Ø§ Ø­Ú©Ù…ÛŒØª Ø±Ùˆ Ø§Ø² Ù„Ø§Ø²Ù… Ø§ÛŒØ¯ÙˆÙ„ÙˆØ¬ÛŒ Ù†Ø´ÙˆÙ† Ø¯ÛŒØ¯Ù‡\n",
            "[07:52.480 --> 07:58.480]  Ù…Ø«Ù„Ø§ ÛŒÚ© Ú©Ø³Ø§Ù†ÛŒ Ù…Ø«Ù„ Ø®Ø§Ù†Ù… Ú¯ÙˆÙ‡Ø± Ø§Ø´Ù‚ÛŒ ÛŒØ§ Ø®Ø§Ù†Ù… ÙØ³ÙÙ‚ÛŒ Ú©Ù‡ Ù…ÛŒØ¨ÛŒÙ†ÛŒÙ… Ø§ÛŒÙ†Ù‡Ø§ Ø¨Ù‡ Ù‡Ø¬Ø§Ø¨ Ø§Ø¹ØªÙ…Ø§Ù„Ø§Ù† Ø§Ø¹ØªÙ‚Ø§Ø¯ Ø¯Ø§Ø±Ù†\n",
            "[07:58.480 --> 08:04.480]  Ø¯Ø§Ø´ØªÙ† Ùˆ Ø³Ø§Ù„Ù‡Ø§ Ù…Ø­Ø¬Ø¨ Ø¨ÙˆØ¯Ù† ÙˆÙ„ÛŒ Ø¨Ù‡ Ù†Ø´Ø§Ù†Ù‡ Ù…Ù‚Ø§ÙˆÙ…Øª Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù‡Ø¬Ø§Ø¨ Ø±Ùˆ Ø¨Ø±Ø§Ù…ÛŒ Ø¯Ø§Ø±Ù†\n",
            "[08:04.480 --> 08:12.480]  Ùˆ Ù‡Ù…ÛŒÙ† Ø·Ø±ÛŒÙ‚Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…ØªØ§Ù„Ø¨Ø§Øª Ø²Ù…Ø§Ù† ÛŒÚ© ÙˆØ³ÛŒÙ„Ù‡ Ù‚Ø¯ÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÙˆÙ† Ù…ØªØ§Ù„Ø¨Ø§Øª Ø¬Ù…Ø¹ÛŒ Ùˆ Ø¹Ù…ÙˆÙ…ÛŒ\n",
            "[08:12.480 --> 08:18.480]  Ú©Ù‡ Ù…Ø±Ú©Ø²Ø´ Ø§ÙˆÙ† Ø±Ø§Ù†Ù‡ Ù‡Ø§ÛŒ Ø§Ù‚ØªØµØ§Ø¯ÛŒÙ‡ Ù…Ù†ØªÙ‚Ù„Ù‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø³Ù…Ø¨ÙˆÙ„ Ø§Ø²Ø´ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒØ´Ù‡\n",
            "[08:18.480 --> 08:24.480]  Ú©Ù‡ Ù…Ø¹Ø«Ø±Ù‡ Ùˆ Ú†ÙˆÙ† Ø´Ø¯Øª Ø§ÛŒØ¯ÙˆÙ„ÙˆØ¬ÛŒ Ù‡Ø§Ú©Ù…ÛŒØª Ø¯Ø± ØªØ¹Ø²Ø§Ø¯Ù‡ Ø¨ÛŒØ´ØªØ± Ø¨Ù‡ Ú†Ø´Ù…ÛŒ Ø¢Ø¯\n",
            "[08:24.480 --> 08:27.480]  Ùˆ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…ÛŒØªÙˆÙ†Ù‡ Ø¢Ø³ÛŒØ¨ Ø´Ø¯ÛŒØ¯ ØªØ§ÛŒÛŒ Ø±Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ùˆ\n",
            "[08:27.480 --> 08:33.480]  Ø®Ø§Ù†Ù… Ù…ØªØ§Ù„Ø¨ÛŒ Ø´Ù…Ø§ ÙÚ©Ø± Ù…ÛŒÚ©Ù†ÛŒØ¯ Ø§Ø² Ø¨ÛŒÙ† Ø±ÙØ¶Ù† Ù‚Ø´Ø± Ù…ØªÙˆØ³Ø· Ø¨Ù‡ Ø®Ø§Ø·Ø± Ø¨Ø­Ø±Ø§Ù† Ù‡Ø§ÛŒ Ø§Ù‚ØªØµØ§Ø¯ÛŒ\n",
            "[08:33.480 --> 08:37.480]  Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ Ø§ÛŒÙ† Ù…Ù†ÛŒÙ‡ Ú©Ù‡ Ù…ØªØ§Ù„Ø¨Ø§Øª Ø§ÛŒÙ† Ù‚Ø´Ø± Ù‡Ù… Ø±Ù†Ú¯ Ù…ÛŒØ¨Ø§Ø²Ù‡ØŸ\n",
            "[08:37.480 --> 08:41.480]  Ø¨Ù‡ Ù†Ø¸Ø± Ù…Ù† Ù…ØªØ§Ù„Ø¨Ø§Øª Ù‚Ø´Ø± Ø¯Ø± ÙˆØ§Ù‚Ø¹ ÛŒÙ‡ ØªØºÛŒÛŒØ± Ù…Ø§Ø­ÛŒØªÛŒ Ù…ÛŒØ¯Ù‡\n",
            "[08:41.480 --> 08:45.480]  ÛŒØ¹Ù†ÛŒ Ø§ÛŒÙ† Ú©Ù‡ ÛŒÚ© Ù…ØªØ§Ù„Ø¨Ø§ØªÛŒ Ú©Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…ØªØ§Ù„Ø¨Ø§Øª Ø¢Ø²Ø§Ø¯ÛŒÛŒ ÛŒØ§ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒÛŒ Ø¨ÙˆØ¯Ù‡\n",
            "[08:45.480 --> 08:51.480]  Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ù‚Ø´Ø± Ù…ØªÙˆØ³Ø· ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù‡ Ùˆ Ø¨Ø¹Ø¯ ÙˆÙ‚ØªÛŒ Ú©Ù‡ Ø·Ø¨Ù‚Ù‡ Ø§Ù‚ØªØµØ§Ø¯ÛŒØ´ ØªØºÛŒÛŒØ± Ù…ÛŒÚ©Ù†Ù‡ Ùˆ Ø³Ù‚ÙˆØ· Ù…ÛŒÚ©Ù†Ù‡\n",
            "[08:51.480 --> 08:54.480]  ÙˆÙ‚ØªÛŒ Ù…ØªØ§Ù„Ø¨Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ù‡Ù… Ø¨Ù‡Ø´ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒØ´Ù‡\n",
            "[08:54.480 --> 09:01.480]  ÛŒØ¹Ù†ÛŒ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¨Ø®ÙˆØ§ÛŒÛŒØ¯ Ø±ÙˆÛŒ Ø§ÛŒÙ† Ø§Ø±Ù‡Ù† Ù…ÙˆØ² Ø±Ùˆ Ù†Ú¯Ø§Ù‡ Ø¨Ú©Ù†ÛŒØ¯ Ù…ØªØ§Ù„Ø¨Ø§ØªØ´ Ù…ÛŒØ±Ù‡ Ø¨Ù‡ Ø³Ù…Øª Ú©Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…Ø´Ø±ÙˆÛŒØªØ´ Ø§ØªÙØ§Ù‚Ø§ Ø¨ÛŒØ´ØªØ± Ù…ÛŒØ´Ù‡\n",
            "[09:01.480 --> 09:07.480]  ØªÙ†Ø´Ù…ÙˆÙ„ÛŒØ´ Ø¨ÛŒØ´ØªØ± Ù…ÛŒØ´Ù‡ Ùˆ Ø­ÛŒØ§ØªÛŒ ØªØ± Ø¨ÙˆØ¯Ù†Ø´ Ø§Ø­Ù†ÛŒØªØ´ Ø¨ÛŒØ´ØªØ± Ù…ÛŒØ´Ù‡ Ùˆ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒØ´Ù‡\n",
            "[09:07.480 --> 09:10.480]  Ø¨Ù‡ Ù…ØªØ§Ù„Ø¨Ø§ØªØ´ Ú©Ù…ØªØ± Ù†Ù…ÛŒØ´Ù‡\n",
            "[09:10.480 --> 09:16.480]  Ø§Ø² Ø·Ø±ÙÛŒ Ø¨Ù‡ Ø®Ø§Ø·Ø± Ø§ÛŒÙ† Ú©Ù‡ Ø¬Ø§ÛŒÚ¯Ø§Ù‡ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ùˆ Ú©Ø±Ø§Ù…Øª Ø§ÙˆÙ† Ø·Ø¨Ù‚Ù‡ Ù…Ø§ ØªÙˆØ³Ø· ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡\n",
            "[09:16.480 --> 09:21.480]  Ø¯ÙˆÚ†Ø§Ø± ØªØºÛŒÛŒØ± Ù‡Ù… Ø´Ø¯Ù‡ Ùˆ Ø§ÛŒÙ† Ù…Ù†Ø¬Ø±Ø¯ Ø§Ù†Ø¨Ø§Ø´Øª Ø´Ø¯Ù† Ø®Ø´Ù…ÛŒ Ù…ÛŒØ´Ù‡\n",
            "[09:21.480 --> 09:28.480]  Ú©Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø§Ù…Ú©Ø§Ù† Ø¯Ø§Ø±Ù‡ Ú©Ù‡ Ø­ØªÛŒ Ø§Ù†Ú¯ÛŒØ²Ù‡ Ù‡Ø§ÛŒ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¬Ø§Ù…Ø¹Ù‡ Ø±Ùˆ ØªØ´Ø¯ÛŒØ¯ Ø¨Ú©Ù†Ù‡\n",
            "[09:28.480 --> 09:33.480]  Ú†ÙˆÙ† Ù‚Ø¨Ù„Ø§ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ù…ØªØ§Ù„Ø¨Ø§Øª ÛŒÚ© Ø³Ø·Ø­ Ø¨Ø§Ù„Ø§Ø¯Ø±Ù‡ Ø±ÙˆØ´Ù† ÙÚ©Ø± Ø¯Ø§Ø±Ø¯\n",
            "[09:33.480 --> 09:41.480]  Ø­Ù‚ÙˆÙ‚ Ø§Ù†Ø³Ø§Ù†ÛŒ Ùˆ Ø¢Ø²Ø§Ø¯ÛŒ Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ø¯Ø§Ø±Ø¯ Ùˆ Ø¨Ø¹Ø¯Ø´ Ø¯Ø±Ø³ÛŒØ¯Ù‡ Ø¨Ù‡ Ù…ØªØ§Ù„Ø¨Ø§Øª Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù…ØªØ±ÛŒ Ø­ÛŒØ§ØªÛŒ ØªØ± Ø§Ù‚ØªØµØ§Ø¯ÛŒ\n",
            "[09:41.480 --> 09:45.480]  Ùˆ Ø¯Ø± Ø§ÛŒÙ† Ø­Ø§Ù„ Ú©Ø±Ø§Ù…ØªØ´ Ù‡Ù… Ø§Ø² Ø¨Ù‡ Ø§ÛŒÙ† ÙˆÙ‚ØªÙ‡ Ù‡Ø³ØªÙ‡\n",
            "[09:45.480 --> 09:56.480]  Ø¯ÙˆÚ†Ø§Ø± Ø¨ØºØ±Ø§Ù† Ø­Ù‚ÙˆÙ‚ÛŒØªÛŒ Ù‡Ù… Ø´Ø¯Ù‡ Ùˆ Ø§ÛŒÙ† Ø§Ø­ØªÙ…Ø§Ù„Ø§ Ù…Ù…Ú©Ù†Ù‡ Ú©Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª Ø§Ù†ØªØ¬Ø§Ø±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø®ÛŒÙ„ÛŒ Ù†ÛŒØ±ÙˆÛŒ Ø´Ø¯ÛŒØ¯ ØªØ±ÛŒ Ø¯Ø§Ø±Ù‡ Ú¯Ø±Ø³ Ø¨Ú©Ù†Ù‡\n",
            "[09:56.480 --> 10:00.480]  ÛŒÚ© Ù†Ú©ØªÙ‡ Ø¯ÛŒÚ¯Ù‡ÛŒ Ú©Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ú¯ÙØªÚ¯Ùˆ ØªÙˆØ¬Ù‡ Ø¬Ø±Ø¨ Ù…ÛŒ Ú©Ù†Ù‡\n",
            "[10:00.480 --> 10:06.480]  Ø§ÙØ¶Ø§Ø¹Ø´ Ù…Ø­Ø§Ø¬Ø±Øª Ùˆ ØªØºÛŒÛŒØ± Ø¬Ø§Ù…Ø¹Ù‡ Ù…Ø­Ø§Ø¬Ø± Ø§ÛŒØ±Ø§Ù†ÛŒ Ø®Ø§Ø±Ø¬ Ø§Ø² Ú©Ø´ÙˆØ±Ù‡ Ú©Ù‡ Ø´Ù…Ø§ Ø¨Ù‡Ø´ Ø§Ø´Ø§Ø±Ù‡ Ú©Ø±Ø¯ÛŒØ¯\n",
            "[10:06.480 --> 10:15.480]  Ø§ÛŒØ±Ø§Ù†ÛŒØ§Ù† Ù…Ø­Ø§Ø¬Ø± Ú©Ù‡ Ø¬Ù…Ø¹ÛŒØªØ´ÙˆÙ† Ø¨Ù‡ Ø´Ú©Ù„ Ú†Ø´Ù…Ú¯ÛŒØ±ÛŒ Ø²ÛŒØ§Ø¯ Ø´Ø¯Ù‡ Ùˆ Ø±ÙˆÙ†Ø¯ ØªØ­ÙˆÙ„Ø§Øª Ø¯Ø§Ø®Ù„ Ø§ÛŒØ±Ø§Ù† ÙÚ©Ø± Ù…ÛŒÚ©Ù†ÛŒØ¯ Ú†Ù‡ ØªØ£Ø«ÛŒØ± Ø®ÙˆØ§Ù‡Ù†Ø¯ Ø¯Ø§Ø´ØªØŸ\n",
            "[10:15.480 --> 10:22.480]  Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø§ÛŒÙ† Ù…Ø³Ø¦Ù„Ù‡ Ù¾ÛŒÙ…Ù‚Ø± Ø¨Ø§Ù‚ÛŒÙ… Ù‡Ø±Ú©ÛŒØ² Ø¨Ù‡ Ù…ØªØ¹Ù„Ù‚Ø§Øª Ø§Ù…Ø±ÙŠÚ©Ø§ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±ÛŒ Ù…Ø§ Ù„Ø§Ø²Ù… Ø¯Ø§Ø±ÛŒÙ…\n",
            "[10:22.480 --> 10:34.480]  Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒ Ø±Ø³Ø¯ Ú©Ù‡ Ø¯Ø± Ø¬Ù…Ø¹Ù‡ Ø¯ÛŒØ§Ø³ÙØ§Ø±Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ ØªÙˆÙ†Ø³Øª Ø¯Ø± ÛŒÚ© ÙˆÙ‚Øª ØªØ®Ù†Ú¯ÙˆÛŒ Ø®ÙˆØ¨ÛŒ Ø¨Ø±Ø§ÛŒ ØµØ¯Ø§ÛŒ Ø¬Ø§Ù…Ø¹ÛŒ Ø¯Ø§Ø®Ù„ Ø§ÛŒØ±Ø§Ù† Ø±Ùˆ Ø¨Ø±Ø³Ù†Ù‡ Ø¨Ù‡ Ø®Ø§Ø±Ø¬ Ø§ÛŒØ±Ø§Ù†\n",
            "[10:34.480 --> 10:44.480]  Ùˆ Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ø¬Ø±Ù… ØªÙˆØ¬Ù‡ Ú©Ø§ÙÛŒ Ø¨Ú©Ù†Ù‡ Ø¯Ø± Ø¬Ø§Ù…Ø¹ÛŒ Ø¬Ø§Ù…Ø¹ÛŒ Ùˆ Ø­ØªÛŒ Ú©Ù‡ ØªÚ©Ø§Ù†Ù‡Ø§ÛŒÛŒ Ø±Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ú©Ù†Ù‡ Ùˆ Ø§ÛŒÙ† Ú©Ù‡ ØªØ±Ø¯ÛŒØ¯ Ø¨Ú©Ù†Ù† Ø¯ÙˆÙ„ØªÛŒ\n",
            "[10:44.480 --> 11:14.480]  Ø§ÛŒÙ† Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ÛŒ\n",
            "[11:14.480 --> 11:19.880]  Ø¨ØªÙˆÙ†Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø¯ÛŒØ§Ø³ØªØ§Ø± Ø¨ÛŒÙ‡ Ú©Ù‡ Ø§ÙˆÙ†Ø¬Ø§ Ù¾ÛŒ ÙˆØ§Ø­Ø¯ÛŒ Ø±Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ú©Ù†Ù‡ Ùˆ Ø¨ØªÙˆÙ†Ù‡ Ù‚Ù„Ø¨Ù‡ Ø¨Ú©Ù†Ù‡\n",
            "[11:19.880 --> 11:27.480]  Ùˆ Ù…Ú©Ø§Ù†ÛŒØ³Ù… Ù‡Ø§ÛŒ Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ø¹Ø¨Ù‚Ø§Ø± Ø§Ù…ÙˆÙ…ÛŒ Ø³ÛŒØ³ØªÙ… Ù‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ø­Ø§Ú©Ù…ÛŒØª Ú©Ù‡ Ø¯Ø±ÙˆÙ‚Øª Ø­ÙØ±Ù‚Ù‡ Ø±Ø§ ØªØ´Ú©ÛŒÙ„ Ù…ÛŒ Ú©Ù†Ù‡\n",
            "[11:27.480 --> 11:31.680]  Ùˆ Ø¨ØªÙˆÙ†Ù‡ Ø§Ø² Ø§ÛŒÙ† Ù…Ù†Ø¹ Ø§Ø¨ÙˆØ± Ø¨Ú©Ù†Ù‡ Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ø²ÛŒØ§Ø¯ Ù…ÛŒØªÙˆÙ†Ù‡ ØªØ£Ø«ÛŒØ± Ú¯Ø°Ø§Ø± Ø¨Ø§Ø´Ù‡\n",
            "[11:31.680 --> 11:38.480]  Ø¨Ø³ÛŒØ§Ø± Ø³Ù¾Ø§Ø³ Ú¯Ø°Ø§Ø±Ù… Ø§Ø² Ø´Ù…Ø§ Ø³Ù‡Ø± Ù…Ø·Ù„Ø¨ÛŒ Ù¾Ø¬ÙˆÛŒØ´Ú¯Ø± Ø¨Ù‡ Ø§Ø®ØªÛŒØ§Ø± Ø¬Ù…Ø¹ÛŒØª Ø¨ÛŒÙ† Ø§Ù„Ù…Ù„Ù„ Ø§Ø² Ù…Ø§Ù„Ù…Ùˆ Ø³ÙˆØ¦Ø¯\n",
            "[11:38.480 --> 11:44.480]  Ø§Ø² Ø·Ø±Ù Ø®ÙˆØ¯Ù… Ùˆ Ø¹Ù„ÛŒ Ø±Ø²Ø§ Ø±ÙˆØ´Ù† ØªÙ‡ÛŒÛŒ Ú©Ù†Ù†Ø¯Ù‡ Ø§ÛŒÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø² Ù‡Ù…Ø±Ø§Ù‡ÛŒ Ø´Ù…Ø§ ØªØ´Ú©Ø± Ù…ÛŒÚ©Ù†Ù…\n",
            "Time consumpution 323.9818706512451s for transcribing\n",
            "Write SRT file to '/content/20636_4_5771510420242174755.srt'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-cd8ca7ae6b75>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mdiarization_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mfinal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiarize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiarization_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from whisper.utils import WriteSRT\n",
        "from whisper import Whisper\n",
        "\n",
        "# Assuming you have a function to extract audio segments and features\n",
        "def extract_features(audio_segment):\n",
        "    # Placeholder for feature extraction logic\n",
        "    # This should return a feature vector for the audio segment\n",
        "    return np.random.rand(10) # Example feature vector\n",
        "\n",
        "# Assuming you have a function to perform clustering\n",
        "def perform_clustering(features, num_speakers):\n",
        "    # Placeholder for clustering logic\n",
        "    # This should return the speaker ID for each audio segment\n",
        "    return [0] * len(features) # Example clustering result\n",
        "\n",
        "# Assuming you have a function to align diarization results with the transcript\n",
        "def diarize_text(transcription, diarization_result):\n",
        "    # Placeholder for diarization result processing\n",
        "    # This should align the diarization results with the transcript\n",
        "    return [] # Example diarization result\n",
        "\n",
        "#@markdown # **Run the model** ğŸš€\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** âš™ï¸\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"Auto detection\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "language = (None if language == \"Auto detection\" else language)\n",
        "verbose = verbose_lut[verbose]\n",
        "\n",
        "\n",
        "if Model.endswith(\".en\") and language not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{language}'; using English instead.\")\n",
        "    language = \"en\"\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(audio_path_local)[0] + \".txt\"\n",
        "\n",
        "# Transcribe the audio\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper.transcribe(\n",
        "    model=whisper_model,\n",
        "    audio=str(audio_path_local),\n",
        "    verbose=True,\n",
        "    task='transcribe',\n",
        "    language=None\n",
        ")\n",
        "toc = time.time()\n",
        "print(f'Time consumed: {toc-tic}s for transcribing')\n",
        "\n",
        "# Extract audio segments and features\n",
        "audio_segments = [] # Placeholder for extracted audio segments\n",
        "features = [extract_features(segment) for segment in audio_segments]\n",
        "\n",
        "# Perform clustering to identify speakers\n",
        "num_speakers = 2 # Example number of speakers\n",
        "clusters = perform_clustering(features, num_speakers)\n",
        "\n",
        "# Align diarization results with the transcript\n",
        "final_result = diarize_text(transcription, clusters)\n",
        "\n",
        "# Write the transcript with speakers to a file\n",
        "lines = []\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    lines.append(line)\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "print(\"Transcript with speakers saved to\", transcript_with_speakers_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "Dw-cx9hNqf2L",
        "outputId": "9356f6dc-f2ff-4646-fddd-45e1a87905da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### /content/20636_4_5771510420242174755.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribe in progress...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'device'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0fe2cffbd25c>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transcribe in progress...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m transcription = whisper.transcribe(\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhisper_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \"\"\"\n\u001b[1;32m    110\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdecode_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fp16\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Performing inference on CPU when CUDA is available\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'device'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from whisper.utils import WriteSRT\n",
        "from whisper import Whisper\n",
        "\n",
        "# Load the Whisper model\n",
        "\n",
        "# Assuming you have a function to extract audio segments and features\n",
        "def extract_features(audio_segment):\n",
        "    # Placeholder for feature extraction logic\n",
        "    # This should return a feature vector for the audio segment\n",
        "    return np.random.rand(10) # Example feature vector\n",
        "\n",
        "# Assuming you have a function to perform clustering\n",
        "def perform_clustering(features, num_speakers):\n",
        "    # Placeholder for clustering logic\n",
        "    # This should return the speaker ID for each audio segment\n",
        "    return [0] * len(features) # Example clustering result\n",
        "\n",
        "# Assuming you have a function to align diarization results with the transcript\n",
        "def diarize_text(transcription, diarization_result):\n",
        "    # Placeholder for diarization result processing\n",
        "    # This should align the diarization results with the transcript\n",
        "    return [] # Example diarization result\n",
        "#@markdown # **Run the model** ğŸš€\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** âš™ï¸\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"Auto detection\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "language = (None if language == \"Auto detection\" else language)\n",
        "verbose = verbose_lut[verbose]\n",
        "\n",
        "\n",
        "if Model.endswith(\".en\") and language not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{language}'; using English instead.\")\n",
        "    language = \"en\"\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "# Your existing code for transcribing with Whisper\n",
        "\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(audio_path_local)[0] + \".txt\"\n",
        "\n",
        "# Transcribe the audio\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper.transcribe(\n",
        "    model=whisper_model,\n",
        "    audio=str(audio_path_local),\n",
        "    verbose=True,\n",
        "    task='transcribe',\n",
        "    language=None\n",
        ")\n",
        "toc = time.time()\n",
        "print(f'Time consumed: {toc-tic}s for transcribing')\n",
        "\n",
        "# Extract audio segments and features\n",
        "audio_segments = [] # Placeholder for extracted audio segments\n",
        "features = [extract_features(segment) for segment in audio_segments]\n",
        "\n",
        "# Perform clustering to identify speakers\n",
        "num_speakers = 2 # Example number of speakers\n",
        "clusters = perform_clustering(features, num_speakers)\n",
        "\n",
        "# Align diarization results with the transcript\n",
        "final_result = diarize_text(transcription, clusters)\n",
        "\n",
        "# Write the transcript with speakers to a file\n",
        "lines = []\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    lines.append(line)\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "print(\"Transcript with speakers saved to\", transcript_with_speakers_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "uL8jCIC4r0hD",
        "outputId": "dee89c04-be30-4020-bb1f-2559edbe0ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### /content/20636_4_5771510420242174755.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### /content/20636_4_5771510420242174755.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribe in progress...\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Persian\n",
            "[00:00.000 --> 00:03.200]  Ø¯Ú©ØªØ± Ø³Ù…Ø§ÛŒÙ‡ ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ù†Ø§Ø³ Ù…ÛŒÚ¯ÙˆÛŒØ¯\n",
            "[00:03.200 --> 00:05.600]  Ø¬Ø§ÛŒÚ¯Ø§Ù‡ Ø²Ù†Ø§Ù† Ø¯Ø± Ø¬Ø§Ù…Ø¹Ù‡ Ø§ÛŒØ±Ø§Ù†ÛŒ\n",
            "[00:05.600 --> 00:10.080]  Ø¨Ø¹Ø¯ Ø§Ø² Ø¬Ù†Ø¨Ø´ Ù‡Ø§ÛŒ Ø³Ø§Ù„Ù‡ 1400 Ùˆ 1ØŒ 2ØŒ 4 ØªØºÛŒÛŒØ± Ùˆ ØªØºÙˆÙ„ Ø´Ø¯Ù‡\n",
            "[00:16.240 --> 00:20.080]  Ø³Ù„Ø§Ù… Ù…Ù† Ø¨ÛŒØª Ø¢Ø°Ø±ÛŒ Ø¨Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¯ÛŒØ¯Ú©Ø§ Ù‡Ù…Ø±Ø§Ù‡ Ø´Ù…Ø§ Ù‡Ø³ØªÙ…\n",
            "[00:22.200 --> 00:25.480]  Ø®Ø§Ù†Ù… ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¨Ù‡ Ø®Ø¨Ø± Ø¢Ù†Ù„Ø§ÛŒÙ† Ú¯ÙØªÙ‡ Ø§Ø² Ø¯Ù‡Ù‡ Ù‡ÙØªØ§Ø¯\n",
            "[00:25.480 --> 00:28.000]  Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡\n",
            "[00:28.000 --> 00:32.000]  Ù…Ø§ ÛŒÚ© Ø¬Ø§Ù…Ø¹Ù‡ Ù…Ø±Ø¯ Ø³Ø§Ù„Ø§Ø± Ø±Ø§ Ø¯Ø§Ø´ØªÛŒÙ… Ú©Ù‡ Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø´Ú©Ù„ Ù…Ø´Ø®ØµÛŒ\n",
            "[00:32.000 --> 00:34.240]  Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø²Ù†Ø§Ù† Ù…ÛŒØ±Ø³ÛŒØ¯\n",
            "[00:34.240 --> 00:38.320]  Ø§Ù…Ø§ Ø¯Ø± Ø³Ø§Ù„ 1400 Ùˆ 2 ÛŒÚ© Ø¨Ø§Ø±Ù‡ Ø¨Ø§ Ø¬Ù…Ø¹ÛŒØªÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒØ´ÙˆÛŒÙ…\n",
            "[00:38.320 --> 00:41.680]  Ú©Ù‡ Ø¨Ù‡ Ø¹Ø±Øµ Ø¨Ø±Ø¯Ù† ÛŒÚ© Ø³Ø§Ù† Ø²Ù† Ùˆ Ù…Ø±Ø¯ Ø¨Ø§ÙˆØ±Ø¯Ø§Ø±Ù†Ø¯\n",
            "[00:41.680 --> 00:45.040]  Ø­Ù‚ ØªÙ„Ø§Ù‚ Ø¨Ø±Ø§ÛŒ Ø²Ù†Ø§Ù† Ù…ÙˆØ±Ø¯ Ù¾Ø°ÛŒØ±Ø´ Ù‚Ø±Ø§Ø± Ù…ÛŒÚ¯ÛŒØ±Ø¯\n",
            "[00:45.040 --> 00:47.480]  Ùˆ Ù¾Ø°ÛŒØ±Ø´ Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ ÙˆØ§Ù„Ø¯ÛŒÙ†\n",
            "[00:47.480 --> 00:50.200]  Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ±Ø§Øª ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø¨Ø§Ù„Ø§ Ø±ÙØªØ³Øª\n",
            "[00:50.240 --> 00:52.720]  Ø¨Ù‡ Ø§Ø¹ØªÙ‚Ø§Ø¯ ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø§ÛŒÙ† ØªØºÛŒÛŒØ±Ø§Øª Ù†Ø´Ø§Ù†Ø¯Ù‡Ù†Ø¯Ù‡\n",
            "[00:52.720 --> 00:57.120]  ØªØ³Ø§Ù‡Ù„ Ø¨ÛŒÙ†Ú¯Ø±ÙˆÙ‡ÛŒ Ùˆ Ø¨ÛŒÙ† Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ Ø¯Ø±Ù…ÛŒØ§Ù† Ù…Ø±Ø¯Ù… Ø§Ø³Øª\n",
            "[00:57.120 --> 01:01.040]  Ø¯Ø± Ø¯ÛŒØ¯Ú¯Ø§Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¬Ø²ÛŒØ§Øª Ú¯ÙØªÚ¯ÙˆÛŒ Ø³Ù…ÛŒØª ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ\n",
            "[01:01.040 --> 01:06.680]  Ø¨Ø§ Ø³Ù‡Ø± Ù…ØªÙ„Ø¨ÛŒ Ù¾Ø¬ÙˆÙ‡Ø´Ú©Ø± Ø¨Ù‡Ø¯Ø§Ø´Øª Ø¬Ù…Ø¹ÛŒØª Ø¨ÛŒÙ† Ø§Ù„Ù…Ù„Ù„ Ø§Ø² Ø³ÙˆØ¦Ø¯ Ù‡Ù…Ø±Ø§Ù‡ Ù…ÛŒØ´ÙˆÛŒÙ…\n",
            "[01:11.680 --> 01:14.720]  Ø®Ø§Ù† Ù…ØªÙ„Ø¨ÛŒ Ù¾ÛŒØ´ Ø§Ø² Ø§ÛŒÙ† Ú©Ù‡ Ù…Ù† Ù¾Ø±Ø³Ø´Ùˆ Ù‡Ù… Ù…Ø·Ø±Ø­ Ú©Ù†Ù…\n",
            "[01:14.720 --> 01:19.200]  Ø®ÙˆØ§Ù‡Ø´ Ù…ÛŒÚ©Ù†Ù… Ø®Ù„Ø§ØµÙ‡ Ø§ÛŒ Ø§Ø² Ø¹Ø±Ø¶ÛŒØ§Ø¨ÛŒ Ù‡Ø§ÛŒ Ø¯Ú©ØªØ± Ø³Ù…ÛŒØª ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ\n",
            "[01:19.200 --> 01:24.600]  Ø§Ø² ØªØ­ÙˆÙ„Ø§Øª Ø¬Ø§Ù…Ø¹Ù‡ Ø§ÛŒØ±Ø§Ù† Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ø¹ØªØ±Ø§Ø²Ø§Øª 1401 Ø±Ùˆ Ø¨Ø±Ù…ÙˆÙ† Ù…Ø±ÙˆØ± Ú©Ù†ÛŒØ¯\n",
            "[01:24.600 --> 01:26.360]  Ø¨Ø¹Ø¯ ÙˆØ§Ø±Ø¯ Ùˆ Ø¬Ø²ÛŒØ§Øª Ø¨Ø´ÛŒÙ…\n",
            "[01:26.360 --> 01:28.680]  Ø¨Ø§ ØµØ¯Ø§ ÙÙ‚Ø· Ø®Ø¯Ù…Øª Ø´Ù…Ø§ Ø¨Ø¨ÛŒÙ†ÛŒØ¯\n",
            "[01:28.680 --> 01:31.720]  Ø§ÛŒÙ† Ø¨ØºØ§Ù„Ø§ Ø¨Ù‡ Ù†Ø¸Ø±Ù…Øª ÙÙ‚Ø· Ù†ÙØ¹Ù‡ Ø®ÛŒÙ„ÛŒ Ø¬Ø§Ù„Ø¨ÛŒ Ø¯Ø§Ø´Øª\n",
            "[01:31.720 --> 01:34.120]  Ø¨Ù‡ Ø·ÙˆÙ„ Ù…Ø´Ø§Ù‚ØµÙ… Ù…Ù‡Ù…ØªØ±ÛŒÙ† Ú†ÛŒØ²ÛŒ Ú©Ù‡\n",
            "[01:34.120 --> 01:37.560]  ØªØºÛŒÛŒØ±Ø§Øª Ú©Ù‡ Ø¯Ø± ÙˆÙ‚Øª Ø§ÛŒØ´ÙˆÙ† Ø§Ø´Ø§Ø±Ù‡ Ú©Ø±Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ø¨Ù‡Ø´\n",
            "[01:37.560 --> 01:41.600]  Ø§ÛŒÙ†ÛŒ Ú©Ù‡ Ø¬Ø§Ù…Ø¹Ù‡ Ø¯Ø± ÙˆÙ‚Øª ØªØ¹Ø§Ù…Ù„ Ú¯Ø±ÙˆÙ‡ Ù‡Ø§ Ùˆ Ø¨Ù‚Ø´ Ùˆ Ø¨Ù‚Ø´ Ùˆ Ù…Ø®ØªÙ„Ù\n",
            "[01:41.600 --> 01:43.800]  Ø¨Ù‡ Ø§ÛŒÚ© ØªØ³Ø§Ù‡Ù„ÛŒ Ø±Ùˆ ØªØ¬Ø±Ø¨Ù‡ Ù…ÛŒÚ©Ù†Ù‡\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming necessary imports are done at the beginning of your script\n",
        "# For example:\n",
        "# from some_library import pipeline, diarize_text\n",
        "\n",
        "# Your existing code for setting parameters and paths\n",
        "# Your existing code for setting parameters and paths\n",
        "language = (None if language == \"Auto detection\" else language)\n",
        "\n",
        "# Safely access the verbose_lut dictionary using .get()\n",
        "verbose = verbose_lut.get(verbose, verbose)\n",
        "\n",
        "if Model.endswith(\".en\") and language not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{language}'; using English instead.\")\n",
        "    language = \"en\"\n",
        "\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(filepath)[0] + \".txt\"\n",
        "print(\"audio local path:\", audio_path_local)\n",
        "\n",
        "import time\n",
        "\n",
        "# Transcribe\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper.transcribe(\n",
        "    model=whisper_model,\n",
        "    audio=str(audio_path_local),\n",
        "    verbose=verbose,\n",
        "    task=task,\n",
        "    language=language\n",
        ")\n",
        "# Time consumed\n",
        "toc = time.time()\n",
        "print(f'Time consumed {toc-tic}s for transcribing')\n",
        "\n",
        "# Write SRT file\n",
        "from whisper.utils import WriteSRT\n",
        "with open(subtitle_file, \"w\", encoding=\"utf-8\") as srt:\n",
        "    writer = WriteSRT(audio_path_local.parent)\n",
        "    writer.write_result(transcription, srt)\n",
        "print(f\"Write SRT file to '{subtitle_file}'\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Check if pipeline is callable before using it\n",
        "if callable(pipeline):\n",
        "    diarization_result = pipeline(audio_path_local)\n",
        "    final_result = diarize_text(transcription, diarization_result)\n",
        "else:\n",
        "    print(\"Error: pipeline is not callable. Please ensure it is correctly defined and initialized.\")\n",
        "    # Handle the error appropriately, e.g., by exiting the script or skipping the diarization step\n",
        "\n",
        "lines = list()\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    print(f\"{line}\")\n",
        "    lines.append(line)\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "display(Markdown(f\"**Transcript file created: {transcript_with_speakers_file}**\"))"
      ],
      "metadata": {
        "id": "Un2zHXulsxQm",
        "outputId": "896a33cd-c811-49c0-9874-c144f64dcf55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### /content/20636_4_5771510420242174755.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio local path: /content/20636_4_5771510420242174755.wav\n",
            "Transcribe in progress...\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Persian\n",
            "[00:00.000 --> 00:03.200]  Ø¯Ú©ØªØ± Ø³Ù…Ø§ÛŒÙ‡ ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ù†Ø§Ø³ Ù…ÛŒÚ¯ÙˆÛŒØ¯\n",
            "[00:03.200 --> 00:05.600]  Ø¬Ø§ÛŒÚ¯Ø§Ù‡ Ø²Ù†Ø§Ù† Ø¯Ø± Ø¬Ø§Ù…Ø¹Ù‡ Ø§ÛŒØ±Ø§Ù†ÛŒ\n",
            "[00:05.600 --> 00:10.080]  Ø¨Ø¹Ø¯ Ø§Ø² Ø¬Ù†Ø¨Ø´ Ù‡Ø§ÛŒ Ø³Ø§Ù„Ù‡ 1400 Ùˆ 1ØŒ 2ØŒ 4 ØªØºÛŒÛŒØ± Ùˆ ØªØºÙˆÙ„ Ø´Ø¯Ù‡\n",
            "[00:16.240 --> 00:20.080]  Ø³Ù„Ø§Ù… Ù…Ù† Ø¨ÛŒØª Ø¢Ø°Ø±ÛŒ Ø¨Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¯ÛŒØ¯Ú©Ø§ Ù‡Ù…Ø±Ø§Ù‡ Ø´Ù…Ø§ Ù‡Ø³ØªÙ…\n",
            "[00:22.200 --> 00:25.480]  Ø®Ø§Ù†Ù… ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¨Ù‡ Ø®Ø¨Ø± Ø¢Ù†Ù„Ø§ÛŒÙ† Ú¯ÙØªÙ‡ Ø§Ø² Ø¯Ù‡Ù‡ Ù‡ÙØªØ§Ø¯\n",
            "[00:25.480 --> 00:28.000]  Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡\n",
            "[00:28.000 --> 00:32.000]  Ù…Ø§ ÛŒÚ© Ø¬Ø§Ù…Ø¹Ù‡ Ù…Ø±Ø¯ Ø³Ø§Ù„Ø§Ø± Ø±Ø§ Ø¯Ø§Ø´ØªÛŒÙ… Ú©Ù‡ Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø´Ú©Ù„ Ù…Ø´Ø®ØµÛŒ\n",
            "[00:32.000 --> 00:34.240]  Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø²Ù†Ø§Ù† Ù…ÛŒØ±Ø³ÛŒØ¯\n",
            "[00:34.240 --> 00:38.320]  Ø§Ù…Ø§ Ø¯Ø± Ø³Ø§Ù„ 1400 Ùˆ 2 ÛŒÚ© Ø¨Ø§Ø±Ù‡ Ø¨Ø§ Ø¬Ù…Ø¹ÛŒØªÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒØ´ÙˆÛŒÙ…\n",
            "[00:38.320 --> 00:41.680]  Ú©Ù‡ Ø¨Ù‡ Ø¹Ø±Øµ Ø¨Ø±Ø¯Ù† ÛŒÚ© Ø³Ø§Ù† Ø²Ù† Ùˆ Ù…Ø±Ø¯ Ø¨Ø§ÙˆØ±Ø¯Ø§Ø±Ù†Ø¯\n",
            "[00:41.680 --> 00:45.040]  Ø­Ù‚ ØªÙ„Ø§Ù‚ Ø¨Ø±Ø§ÛŒ Ø²Ù†Ø§Ù† Ù…ÙˆØ±Ø¯ Ù¾Ø°ÛŒØ±Ø´ Ù‚Ø±Ø§Ø± Ù…ÛŒÚ¯ÛŒØ±Ø¯\n",
            "[00:45.040 --> 00:47.480]  Ùˆ Ù¾Ø°ÛŒØ±Ø´ Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ ÙˆØ§Ù„Ø¯ÛŒÙ†\n",
            "[00:47.480 --> 00:50.200]  Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ±Ø§Øª ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø¨Ø§Ù„Ø§ Ø±ÙØªØ³Øª\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-fd77d6136fd5>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transcribe in progress...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m transcription = whisper.transcribe(\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhisper_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mneeds_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;31m# call the main sampling loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_speech_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mlogits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    202\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2544\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m         )\n\u001b[0;32m-> 2546\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from whisper.utils import WriteSRT\n",
        "import whisper\n",
        "\n",
        "# Load the Whisper model\n",
        "\n",
        "# Assuming you have a function to extract audio segments and features\n",
        "def extract_features(audio_segment):\n",
        "    # Placeholder for feature extraction logic\n",
        "    # This should return a feature vector for the audio segment\n",
        "    return np.random.rand(10) # Example feature vector\n",
        "\n",
        "# Assuming you have a function to perform clustering\n",
        "def perform_clustering(features, num_speakers):\n",
        "    # Placeholder for clustering logic\n",
        "    # This should return the speaker ID for each audio segment\n",
        "    return [0] * len(features) # Example clustering result\n",
        "\n",
        "# Assuming you have a function to align diarization results with the transcript\n",
        "def diarize_text(transcription, diarization_result):\n",
        "    # Placeholder for diarization result processing\n",
        "    # This should align the diarization results with the transcript\n",
        "    return [] # Example diarization result\n",
        "\n",
        "# Your existing code for transcribing with Whisper\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(filepath)[0] + \".txt\"\n",
        "print(\"audio local path:\", audio_path_local)\n",
        "\n",
        "# Transcribe the audio\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper_model.transcribe(\n",
        "    audio=str(audio_path_local),\n",
        "    verbose=True,\n",
        "    task='transcribe',\n",
        "    language=None\n",
        ")\n",
        "toc = time.time()\n",
        "print(f'Time consumed: {toc-tic}s for transcribing')\n",
        "\n",
        "# Extract audio segments and features\n",
        "audio_segments = [] # Placeholder for extracted audio segments\n",
        "features = [extract_features(segment) for segment in audio_segments]\n",
        "\n",
        "# Perform clustering to identify speakers\n",
        "num_speakers = 2 # Example number of speakers\n",
        "clusters = perform_clustering(features, num_speakers)\n",
        "\n",
        "# Align diarization results with the transcript\n",
        "final_result = diarize_text(transcription, clusters)\n",
        "\n",
        "# Write the transcript with speakers to a file\n",
        "lines = []\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    lines.append(line)\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "print(\"Transcript with speakers saved to\", transcript_with_speakers_file)"
      ],
      "metadata": {
        "id": "bo3Bd07ztRA6",
        "outputId": "89e2c5f0-5d59-449c-d3ba-a38f9387ec4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio local path: /content/20636_4_5771510420242174755.wav\n",
            "Transcribe in progress...\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Persian\n",
            "[00:00.000 --> 00:03.200]  Ø¯Ú©ØªØ± Ø³Ù…Ø§ÛŒÙ‡ ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ù†Ø§Ø³ Ù…ÛŒÚ¯ÙˆÛŒØ¯\n",
            "[00:03.200 --> 00:05.600]  Ø¬Ø§ÛŒÚ¯Ø§Ù‡ Ø²Ù†Ø§Ù† Ø¯Ø± Ø¬Ø§Ù…Ø¹Ù‡ Ø§ÛŒØ±Ø§Ù†ÛŒ\n",
            "[00:05.600 --> 00:10.080]  Ø¨Ø¹Ø¯ Ø§Ø² Ø¬Ù†Ø¨Ø´ Ù‡Ø§ÛŒ Ø³Ø§Ù„Ù‡ 1400 Ùˆ 1ØŒ 2ØŒ 4 ØªØºÛŒÛŒØ± Ùˆ ØªØºÙˆÙ„ Ø´Ø¯Ù‡\n",
            "[00:16.240 --> 00:20.080]  Ø³Ù„Ø§Ù… Ù…Ù† Ø¨ÛŒØª Ø¢Ø°Ø±ÛŒ Ø¨Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¯ÛŒØ¯Ú©Ø§ Ù‡Ù…Ø±Ø§Ù‡ Ø´Ù…Ø§ Ù‡Ø³ØªÙ…\n",
            "[00:22.200 --> 00:25.480]  Ø®Ø§Ù†Ù… ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø¨Ù‡ Ø®Ø¨Ø± Ø¢Ù†Ù„Ø§ÛŒÙ† Ú¯ÙØªÙ‡ Ø§Ø² Ø¯Ù‡Ù‡ Ù‡ÙØªØ§Ø¯\n",
            "[00:25.480 --> 00:28.000]  Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù¾ÛŒÙ…Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡\n",
            "[00:28.000 --> 00:32.000]  Ù…Ø§ ÛŒÚ© Ø¬Ø§Ù…Ø¹Ù‡ Ù…Ø±Ø¯ Ø³Ø§Ù„Ø§Ø± Ø±Ø§ Ø¯Ø§Ø´ØªÛŒÙ… Ú©Ù‡ Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ Ø´Ú©Ù„ Ù…Ø´Ø®ØµÛŒ\n",
            "[00:32.000 --> 00:34.240]  Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø²Ù†Ø§Ù† Ù…ÛŒØ±Ø³ÛŒØ¯\n",
            "[00:34.240 --> 00:38.320]  Ø§Ù…Ø§ Ø¯Ø± Ø³Ø§Ù„ 1400 Ùˆ 2 ÛŒÚ© Ø¨Ø§Ø±Ù‡ Ø¨Ø§ Ø¬Ù…Ø¹ÛŒØªÛŒ Ù…ÙˆØ§Ø¬Ù‡ Ù…ÛŒØ´ÙˆÛŒÙ…\n",
            "[00:38.320 --> 00:41.680]  Ú©Ù‡ Ø¨Ù‡ Ø¹Ø±Øµ Ø¨Ø±Ø¯Ù† ÛŒÚ© Ø³Ø§Ù† Ø²Ù† Ùˆ Ù…Ø±Ø¯ Ø¨Ø§ÙˆØ±Ø¯Ø§Ø±Ù†Ø¯\n",
            "[00:41.680 --> 00:45.040]  Ø­Ù‚ ØªÙ„Ø§Ù‚ Ø¨Ø±Ø§ÛŒ Ø²Ù†Ø§Ù† Ù…ÙˆØ±Ø¯ Ù¾Ø°ÛŒØ±Ø´ Ù‚Ø±Ø§Ø± Ù…ÛŒÚ¯ÛŒØ±Ø¯\n",
            "[00:45.040 --> 00:47.480]  Ùˆ Ù¾Ø°ÛŒØ±Ø´ Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ ÙˆØ§Ù„Ø¯ÛŒÙ†\n",
            "[00:47.480 --> 00:50.200]  Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ±Ø§Øª ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø¨Ø§Ù„Ø§ Ø±ÙØªØ³Øª\n",
            "[00:50.240 --> 00:52.720]  Ø¨Ù‡ Ø§Ø¹ØªÙ‚Ø§Ø¯ ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ Ø§ÛŒÙ† ØªØºÛŒÛŒØ±Ø§Øª Ù†Ø´Ø§Ù†Ø¯Ù‡Ù†Ø¯Ù‡\n",
            "[00:52.720 --> 00:57.120]  ØªØ³Ø§Ù‡Ù„ Ø¨ÛŒÙ†Ú¯Ø±ÙˆÙ‡ÛŒ Ùˆ Ø¨ÛŒÙ† Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ Ø¯Ø±Ù…ÛŒØ§Ù† Ù…Ø±Ø¯Ù… Ø§Ø³Øª\n",
            "[00:57.120 --> 01:01.040]  Ø¯Ø± Ø¯ÛŒØ¯Ú¯Ø§Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¬Ø²ÛŒØ§Øª Ú¯ÙØªÚ¯ÙˆÛŒ Ø³Ù…ÛŒØª ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ\n",
            "[01:01.040 --> 01:06.680]  Ø¨Ø§ Ø³Ù‡Ø± Ù…ØªÙ„Ø¨ÛŒ Ù¾Ø¬ÙˆÙ‡Ø´Ú©Ø± Ø¨Ù‡Ø¯Ø§Ø´Øª Ø¬Ù…Ø¹ÛŒØª Ø¨ÛŒÙ† Ø§Ù„Ù…Ù„Ù„ Ø§Ø² Ø³ÙˆØ¦Ø¯ Ù‡Ù…Ø±Ø§Ù‡ Ù…ÛŒØ´ÙˆÛŒÙ…\n",
            "[01:11.680 --> 01:14.720]  Ø®Ø§Ù† Ù…ØªÙ„Ø¨ÛŒ Ù¾ÛŒØ´ Ø§Ø² Ø§ÛŒÙ† Ú©Ù‡ Ù…Ù† Ù¾Ø±Ø³Ø´Ùˆ Ù‡Ù… Ù…Ø·Ø±Ø­ Ú©Ù†Ù…\n",
            "[01:14.720 --> 01:19.200]  Ø®ÙˆØ§Ù‡Ø´ Ù…ÛŒÚ©Ù†Ù… Ø®Ù„Ø§ØµÙ‡ Ø§ÛŒ Ø§Ø² Ø¹Ø±Ø¶ÛŒØ§Ø¨ÛŒ Ù‡Ø§ÛŒ Ø¯Ú©ØªØ± Ø³Ù…ÛŒØª ØªÙˆÙ‡ÛŒØ¯Ù„Ùˆ\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-b5b8ad649751>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transcribe in progress...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m transcription = whisper_model.transcribe(\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mneeds_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;31m# call the main sampling loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_speech_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mlogits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mqkv_attention\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_ctx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Download the subtitle file** ğŸ†\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "display(Markdown(f\"**Download Subtitle: {subtitle_file}**\"))\n",
        "files.download(subtitle_file)\n",
        "\n",
        "display(Markdown(f\"**Download Transcript With Speakers: {transcript_with_speakers_file}**\"))\n",
        "files.download(transcript_with_speakers_file)\n",
        "\n",
        "display(Markdown(f\"**Download Audio: {filepath}**\"))\n",
        "files.download(filepath)"
      ],
      "metadata": {
        "id": "yBGKpOjFHLTx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "outputId": "fec6f886-ec7e-4f92-d11c-de20a1c90586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Download Subtitle: /content/20636_4_5771510420242174755.srt**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d0ed7327-4471-45e3-a102-2da9ad11111f\", \"20636_4_5771510420242174755.srt\", 19617)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Download Transcript With Speakers: /content/20636_4_5771510420242174755.txt**"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: /content/20636_4_5771510420242174755.txt",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ded2a3815ba0>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"**Download Transcript With Speakers: {transcript_with_speakers_file}**\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript_with_speakers_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"**Download Audio: {filepath}**\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/20636_4_5771510420242174755.txt"
          ]
        }
      ]
    }
  ]
}