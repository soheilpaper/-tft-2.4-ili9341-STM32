{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soheilpaper/-tft-2.4-ili9341-STM32/blob/master/youtube_subtitle/whisper_podcast_subtitles_with_speakers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ÁîüÊàêApple PodCastÂ≠óÂπï\n",
        "\n"
      ],
      "metadata": {
        "id": "73JHCOCS99hl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "mBUm1pmC90Mk",
        "outputId": "89b7d792-fc35-4085-a29e-6f87ce9d4bf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-7599fce7-50cf-846d-6293-33be61f2c71d)\n",
            "Thu Apr 18 16:25:17 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0              28W /  70W |  15101MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Check GPU type** üïµÔ∏è\n",
        "\n",
        "#@markdown The type of GPU you get assigned in your Colab session defined the speed at which the video will be transcribed.\n",
        "#@markdown The higher the number of floating point operations per second (FLOPS), the faster the transcription.\n",
        "#@markdown But even the least powerful GPU available in Colab is able to run any Whisper model.\n",
        "#@markdown Make sure you've selected `GPU` as hardware accelerator for the Notebook (Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator).\n",
        "\n",
        "#@markdown |  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "#@markdown |:------:|:----------:|:--------------:|:------------------:|\n",
        "#@markdown |  T4    |    16 GB   |       8.1      |         Free       |\n",
        "#@markdown | P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "#@markdown | V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Factory reset your Notebook's runtime if you want to get assigned a new GPU.**\n",
        "\n",
        "!nvidia-smi -L\n",
        "\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **ÈÖçÁΩÆWhisper/Setup Whisper** üèóÔ∏è\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!pip install git+https://github.com/yinruiqing/pyannote-whisper.git\n",
        "!pip install requests beautifulsoup4 pyannote.audio pydub\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "import whisper\n",
        "import numpy as np\n",
        "import warnings\n",
        "import shutil\n",
        "from IPython.display import Markdown\n",
        "import os\n",
        "import requests\n",
        "import re\n",
        "from pydub import AudioSegment\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "from pathlib import Path\n",
        "from pyannote.audio import Pipeline\n",
        "from pyannote_whisper.utils import diarize_text\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "\n",
        "print('Whisper installedÔºåplease execute next cell')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMRtV2Lw_BHU",
        "outputId": "3ce611c0-82b2-443b-c92f-b8e0603ab62e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/yinruiqing/pyannote-whisper.git\n",
            "  Cloning https://github.com/yinruiqing/pyannote-whisper.git to /tmp/pip-req-build-2jqqwjdj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/yinruiqing/pyannote-whisper.git /tmp/pip-req-build-2jqqwjdj\n",
            "  Resolved https://github.com/yinruiqing/pyannote-whisper.git to commit bb55b6547d611de04f07fafc6c149f51ae3ca5a3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools==59.5.0 in /usr/local/lib/python3.10/dist-packages (from pyannote-whisper==1.0) (59.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyannote-whisper==1.0) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pyannote-whisper==1.0) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from pyannote-whisper==1.0) (0.17.1+cu121)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (from pyannote-whisper==1.0) (20231117)\n",
            "Requirement already satisfied: pyannote.audio in /usr/local/lib/python3.10/dist-packages (from pyannote-whisper==1.0) (3.1.1)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from pyannote-whisper==1.0) (0.12.1)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper->pyannote-whisper==1.0) (2.2.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper->pyannote-whisper==1.0) (0.58.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper->pyannote-whisper==1.0) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper->pyannote-whisper==1.0) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper->pyannote-whisper==1.0) (0.6.0)\n",
            "Requirement already satisfied: asteroid-filterbanks>=0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (0.4.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (0.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (0.20.3)\n",
            "Requirement already satisfied: lightning>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (2.2.2)\n",
            "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (2.3.0)\n",
            "Requirement already satisfied: pyannote.core>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (5.0.0)\n",
            "Requirement already satisfied: pyannote.database>=5.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (5.1.0)\n",
            "Requirement already satisfied: pyannote.metrics>=3.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (3.2.1)\n",
            "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (3.0.1)\n",
            "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (2.5.0)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (13.7.1)\n",
            "Requirement already satisfied: semver>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (3.0.2)\n",
            "Requirement already satisfied: speechbrain>=0.5.14 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (1.0.0)\n",
            "Requirement already satisfied: tensorboardX>=2.6 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (2.6.2.2)\n",
            "Requirement already satisfied: torch-audiomentations>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (0.11.1)\n",
            "Requirement already satisfied: torchaudio>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio->pyannote-whisper==1.0) (1.3.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->pyannote-whisper==1.0) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->pyannote-whisper==1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->pyannote-whisper==1.0) (12.4.127)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->pyannote-whisper==1.0) (9.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->pyannote-whisper==1.0) (2.22)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio->pyannote-whisper==1.0) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio->pyannote-whisper==1.0) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio->pyannote-whisper==1.0) (24.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote.audio->pyannote-whisper==1.0) (0.11.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote.audio->pyannote-whisper==1.0) (2.2.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio->pyannote-whisper==1.0) (4.9.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio->pyannote-whisper==1.0) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio->pyannote-whisper==1.0) (1.11.4)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote.audio->pyannote-whisper==1.0) (2.0.3)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote.audio->pyannote-whisper==1.0) (0.12.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (1.2.2)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (0.6.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (3.7.1)\n",
            "Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.pipeline>=3.0.1->pyannote.audio->pyannote-whisper==1.0) (3.6.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio->pyannote-whisper==1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio->pyannote-whisper==1.0) (2.16.1)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio->pyannote-whisper==1.0) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio->pyannote-whisper==1.0) (1.4.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio->pyannote-whisper==1.0) (0.1.99)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pyannote-whisper==1.0) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.6->pyannote.audio->pyannote-whisper==1.0) (3.20.3)\n",
            "Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (0.2.7)\n",
            "Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (0.10.1)\n",
            "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (1.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pyannote-whisper==1.0) (2.1.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper->pyannote-whisper==1.0) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper->pyannote-whisper==1.0) (2023.12.25)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->torch->pyannote-whisper==1.0) (3.9.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (3.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (1.0.8)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio->pyannote-whisper==1.0) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (2.8.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->pyannote-whisper==1.0) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->pyannote-whisper==1.0) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->pyannote-whisper==1.0) (2.0.29)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio->pyannote-whisper==1.0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio->pyannote-whisper==1.0) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio->pyannote-whisper==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio->pyannote-whisper==1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio->pyannote-whisper==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio->pyannote-whisper==1.0) (2024.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (3.4.0)\n",
            "Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.10/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio->pyannote-whisper==1.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio->pyannote-whisper==1.0) (1.5.4)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml->speechbrain>=0.5.14->pyannote.audio->pyannote-whisper==1.0) (0.18.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->pyannote-whisper==1.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->pyannote-whisper==1.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->pyannote-whisper==1.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->pyannote-whisper==1.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->pyannote-whisper==1.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->pyannote-whisper==1.0) (4.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->pyannote-whisper==1.0) (1.3.3)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio->pyannote-whisper==1.0) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio->pyannote-whisper==1.0) (1.16.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=0.5.14->pyannote.audio->pyannote-whisper==1.0) (0.2.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio->pyannote-whisper==1.0) (3.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pyannote.audio in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: asteroid-filterbanks>=0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (0.4.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (0.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (0.20.3)\n",
            "Requirement already satisfied: lightning>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (2.2.2)\n",
            "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (2.3.0)\n",
            "Requirement already satisfied: pyannote.core>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (5.0.0)\n",
            "Requirement already satisfied: pyannote.database>=5.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (5.1.0)\n",
            "Requirement already satisfied: pyannote.metrics>=3.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (3.2.1)\n",
            "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (3.0.1)\n",
            "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (2.5.0)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (13.7.1)\n",
            "Requirement already satisfied: semver>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (3.0.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (0.12.1)\n",
            "Requirement already satisfied: speechbrain>=0.5.14 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (1.0.0)\n",
            "Requirement already satisfied: tensorboardX>=2.6 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (2.6.2.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (2.2.1+cu121)\n",
            "Requirement already satisfied: torch-audiomentations>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (0.11.1)\n",
            "Requirement already satisfied: torchaudio>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio) (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (1.25.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->pyannote.audio) (24.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote.audio) (0.11.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote.audio) (2.2.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.11.4)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.0.3)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.12.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.2.2)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.6.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.7.1)\n",
            "Requirement already satisfied: sympy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.12)\n",
            "Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.pipeline>=3.0.1->pyannote.audio) (3.6.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio) (2.16.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->pyannote.audio) (1.16.0)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio) (1.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio) (1.4.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio) (0.1.99)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.6->pyannote.audio) (3.20.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pyannote.audio) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->pyannote.audio) (12.4.127)\n",
            "Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.2.7)\n",
            "Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.10.1)\n",
            "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (1.2.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (3.9.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (3.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.58.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.8.0->lightning>=2.0.1->pyannote.audio) (59.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.8.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.29)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.4.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio) (1.3.0)\n",
            "Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.10/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio) (1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml->speechbrain>=0.5.14->pyannote.audio) (0.18.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->pyannote.audio) (2.1.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (4.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.3.3)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.16.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=0.5.14->pyannote.audio) (0.2.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.0.3)\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ubj8usmm\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ubj8usmm\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.6.0)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.4)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Whisper installedÔºåplease execute next cell\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Model selection** üß†\n",
        "\n",
        "#@markdown As of the first public release, there are 4 pre-trained options to play with:\n",
        "\n",
        "#@markdown |  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "#@markdown |:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "#@markdown |  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "#@markdown |  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "#@markdown | small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "#@markdown | medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "#@markdown | large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Model = 'tiny' #@param ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large', 'large-v2','large-v3']\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the model.**\n",
        "\n",
        "# load pyannote speaker-diarization\n",
        "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\",\n",
        "                                            use_auth_token=\"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\")\n",
        "\n",
        "whisper_model = whisper.load_model(Model)\n",
        "\n",
        "if Model in whisper.available_models():\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is selected.**\"\n",
        "    ))\n",
        "else:\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is no longer available.** Please select one of the following: - {' - '.join(whisper.available_models())}\"\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nPV9yHeqARiK",
        "outputId": "5fc6f84a-6a0b-4cd5-90ac-0b7c9dd81d4b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Could not download 'pyannote/speaker-diarization' pipeline.\n",
            "It might be because the pipeline is private or gated so make\n",
            "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
            "create your access token and retry with:\n",
            "\n",
            "   >>> Pipeline.from_pretrained('pyannote/speaker-diarization',\n",
            "   ...                          use_auth_token=YOUR_AUTH_TOKEN)\n",
            "\n",
            "If this still does not work, it might be because the pipeline is gated:\n",
            "visit https://hf.co/pyannote/speaker-diarization to accept the user conditions.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 1.06 MiB is free. Process 111550 has 14.74 GiB memory in use. Of the allocated memory 14.13 GiB is allocated by PyTorch, and 487.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-22890428aeeb>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                                             use_auth_token=\"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\")\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mwhisper_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0min_memory\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     ) as fp:\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1024\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                 return _load(opened_zipfile,\n\u001b[0m\u001b[1;32m   1027\u001b[0m                              \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                              \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m         typed_storage = torch.storage.TypedStorage(\n\u001b[0;32m-> 1382\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m             _internal=True)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mrestore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m   1306\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             untyped_storage = torch.UntypedStorage(\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 1.06 MiB is free. Process 111550 has 14.74 GiB memory in use. Of the allocated memory 14.13 GiB is allocated by PyTorch, and 487.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests #beautifulsoup\n",
        "\n",
        "!sudo apt-get install python-beautifulsoup"
      ],
      "metadata": {
        "id": "Xt3SX8edQH0s",
        "outputId": "f5268bbe-68c2-4c1c-ca12-6d4fb8355e8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python-beautifulsoup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "3cVLD--WgYRe",
        "outputId": "20e9bd92-84a8-4c35-b034-26c1f93558ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Apple Podcast selection** üéôÔ∏è\n",
        "\n",
        "#@markdown Enter the URL of the Apple Podcast you want to transcribe.\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### **Apple Podcast**\n",
        "URL = \"https://pro-arpit-69-f899161164e6.herokuapp.com/548299/4_5771510420242174755.wav\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the video.**\n",
        "import requests,re,os\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "from pydub import AudioSegment\n",
        "def convert_audio_to_wav(input_file: str):\n",
        "    # Determine the output file name by replacing the input file extension with .wav\n",
        "    output_file = os.path.splitext(input_file)[0] + \".wav\"\n",
        "\n",
        "    # Check the input file extension and load the audio accordingly\n",
        "    if input_file.lower().endswith(\".mp3\"):\n",
        "        audio = AudioSegment.from_mp3(input_file)\n",
        "    elif input_file.lower().endswith(\".m4a\"):\n",
        "        audio = AudioSegment.from_file(input_file, \"m4a\")\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported audio format. Please provide an MP3 or M4A file.\")\n",
        "\n",
        "    # Export the audio as a WAV file\n",
        "    audio.export(output_file, format=\"wav\")\n",
        "\n",
        "    return output_file\n",
        "\n",
        "\n",
        "def find_audio_url(html: str) -> str:\n",
        "    # Find all .mp3 and .m4a URLs in the HTML content\n",
        "    audio_urls = re.findall(r'https://[^\\s^\"]+(?:\\.mp3|\\.m4a)', html)\n",
        "\n",
        "    # If there's at least one URL, return the first one\n",
        "    if audio_urls:\n",
        "        return audio_urls[-1]\n",
        "\n",
        "    # Otherwise, return None\n",
        "    return None\n",
        "\n",
        "def get_file_extension(url: str) -> str:\n",
        "    # Parse the URL to get the path\n",
        "    parsed_url = urlparse(url)\n",
        "    path = parsed_url.path\n",
        "\n",
        "    # Extract the file extension using os.path.splitext\n",
        "    _, file_extension = os.path.splitext(path)\n",
        "\n",
        "    # Return the file extension\n",
        "    return file_extension\n",
        "\n",
        "def download_apple_podcast(url: str, output_folder: str = 'downloads'):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(\n",
        "            f\"Error: Unable to fetch the podcast page. Status code: {response.status_code}\")\n",
        "        return\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    audio_url = find_audio_url(response.text)\n",
        "\n",
        "    if not audio_url:\n",
        "        print(\"Error: Unable to find the podcast audio url.\")\n",
        "        return\n",
        "\n",
        "    episode_title = soup.find('span', {'class': 'product-header__title'})\n",
        "\n",
        "    if not episode_title:\n",
        "        print(\"Error: Unable to find the podcast title.\")\n",
        "        return\n",
        "\n",
        "    episode_title = episode_title.text.strip().replace('/', '-')\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    output_file = os.path.join(output_folder, f\"{episode_title}{get_file_extension(audio_url)}\")\n",
        "\n",
        "    with requests.get(audio_url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(output_file, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "    output_file = convert_audio_to_wav(output_file)\n",
        "\n",
        "    return episode_title, output_file\n",
        "\n",
        "\n",
        "result = download_apple_podcast(URL)\n",
        "if not result:\n",
        "  print(\"Error: Unable to download podcast.\")\n",
        "else:\n",
        "  (title, filepath) = result\n",
        "  print(f\"Downloaded podcast episode '{title}' to '{filepath}'\")"
      ],
      "metadata": {
        "id": "h2AL0Hw-Bow2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "spUB1xPHmywD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "#@markdown #### **Download Podcast from URL**\n",
        "URL = \"https://fileiran.net/Download/File/DitjzXY11B/20636_4_5771510420242174755.mp3\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Function to download a file from a URL\n",
        "def download_file_from_url(url: str, output_filename: str = None):\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        if not output_filename:\n",
        "            output_filename = url.split(\"/\")[-1]\n",
        "        with open(output_filename, 'wb') as file:\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                if chunk:\n",
        "                    file.write(chunk)\n",
        "        return output_filename\n",
        "    else:\n",
        "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "# Function to convert audio to WAV format\n",
        "def convert_audio_to_wav(input_file: str):\n",
        "    output_file = os.path.splitext(input_file)[0] + \".wav\"\n",
        "    if input_file.lower().endswith(\".mp3\"):\n",
        "        audio = AudioSegment.from_mp3(input_file)\n",
        "    elif input_file.lower().endswith(\".m4a\"):\n",
        "        audio = AudioSegment.from_file(input_file, \"m4a\")\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported audio format. Please provide an MP3 or M4A file.\")\n",
        "    audio.export(output_file, format=\"wav\")\n",
        "    return output_file\n",
        "\n",
        "# Function to find the audio URL in the HTML content\n",
        "def find_audio_url(html: str) -> str:\n",
        "    audio_urls = re.findall(r'https://[^\\s^\"]+(?:\\.mp3|\\.m4a)', html)\n",
        "    if audio_urls:\n",
        "        return audio_urls[-1]\n",
        "    return None\n",
        "\n",
        "# Function to get the file extension from a URL\n",
        "def get_file_extension(url: str) -> str:\n",
        "    parsed_url = urlparse(url)\n",
        "    _, file_extension = os.path.splitext(parsed_url.path)\n",
        "    return file_extension\n",
        "\n",
        "# Function to download and convert an audio file from a URL\n",
        "def download_and_convert_audio(url: str, output_folder: str = 'downloads'):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error: Unable to fetch the page. Status code: {response.status_code}\")\n",
        "        return\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    audio_url = find_audio_url(response.text)\n",
        "    if not audio_url:\n",
        "        print(\"Error: Unable to find the audio URL.\")\n",
        "        return\n",
        "    episode_title = soup.find('span', {'class': 'product-header__title'})\n",
        "    if not episode_title:\n",
        "        print(\"Error: Unable to find the title.\")\n",
        "        return\n",
        "    episode_title = episode_title.text.strip().replace('/', '-')\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    output_file = os.path.join(output_folder, f\"{episode_title}{get_file_extension(audio_url)}\")\n",
        "    downloaded_file = download_file_from_url(audio_url, output_file)\n",
        "    if not downloaded_file:\n",
        "        print(\"Error: Unable to download the file.\")\n",
        "        return\n",
        "    output_file = convert_audio_to_wav(downloaded_file)\n",
        "    return episode_title, output_file\n",
        "\n",
        "# Example usage\n",
        "result = download_and_convert_audio(URL)\n",
        "if not result:\n",
        "    print(\"Error: Unable to download podcast.\")\n",
        "else:\n",
        "    (title, filepath) = result\n",
        "    print(f\"Downloaded podcast episode '{title}' to '{filepath}'\")"
      ],
      "metadata": {
        "id": "PWKcY05fjrAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import whisper\n",
        "\n",
        "# Function to load a tiny Whisper model\n",
        "def load_tiny_whisper_model():\n",
        "    # Load a tiny Whisper model\n",
        "    # This is a placeholder; replace with actual code to load a tiny model\n",
        "    tiny_model = whisper.load_model(\"tiny\")\n",
        "    return tiny_model\n",
        "\n",
        "# Function to detect the language from a transcription\n",
        "def detect_language(transcription):\n",
        "    # Placeholder for language detection logic\n",
        "    # This should return the detected language\n",
        "    # For simplicity, let's assume the language is always English\n",
        "    return \"English\"\n",
        "\n",
        "# Function to load the appropriate large Whisper model based on the detected language\n",
        "def load_large_whisper_model(language):\n",
        "    # Load the large Whisper model for the detected language\n",
        "    # This is a placeholder; replace with actual code to load a large model\n",
        "    large_model = whisper.load_model(\"large\")\n",
        "    return large_model\n",
        "\n",
        "# Load the tiny Whisper model\n",
        "tiny_model = load_tiny_whisper_model()\n",
        "\n",
        "# Transcribe a short segment of the audio to detect the language\n",
        "# This is a placeholder; replace with actual code to transcribe a short segment\n",
        "transcription = tiny_model.transcribe(filepath) #\"path/to/short/audio/segment.wav\")\n",
        "\n",
        "# Detect the language from the transcription\n",
        "detected_language = detect_language(transcription)\n",
        "\n",
        "# Load the appropriate large Whisper model based on the detected language\n",
        "large_model = load_large_whisper_model(detected_language)\n",
        "\n",
        "# Now you can use the large_model for further processing"
      ],
      "metadata": {
        "id": "X9G3c-zDCEGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "from urllib.parse import urlparse\n",
        "from bs4 import BeautifulSoup\n",
        "from pydub import AudioSegment\n",
        "from tqdm import tqdm # Import tqdm for progress bars\n",
        "\n",
        "# Function to download a file from a URL with a progress bar\n",
        "def download_file_from_url(url: str, output_filename: str = None):\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        if not output_filename:\n",
        "            output_filename = url.split(\"/\")[-1]\n",
        "        with open(output_filename, 'wb') as file:\n",
        "            # Use tqdm to create a progress bar\n",
        "            for chunk in tqdm(response.iter_content(chunk_size=1024),\n",
        "                              unit='KB', unit_scale=True, desc=f\"Downloading {output_filename}\"):\n",
        "                if chunk:\n",
        "                    file.write(chunk)\n",
        "        return output_filename\n",
        "    else:\n",
        "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "def convert_audio_to_wav(input_file: str):\n",
        "    output_file = os.path.splitext(input_file)[0] + \".wav\"\n",
        "    if input_file.lower().endswith(\".mp3\"):\n",
        "        audio = AudioSegment.from_mp3(input_file)\n",
        "    elif input_file.lower().endswith(\".m4a\"):\n",
        "        audio = AudioSegment.from_file(input_file, \"m4a\")\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported audio format. Please provide an MP3 or M4A file.\")\n",
        "\n",
        "    # Export the audio without using a progress_hook\n",
        "    audio.export(output_file, format=\"wav\", codec=\"pcm_s16le\", parameters=[\"-q:a\", \"0\"])\n",
        "    return output_file\n",
        "\n",
        "# Example usage\n",
        "URL = \"https://fileiran.net/Download/File/DitjzXY11B/20636_4_5771510420242174755.mp3\"\n",
        "result = download_file_from_url(URL)\n",
        "if not result:\n",
        "    print(\"Error: Unable to download file.\")\n",
        "else:\n",
        "    print(f\"Downloaded file to '{result}'\")\n",
        "    wav_file = convert_audio_to_wav(result)\n",
        "    print(f\"Converted file to WAV format and saved as '{wav_file}'\")\n",
        "(title, filepath) = 'Title','/content/'+wav_file\n",
        "print(title, filepath)"
      ],
      "metadata": {
        "id": "MJgO7QPzm0bP",
        "outputId": "0da1434a-1eca-404d-a62d-c88021c8d094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading 20636_4_5771510420242174755.mp3: 8.44kKB [00:01, 8.21kKB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded file to '20636_4_5771510420242174755.mp3'\n",
            "Converted file to WAV format and saved as '20636_4_5771510420242174755.wav'\n",
            "Title /content/20636_4_5771510420242174755.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Run the model** üöÄ\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** ‚öôÔ∏è\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"Auto detection\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "language = (None if language == \"Auto detection\" else language)\n",
        "verbose = verbose_lut[verbose]\n",
        "\n",
        "\n",
        "if Model.endswith(\".en\") and language not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{language}'; using English instead.\")\n",
        "    language = \"en\"\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(filepath)[0] + \".txt\"\n",
        "print(\"audio local path:\", audio_path_local)\n",
        "\n",
        "import time\n",
        "\n",
        "#Transcribe\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper.transcribe(\n",
        "    model=whisper_model,\n",
        "    audio = str(audio_path_local),\n",
        "    verbose=verbose,\n",
        "    task=task,\n",
        "    language=language\n",
        ")\n",
        "#Time comsumed\n",
        "toc = time.time()\n",
        "print(f'Time consumpution {toc-tic}s for transcribing')\n",
        "\n",
        "#Write SRT file\n",
        "from whisper.utils import WriteSRT\n",
        "with open(subtitle_file, \"w\", encoding=\"utf-8\") as srt:\n",
        "    writer = WriteSRT(audio_path_local.parent)\n",
        "    writer.write_result(transcription, srt)\n",
        "print(f\"Write SRT file to '{subtitle_file}'\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "diarization_result = pipeline(audio_path_local)\n",
        "final_result = diarize_text(transcription, diarization_result)\n",
        "\n",
        "lines = list()\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    print(f\"{line}\")\n",
        "    lines.append(line)\n",
        "\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "display(Markdown(f\"**Transcript file created: {transcript_with_speakers_file}**\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lOnyZpK2EsVe",
        "outputId": "7c7d801e-1259-47ae-e695-2de79deb329d"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/markdown": "### /content/20636_4_5771510420242174755.wav",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio local path: /content/20636_4_5771510420242174755.wav\n",
            "Transcribe in progress...\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Persian\n",
            "[00:00.000 --> 00:03.200]  ÿØ⁄©ÿ™ÿ± ÿ≥ŸÖÿß€åŸá ÿ™ŸàŸá€åÿØŸÑŸà ÿ¨ÿßŸÖÿπŸá ÿ¥ŸÜÿßÿ≥ ŸÖ€å⁄ØŸà€åÿØ\n",
            "[00:03.200 --> 00:05.600]  ÿ¨ÿß€å⁄ØÿßŸá ÿ≤ŸÜÿßŸÜ ÿØÿ± ÿ¨ÿßŸÖÿπŸá ÿß€åÿ±ÿßŸÜ€å\n",
            "[00:05.600 --> 00:10.080]  ÿ®ÿπÿØ ÿßÿ≤ ÿ¨ŸÜÿ®ÿ¥ Ÿáÿß€å ÿ≥ÿßŸÑŸá 1400 Ÿà 1ÿå 2ÿå 4 ÿ™ÿ∫€å€åÿ± Ÿà ÿ™ÿ∫ŸàŸÑ ÿ¥ÿØŸá\n",
            "[00:16.240 --> 00:20.080]  ÿ≥ŸÑÿßŸÖ ŸÖŸÜ ÿ®€åÿ™ ÿ¢ÿ∞ÿ±€å ÿ®ÿß ÿ®ÿ±ŸÜÿßŸÖŸá ÿØ€åÿØ⁄©ÿß ŸáŸÖÿ±ÿßŸá ÿ¥ŸÖÿß Ÿáÿ≥ÿ™ŸÖ\n",
            "[00:22.200 --> 00:25.480]  ÿÆÿßŸÜŸÖ ÿ™ŸàŸá€åÿØŸÑŸà ÿ®Ÿá ÿÆÿ®ÿ± ÿ¢ŸÜŸÑÿß€åŸÜ ⁄ØŸÅÿ™Ÿá ÿßÿ≤ ÿØŸáŸá ŸáŸÅÿ™ÿßÿØ\n",
            "[00:25.480 --> 00:28.000]  ÿ®ÿß ÿ™Ÿàÿ¨Ÿá ÿ®Ÿá Ÿæ€åŸÖÿß€åÿ¥ Ÿáÿß€å ÿßŸÜÿ¨ÿßŸÖ ÿ¥ÿØŸá\n",
            "[00:28.000 --> 00:32.000]  ŸÖÿß €å⁄© ÿ¨ÿßŸÖÿπŸá ŸÖÿ±ÿØ ÿ≥ÿßŸÑÿßÿ± ÿ±ÿß ÿØÿßÿ¥ÿ™€åŸÖ ⁄©Ÿá ŸáŸÖ€åÿ¥Ÿá ÿ®Ÿá ÿ¥⁄©ŸÑ ŸÖÿ¥ÿÆÿµ€å\n",
            "[00:32.000 --> 00:34.240]  ÿ®Ÿá ŸÖÿ≠ÿØŸàÿØ ⁄©ÿ±ÿØŸÜ ÿ≤ŸÜÿßŸÜ ŸÖ€åÿ±ÿ≥€åÿØ\n",
            "[00:34.240 --> 00:38.320]  ÿßŸÖÿß ÿØÿ± ÿ≥ÿßŸÑ 1400 Ÿà 2 €å⁄© ÿ®ÿßÿ±Ÿá ÿ®ÿß ÿ¨ŸÖÿπ€åÿ™€å ŸÖŸàÿßÿ¨Ÿá ŸÖ€åÿ¥Ÿà€åŸÖ\n",
            "[00:38.320 --> 00:41.680]  ⁄©Ÿá ÿ®Ÿá ÿπÿ±ÿµ ÿ®ÿ±ÿØŸÜ €å⁄© ÿ≥ÿßŸÜ ÿ≤ŸÜ Ÿà ŸÖÿ±ÿØ ÿ®ÿßŸàÿ±ÿØÿßÿ±ŸÜÿØ\n",
            "[00:41.680 --> 00:45.040]  ÿ≠ŸÇ ÿ™ŸÑÿßŸÇ ÿ®ÿ±ÿß€å ÿ≤ŸÜÿßŸÜ ŸÖŸàÿ±ÿØ Ÿæÿ∞€åÿ±ÿ¥ ŸÇÿ±ÿßÿ± ŸÖ€å⁄Ø€åÿ±ÿØ\n",
            "[00:45.040 --> 00:47.480]  Ÿà Ÿæÿ∞€åÿ±ÿ¥ Ÿáÿß€å ÿßÿ¨ÿ™ŸÖÿßÿπ€å ŸàÿßŸÑÿØ€åŸÜ\n",
            "[00:47.480 --> 00:50.200]  ÿ®ÿ±ÿß€å ÿ™ÿ∫€å€åÿ±ÿßÿ™ ŸÅÿ±ÿ≤ŸÜÿØÿßŸÜ ÿ®ÿßŸÑÿß ÿ±ŸÅÿ™ÿ≥ÿ™\n",
            "[00:50.240 --> 00:52.720]  ÿ®Ÿá ÿßÿπÿ™ŸÇÿßÿØ ÿ™ŸàŸá€åÿØŸÑŸà ÿß€åŸÜ ÿ™ÿ∫€å€åÿ±ÿßÿ™ ŸÜÿ¥ÿßŸÜÿØŸáŸÜÿØŸá\n",
            "[00:52.720 --> 00:57.120]  ÿ™ÿ≥ÿßŸáŸÑ ÿ®€åŸÜ⁄Øÿ±ŸàŸá€å Ÿà ÿ®€åŸÜ ÿÆÿßŸÜŸàÿßÿØ⁄Ø€å ÿØÿ±ŸÖ€åÿßŸÜ ŸÖÿ±ÿØŸÖ ÿßÿ≥ÿ™\n",
            "[00:57.120 --> 01:01.040]  ÿØÿ± ÿØ€åÿØ⁄ØÿßŸá ÿ®ÿ±ÿß€å ÿ®ÿ±ÿ±ÿ≥€å ÿ¨ÿ≤€åÿßÿ™ ⁄ØŸÅÿ™⁄ØŸà€å ÿ≥ŸÖ€åÿ™ ÿ™ŸàŸá€åÿØŸÑŸà\n",
            "[01:01.040 --> 01:06.680]  ÿ®ÿß ÿ≥Ÿáÿ± ŸÖÿ™ŸÑÿ®€å Ÿæÿ¨ŸàŸáÿ¥⁄©ÿ± ÿ®ŸáÿØÿßÿ¥ÿ™ ÿ¨ŸÖÿπ€åÿ™ ÿ®€åŸÜ ÿßŸÑŸÖŸÑŸÑ ÿßÿ≤ ÿ≥Ÿàÿ¶ÿØ ŸáŸÖÿ±ÿßŸá ŸÖ€åÿ¥Ÿà€åŸÖ\n",
            "[01:11.680 --> 01:14.720]  ÿÆÿßŸÜ ŸÖÿ™ŸÑÿ®€å Ÿæ€åÿ¥ ÿßÿ≤ ÿß€åŸÜ ⁄©Ÿá ŸÖŸÜ Ÿæÿ±ÿ≥ÿ¥Ÿà ŸáŸÖ ŸÖÿ∑ÿ±ÿ≠ ⁄©ŸÜŸÖ\n",
            "[01:14.720 --> 01:19.200]  ÿÆŸàÿßŸáÿ¥ ŸÖ€å⁄©ŸÜŸÖ ÿÆŸÑÿßÿµŸá ÿß€å ÿßÿ≤ ÿπÿ±ÿ∂€åÿßÿ®€å Ÿáÿß€å ÿØ⁄©ÿ™ÿ± ÿ≥ŸÖ€åÿ™ ÿ™ŸàŸá€åÿØŸÑŸà\n",
            "[01:19.200 --> 01:24.600]  ÿßÿ≤ ÿ™ÿ≠ŸàŸÑÿßÿ™ ÿ¨ÿßŸÖÿπŸá ÿß€åÿ±ÿßŸÜ ÿ®ÿπÿØ ÿßÿ≤ ÿßÿπÿ™ÿ±ÿßÿ≤ÿßÿ™ 1401 ÿ±Ÿà ÿ®ÿ±ŸÖŸàŸÜ ŸÖÿ±Ÿàÿ± ⁄©ŸÜ€åÿØ\n",
            "[01:24.600 --> 01:26.360]  ÿ®ÿπÿØ Ÿàÿßÿ±ÿØ Ÿà ÿ¨ÿ≤€åÿßÿ™ ÿ®ÿ¥€åŸÖ\n",
            "[01:26.360 --> 01:28.680]  ÿ®ÿß ÿµÿØÿß ŸÅŸÇÿ∑ ÿÆÿØŸÖÿ™ ÿ¥ŸÖÿß ÿ®ÿ®€åŸÜ€åÿØ\n",
            "[01:28.680 --> 01:31.720]  ÿß€åŸÜ ÿ®ÿ∫ÿßŸÑÿß ÿ®Ÿá ŸÜÿ∏ÿ±ŸÖÿ™ ŸÅŸÇÿ∑ ŸÜŸÅÿπŸá ÿÆ€åŸÑ€å ÿ¨ÿßŸÑÿ®€å ÿØÿßÿ¥ÿ™\n",
            "[01:31.720 --> 01:34.120]  ÿ®Ÿá ÿ∑ŸàŸÑ ŸÖÿ¥ÿßŸÇÿµŸÖ ŸÖŸáŸÖÿ™ÿ±€åŸÜ ⁄Ü€åÿ≤€å ⁄©Ÿá\n",
            "[01:34.120 --> 01:37.560]  ÿ™ÿ∫€å€åÿ±ÿßÿ™ ⁄©Ÿá ÿØÿ± ŸàŸÇÿ™ ÿß€åÿ¥ŸàŸÜ ÿßÿ¥ÿßÿ±Ÿá ⁄©ÿ±ÿØŸá ÿ®ŸàÿØŸÜ ÿ®Ÿáÿ¥\n",
            "[01:37.560 --> 01:41.600]  ÿß€åŸÜ€å ⁄©Ÿá ÿ¨ÿßŸÖÿπŸá ÿØÿ± ŸàŸÇÿ™ ÿ™ÿπÿßŸÖŸÑ ⁄Øÿ±ŸàŸá Ÿáÿß Ÿà ÿ®ŸÇÿ¥ Ÿà ÿ®ŸÇÿ¥ Ÿà ŸÖÿÆÿ™ŸÑŸÅ\n",
            "[01:41.600 --> 01:43.800]  ÿ®Ÿá ÿß€å⁄© ÿ™ÿ≥ÿßŸáŸÑ€å ÿ±Ÿà ÿ™ÿ¨ÿ±ÿ®Ÿá ŸÖ€å⁄©ŸÜŸá\n",
            "[01:43.840 --> 01:45.760]  ⁄©Ÿá ŸÖÿ´ŸÑÿß ÿØÿ± ÿ≤ŸÖÿßŸÜŸáŸàŸÇ ÿ≤ŸÜÿßŸÜ\n",
            "[01:45.760 --> 01:49.600]  ÿÆ€åŸÑ€å ŸÖŸàÿßÿØ ÿØ€åÿØŸá ŸÖ€åÿ¥Ÿá ⁄©Ÿá ÿ≠ŸÇ ÿ™ŸÑÿßŸÇŸá ÿ≥€åŸá ÿ®ÿ±ÿßÿ®ÿ± ÿØÿßÿ±Ÿá\n",
            "[01:49.600 --> 01:52.800]  ÿ®€åÿ¥ÿ™ÿ± Ÿæÿ∞ÿ±ŸàŸÅÿ™Ÿá ŸÖ€åÿ¥Ÿá ÿ™Ÿà€å ÿ¨ÿßŸÖÿπŸá\n",
            "[01:52.800 --> 01:55.920]  Ÿà ŸáŸÖ€åŸÜÿ∑Ÿàÿ± ŸÖÿØÿßÿ±ÿß€å ŸàÿßŸÑÿØ€åŸÜ ÿ®ÿß ÿÆŸàÿßÿ≥ÿ™ÿß€å Ÿæÿ±ÿ≤ŸÜÿØÿßŸÜÿ¥ŸàŸÜ\n",
            "[01:55.920 --> 02:00.200]  ⁄©Ÿá ŸÖŸÖ⁄©ŸÜŸá ⁄©Ÿá ÿ®Ÿá ŸÑÿ≠ÿßÿ∏ ÿπŸÇ€åÿØÿ™€å ÿ®ÿß ÿÆŸàÿßÿ≥ÿ™ÿß€å ÿÆŸàÿØÿ¥ŸàŸÜ ŸÖÿ™ŸÅÿßÿ®ÿ∑ ÿ®ÿßÿ¥Ÿá\n",
            "[02:00.200 --> 02:04.360]  Ÿà ÿß€åŸÜ ÿ™ÿ≥ÿßÿ±ŸÑ ÿØÿ± ŸàÿßŸÇÿπ ÿ®€åŸÜ ⁄Øÿ±ŸàŸá€å Ÿà ÿ®€åŸÜ ÿÆÿßŸÜŸàÿßÿØ⁄Ø€å ŸáŸÖ ÿØÿßÿ±Ÿá ÿ¥⁄©ŸÑ ŸÖ€å⁄Ø€åÿØ\n",
            "[02:04.360 --> 02:07.960]  ŸÖÿ´ŸÑÿß ÿ®€åŸÜ ÿπŸÇŸÑ€åÿ™Ÿáÿß€å ŸÖÿ±ÿ´ŸáŸà€å ŸÖÿÆÿ™ŸÑŸÅ ÿ®€åÿ¥ÿ™ÿ± Ÿæÿ∞ÿ±ŸàŸÅÿ™Ÿá ŸÖ€åÿ¥ŸÜ\n",
            "[02:07.960 --> 02:10.920]  Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ÿ≥ÿßÿ®ŸÇ ÿ®€åÿ¥ÿ™ÿ± ÿØ€åÿØŸá ŸÖ€åÿ¥ŸÜ Ÿà ÿ¥ÿß€åÿØ Ÿæÿ∞ÿ±€åÿ¥ŸàŸÜ ÿ≤€åÿßÿØ ÿ¥ÿØŸá\n",
            "[02:10.920 --> 02:12.960]  ÿØ€å⁄ØŸá ŸÜ⁄©ÿ™Ÿá €å⁄©€å ⁄©Ÿá ⁄ØŸÅÿ™ŸÜ ÿß€åŸÜŸá ⁄©Ÿá\n",
            "[02:12.960 --> 02:17.440]  ŸàŸÇÿ™€å ŸÜÿßÿ±ÿ∂€åÿßÿ™€å ÿ¨ŸÖÿπ€å ŸÜÿßÿ¥€å ÿßÿ≤ ÿπÿØŸÖ€å ÿ±ÿ≥€åÿØŸÜ ÿ®Ÿá ÿÆŸàÿßÿ≥ÿ™ÿßŸáÿß ÿ®Ÿá Ÿàÿ¨ŸàÿØ ÿ®€åÿßÿØ\n",
            "[02:17.440 --> 02:20.080]  ÿßŸÜÿ™ÿ∏ÿßÿ± ŸÖ€å⁄©ŸÜŸá ⁄©Ÿá ÿØŸà ÿ™ÿß ŸÜÿ™€åÿ¨Ÿá ÿØÿßÿ¥ÿ™Ÿá ÿ®ÿßÿ¥Ÿá\n",
            "[02:20.080 --> 02:23.320]  €åÿß ÿß€åŸÜ ⁄©Ÿá ÿ¨ÿßŸÖÿπŸá ⁄©ÿ±ÿÆÿ™ Ÿà ŸÑŸÖÿ≥ Ÿà ÿ®€åÿ™ŸÅÿßŸàÿ™ ŸÖ€åÿ¥Ÿá\n",
            "[02:23.320 --> 02:26.960]  Ÿà €åÿß ÿß€åŸÜ€å ⁄©Ÿá ÿßÿ™ŸÅÿßŸÇÿß ÿ®ÿß ⁄©ÿßŸÜÿ¥Ÿáÿß€å ÿ±ÿßÿØ€å⁄©ÿßŸÑ ÿπŸÇÿµ ÿßÿ¥ÿ¥ÿßŸÅÿ™€å ÿØÿßÿ±Ÿá\n",
            "[02:26.960 --> 02:31.800]  ÿØÿ± ŸàÿßŸÇÿπ Ÿáÿ± ÿØŸà €å⁄© ÿ®ÿß ⁄©ÿßŸÜÿ¥ ÿßŸÅÿ±ÿßÿØ€åŸá ⁄©Ÿá ÿß€åŸÜ ÿ®ÿßÿπÿ´ŸÖÿ¥ ⁄©Ÿá ⁄©ŸÜÿ¥⁄Øÿ±€å ÿ≥ÿÆÿ™ Ÿáÿ± ÿ®ÿ¥Ÿá\n",
            "[02:31.800 --> 02:34.640]  ÿ®ÿπÿØ ŸÜ⁄©ÿ™Ÿá ÿØ€å⁄ØŸá ⁄©Ÿá ⁄ØŸÅÿ™Ÿá ÿ®ŸàÿØŸÜ ÿß€åŸÜ ÿ®ŸàÿØŸá ⁄©Ÿá\n",
            "[02:34.640 --> 02:37.520]  ÿØÿ± ŸàÿßŸÇÿπ ÿ∑ÿ®ŸÇŸá Ÿæÿß€åŸÜÿØ ÿ±Ÿà€å ŸÅŸÇŸÇ ŸàÿßŸÇÿπ€å ŸÖŸàŸÜÿØŸá\n",
            "[02:37.520 --> 02:39.720]  Ÿà ÿ∑ÿ®ŸÇŸá ŸÖÿ™Ÿàÿ≥ÿ∑ ÿØÿßÿ±Ÿá ŸÖÿ≤ŸÖÿ≠ŸÑ ŸÖ€åÿ¥Ÿá\n",
            "[02:39.720 --> 02:43.000]  Ÿà ÿßÿ¥ÿπÿßŸÑ€å ⁄©ÿ±ÿØŸá ÿ®ŸàÿØŸÜ ⁄©Ÿá ÿ¢ŸÖÿßÿ± ÿ®€å⁄©ÿßÿ±€å ⁄©Ÿá 75% ÿßÿπŸÑÿßŸÖ ÿ¥ÿØŸá\n",
            "[02:43.000 --> 02:44.200]  ÿß€å ÿÆÿ® ŸÖÿßŸÑÿß ÿßÿ¥ÿ™ÿ®ÿßŸá ÿßÿ≥ÿ™\n",
            "[02:44.200 --> 02:49.360]  ÿ¨ÿßŸÜÿØŸá €å⁄© ÿ®ÿÆÿ¥€å ÿßÿ≤ ÿ®€å⁄©ÿßÿ±ÿßŸÜ ⁄©Ÿá ÿ®Ÿá ÿ≥ÿ±ÿ≤ÿØŸá ÿ¥ŸÇÿß€å Ÿæÿßÿ±ŸàÿßÿÆÿ™€å Ÿáÿ≥ÿ™ŸÜ\n",
            "[02:49.360 --> 02:53.360]  Ÿà €åÿß ÿ®ÿ±ÿ∑ŸÖŸá ŸàÿßŸÇÿπ ÿ¥ÿßÿ∫ŸÑ Ÿáÿ≥ÿ™ŸÜ ÿß€åŸÜŸáÿß ÿØÿ± ŸàÿßŸÇÿπ ÿ¨ÿ≤ ÿ¢ŸÖÿßÿ± ÿ¥ÿßÿ∫ŸÑ ŸÖ€åŸáŸÜŸá\n",
            "[02:53.360 --> 02:56.760]  ÿ≥ÿ®ÿ¥ÿ™Ÿá ⁄©Ÿá ÿØÿ± ÿ≥ÿ±ÿ≤ÿØŸá ⁄©Ÿá ÿπŸÑÿßŸÇŸá ÿß€åŸÜŸáÿß ÿ®ÿß ÿ¨ÿ≤ ÿ¢ŸÖÿßÿ± ÿ®€å⁄©ÿßÿ±ÿßŸÜ ÿ≠ÿ≥ÿßÿ® ⁄©ÿ¥ŸÜÿØ\n",
            "[02:56.760 --> 03:02.480]  Ÿà ŸÜ⁄©ÿ™Ÿá ÿØ€å⁄ØŸá ÿß€åŸÜ€å ⁄©Ÿá 40% ÿØÿ± ŸàÿßŸÇÿπ ÿ®€å⁄©ÿßÿ±ÿßŸÜ ÿ™ÿ≠ÿµ€åŸÑ ⁄©ÿ±ÿØŸá Ÿáÿ≥ÿ™ŸÜ\n",
            "[03:02.480 --> 03:04.840]  Ÿà 71% ÿßŸàŸÜŸáÿß ŸáŸÖ ÿ≤ŸÜÿßŸÜ Ÿáÿ≥ÿ™ŸÜ\n",
            "[03:04.840 --> 03:08.640]  ŸÜ⁄©ÿ™Ÿá ⁄©Ÿá ⁄ØŸÅÿ™Ÿá ÿ®ŸàÿØŸÜ ÿß€åŸÜ ÿ®ŸàÿØŸá ⁄©Ÿá ÿ®€åÿ¥ÿ™ÿ±€å ŸÖ€åÿ≤ÿßŸÜ ⁄©ŸÜÿ¥⁄Øÿ±€å ÿßÿ¨ÿ™ŸÖÿßÿπ€å\n",
            "[03:08.640 --> 03:10.560]  ŸÖÿπŸÖŸàŸÑÿßŸã ÿßÿ≤ ÿ∑ÿ®ŸÇŸá ŸÖÿ™Ÿàÿ≥ÿ∑ ÿ¥ÿØŸá ŸÖ€åÿ¥Ÿá\n",
            "[03:10.560 --> 03:13.760]  Ÿà ÿØÿ± ŸàÿßŸÇÿπ ŸÖÿÆÿ™ÿµŸÖ ŸàŸÇÿ™€å ÿ∑ÿ®ŸÇŸá ŸÖÿ™Ÿàÿ≥ÿ∑ ⁄©ŸÑÿßŸÖÿ™ Ÿà ÿ¨ÿß€å⁄ØÿßŸá ÿßŸÜÿ≥ÿßŸÜ€åŸá\n",
            "[03:13.760 --> 03:18.040]  ÿßÿ≤ ÿØÿ≥ÿ™ ŸÜ€åÿØŸá Ÿà ÿØÿ± ŸàÿßŸÇÿπ ŸÑ⁄Üÿßÿ±Ÿá ÿÆÿ¥ŸÖ ŸáŸÖ ÿ®ÿßÿ¥Ÿá ŸÜ€åŸÖ€åÿ¥Ÿá\n",
            "[03:18.040 --> 03:23.680]  ÿ≤€åÿ± ŸÇÿµÿØ ÿ¨ÿßŸÖÿπŸá ÿ™ŸÅÿßŸáŸÖ€å ÿØÿ± ŸàÿßŸÇÿπ ÿ≠ŸÇŸàŸÇ ÿ≤ŸÜÿßŸÜ ÿØÿ± ÿ≠ÿßŸÑ ÿ¥⁄©ŸÑ ⁄Øÿ±ŸÅÿ™ŸÜ\n",
            "[03:23.680 --> 03:29.920]  ÿß⁄Øÿ±⁄ÜŸá ÿ≠ÿß⁄©ŸÖ€åÿ™ ŸÖÿß ŸÜŸæÿ∞€åÿ±ŸÅÿ™Ÿá ŸàŸÑ€å ⁄©Ÿá ÿ®ŸÜÿ∏ÿ± ŸÖ€åÿ±ÿ≥ÿØ ⁄©Ÿá ÿß€åŸÜ ŸÜÿ¥ÿßŸÜŸá Ÿáÿßÿ¥ ÿØÿ± ŸàÿßŸÇÿπ\n",
            "[03:29.920 --> 03:35.920]  ŸÖÿ´ŸÑÿßŸã ÿ®ÿ≥ÿ±ÿßÿ™ ÿß€åŸÜŸá ⁄©Ÿá ÿ±ÿ≥ÿßŸÜŸá Ÿáÿß ÿ®€åÿ¥ÿ™ÿ± ÿØÿ± ŸÖŸÇÿßÿ®ŸÑ ŸæŸàÿ¥ÿ¥ ÿ≤ŸÜÿßŸÜ ÿ™ÿ≥ÿßÿ≠ŸÑ ÿØÿßÿ±ŸÜÿØ ÿØ€åÿØŸá ŸÖ€åÿ¥Ÿá\n",
            "[03:35.960 --> 03:41.080]  ÿØÿ± ŸÖŸàÿ±ÿØ ŸÖŸáÿßÿ¨ÿ±ÿ™ ŸáŸÖ ÿß€åÿ¥ŸàŸÜ ÿ®⁄©ŸÜŸÜ ⁄©Ÿá ÿß€åÿ±ÿßŸÜ ŸáŸÅÿ™Ÿá ŸÖŸÜ ⁄©ÿ¥Ÿàÿ±Ÿá ŸÖŸáÿßÿ¨ÿ±ÿ™ ÿ®ÿ±ÿ≥ÿ™Ÿá\n",
            "[03:41.080 --> 03:45.160]  ⁄©Ÿá ÿ®ŸÜÿ∏ÿ± ŸÖ€åÿ±ÿ≥ÿ™Ÿá ⁄©Ÿá ÿßŸÜ⁄Ø€åÿ≤Ÿá Ÿáÿß€å ŸÖŸáÿßÿ¨ÿ±ÿ™ ÿß€å ⁄©Ÿá ŸÖŸÇÿß€å€å ÿ™ŸÇÿ±€åÿ± ⁄©ÿ±ÿØŸá\n",
            "[03:45.160 --> 03:48.960]  ŸÖÿ´ŸÑÿßŸã ÿ®Ÿá Ÿæÿ¥ÿßÿ±Ÿá ÿßÿ¨ÿ™ŸÖÿßÿπ€å ŸÖ€åŸÜŸá ÿ≠ÿ™€å ÿØÿ± ÿ®€åŸÜ ⁄Øÿ±ŸàŸá Ÿáÿß€å€å ⁄©Ÿá ÿÆŸàÿØÿ¥ŸàŸÜ\n",
            "[03:48.960 --> 03:54.280]  ÿßÿØŸà€åÿ≤ ÿßŸÇÿ™ÿµÿßÿØ€å Ÿà Ÿàÿ∂ÿπ€åÿ™ ÿ®Ÿáÿ™ÿ±€å ÿØÿßÿ±ŸÜÿØ ŸàŸÑ€å ⁄©Ÿá ŸáŸÅÿ™Ÿá Ÿæÿ¥ÿßÿ± ŸáŸÖ ŸÜÿ≥ŸÑŸá Ÿáÿßÿ¥ŸàŸÜ ÿØÿßÿ±ŸÜÿØ\n",
            "[03:54.280 --> 04:00.040]  ÿ≥ÿπ€å ŸÖ€å ⁄©ŸÜŸÜÿØ ⁄©Ÿá ŸÖŸáÿßÿ¨ÿ±ÿ™ ÿ®⁄©ŸÜŸÜÿØ Ÿà ŸÖŸÖ⁄©ŸÜŸá ÿØŸÑ€åŸÑ ÿßÿµŸÑÿ¥ ÿß€åŸÜ ÿ®ŸàÿØŸá ⁄©Ÿá ÿØÿ± ÿÆŸàŸÜÿØ ⁄Üÿ¥ŸÖÿßŸÜÿØÿßÿ≤€å ÿ®ÿ±ÿß€å ÿ¢€åŸÜÿØŸá Ÿàÿ¨ŸàÿØ ŸÜÿØÿßÿ±Ÿá\n",
            "[04:00.040 --> 04:06.720]  ÿÆÿßŸÜŸÖ ÿ™ÿπŸÑ€åÿ®€å ÿßÿ≤ €å⁄© ÿ∑ÿ±ŸÅ ŸÜ⁄ØÿßŸá ÿ¨ÿßŸÖÿπŸá ÿ®Ÿá ŸÖÿ≥ÿ¶ŸÑŸá ÿ≤ŸÜÿßŸÜ ÿØŸà⁄Üÿßÿ± ÿ™ÿ≠ŸàŸÑ ŸÖÿπŸÜÿßÿØÿßÿ± ÿ¥ÿØŸá\n",
            "[04:06.720 --> 04:11.280]  ÿßÿ≤ ÿ∑ÿ±ŸÅ ÿØ€å⁄ØŸá ÿ®Ÿá ÿ¥ŸáÿßÿØÿ™ ŸáŸÖ€åŸÜ ⁄ØŸÅÿ™⁄ØŸà ÿ®ÿß ÿÆÿßŸÜŸÖ ÿ™Ÿàÿ≠€åÿØŸÑŸà\n",
            "[04:11.280 --> 04:17.240]  Ÿæÿ¥ÿßÿ±ÿß€å ÿßŸÇÿ™ÿµÿßÿØ€å ŸÇÿ¥ÿ± ŸÖÿ™Ÿàÿ≥ÿ∑ ÿ±Ÿà ⁄ÜŸÜÿßŸÜ ÿ≤ÿπ€åŸÅ ⁄©ÿ±ÿØŸá ⁄©Ÿá ÿßÿ≤ ⁄©ÿßÿ±⁄©ÿ±ÿØ ÿßŸÜÿØÿßÿÆÿ™Ÿá\n",
            "[04:17.240 --> 04:24.840]  ÿ≥ŸàÿßŸÑ ŸÖŸÜ ÿß€åŸÜŸá ⁄©Ÿá ÿßÿ≤ ŸÜÿ∏ÿ± ÿ¥ŸÖÿß Ÿàÿ≤ŸÜ Ÿæÿ¥ÿßÿ±ÿß€å ÿßŸÇÿ™ÿµÿßÿØ€å ÿØÿ± ÿ™ÿ≠ŸàŸÑÿßÿ™ ÿßÿ¨ÿ™ŸÖÿßÿπ€å ÿ≥ŸáŸÖ ÿ®€åÿ¥ÿ™ÿ±€å ÿØÿßÿ±Ÿáÿü\n",
            "[04:24.840 --> 04:28.480]  €åÿß ÿ≠ŸÇŸàŸÇ ÿ≤ŸÜÿßŸÜ ⁄©Ÿá ÿ™ÿ®ÿØ€åŸÑ ÿ®Ÿá ŸÖÿ™ÿßŸÑÿ®Ÿá ÿ¨ÿßŸÖÿπŸá ÿ¥ÿØŸáÿü\n",
            "[04:28.480 --> 04:36.440]  ÿ®Ÿá ŸÜÿ∏ÿ± ÿ¥ÿÆÿµ€å ŸÖŸÜ ÿß€åŸÜÿ∑Ÿàÿ± ŸÜ€åÿßÿØÿ¥ ⁄©Ÿá ŸÖÿ±ŸÇÿ¨ ŸÖÿ¥ÿ™ÿ±⁄© ŸÖÿ™ÿßŸÑÿ®ÿßÿ™ ÿ¨ÿßŸÖÿπ€å ÿß€åÿ±ÿßŸÜ€å ÿßŸÑÿßŸÜ ŸÖÿ™ÿßŸÑÿ®ÿßÿ™ ÿßŸÇÿ™ÿµÿßÿØ€åŸá\n",
            "[04:36.440 --> 04:43.120]  ŸàŸÇÿ™ÿßŸÜ ÿßÿ≤ ŸÑÿßÿ≥Ÿá ÿ¢ŸÖÿßÿ±€å ⁄©Ÿá ŸÖ€å ÿÆŸàÿßŸá€åŸÖ ÿ®ÿ±ÿ≥€åÿ® ⁄©ŸÜ€åŸÖ ŸÖ€å ÿ®€åŸÜ€åŸÖ ⁄©Ÿá ÿ®€åŸÜ ÿ¨ÿßŸÖÿπŸá ÿ¥ÿß⁄©ÿ± ŸÖÿ´ŸÑÿß ÿ≥ÿßŸÑ 1378-18\n",
            "[04:43.120 --> 04:46.880]  ÿ™ŸàÿßŸÇÿπ ÿØÿ± ŸÖŸàÿ±ÿØ ÿ¢ÿ≤ÿßÿØ€å ŸÖÿØÿ™ ÿ®ŸàÿØÿå ÿ≥ÿßŸÑ 828 ÿ≠ŸÇ ÿ±ÿπ€å ÿ®ŸàÿØ\n",
            "[04:46.880 --> 04:55.000]  ŸàŸÑ€å ÿßÿ≤ ÿØÿ± ŸàÿßŸÇÿπ €å⁄© ÿØŸáŸá ÿßÿÆ€åÿ±ÿå ÿ≥ÿßŸÑ 96-98-1401 ŸÖÿ™ÿßŸÑÿ®ÿßÿ™ ÿ®Ÿá ÿ∑Ÿàÿ± ŸÖÿ¥ÿÆÿµ\n",
            "[04:55.000 --> 05:00.360]  ŸÖÿ™ÿßŸÑÿ®ÿßÿ™ ÿßŸÇÿ™ÿµÿßÿØ€å Ÿà ÿ±ŸÅÿπ ÿßÿ¨ÿ™ŸÖÿßÿπ€å Ÿà ÿ™ŸàÿßŸÇÿπ ⁄©ÿ±ŸàÿØÿ≥ÿ™ ÿ®€åÿ¥ÿ™ÿ± ŸÖÿ¥ÿßÿ±⁄©ÿ™ ⁄©ÿ±ÿØŸÜ\n",
            "[05:00.360 --> 05:08.880]  Ÿà ÿ™ÿπÿØÿßÿØ ÿØÿ± ŸàÿßŸÇÿπ ⁄Øÿ±ŸàŸá Ÿáÿß€å€å ⁄©Ÿá ŸÖÿ¥ÿßÿ±⁄©ÿ™ ⁄©ÿ±ÿØŸÜ ŸáŸÖ ŸÖÿ´ŸÑÿß ÿØÿ± ŸÖÿµÿØÿ± ÿ¥ÿπÿ±Ÿáÿß ÿß⁄Øÿ± ÿ®ÿÆŸàÿß€å€åŸÖ ÿØÿ± ŸÜÿ∏ÿ± ÿ®⁄Ø€åÿ±€åŸÖ ÿÆ€åŸÑ€å ÿ®€åÿ¥ÿ™ÿ± ÿ¥ÿØŸá\n",
            "[05:08.880 --> 05:18.840]  Ÿà ÿØ€å⁄ØŸá ÿß€åŸÜ ⁄©Ÿá ŸÖÿ´ŸÑÿß ÿß⁄Øÿ± ÿ®ÿÆŸàÿß€å€åŸÖ ÿ≠ÿ™€å ÿßŸàŸÜ ÿØŸà ÿ™ÿß ŸÜŸÇÿ¥Ÿá ÿØÿ± ŸàÿßŸÇÿπ ÿØÿ±ŸÖŸàŸÖÿØŸá ⁄©Ÿá ŸÜŸÇÿ¥ ÿ™Ÿàÿ∂€åÿ≠ ÿ®Ÿàÿ¨Ÿá€å ÿ≥ÿßŸÑ 1401 ⁄©Ÿá ÿßÿπÿ™ŸÖÿßÿØ ÿ¢ŸÜŸÑÿß€åŸÜ ŸÖŸÜÿ™ÿ¥ÿ± ⁄©ÿ±ÿØŸá\n",
            "[05:18.840 --> 05:24.000]  ÿßŸàŸÜ ÿ±Ÿà ŸÖŸÇÿßÿ±€åÿ≥Ÿá ÿ®⁄©ŸÜ€åŸÖ ÿ®ÿß ŸÜŸÇÿ¥Ÿá ÿ¢ÿ≥€åÿØ ÿ®€åÿØ⁄ØÿßŸÜ ÿ¨ŸÜÿ®ÿ¥ÿå ÿÆ€åŸÑ€å ÿØÿ± ŸàÿßŸÇÿπ ŸáŸÖ⁄©Ÿàÿ¥ÿßŸÜ€å ÿ¨ÿßŸÑÿ®€å ÿØÿßÿ±Ÿá\n",
            "[05:24.000 --> 05:34.600]  ÿßŸàŸÜ ÿßÿ≥ÿ™ÿßŸÜŸáÿß€å€å ⁄©Ÿá ÿØÿ± ŸàÿßŸÇÿπ ÿ®Ÿàÿ¨Ÿá€å ÿ®€åÿ¥ÿ™ÿ±€å ÿØÿßÿ±ŸÜ ⁄©ŸÖÿ™ÿ±€åŸÜ ŸÖ€åÿ≤ÿßŸÜ ŸÖÿ¥ÿßÿ±⁄©ÿ™ ÿ±Ÿà ÿØÿ± ÿ¨ŸÜÿ®ÿ¥ ÿßÿ≤ ŸÑÿßÿ≤ŸÖ ÿ¢ŸÖÿßÿ± ÿ¢ÿ≥€åÿØ ÿ®€åÿØ⁄ØÿßŸÜ Ÿà ⁄©ÿ¥ÿ™ ÿ¥ÿØ⁄ØÿßŸÜ Ÿà ÿ®ÿßÿ≤ÿ¥ ÿ¥ÿØ⁄ØÿßŸÜ ÿØÿßÿ±ŸÜ\n",
            "[05:34.600 --> 05:43.640]  ÿØÿ± ÿ≠ÿßŸÑ€å ⁄©Ÿá ÿßÿ≥ÿ™ÿßŸÜŸáÿß€å€å ÿ≠ÿßÿ¥€åŸá ⁄©Ÿá ÿØÿ± ŸàÿßŸÇÿπ ⁄©ŸÖÿ™ÿ±€åŸÜ ŸÖ€åÿ≤ÿßŸÜ ÿ®Ÿá ÿ®Ÿàÿ¨Ÿá ÿ±Ÿà Ÿàÿßÿ≥ÿßÿ≥ ÿ≥ÿ±ÿßŸÜŸá ÿØÿßÿ±ŸÜ ÿ®€åÿ¥ÿ™ÿ±€å ŸÖ€åÿ≤ÿßŸÜ ÿ¢ÿ≥€åÿØ ÿ®€åÿØ⁄ØÿßŸÜ ÿ¨ŸÜÿ®ÿ¥ ÿØÿßÿ±ŸÜ\n",
            "[05:43.640 --> 05:54.400]  ÿØÿ± ŸàÿßŸÇÿπ ŸÜÿ¥ŸàŸÜÿØŸá ⁄©Ÿá ÿß€åŸÜ Ÿáÿß ŸÖÿ¥ÿßÿ±⁄©ÿ™ ÿ®€åÿ¥ÿ™ÿ±€å ⁄©ÿ±ÿØŸÜ €åÿπŸÜ€å ÿ®ÿß ÿß€åŸÜ ÿ≠ÿßŸÑ ŸáŸÖ€åÿ≤ ÿ®Ÿá ŸÜÿ∏ÿ± ŸÖ€åÿßÿØ ⁄©Ÿá ŸÖÿ™ÿπŸÑŸÇÿßÿ™ ÿßŸÇÿ™ÿµÿßÿØ€åÿå ŸÖÿ™ÿπŸÑŸÇÿßÿ™ ÿπŸÖŸàŸÖ€å ÿ™ŸÑ€åŸá Ÿà Ÿàÿ≤ŸÜ ÿ®€åÿ¥ÿ™ÿ±€å ÿØÿßÿ±Ÿá\n",
            "[05:54.400 --> 06:06.560]  ÿßŸÖÿß ŸÜ⁄©ÿ™Ÿá ⁄©Ÿá ÿ®Ÿàÿ¨ŸàÿØ ÿØÿßÿ±Ÿá ÿß€åŸÜŸá ⁄©Ÿá 10.401 ÿß€å⁄© ÿ™ŸÇÿßÿ®ŸÑ ÿØ€å⁄ØŸá ÿß€åÿ¨ÿßÿØ ÿ¥ÿØÿå ÿßŸàŸÜ ŸáŸÖŸàŸÜ€å ⁄©Ÿá ŸÜ€åŸÖ€å ÿßÿ≤ ÿ¨ÿßŸÖÿπŸá ⁄©Ÿá ÿ≤ŸÜÿßŸÜ ÿ®ŸàÿØŸÜ ⁄©Ÿá ÿ®Ÿá ÿ∑Ÿàÿ± ÿµŸÜÿØÿ™€å ÿØÿ± ÿ¨ÿßŸÖÿπŸá ŸÖÿ±ÿ≥ÿßŸÑŸá ÿ±€åÿ∂ÿßŸÜ ŸÇ€åÿ± ÿ¢ŸÖŸÑ ÿ®ÿ±ÿ≤ŸÜ ÿ¥ÿØŸÜ\n",
            "[06:06.560 --> 06:16.160]  ÿßŸÖÿß ÿß€åŸÜ Ÿáÿß ÿ¢ŸÖŸÑ€åÿ™ Ÿæ€åÿØÿß ⁄©ÿ±ÿØŸÜ Ÿà ÿ¢ŸÖŸÑ€åÿ™ ÿ¥ÿØŸÜ Ÿà ÿ¢ŸÖŸÑŸáÿß€å ÿß€åŸÜ ÿ¨ŸÖÿ®ÿ¥ €å⁄© ÿ¨ÿß ÿ®Ÿá ÿ¨ÿß€å€å ÿØÿ±ÿ¥ŸàŸÜ ÿß€åÿ¨ÿßÿØ ÿ¥ÿØŸá Ÿáÿ≥ÿ™ŸÜÿØ\n",
            "[06:16.160 --> 06:20.440]  ÿßÿ≤ ÿ¨ÿßŸÖÿπŸá ŸÖÿ±ÿØÿßŸÜ ŸàŸÅÿ™Ÿá ÿØÿ± ÿ¨ÿßŸÖÿπŸá ÿ≤ŸÜÿßŸÜ Ÿà ŸÖÿ±ÿØŸáÿß ŸáŸÖ ÿßŸÖÿ±Ÿàÿ≤ ÿ≤ŸÜÿßŸÜ ÿ¥ÿØŸÜÿØ\n",
            "[06:20.440 --> 06:27.480]  ŸÜ⁄©ÿ™Ÿá ⁄©Ÿá ÿ®Ÿàÿ¨ŸàÿØ ÿØÿßÿ±Ÿá ÿß€åŸÜŸá ⁄©Ÿá ÿ®Ÿá ŸÑÿ≠ÿßÿ∏ ÿ∑ÿ®€åÿπ€å ÿ®Ÿá ŸÜÿ∏ÿ± ŸÖŸÜ ÿ≤ŸÜÿßŸÜ ÿ®Ÿá ÿÆÿßÿ∑ÿ± ÿ∑ÿ®€åÿπÿ™ ŸÖÿßÿØÿ±⁄ØŸàŸÜŸá\n",
            "[06:27.480 --> 06:32.640]  ÿß€åŸÜ Ÿáÿß ŸÖŸáŸÖŸàŸÜÿßŸÜ ⁄Øÿ±ÿß€åÿ¥ ÿ®Ÿá ŸáŸÖŸá ÿ¥ŸÖŸàŸÑ€åŸá ÿ®€åÿ¥ÿ™ÿ±€å ÿØÿßÿ±ŸÜ\n",
            "[06:32.640 --> 06:36.200]  ŸáŸÖŸàŸÜÿ∑Ÿàÿ± ⁄©Ÿá ŸÖ€åÿ®€åŸÜ€åÿØ ÿ®€åÿ¥ÿ™ÿ±€å ŸÖ€åÿ≤ÿßŸÜ ÿÆ€åÿ±€å Ÿáÿß ŸáŸÖ ÿ∑ÿ®ÿπÿß ÿßÿ≤ ⁄©Ÿá ÿ≤ŸÜÿßŸÜ ÿßÿØÿßÿ±Ÿá ŸÖ€åÿ¥Ÿá\n",
            "[06:36.200 --> 06:42.680]  ÿß€åŸÜ Ÿáÿß ÿ®ÿß ÿßŸÇÿ¥ÿßÿ± ÿ®Ÿáÿ™ÿ± ⁄©ŸÖ ÿ®Ÿáÿ™ÿ± ŸÖŸÜÿ™ŸÇŸÑ ÿ®€åÿ¥ÿ™ÿ± ÿØÿ±ÿ™ŸÖÿßÿ≥ Ÿáÿ≥ÿ™ŸÜ Ÿà ⁄©Ÿæ ÿ¨ÿßŸÖÿπŸá ÿ™ŸÖÿßÿ≥ ÿ®€åÿ¥ÿ™ÿ±€å ÿØÿßÿ±ŸÜ\n",
            "[06:42.680 --> 06:47.480]  Ÿà ŸÖÿ™ÿπŸÑÿ®ÿßÿ™ÿ¥ŸàŸÜ ŸÅŸÇÿ∑ ŸÖÿ™ÿπŸÑÿ®ÿßÿ™ ÿÆŸàÿØÿ¥ŸàŸÜ ŸÜ€åÿ≥ÿ™ÿå ÿØÿ± ŸàÿßŸÇÿπ ŸÖÿ™ÿπŸÑÿ®ÿßÿ™ ÿπŸÖŸàŸÖ€å Ÿà ÿ¨ŸÖÿπ€å ŸÜ€åÿ≥ÿ™\n",
            "[06:47.480 --> 06:53.480]  ŸÖÿ™ÿ≠ÿßŸÑ ŸÇÿ∂€åŸá Ÿáÿ¨ÿßÿ® ÿ®Ÿá ŸÜÿ∏ÿ± ŸÖŸÜ ÿØÿ± ŸàÿßŸÇÿπ ÿ®ÿ≥ÿ±ÿßÿ™ €å⁄© ÿ≥ŸÖÿ®ŸàŸÑ ŸÖŸÇÿßÿ®ŸÑŸá ÿ®⁄©ŸÜŸá\n",
            "[06:53.480 --> 07:00.480]  ⁄ÜŸàŸÜ ÿß€åŸÜ ÿ±Ÿà ŸÜŸá ÿ™ŸÜŸáÿß ÿß€åÿ±ÿßŸÜ ÿ™Ÿà€å ÿ¨ÿßŸÖÿπŸá ÿ¥ÿß€å ŸÖÿÆÿ™ŸÑŸÅ ÿ®ŸÑ⁄©Ÿá ÿØÿ± ⁄©ÿ¥Ÿàÿ±Ÿáÿß€å ÿØ€å⁄ØŸá ŸáŸÖ ŸÖ€åÿ®€åŸÜ€åÿØ\n",
            "[07:00.480 --> 07:05.480]  ŸÖÿ´ŸÑÿß ŸÇÿ®ŸÑ ÿßÿ≤ ÿßŸÜŸÇŸÑÿßÿ® €å⁄© ⁄Øÿ±ÿß€åÿ¥€å ÿ®Ÿá Ÿáÿ¨ÿßÿ® ÿ®Ÿàÿ¨ŸàÿØ ÿßŸàŸÖÿØŸá ÿ®ŸàÿØ\n",
            "[07:05.480 --> 07:11.480]  ÿßŸàŸÜ ŸáŸÖ ÿ®€åŸÜ ⁄Øÿ±ŸàŸá Ÿáÿß€å€å ⁄©Ÿá ŸÖÿ´ŸÑÿß ŸÖŸàÿ™ÿ±ÿ≤€åŸÜ ÿØÿ± ŸàÿßŸÇÿπ ÿ¥ÿßŸá ÿ®Ÿá Ÿáÿ¨ÿßÿ® ŸÖ€åÿØŸàÿ¥ÿ™ŸÜ\n",
            "[07:11.480 --> 07:15.480]  ÿ®Ÿá ÿÆÿßÿ∑ÿ± ÿß€åŸÜ ⁄©Ÿá ÿ¥ÿßŸá ÿ≥ŸÖÿ®ŸàŸÑ ŸÖÿØÿ±ŸÜ€åÿ≥ÿ™ ÿ®ŸàÿØ Ÿà ÿØÿ± ŸàÿßŸÇÿπ ŸÖ€åÿÆŸàÿßÿ≥ÿ™ŸÜ ÿ®Ÿá ÿßŸàŸÜ ŸÖŸÇÿßÿ®ŸÑŸá ÿ®⁄©ŸÜŸÜ\n",
            "[07:15.480 --> 07:23.480]  Ÿà ÿß€åŸÜ ÿßÿ™ŸÅÿßŸÇ ÿØŸÇ€åŸÇÿß ÿ™Ÿà€å ŸÖÿµÿ± ŸáŸÖ ÿßŸÅÿ™ÿßÿØ ⁄©Ÿá ŸÖÿ´ŸÑÿß ⁄ØŸÅÿ™Ÿá ŸÖ€åÿ¥ŸàÿØ ⁄©Ÿá 70% ÿ¨ŸÖÿπ€åÿ™ ŸÖÿµÿ± ÿ≤ŸÖÿßŸÜ ŸÖÿ®ÿßÿ±⁄© ⁄Øÿ±ÿß€åÿ¥ ÿ®Ÿá Ÿáÿ¨ÿßÿ® Ÿæ€åÿØÿß ⁄©ÿ±ÿØŸÜ\n",
            "[07:23.480 --> 07:29.480]  ÿ≥ÿßŸÑŸáÿß€å ÿ¢ÿÆÿ± ŸÖÿ®ÿßÿ±⁄© ÿßŸàŸÜ ŸáŸÖ ŸàŸÇÿ™€å ŸÖŸÜ ⁄ÜŸÇÿµÿß Ÿæÿ±ÿ≥€åÿØŸÖ ÿßÿ≤ ⁄©ŸÜÿ¥⁄Øÿ±ÿßŸÜ ŸÖÿµÿ±€å ⁄©ŸÅÿ™ŸÜ\n",
            "[07:29.480 --> 07:34.480]  €å⁄©€å ÿØŸÑŸÑÿ¥ ÿß€åŸÜŸá ⁄©Ÿá ÿØÿ± ŸàÿßŸÇÿπ€å ÿ≥ŸÖÿ®ŸàŸÑ ŸÖŸÇÿßÿ®ŸÑŸá ÿ®ÿ± ÿπŸÑ€åŸá ŸÖÿ®ÿßÿ±⁄©€å ⁄©Ÿá ÿ≥ŸÖÿ®ŸàŸÑ ŸÖÿØÿ±ŸÜ€åÿ≥ÿ™€åŸÖ\n",
            "[07:34.480 --> 07:39.480]  Ÿà ÿ®ÿÆÿßÿ∑ÿ± ŸáŸÖ€åŸÜ ÿ®ÿßÿ≤⁄Øÿ¥ÿ™ ÿµÿßŸÜÿ™Ÿà ŸáŸÖ€åÿÆŸàÿßÿ≥ÿ™ŸÜ ŸÅÿßÿµŸÑŸá ÿÆŸàÿØÿ¥ŸàŸÜ ÿ±Ÿà ÿ®ÿß ŸÖÿ®ÿßÿ±⁄© ŸÜÿ¥ŸàŸÜ ÿØÿßÿ±ÿØ\n",
            "[07:39.480 --> 07:47.480]  Ÿà ÿß€åŸÜ ÿ≠ÿßŸÑŸà ŸÖÿß ÿßŸÑÿßŸÜ ÿ™Ÿà ÿß€åŸÜ ÿ≤ŸÖÿßŸÜ ÿØŸÇ€åŸÇÿß ŸÖ€åÿ®€åŸÜ€åŸÖ ⁄©Ÿá ÿ®ÿß ⁄©ÿ¥ŸÅ Ÿáÿ¨ÿßÿ® ÿØÿ± ŸàÿßŸÇÿπ ÿ≤ŸÜÿØŸá ÿ¨ÿßŸÖÿπŸá ÿØÿßÿ±Ÿá\n",
            "[07:47.480 --> 07:52.480]  ŸÅÿßÿµŸÑŸá€å Ÿæ€åÿØÿß ⁄©ÿ±ÿØŸá ÿ®ÿß ÿ≠⁄©ŸÖ€åÿ™ ÿ±Ÿà ÿßÿ≤ ŸÑÿßÿ≤ŸÖ ÿß€åÿØŸàŸÑŸàÿ¨€å ŸÜÿ¥ŸàŸÜ ÿØ€åÿØŸá\n",
            "[07:52.480 --> 07:58.480]  ŸÖÿ´ŸÑÿß €å⁄© ⁄©ÿ≥ÿßŸÜ€å ŸÖÿ´ŸÑ ÿÆÿßŸÜŸÖ ⁄ØŸàŸáÿ± ÿßÿ¥ŸÇ€å €åÿß ÿÆÿßŸÜŸÖ ŸÅÿ≥ŸÅŸÇ€å ⁄©Ÿá ŸÖ€åÿ®€åŸÜ€åŸÖ ÿß€åŸÜŸáÿß ÿ®Ÿá Ÿáÿ¨ÿßÿ® ÿßÿπÿ™ŸÖÿßŸÑÿßŸÜ ÿßÿπÿ™ŸÇÿßÿØ ÿØÿßÿ±ŸÜ\n",
            "[07:58.480 --> 08:04.480]  ÿØÿßÿ¥ÿ™ŸÜ Ÿà ÿ≥ÿßŸÑŸáÿß ŸÖÿ≠ÿ¨ÿ® ÿ®ŸàÿØŸÜ ŸàŸÑ€å ÿ®Ÿá ŸÜÿ¥ÿßŸÜŸá ŸÖŸÇÿßŸàŸÖÿ™ ÿØÿ± ŸàÿßŸÇÿπ Ÿáÿ¨ÿßÿ® ÿ±Ÿà ÿ®ÿ±ÿßŸÖ€å ÿØÿßÿ±ŸÜ\n",
            "[08:04.480 --> 08:12.480]  Ÿà ŸáŸÖ€åŸÜ ÿ∑ÿ±€åŸÇŸá ÿØÿ± ŸàÿßŸÇÿπ ŸÖÿ™ÿßŸÑÿ®ÿßÿ™ ÿ≤ŸÖÿßŸÜ €å⁄© Ÿàÿ≥€åŸÑŸá ŸÇÿØ€åÿ±€å ÿ®ÿ±ÿß€å ÿßŸàŸÜ ŸÖÿ™ÿßŸÑÿ®ÿßÿ™ ÿ¨ŸÖÿπ€å Ÿà ÿπŸÖŸàŸÖ€å\n",
            "[08:12.480 --> 08:18.480]  ⁄©Ÿá ŸÖÿ±⁄©ÿ≤ÿ¥ ÿßŸàŸÜ ÿ±ÿßŸÜŸá Ÿáÿß€å ÿßŸÇÿ™ÿµÿßÿØ€åŸá ŸÖŸÜÿ™ŸÇŸÑŸáÿß ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿ≥ŸÖÿ®ŸàŸÑ ÿßÿ≤ÿ¥ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€åÿ¥Ÿá\n",
            "[08:18.480 --> 08:24.480]  ⁄©Ÿá ŸÖÿπÿ´ÿ±Ÿá Ÿà ⁄ÜŸàŸÜ ÿ¥ÿØÿ™ ÿß€åÿØŸàŸÑŸàÿ¨€å Ÿáÿß⁄©ŸÖ€åÿ™ ÿØÿ± ÿ™ÿπÿ≤ÿßÿØŸá ÿ®€åÿ¥ÿ™ÿ± ÿ®Ÿá ⁄Üÿ¥ŸÖ€å ÿ¢ÿØ\n",
            "[08:24.480 --> 08:27.480]  Ÿà ÿØÿ± ŸàÿßŸÇÿπ ŸÖ€åÿ™ŸàŸÜŸá ÿ¢ÿ≥€åÿ® ÿ¥ÿØ€åÿØ ÿ™ÿß€å€å ÿ±Ÿà ÿß€åÿ¨ÿßÿØ ÿØŸà\n",
            "[08:27.480 --> 08:33.480]  ÿÆÿßŸÜŸÖ ŸÖÿ™ÿßŸÑÿ®€å ÿ¥ŸÖÿß ŸÅ⁄©ÿ± ŸÖ€å⁄©ŸÜ€åÿØ ÿßÿ≤ ÿ®€åŸÜ ÿ±ŸÅÿ∂ŸÜ ŸÇÿ¥ÿ± ŸÖÿ™Ÿàÿ≥ÿ∑ ÿ®Ÿá ÿÆÿßÿ∑ÿ± ÿ®ÿ≠ÿ±ÿßŸÜ Ÿáÿß€å ÿßŸÇÿ™ÿµÿßÿØ€å\n",
            "[08:33.480 --> 08:37.480]  Ÿáÿß€å€å ÿ®Ÿá ÿß€åŸÜ ŸÖŸÜ€åŸá ⁄©Ÿá ŸÖÿ™ÿßŸÑÿ®ÿßÿ™ ÿß€åŸÜ ŸÇÿ¥ÿ± ŸáŸÖ ÿ±ŸÜ⁄Ø ŸÖ€åÿ®ÿßÿ≤Ÿáÿü\n",
            "[08:37.480 --> 08:41.480]  ÿ®Ÿá ŸÜÿ∏ÿ± ŸÖŸÜ ŸÖÿ™ÿßŸÑÿ®ÿßÿ™ ŸÇÿ¥ÿ± ÿØÿ± ŸàÿßŸÇÿπ €åŸá ÿ™ÿ∫€å€åÿ± ŸÖÿßÿ≠€åÿ™€å ŸÖ€åÿØŸá\n",
            "[08:41.480 --> 08:45.480]  €åÿπŸÜ€å ÿß€åŸÜ ⁄©Ÿá €å⁄© ŸÖÿ™ÿßŸÑÿ®ÿßÿ™€å ⁄©Ÿá ÿØÿ± ŸàÿßŸÇÿπ ŸÖÿ™ÿßŸÑÿ®ÿßÿ™ ÿ¢ÿ≤ÿßÿØ€å€å €åÿß ÿßÿ¨ÿ™ŸÖÿßÿπ€å€å ÿ®ŸàÿØŸá\n",
            "[08:45.480 --> 08:51.480]  ⁄©Ÿá ÿ®ÿ±ÿß€å ŸÇÿ¥ÿ± ŸÖÿ™Ÿàÿ≥ÿ∑ Ÿàÿ¨ŸàÿØ ÿØÿßÿ±Ÿá Ÿà ÿ®ÿπÿØ ŸàŸÇÿ™€å ⁄©Ÿá ÿ∑ÿ®ŸÇŸá ÿßŸÇÿ™ÿµÿßÿØ€åÿ¥ ÿ™ÿ∫€å€åÿ± ŸÖ€å⁄©ŸÜŸá Ÿà ÿ≥ŸÇŸàÿ∑ ŸÖ€å⁄©ŸÜŸá\n",
            "[08:51.480 --> 08:54.480]  ŸàŸÇÿ™€å ŸÖÿ™ÿßŸÑÿ®ÿßÿ™ ÿßŸÇÿ™ÿµÿßÿØ€å ŸáŸÖ ÿ®Ÿáÿ¥ ÿßÿ∂ÿßŸÅŸá ŸÖ€åÿ¥Ÿá\n",
            "[08:54.480 --> 09:01.480]  €åÿπŸÜ€å ÿØÿ± ŸàÿßŸÇÿπ ÿ®ÿÆŸàÿß€å€åÿØ ÿ±Ÿà€å ÿß€åŸÜ ÿßÿ±ŸáŸÜ ŸÖŸàÿ≤ ÿ±Ÿà ŸÜ⁄ØÿßŸá ÿ®⁄©ŸÜ€åÿØ ŸÖÿ™ÿßŸÑÿ®ÿßÿ™ÿ¥ ŸÖ€åÿ±Ÿá ÿ®Ÿá ÿ≥ŸÖÿ™ ⁄©Ÿá ÿØÿ± ŸàÿßŸÇÿπ ŸÖÿ¥ÿ±Ÿà€åÿ™ÿ¥ ÿßÿ™ŸÅÿßŸÇÿß ÿ®€åÿ¥ÿ™ÿ± ŸÖ€åÿ¥Ÿá\n",
            "[09:01.480 --> 09:07.480]  ÿ™ŸÜÿ¥ŸÖŸàŸÑ€åÿ¥ ÿ®€åÿ¥ÿ™ÿ± ŸÖ€åÿ¥Ÿá Ÿà ÿ≠€åÿßÿ™€å ÿ™ÿ± ÿ®ŸàÿØŸÜÿ¥ ÿßÿ≠ŸÜ€åÿ™ÿ¥ ÿ®€åÿ¥ÿ™ÿ± ŸÖ€åÿ¥Ÿá Ÿà ÿØÿ± ŸàÿßŸÇÿπ ÿßÿ∂ÿßŸÅŸá ŸÖ€åÿ¥Ÿá\n",
            "[09:07.480 --> 09:10.480]  ÿ®Ÿá ŸÖÿ™ÿßŸÑÿ®ÿßÿ™ÿ¥ ⁄©ŸÖÿ™ÿ± ŸÜŸÖ€åÿ¥Ÿá\n",
            "[09:10.480 --> 09:16.480]  ÿßÿ≤ ÿ∑ÿ±ŸÅ€å ÿ®Ÿá ÿÆÿßÿ∑ÿ± ÿß€åŸÜ ⁄©Ÿá ÿ¨ÿß€å⁄ØÿßŸá ÿßÿ¨ÿ™ŸÖÿßÿπ€å Ÿà ⁄©ÿ±ÿßŸÖÿ™ ÿßŸàŸÜ ÿ∑ÿ®ŸÇŸá ŸÖÿß ÿ™Ÿàÿ≥ÿ∑ ÿ™ÿ∫€å€åÿ± ⁄©ÿ±ÿØŸá\n",
            "[09:16.480 --> 09:21.480]  ÿØŸà⁄Üÿßÿ± ÿ™ÿ∫€å€åÿ± ŸáŸÖ ÿ¥ÿØŸá Ÿà ÿß€åŸÜ ŸÖŸÜÿ¨ÿ±ÿØ ÿßŸÜÿ®ÿßÿ¥ÿ™ ÿ¥ÿØŸÜ ÿÆÿ¥ŸÖ€å ŸÖ€åÿ¥Ÿá\n",
            "[09:21.480 --> 09:28.480]  ⁄©Ÿá ÿØÿ± ŸàÿßŸÇÿπ ÿßŸÖ⁄©ÿßŸÜ ÿØÿßÿ±Ÿá ⁄©Ÿá ÿ≠ÿ™€å ÿßŸÜ⁄Ø€åÿ≤Ÿá Ÿáÿß€å ÿß€åŸÜ ÿ®ÿÆÿ¥ ÿ¨ÿßŸÖÿπŸá ÿ±Ÿà ÿ™ÿ¥ÿØ€åÿØ ÿ®⁄©ŸÜŸá\n",
            "[09:28.480 --> 09:33.480]  ⁄ÜŸàŸÜ ŸÇÿ®ŸÑÿß ÿØÿ± ŸàÿßŸÇÿπ ŸÖÿ™ÿßŸÑÿ®ÿßÿ™ €å⁄© ÿ≥ÿ∑ÿ≠ ÿ®ÿßŸÑÿßÿØÿ±Ÿá ÿ±Ÿàÿ¥ŸÜ ŸÅ⁄©ÿ± ÿØÿßÿ±ÿØ\n",
            "[09:33.480 --> 09:41.480]  ÿ≠ŸÇŸàŸÇ ÿßŸÜÿ≥ÿßŸÜ€å Ÿà ÿ¢ÿ≤ÿßÿØ€å Ÿáÿß€å ÿßÿ¨ÿ™ŸÖÿßÿπ€å ÿØÿßÿ±ÿØ Ÿà ÿ®ÿπÿØÿ¥ ÿØÿ±ÿ≥€åÿØŸá ÿ®Ÿá ŸÖÿ™ÿßŸÑÿ®ÿßÿ™ ÿÆ€åŸÑ€å ŸÖŸáŸÖÿ™ÿ±€å ÿ≠€åÿßÿ™€å ÿ™ÿ± ÿßŸÇÿ™ÿµÿßÿØ€å\n",
            "[09:41.480 --> 09:45.480]  Ÿà ÿØÿ± ÿß€åŸÜ ÿ≠ÿßŸÑ ⁄©ÿ±ÿßŸÖÿ™ÿ¥ ŸáŸÖ ÿßÿ≤ ÿ®Ÿá ÿß€åŸÜ ŸàŸÇÿ™Ÿá Ÿáÿ≥ÿ™Ÿá\n",
            "[09:45.480 --> 09:56.480]  ÿØŸà⁄Üÿßÿ± ÿ®ÿ∫ÿ±ÿßŸÜ ÿ≠ŸÇŸàŸÇ€åÿ™€å ŸáŸÖ ÿ¥ÿØŸá Ÿà ÿß€åŸÜ ÿßÿ≠ÿ™ŸÖÿßŸÑÿß ŸÖŸÖ⁄©ŸÜŸá ⁄©Ÿá ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿßŸÜÿ™ÿ¨ÿßÿ±Ÿáÿß€å€å ⁄©Ÿá ÿÆ€åŸÑ€å ŸÜ€åÿ±Ÿà€å ÿ¥ÿØ€åÿØ ÿ™ÿ±€å ÿØÿßÿ±Ÿá ⁄Øÿ±ÿ≥ ÿ®⁄©ŸÜŸá\n",
            "[09:56.480 --> 10:00.480]  €å⁄© ŸÜ⁄©ÿ™Ÿá ÿØ€å⁄ØŸá€å ⁄©Ÿá ÿØÿ± ÿß€åŸÜ ⁄ØŸÅÿ™⁄ØŸà ÿ™Ÿàÿ¨Ÿá ÿ¨ÿ±ÿ® ŸÖ€å ⁄©ŸÜŸá\n",
            "[10:00.480 --> 10:06.480]  ÿßŸÅÿ∂ÿßÿπÿ¥ ŸÖÿ≠ÿßÿ¨ÿ±ÿ™ Ÿà ÿ™ÿ∫€å€åÿ± ÿ¨ÿßŸÖÿπŸá ŸÖÿ≠ÿßÿ¨ÿ± ÿß€åÿ±ÿßŸÜ€å ÿÆÿßÿ±ÿ¨ ÿßÿ≤ ⁄©ÿ¥Ÿàÿ±Ÿá ⁄©Ÿá ÿ¥ŸÖÿß ÿ®Ÿáÿ¥ ÿßÿ¥ÿßÿ±Ÿá ⁄©ÿ±ÿØ€åÿØ\n",
            "[10:06.480 --> 10:15.480]  ÿß€åÿ±ÿßŸÜ€åÿßŸÜ ŸÖÿ≠ÿßÿ¨ÿ± ⁄©Ÿá ÿ¨ŸÖÿπ€åÿ™ÿ¥ŸàŸÜ ÿ®Ÿá ÿ¥⁄©ŸÑ ⁄Üÿ¥ŸÖ⁄Ø€åÿ±€å ÿ≤€åÿßÿØ ÿ¥ÿØŸá Ÿà ÿ±ŸàŸÜÿØ ÿ™ÿ≠ŸàŸÑÿßÿ™ ÿØÿßÿÆŸÑ ÿß€åÿ±ÿßŸÜ ŸÅ⁄©ÿ± ŸÖ€å⁄©ŸÜ€åÿØ ⁄ÜŸá ÿ™ÿ£ÿ´€åÿ± ÿÆŸàÿßŸáŸÜÿØ ÿØÿßÿ¥ÿ™ÿü\n",
            "[10:15.480 --> 10:22.480]  ÿØÿ± ŸÖŸàÿ±ÿØ ÿß€åŸÜ ŸÖÿ≥ÿ¶ŸÑŸá Ÿæ€åŸÖŸÇÿ± ÿ®ÿßŸÇ€åŸÖ Ÿáÿ±⁄©€åÿ≤ ÿ®Ÿá ŸÖÿ™ÿπŸÑŸÇÿßÿ™ ÿßŸÖÿ±Ÿä⁄©ÿß Ÿàÿ¨ŸàÿØ ÿØÿßÿØŸá Ÿáÿß€å ÿ®€åÿ¥ÿ™ÿ±€å ŸÖÿß ŸÑÿßÿ≤ŸÖ ÿØÿßÿ±€åŸÖ\n",
            "[10:22.480 --> 10:34.480]  ÿ®Ÿá ŸÜÿ∏ÿ± ŸÖ€å ÿ±ÿ≥ÿØ ⁄©Ÿá ÿØÿ± ÿ¨ŸÖÿπŸá ÿØ€åÿßÿ≥ŸÅÿßÿ±Ÿá ÿØÿ± ŸàÿßŸÇÿπ ÿ™ŸàŸÜÿ≥ÿ™ ÿØÿ± €å⁄© ŸàŸÇÿ™ ÿ™ÿÆŸÜ⁄ØŸà€å ÿÆŸàÿ®€å ÿ®ÿ±ÿß€å ÿµÿØÿß€å ÿ¨ÿßŸÖÿπ€å ÿØÿßÿÆŸÑ ÿß€åÿ±ÿßŸÜ ÿ±Ÿà ÿ®ÿ±ÿ≥ŸÜŸá ÿ®Ÿá ÿÆÿßÿ±ÿ¨ ÿß€åÿ±ÿßŸÜ\n",
            "[10:34.480 --> 10:44.480]  Ÿà ÿØÿ± ŸàÿßŸÇÿπ ÿ¨ÿ±ŸÖ ÿ™Ÿàÿ¨Ÿá ⁄©ÿßŸÅ€å ÿ®⁄©ŸÜŸá ÿØÿ± ÿ¨ÿßŸÖÿπ€å ÿ¨ÿßŸÖÿπ€å Ÿà ÿ≠ÿ™€å ⁄©Ÿá ÿ™⁄©ÿßŸÜŸáÿß€å€å ÿ±Ÿà ÿß€åÿ¨ÿßÿØ ÿ®⁄©ŸÜŸá Ÿà ÿß€åŸÜ ⁄©Ÿá ÿ™ÿ±ÿØ€åÿØ ÿ®⁄©ŸÜŸÜ ÿØŸàŸÑÿ™€å\n",
            "[10:44.480 --> 11:14.480]  ÿß€åŸÜ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€åÿØ ÿ®ÿß€å\n",
            "[11:14.480 --> 11:19.880]  ÿ®ÿ™ŸàŸÜŸá ÿ¨ÿßŸÖÿπŸá ÿØ€åÿßÿ≥ÿ™ÿßÿ± ÿ®€åŸá ⁄©Ÿá ÿßŸàŸÜÿ¨ÿß Ÿæ€å Ÿàÿßÿ≠ÿØ€å ÿ±Ÿà ÿß€åÿ¨ÿßÿØ ÿ®⁄©ŸÜŸá Ÿà ÿ®ÿ™ŸàŸÜŸá ŸÇŸÑÿ®Ÿá ÿ®⁄©ŸÜŸá\n",
            "[11:19.880 --> 11:27.480]  Ÿà ŸÖ⁄©ÿßŸÜ€åÿ≥ŸÖ Ÿáÿß€å ŸÖŸáŸÜÿØÿ≥€å ÿπÿ®ŸÇÿßÿ± ÿßŸÖŸàŸÖ€å ÿ≥€åÿ≥ÿ™ŸÖ Ÿáÿß€å ÿßŸÖŸÜ€åÿ™€å ÿ≠ÿß⁄©ŸÖ€åÿ™ ⁄©Ÿá ÿØÿ±ŸàŸÇÿ™ ÿ≠ŸÅÿ±ŸÇŸá ÿ±ÿß ÿ™ÿ¥⁄©€åŸÑ ŸÖ€å ⁄©ŸÜŸá\n",
            "[11:27.480 --> 11:31.680]  Ÿà ÿ®ÿ™ŸàŸÜŸá ÿßÿ≤ ÿß€åŸÜ ŸÖŸÜÿπ ÿßÿ®Ÿàÿ± ÿ®⁄©ŸÜŸá ÿ®Ÿá ÿßÿ≠ÿ™ŸÖÿßŸÑ ÿ≤€åÿßÿØ ŸÖ€åÿ™ŸàŸÜŸá ÿ™ÿ£ÿ´€åÿ± ⁄Øÿ∞ÿßÿ± ÿ®ÿßÿ¥Ÿá\n",
            "[11:31.680 --> 11:38.480]  ÿ®ÿ≥€åÿßÿ± ÿ≥Ÿæÿßÿ≥ ⁄Øÿ∞ÿßÿ±ŸÖ ÿßÿ≤ ÿ¥ŸÖÿß ÿ≥Ÿáÿ± ŸÖÿ∑ŸÑÿ®€å Ÿæÿ¨Ÿà€åÿ¥⁄Øÿ± ÿ®Ÿá ÿßÿÆÿ™€åÿßÿ± ÿ¨ŸÖÿπ€åÿ™ ÿ®€åŸÜ ÿßŸÑŸÖŸÑŸÑ ÿßÿ≤ ŸÖÿßŸÑŸÖŸà ÿ≥Ÿàÿ¶ÿØ\n",
            "[11:38.480 --> 11:44.480]  ÿßÿ≤ ÿ∑ÿ±ŸÅ ÿÆŸàÿØŸÖ Ÿà ÿπŸÑ€å ÿ±ÿ≤ÿß ÿ±Ÿàÿ¥ŸÜ ÿ™Ÿá€å€å ⁄©ŸÜŸÜÿØŸá ÿß€åŸÜ ÿ®ÿ±ŸÜÿßŸÖŸá ÿßÿ≤ ŸáŸÖÿ±ÿßŸá€å ÿ¥ŸÖÿß ÿ™ÿ¥⁄©ÿ± ŸÖ€å⁄©ŸÜŸÖ\n",
            "Time consumpution 323.9818706512451s for transcribing\n",
            "Write SRT file to '/content/20636_4_5771510420242174755.srt'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-cd8ca7ae6b75>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mdiarization_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mfinal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiarize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiarization_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from whisper.utils import WriteSRT\n",
        "from whisper import Whisper\n",
        "\n",
        "# Assuming you have a function to extract audio segments and features\n",
        "def extract_features(audio_segment):\n",
        "    # Placeholder for feature extraction logic\n",
        "    # This should return a feature vector for the audio segment\n",
        "    return np.random.rand(10) # Example feature vector\n",
        "\n",
        "# Assuming you have a function to perform clustering\n",
        "def perform_clustering(features, num_speakers):\n",
        "    # Placeholder for clustering logic\n",
        "    # This should return the speaker ID for each audio segment\n",
        "    return [0] * len(features) # Example clustering result\n",
        "\n",
        "# Assuming you have a function to align diarization results with the transcript\n",
        "def diarize_text(transcription, diarization_result):\n",
        "    # Placeholder for diarization result processing\n",
        "    # This should align the diarization results with the transcript\n",
        "    return [] # Example diarization result\n",
        "\n",
        "#@markdown # **Run the model** üöÄ\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** ‚öôÔ∏è\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"Auto detection\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "language = (None if language == \"Auto detection\" else language)\n",
        "verbose = verbose_lut[verbose]\n",
        "\n",
        "\n",
        "if Model.endswith(\".en\") and language not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{language}'; using English instead.\")\n",
        "    language = \"en\"\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(audio_path_local)[0] + \".txt\"\n",
        "\n",
        "# Transcribe the audio\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper.transcribe(\n",
        "    model=whisper_model,\n",
        "    audio=str(audio_path_local),\n",
        "    verbose=True,\n",
        "    task='transcribe',\n",
        "    language=None\n",
        ")\n",
        "toc = time.time()\n",
        "print(f'Time consumed: {toc-tic}s for transcribing')\n",
        "\n",
        "# Extract audio segments and features\n",
        "audio_segments = [] # Placeholder for extracted audio segments\n",
        "features = [extract_features(segment) for segment in audio_segments]\n",
        "\n",
        "# Perform clustering to identify speakers\n",
        "num_speakers = 2 # Example number of speakers\n",
        "clusters = perform_clustering(features, num_speakers)\n",
        "\n",
        "# Align diarization results with the transcript\n",
        "final_result = diarize_text(transcription, clusters)\n",
        "\n",
        "# Write the transcript with speakers to a file\n",
        "lines = []\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    lines.append(line)\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "print(\"Transcript with speakers saved to\", transcript_with_speakers_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "Dw-cx9hNqf2L",
        "outputId": "9356f6dc-f2ff-4646-fddd-45e1a87905da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### /content/20636_4_5771510420242174755.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribe in progress...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'device'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0fe2cffbd25c>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transcribe in progress...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m transcription = whisper.transcribe(\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhisper_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \"\"\"\n\u001b[1;32m    110\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdecode_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fp16\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Performing inference on CPU when CUDA is available\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'device'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from whisper.utils import WriteSRT\n",
        "from whisper import Whisper\n",
        "\n",
        "# Load the Whisper model\n",
        "\n",
        "# Assuming you have a function to extract audio segments and features\n",
        "def extract_features(audio_segment):\n",
        "    # Placeholder for feature extraction logic\n",
        "    # This should return a feature vector for the audio segment\n",
        "    return np.random.rand(10) # Example feature vector\n",
        "\n",
        "# Assuming you have a function to perform clustering\n",
        "def perform_clustering(features, num_speakers):\n",
        "    # Placeholder for clustering logic\n",
        "    # This should return the speaker ID for each audio segment\n",
        "    return [0] * len(features) # Example clustering result\n",
        "\n",
        "# Assuming you have a function to align diarization results with the transcript\n",
        "def diarize_text(transcription, diarization_result):\n",
        "    # Placeholder for diarization result processing\n",
        "    # This should align the diarization results with the transcript\n",
        "    return [] # Example diarization result\n",
        "#@markdown # **Run the model** üöÄ\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** ‚öôÔ∏è\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"Auto detection\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "language = (None if language == \"Auto detection\" else language)\n",
        "verbose = verbose_lut[verbose]\n",
        "\n",
        "\n",
        "if Model.endswith(\".en\") and language not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{language}'; using English instead.\")\n",
        "    language = \"en\"\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "# Your existing code for transcribing with Whisper\n",
        "\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(audio_path_local)[0] + \".txt\"\n",
        "\n",
        "# Transcribe the audio\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper.transcribe(\n",
        "    model=whisper_model,\n",
        "    audio=str(audio_path_local),\n",
        "    verbose=True,\n",
        "    task='transcribe',\n",
        "    language=None\n",
        ")\n",
        "toc = time.time()\n",
        "print(f'Time consumed: {toc-tic}s for transcribing')\n",
        "\n",
        "# Extract audio segments and features\n",
        "audio_segments = [] # Placeholder for extracted audio segments\n",
        "features = [extract_features(segment) for segment in audio_segments]\n",
        "\n",
        "# Perform clustering to identify speakers\n",
        "num_speakers = 2 # Example number of speakers\n",
        "clusters = perform_clustering(features, num_speakers)\n",
        "\n",
        "# Align diarization results with the transcript\n",
        "final_result = diarize_text(transcription, clusters)\n",
        "\n",
        "# Write the transcript with speakers to a file\n",
        "lines = []\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    lines.append(line)\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "print(\"Transcript with speakers saved to\", transcript_with_speakers_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "uL8jCIC4r0hD",
        "outputId": "dee89c04-be30-4020-bb1f-2559edbe0ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### /content/20636_4_5771510420242174755.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### /content/20636_4_5771510420242174755.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribe in progress...\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Persian\n",
            "[00:00.000 --> 00:03.200]  ÿØ⁄©ÿ™ÿ± ÿ≥ŸÖÿß€åŸá ÿ™ŸàŸá€åÿØŸÑŸà ÿ¨ÿßŸÖÿπŸá ÿ¥ŸÜÿßÿ≥ ŸÖ€å⁄ØŸà€åÿØ\n",
            "[00:03.200 --> 00:05.600]  ÿ¨ÿß€å⁄ØÿßŸá ÿ≤ŸÜÿßŸÜ ÿØÿ± ÿ¨ÿßŸÖÿπŸá ÿß€åÿ±ÿßŸÜ€å\n",
            "[00:05.600 --> 00:10.080]  ÿ®ÿπÿØ ÿßÿ≤ ÿ¨ŸÜÿ®ÿ¥ Ÿáÿß€å ÿ≥ÿßŸÑŸá 1400 Ÿà 1ÿå 2ÿå 4 ÿ™ÿ∫€å€åÿ± Ÿà ÿ™ÿ∫ŸàŸÑ ÿ¥ÿØŸá\n",
            "[00:16.240 --> 00:20.080]  ÿ≥ŸÑÿßŸÖ ŸÖŸÜ ÿ®€åÿ™ ÿ¢ÿ∞ÿ±€å ÿ®ÿß ÿ®ÿ±ŸÜÿßŸÖŸá ÿØ€åÿØ⁄©ÿß ŸáŸÖÿ±ÿßŸá ÿ¥ŸÖÿß Ÿáÿ≥ÿ™ŸÖ\n",
            "[00:22.200 --> 00:25.480]  ÿÆÿßŸÜŸÖ ÿ™ŸàŸá€åÿØŸÑŸà ÿ®Ÿá ÿÆÿ®ÿ± ÿ¢ŸÜŸÑÿß€åŸÜ ⁄ØŸÅÿ™Ÿá ÿßÿ≤ ÿØŸáŸá ŸáŸÅÿ™ÿßÿØ\n",
            "[00:25.480 --> 00:28.000]  ÿ®ÿß ÿ™Ÿàÿ¨Ÿá ÿ®Ÿá Ÿæ€åŸÖÿß€åÿ¥ Ÿáÿß€å ÿßŸÜÿ¨ÿßŸÖ ÿ¥ÿØŸá\n",
            "[00:28.000 --> 00:32.000]  ŸÖÿß €å⁄© ÿ¨ÿßŸÖÿπŸá ŸÖÿ±ÿØ ÿ≥ÿßŸÑÿßÿ± ÿ±ÿß ÿØÿßÿ¥ÿ™€åŸÖ ⁄©Ÿá ŸáŸÖ€åÿ¥Ÿá ÿ®Ÿá ÿ¥⁄©ŸÑ ŸÖÿ¥ÿÆÿµ€å\n",
            "[00:32.000 --> 00:34.240]  ÿ®Ÿá ŸÖÿ≠ÿØŸàÿØ ⁄©ÿ±ÿØŸÜ ÿ≤ŸÜÿßŸÜ ŸÖ€åÿ±ÿ≥€åÿØ\n",
            "[00:34.240 --> 00:38.320]  ÿßŸÖÿß ÿØÿ± ÿ≥ÿßŸÑ 1400 Ÿà 2 €å⁄© ÿ®ÿßÿ±Ÿá ÿ®ÿß ÿ¨ŸÖÿπ€åÿ™€å ŸÖŸàÿßÿ¨Ÿá ŸÖ€åÿ¥Ÿà€åŸÖ\n",
            "[00:38.320 --> 00:41.680]  ⁄©Ÿá ÿ®Ÿá ÿπÿ±ÿµ ÿ®ÿ±ÿØŸÜ €å⁄© ÿ≥ÿßŸÜ ÿ≤ŸÜ Ÿà ŸÖÿ±ÿØ ÿ®ÿßŸàÿ±ÿØÿßÿ±ŸÜÿØ\n",
            "[00:41.680 --> 00:45.040]  ÿ≠ŸÇ ÿ™ŸÑÿßŸÇ ÿ®ÿ±ÿß€å ÿ≤ŸÜÿßŸÜ ŸÖŸàÿ±ÿØ Ÿæÿ∞€åÿ±ÿ¥ ŸÇÿ±ÿßÿ± ŸÖ€å⁄Ø€åÿ±ÿØ\n",
            "[00:45.040 --> 00:47.480]  Ÿà Ÿæÿ∞€åÿ±ÿ¥ Ÿáÿß€å ÿßÿ¨ÿ™ŸÖÿßÿπ€å ŸàÿßŸÑÿØ€åŸÜ\n",
            "[00:47.480 --> 00:50.200]  ÿ®ÿ±ÿß€å ÿ™ÿ∫€å€åÿ±ÿßÿ™ ŸÅÿ±ÿ≤ŸÜÿØÿßŸÜ ÿ®ÿßŸÑÿß ÿ±ŸÅÿ™ÿ≥ÿ™\n",
            "[00:50.240 --> 00:52.720]  ÿ®Ÿá ÿßÿπÿ™ŸÇÿßÿØ ÿ™ŸàŸá€åÿØŸÑŸà ÿß€åŸÜ ÿ™ÿ∫€å€åÿ±ÿßÿ™ ŸÜÿ¥ÿßŸÜÿØŸáŸÜÿØŸá\n",
            "[00:52.720 --> 00:57.120]  ÿ™ÿ≥ÿßŸáŸÑ ÿ®€åŸÜ⁄Øÿ±ŸàŸá€å Ÿà ÿ®€åŸÜ ÿÆÿßŸÜŸàÿßÿØ⁄Ø€å ÿØÿ±ŸÖ€åÿßŸÜ ŸÖÿ±ÿØŸÖ ÿßÿ≥ÿ™\n",
            "[00:57.120 --> 01:01.040]  ÿØÿ± ÿØ€åÿØ⁄ØÿßŸá ÿ®ÿ±ÿß€å ÿ®ÿ±ÿ±ÿ≥€å ÿ¨ÿ≤€åÿßÿ™ ⁄ØŸÅÿ™⁄ØŸà€å ÿ≥ŸÖ€åÿ™ ÿ™ŸàŸá€åÿØŸÑŸà\n",
            "[01:01.040 --> 01:06.680]  ÿ®ÿß ÿ≥Ÿáÿ± ŸÖÿ™ŸÑÿ®€å Ÿæÿ¨ŸàŸáÿ¥⁄©ÿ± ÿ®ŸáÿØÿßÿ¥ÿ™ ÿ¨ŸÖÿπ€åÿ™ ÿ®€åŸÜ ÿßŸÑŸÖŸÑŸÑ ÿßÿ≤ ÿ≥Ÿàÿ¶ÿØ ŸáŸÖÿ±ÿßŸá ŸÖ€åÿ¥Ÿà€åŸÖ\n",
            "[01:11.680 --> 01:14.720]  ÿÆÿßŸÜ ŸÖÿ™ŸÑÿ®€å Ÿæ€åÿ¥ ÿßÿ≤ ÿß€åŸÜ ⁄©Ÿá ŸÖŸÜ Ÿæÿ±ÿ≥ÿ¥Ÿà ŸáŸÖ ŸÖÿ∑ÿ±ÿ≠ ⁄©ŸÜŸÖ\n",
            "[01:14.720 --> 01:19.200]  ÿÆŸàÿßŸáÿ¥ ŸÖ€å⁄©ŸÜŸÖ ÿÆŸÑÿßÿµŸá ÿß€å ÿßÿ≤ ÿπÿ±ÿ∂€åÿßÿ®€å Ÿáÿß€å ÿØ⁄©ÿ™ÿ± ÿ≥ŸÖ€åÿ™ ÿ™ŸàŸá€åÿØŸÑŸà\n",
            "[01:19.200 --> 01:24.600]  ÿßÿ≤ ÿ™ÿ≠ŸàŸÑÿßÿ™ ÿ¨ÿßŸÖÿπŸá ÿß€åÿ±ÿßŸÜ ÿ®ÿπÿØ ÿßÿ≤ ÿßÿπÿ™ÿ±ÿßÿ≤ÿßÿ™ 1401 ÿ±Ÿà ÿ®ÿ±ŸÖŸàŸÜ ŸÖÿ±Ÿàÿ± ⁄©ŸÜ€åÿØ\n",
            "[01:24.600 --> 01:26.360]  ÿ®ÿπÿØ Ÿàÿßÿ±ÿØ Ÿà ÿ¨ÿ≤€åÿßÿ™ ÿ®ÿ¥€åŸÖ\n",
            "[01:26.360 --> 01:28.680]  ÿ®ÿß ÿµÿØÿß ŸÅŸÇÿ∑ ÿÆÿØŸÖÿ™ ÿ¥ŸÖÿß ÿ®ÿ®€åŸÜ€åÿØ\n",
            "[01:28.680 --> 01:31.720]  ÿß€åŸÜ ÿ®ÿ∫ÿßŸÑÿß ÿ®Ÿá ŸÜÿ∏ÿ±ŸÖÿ™ ŸÅŸÇÿ∑ ŸÜŸÅÿπŸá ÿÆ€åŸÑ€å ÿ¨ÿßŸÑÿ®€å ÿØÿßÿ¥ÿ™\n",
            "[01:31.720 --> 01:34.120]  ÿ®Ÿá ÿ∑ŸàŸÑ ŸÖÿ¥ÿßŸÇÿµŸÖ ŸÖŸáŸÖÿ™ÿ±€åŸÜ ⁄Ü€åÿ≤€å ⁄©Ÿá\n",
            "[01:34.120 --> 01:37.560]  ÿ™ÿ∫€å€åÿ±ÿßÿ™ ⁄©Ÿá ÿØÿ± ŸàŸÇÿ™ ÿß€åÿ¥ŸàŸÜ ÿßÿ¥ÿßÿ±Ÿá ⁄©ÿ±ÿØŸá ÿ®ŸàÿØŸÜ ÿ®Ÿáÿ¥\n",
            "[01:37.560 --> 01:41.600]  ÿß€åŸÜ€å ⁄©Ÿá ÿ¨ÿßŸÖÿπŸá ÿØÿ± ŸàŸÇÿ™ ÿ™ÿπÿßŸÖŸÑ ⁄Øÿ±ŸàŸá Ÿáÿß Ÿà ÿ®ŸÇÿ¥ Ÿà ÿ®ŸÇÿ¥ Ÿà ŸÖÿÆÿ™ŸÑŸÅ\n",
            "[01:41.600 --> 01:43.800]  ÿ®Ÿá ÿß€å⁄© ÿ™ÿ≥ÿßŸáŸÑ€å ÿ±Ÿà ÿ™ÿ¨ÿ±ÿ®Ÿá ŸÖ€å⁄©ŸÜŸá\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming necessary imports are done at the beginning of your script\n",
        "# For example:\n",
        "# from some_library import pipeline, diarize_text\n",
        "\n",
        "# Your existing code for setting parameters and paths\n",
        "# Your existing code for setting parameters and paths\n",
        "language = (None if language == \"Auto detection\" else language)\n",
        "\n",
        "# Safely access the verbose_lut dictionary using .get()\n",
        "verbose = verbose_lut.get(verbose, verbose)\n",
        "\n",
        "if Model.endswith(\".en\") and language not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{language}'; using English instead.\")\n",
        "    language = \"en\"\n",
        "\n",
        "\n",
        "display(Markdown(f\"### {filepath}\"))\n",
        "\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(filepath)[0] + \".txt\"\n",
        "print(\"audio local path:\", audio_path_local)\n",
        "\n",
        "import time\n",
        "\n",
        "# Transcribe\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper.transcribe(\n",
        "    model=whisper_model,\n",
        "    audio=str(audio_path_local),\n",
        "    verbose=verbose,\n",
        "    task=task,\n",
        "    language=language\n",
        ")\n",
        "# Time consumed\n",
        "toc = time.time()\n",
        "print(f'Time consumed {toc-tic}s for transcribing')\n",
        "\n",
        "# Write SRT file\n",
        "from whisper.utils import WriteSRT\n",
        "with open(subtitle_file, \"w\", encoding=\"utf-8\") as srt:\n",
        "    writer = WriteSRT(audio_path_local.parent)\n",
        "    writer.write_result(transcription, srt)\n",
        "print(f\"Write SRT file to '{subtitle_file}'\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Check if pipeline is callable before using it\n",
        "if callable(pipeline):\n",
        "    diarization_result = pipeline(audio_path_local)\n",
        "    final_result = diarize_text(transcription, diarization_result)\n",
        "else:\n",
        "    print(\"Error: pipeline is not callable. Please ensure it is correctly defined and initialized.\")\n",
        "    # Handle the error appropriately, e.g., by exiting the script or skipping the diarization step\n",
        "\n",
        "lines = list()\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    print(f\"{line}\")\n",
        "    lines.append(line)\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "display(Markdown(f\"**Transcript file created: {transcript_with_speakers_file}**\"))"
      ],
      "metadata": {
        "id": "Un2zHXulsxQm",
        "outputId": "896a33cd-c811-49c0-9874-c144f64dcf55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### /content/20636_4_5771510420242174755.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio local path: /content/20636_4_5771510420242174755.wav\n",
            "Transcribe in progress...\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Persian\n",
            "[00:00.000 --> 00:03.200]  ÿØ⁄©ÿ™ÿ± ÿ≥ŸÖÿß€åŸá ÿ™ŸàŸá€åÿØŸÑŸà ÿ¨ÿßŸÖÿπŸá ÿ¥ŸÜÿßÿ≥ ŸÖ€å⁄ØŸà€åÿØ\n",
            "[00:03.200 --> 00:05.600]  ÿ¨ÿß€å⁄ØÿßŸá ÿ≤ŸÜÿßŸÜ ÿØÿ± ÿ¨ÿßŸÖÿπŸá ÿß€åÿ±ÿßŸÜ€å\n",
            "[00:05.600 --> 00:10.080]  ÿ®ÿπÿØ ÿßÿ≤ ÿ¨ŸÜÿ®ÿ¥ Ÿáÿß€å ÿ≥ÿßŸÑŸá 1400 Ÿà 1ÿå 2ÿå 4 ÿ™ÿ∫€å€åÿ± Ÿà ÿ™ÿ∫ŸàŸÑ ÿ¥ÿØŸá\n",
            "[00:16.240 --> 00:20.080]  ÿ≥ŸÑÿßŸÖ ŸÖŸÜ ÿ®€åÿ™ ÿ¢ÿ∞ÿ±€å ÿ®ÿß ÿ®ÿ±ŸÜÿßŸÖŸá ÿØ€åÿØ⁄©ÿß ŸáŸÖÿ±ÿßŸá ÿ¥ŸÖÿß Ÿáÿ≥ÿ™ŸÖ\n",
            "[00:22.200 --> 00:25.480]  ÿÆÿßŸÜŸÖ ÿ™ŸàŸá€åÿØŸÑŸà ÿ®Ÿá ÿÆÿ®ÿ± ÿ¢ŸÜŸÑÿß€åŸÜ ⁄ØŸÅÿ™Ÿá ÿßÿ≤ ÿØŸáŸá ŸáŸÅÿ™ÿßÿØ\n",
            "[00:25.480 --> 00:28.000]  ÿ®ÿß ÿ™Ÿàÿ¨Ÿá ÿ®Ÿá Ÿæ€åŸÖÿß€åÿ¥ Ÿáÿß€å ÿßŸÜÿ¨ÿßŸÖ ÿ¥ÿØŸá\n",
            "[00:28.000 --> 00:32.000]  ŸÖÿß €å⁄© ÿ¨ÿßŸÖÿπŸá ŸÖÿ±ÿØ ÿ≥ÿßŸÑÿßÿ± ÿ±ÿß ÿØÿßÿ¥ÿ™€åŸÖ ⁄©Ÿá ŸáŸÖ€åÿ¥Ÿá ÿ®Ÿá ÿ¥⁄©ŸÑ ŸÖÿ¥ÿÆÿµ€å\n",
            "[00:32.000 --> 00:34.240]  ÿ®Ÿá ŸÖÿ≠ÿØŸàÿØ ⁄©ÿ±ÿØŸÜ ÿ≤ŸÜÿßŸÜ ŸÖ€åÿ±ÿ≥€åÿØ\n",
            "[00:34.240 --> 00:38.320]  ÿßŸÖÿß ÿØÿ± ÿ≥ÿßŸÑ 1400 Ÿà 2 €å⁄© ÿ®ÿßÿ±Ÿá ÿ®ÿß ÿ¨ŸÖÿπ€åÿ™€å ŸÖŸàÿßÿ¨Ÿá ŸÖ€åÿ¥Ÿà€åŸÖ\n",
            "[00:38.320 --> 00:41.680]  ⁄©Ÿá ÿ®Ÿá ÿπÿ±ÿµ ÿ®ÿ±ÿØŸÜ €å⁄© ÿ≥ÿßŸÜ ÿ≤ŸÜ Ÿà ŸÖÿ±ÿØ ÿ®ÿßŸàÿ±ÿØÿßÿ±ŸÜÿØ\n",
            "[00:41.680 --> 00:45.040]  ÿ≠ŸÇ ÿ™ŸÑÿßŸÇ ÿ®ÿ±ÿß€å ÿ≤ŸÜÿßŸÜ ŸÖŸàÿ±ÿØ Ÿæÿ∞€åÿ±ÿ¥ ŸÇÿ±ÿßÿ± ŸÖ€å⁄Ø€åÿ±ÿØ\n",
            "[00:45.040 --> 00:47.480]  Ÿà Ÿæÿ∞€åÿ±ÿ¥ Ÿáÿß€å ÿßÿ¨ÿ™ŸÖÿßÿπ€å ŸàÿßŸÑÿØ€åŸÜ\n",
            "[00:47.480 --> 00:50.200]  ÿ®ÿ±ÿß€å ÿ™ÿ∫€å€åÿ±ÿßÿ™ ŸÅÿ±ÿ≤ŸÜÿØÿßŸÜ ÿ®ÿßŸÑÿß ÿ±ŸÅÿ™ÿ≥ÿ™\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-fd77d6136fd5>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transcribe in progress...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m transcription = whisper.transcribe(\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhisper_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mneeds_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;31m# call the main sampling loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_speech_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mlogits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    202\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2544\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m         )\n\u001b[0;32m-> 2546\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from whisper.utils import WriteSRT\n",
        "import whisper\n",
        "\n",
        "# Load the Whisper model\n",
        "\n",
        "# Assuming you have a function to extract audio segments and features\n",
        "def extract_features(audio_segment):\n",
        "    # Placeholder for feature extraction logic\n",
        "    # This should return a feature vector for the audio segment\n",
        "    return np.random.rand(10) # Example feature vector\n",
        "\n",
        "# Assuming you have a function to perform clustering\n",
        "def perform_clustering(features, num_speakers):\n",
        "    # Placeholder for clustering logic\n",
        "    # This should return the speaker ID for each audio segment\n",
        "    return [0] * len(features) # Example clustering result\n",
        "\n",
        "# Assuming you have a function to align diarization results with the transcript\n",
        "def diarize_text(transcription, diarization_result):\n",
        "    # Placeholder for diarization result processing\n",
        "    # This should align the diarization results with the transcript\n",
        "    return [] # Example diarization result\n",
        "\n",
        "# Your existing code for transcribing with Whisper\n",
        "audio_path_local = Path(filepath).resolve()\n",
        "subtitle_file = os.path.splitext(filepath)[0] + \".srt\"\n",
        "transcript_with_speakers_file = os.path.splitext(filepath)[0] + \".txt\"\n",
        "print(\"audio local path:\", audio_path_local)\n",
        "\n",
        "# Transcribe the audio\n",
        "tic = time.time()\n",
        "print('Transcribe in progress...')\n",
        "transcription = whisper_model.transcribe(\n",
        "    audio=str(audio_path_local),\n",
        "    verbose=True,\n",
        "    task='transcribe',\n",
        "    language=None\n",
        ")\n",
        "toc = time.time()\n",
        "print(f'Time consumed: {toc-tic}s for transcribing')\n",
        "\n",
        "# Extract audio segments and features\n",
        "audio_segments = [] # Placeholder for extracted audio segments\n",
        "features = [extract_features(segment) for segment in audio_segments]\n",
        "\n",
        "# Perform clustering to identify speakers\n",
        "num_speakers = 2 # Example number of speakers\n",
        "clusters = perform_clustering(features, num_speakers)\n",
        "\n",
        "# Align diarization results with the transcript\n",
        "final_result = diarize_text(transcription, clusters)\n",
        "\n",
        "# Write the transcript with speakers to a file\n",
        "lines = []\n",
        "for seg, spk, sent in final_result:\n",
        "    line = f'[{seg.start:.2f} --> {seg.end:.2f}]\\n{spk}: {sent}'\n",
        "    lines.append(line)\n",
        "\n",
        "print(\"Save Transcript With Speakers file\", transcript_with_speakers_file)\n",
        "with open(transcript_with_speakers_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(\"\\n\\n\".join(lines))\n",
        "\n",
        "print(\"Transcript with speakers saved to\", transcript_with_speakers_file)"
      ],
      "metadata": {
        "id": "bo3Bd07ztRA6",
        "outputId": "89e2c5f0-5d59-449c-d3ba-a38f9387ec4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio local path: /content/20636_4_5771510420242174755.wav\n",
            "Transcribe in progress...\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Persian\n",
            "[00:00.000 --> 00:03.200]  ÿØ⁄©ÿ™ÿ± ÿ≥ŸÖÿß€åŸá ÿ™ŸàŸá€åÿØŸÑŸà ÿ¨ÿßŸÖÿπŸá ÿ¥ŸÜÿßÿ≥ ŸÖ€å⁄ØŸà€åÿØ\n",
            "[00:03.200 --> 00:05.600]  ÿ¨ÿß€å⁄ØÿßŸá ÿ≤ŸÜÿßŸÜ ÿØÿ± ÿ¨ÿßŸÖÿπŸá ÿß€åÿ±ÿßŸÜ€å\n",
            "[00:05.600 --> 00:10.080]  ÿ®ÿπÿØ ÿßÿ≤ ÿ¨ŸÜÿ®ÿ¥ Ÿáÿß€å ÿ≥ÿßŸÑŸá 1400 Ÿà 1ÿå 2ÿå 4 ÿ™ÿ∫€å€åÿ± Ÿà ÿ™ÿ∫ŸàŸÑ ÿ¥ÿØŸá\n",
            "[00:16.240 --> 00:20.080]  ÿ≥ŸÑÿßŸÖ ŸÖŸÜ ÿ®€åÿ™ ÿ¢ÿ∞ÿ±€å ÿ®ÿß ÿ®ÿ±ŸÜÿßŸÖŸá ÿØ€åÿØ⁄©ÿß ŸáŸÖÿ±ÿßŸá ÿ¥ŸÖÿß Ÿáÿ≥ÿ™ŸÖ\n",
            "[00:22.200 --> 00:25.480]  ÿÆÿßŸÜŸÖ ÿ™ŸàŸá€åÿØŸÑŸà ÿ®Ÿá ÿÆÿ®ÿ± ÿ¢ŸÜŸÑÿß€åŸÜ ⁄ØŸÅÿ™Ÿá ÿßÿ≤ ÿØŸáŸá ŸáŸÅÿ™ÿßÿØ\n",
            "[00:25.480 --> 00:28.000]  ÿ®ÿß ÿ™Ÿàÿ¨Ÿá ÿ®Ÿá Ÿæ€åŸÖÿß€åÿ¥ Ÿáÿß€å ÿßŸÜÿ¨ÿßŸÖ ÿ¥ÿØŸá\n",
            "[00:28.000 --> 00:32.000]  ŸÖÿß €å⁄© ÿ¨ÿßŸÖÿπŸá ŸÖÿ±ÿØ ÿ≥ÿßŸÑÿßÿ± ÿ±ÿß ÿØÿßÿ¥ÿ™€åŸÖ ⁄©Ÿá ŸáŸÖ€åÿ¥Ÿá ÿ®Ÿá ÿ¥⁄©ŸÑ ŸÖÿ¥ÿÆÿµ€å\n",
            "[00:32.000 --> 00:34.240]  ÿ®Ÿá ŸÖÿ≠ÿØŸàÿØ ⁄©ÿ±ÿØŸÜ ÿ≤ŸÜÿßŸÜ ŸÖ€åÿ±ÿ≥€åÿØ\n",
            "[00:34.240 --> 00:38.320]  ÿßŸÖÿß ÿØÿ± ÿ≥ÿßŸÑ 1400 Ÿà 2 €å⁄© ÿ®ÿßÿ±Ÿá ÿ®ÿß ÿ¨ŸÖÿπ€åÿ™€å ŸÖŸàÿßÿ¨Ÿá ŸÖ€åÿ¥Ÿà€åŸÖ\n",
            "[00:38.320 --> 00:41.680]  ⁄©Ÿá ÿ®Ÿá ÿπÿ±ÿµ ÿ®ÿ±ÿØŸÜ €å⁄© ÿ≥ÿßŸÜ ÿ≤ŸÜ Ÿà ŸÖÿ±ÿØ ÿ®ÿßŸàÿ±ÿØÿßÿ±ŸÜÿØ\n",
            "[00:41.680 --> 00:45.040]  ÿ≠ŸÇ ÿ™ŸÑÿßŸÇ ÿ®ÿ±ÿß€å ÿ≤ŸÜÿßŸÜ ŸÖŸàÿ±ÿØ Ÿæÿ∞€åÿ±ÿ¥ ŸÇÿ±ÿßÿ± ŸÖ€å⁄Ø€åÿ±ÿØ\n",
            "[00:45.040 --> 00:47.480]  Ÿà Ÿæÿ∞€åÿ±ÿ¥ Ÿáÿß€å ÿßÿ¨ÿ™ŸÖÿßÿπ€å ŸàÿßŸÑÿØ€åŸÜ\n",
            "[00:47.480 --> 00:50.200]  ÿ®ÿ±ÿß€å ÿ™ÿ∫€å€åÿ±ÿßÿ™ ŸÅÿ±ÿ≤ŸÜÿØÿßŸÜ ÿ®ÿßŸÑÿß ÿ±ŸÅÿ™ÿ≥ÿ™\n",
            "[00:50.240 --> 00:52.720]  ÿ®Ÿá ÿßÿπÿ™ŸÇÿßÿØ ÿ™ŸàŸá€åÿØŸÑŸà ÿß€åŸÜ ÿ™ÿ∫€å€åÿ±ÿßÿ™ ŸÜÿ¥ÿßŸÜÿØŸáŸÜÿØŸá\n",
            "[00:52.720 --> 00:57.120]  ÿ™ÿ≥ÿßŸáŸÑ ÿ®€åŸÜ⁄Øÿ±ŸàŸá€å Ÿà ÿ®€åŸÜ ÿÆÿßŸÜŸàÿßÿØ⁄Ø€å ÿØÿ±ŸÖ€åÿßŸÜ ŸÖÿ±ÿØŸÖ ÿßÿ≥ÿ™\n",
            "[00:57.120 --> 01:01.040]  ÿØÿ± ÿØ€åÿØ⁄ØÿßŸá ÿ®ÿ±ÿß€å ÿ®ÿ±ÿ±ÿ≥€å ÿ¨ÿ≤€åÿßÿ™ ⁄ØŸÅÿ™⁄ØŸà€å ÿ≥ŸÖ€åÿ™ ÿ™ŸàŸá€åÿØŸÑŸà\n",
            "[01:01.040 --> 01:06.680]  ÿ®ÿß ÿ≥Ÿáÿ± ŸÖÿ™ŸÑÿ®€å Ÿæÿ¨ŸàŸáÿ¥⁄©ÿ± ÿ®ŸáÿØÿßÿ¥ÿ™ ÿ¨ŸÖÿπ€åÿ™ ÿ®€åŸÜ ÿßŸÑŸÖŸÑŸÑ ÿßÿ≤ ÿ≥Ÿàÿ¶ÿØ ŸáŸÖÿ±ÿßŸá ŸÖ€åÿ¥Ÿà€åŸÖ\n",
            "[01:11.680 --> 01:14.720]  ÿÆÿßŸÜ ŸÖÿ™ŸÑÿ®€å Ÿæ€åÿ¥ ÿßÿ≤ ÿß€åŸÜ ⁄©Ÿá ŸÖŸÜ Ÿæÿ±ÿ≥ÿ¥Ÿà ŸáŸÖ ŸÖÿ∑ÿ±ÿ≠ ⁄©ŸÜŸÖ\n",
            "[01:14.720 --> 01:19.200]  ÿÆŸàÿßŸáÿ¥ ŸÖ€å⁄©ŸÜŸÖ ÿÆŸÑÿßÿµŸá ÿß€å ÿßÿ≤ ÿπÿ±ÿ∂€åÿßÿ®€å Ÿáÿß€å ÿØ⁄©ÿ™ÿ± ÿ≥ŸÖ€åÿ™ ÿ™ŸàŸá€åÿØŸÑŸà\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-b5b8ad649751>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transcribe in progress...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m transcription = whisper_model.transcribe(\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mneeds_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;31m# call the main sampling loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_speech_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mlogits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mqkv_attention\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_ctx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Download the subtitle file** üéÜ\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "display(Markdown(f\"**Download Subtitle: {subtitle_file}**\"))\n",
        "files.download(subtitle_file)\n",
        "\n",
        "display(Markdown(f\"**Download Transcript With Speakers: {transcript_with_speakers_file}**\"))\n",
        "files.download(transcript_with_speakers_file)\n",
        "\n",
        "display(Markdown(f\"**Download Audio: {filepath}**\"))\n",
        "files.download(filepath)"
      ],
      "metadata": {
        "id": "yBGKpOjFHLTx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "outputId": "fec6f886-ec7e-4f92-d11c-de20a1c90586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Download Subtitle: /content/20636_4_5771510420242174755.srt**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d0ed7327-4471-45e3-a102-2da9ad11111f\", \"20636_4_5771510420242174755.srt\", 19617)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Download Transcript With Speakers: /content/20636_4_5771510420242174755.txt**"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: /content/20636_4_5771510420242174755.txt",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ded2a3815ba0>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"**Download Transcript With Speakers: {transcript_with_speakers_file}**\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript_with_speakers_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"**Download Audio: {filepath}**\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/20636_4_5771510420242174755.txt"
          ]
        }
      ]
    }
  ]
}