{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SEMRush Weekly Wisdom - Competitor SERP Features.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soheilpaper/-tft-2.4-ili9341-STM32/blob/master/Real_state_url_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIWnvByQQBB3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import re,os\n",
        "import time\n",
        "from datetime import datetime\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as ticker\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "for dirname, _, filenames in os.walk('/content/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZpKA3gPQNWi"
      },
      "source": [
        "def get_data(url):  \n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    real_estate_data = soup.find_all(\"dl\", class_='dl-horizontal-border')\n",
        "    is_property_found = \"Yes\"\n",
        "    data_dict = {}\n",
        "    data_dict[\"URL\"] = url\n",
        "    if real_estate_data:\n",
        "        for d in real_estate_data:\n",
        "            dt = d.find_all('dt')\n",
        "            dd = d.find_all('dd')\n",
        "            \n",
        "            for i,j in zip(dt, dd):\n",
        "                i = i.contents[0].strip()\n",
        "                j = j.contents[0].strip()\n",
        "                if i == \"Unit Number\":\n",
        "                    if j == \"-\":\n",
        "                        data_dict[\"Unit Number\"] = np.nan\n",
        "                    else:\n",
        "                        data_dict[\"Unit Number\"] = j\n",
        "                elif i == \"Price\":\n",
        "                    data_dict[\"Price(¥)\"] = float(j.replace(\",\",\"\").replace(\"¥\",\"\").strip())\n",
        "                elif i == \"Building Name\":\n",
        "                    data_dict[\"Building Name\"] = j\n",
        "                elif i == \"Available From\":\n",
        "                    if \"Please Inquire\" in j:\n",
        "                        data_dict[\"Available From\"] = np.nan\n",
        "                    else:\n",
        "                        data_dict[\"Available From\"] = datetime.strptime(j, '%b %d, %Y')\n",
        "                elif i == \"Type\":\n",
        "                    data_dict[\"Type\"] = j.replace(\" \", \"\")\n",
        "                elif i == \"Size\":\n",
        "                    data_dict[\"Size(m²)\"] = float(j.replace(\"m²\", \"\").replace(\",\", \"\").strip())\n",
        "                elif i == \"Gross Yield\":\n",
        "                    data_dict[\"Gross Yield(%)\"] = float(j.replace(\"%\", \"\").strip())\n",
        "                elif i == \"Land Rights\":\n",
        "                    data_dict[\"Land Rights\"] = j\n",
        "                elif i == \"Maintenance Fee\":\n",
        "                    data_dict[\"Maintenance Fee(¥/mnt)\"] = float(j.replace(\"¥\", \"\").replace(\" / mth\", \"\").strip().replace(\",\",\"\"))\n",
        "                elif i == \"Location\":\n",
        "                    data_dict[\"Location\"] = j.replace(\",\", \"\")\n",
        "                elif i == \"Occupancy\":\n",
        "                    data_dict[\"Occupancy\"] = j\n",
        "                elif i == \"Floor\":\n",
        "                    data_dict[\"Floor\"] = j.replace(\" \", \"\")\n",
        "                elif i == \"Nearest Station\":\n",
        "                    data_dict[\"Nearest Station\"] = j.split(\"(\")[0].strip()\n",
        "                    if len(j.split(\"(\")) > 1:\n",
        "                        if \"walk\" in j:\n",
        "                            data_dict[\"Way to Nearest Station\"] = \"Walk\"\n",
        "                            data_dict[\"Distance From Station(min)\"] = j.split(\"(\")[1].split(\"min\")[0].strip()\n",
        "                        elif \"bus\" in j:\n",
        "                            data_dict[\"Way to Nearest Station\"] = \"Bus\"\n",
        "                            data_dict[\"Distance From Station(min)\"] = j.split(\"(\")[1].split(\"min\")[0].strip()\n",
        "                elif i == \"Layout\":\n",
        "                    data_dict[\"Layout\"] = j\n",
        "                elif i == \"Year Built\":\n",
        "                    data_dict[\"Year Built\"] = j\n",
        "                elif i == \"Direction Facing\":\n",
        "                    data_dict[\"Direction Facing\"] = j.replace(\",\", \"\")\n",
        "                elif i == \"Transaction Type\":\n",
        "                    data_dict[\"Transaction Type\"] = j\n",
        "                elif i == \"Balcony Size\":\n",
        "                    data_dict[\"Balcony Size(m²)\"] = float(j.replace(\"m²\", \"\").replace(\",\", \"\").strip())\n",
        "                elif i == \"Building Description\":\n",
        "                    data_dict[\"Building Description\"] = j.replace(\",\", \"\")\n",
        "                elif i == \"Other Expenses\":\n",
        "                    j = j.replace(\",\", \"\").replace(\" \", \"\").replace(\"，\", \"\")\n",
        "                    lst = re.findall(r'\\d+', j)\n",
        "                    if len(lst) > 0:\n",
        "                        lst = [int(i) for i in lst] \n",
        "                        data_dict[\"Other Expenses\"] = sum(lst)\n",
        "                elif i == \"Parking\":\n",
        "                    data_dict[\"Parking Available\"] = j.split()[0].replace(\",\", \"\")\n",
        "                    if len(j.split()) > 1:\n",
        "                        if j.split()[0].replace(\",\", \"\") == \"Available\":\n",
        "                            data_dict[\"Parking Fee(¥/mnt)\"] = float(j.split()[1].replace(\",\", \"\").replace(\"¥\", \"\").strip())\n",
        "                elif i == \"Date Updated\":\n",
        "                    if \"Please Inquire\" in j:\n",
        "                        data_dict[\"Date Updated\"] = np.nan\n",
        "                    else:\n",
        "                        data_dict[\"Date Updated\"] = datetime.strptime(j, '%b %d, %Y')\n",
        "                elif i == \"Next Update Schedule\":\n",
        "                    if \"Please Inquire\" in j:\n",
        "                        data_dict[\"Next Update Schedule\"] = np.nan\n",
        "                    else:\n",
        "                        data_dict[\"Next Update Schedule\"] = datetime.strptime(j, '%b %d, %Y')\n",
        "                    \n",
        "    else:\n",
        "        is_property_found = \"No\"\n",
        "    data_dict[\"Is_Prop_Avl\"] = is_property_found\n",
        "    return data_dict"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3msuyXsEQ38L"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awq_ZD9ewSf8",
        "outputId": "6c68c95e-8b1c-496e-a7de-aabaf5b30a9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install cssselect"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cssselect\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: cssselect\n",
            "Successfully installed cssselect-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK3UUdIawK_J"
      },
      "source": [
        "from urllib.parse import urlencode, urlparse, parse_qs\n",
        "\n",
        "from lxml.html import fromstring\n",
        "from requests import get\n",
        "\n",
        "raw = get(\"https://www.google.com/search?q=StackOverflow\").text\n",
        "page = fromstring(raw)\n",
        "\n",
        "for result in page.cssselect(\".r a\"):\n",
        "    url = result.get(\"href\")\n",
        "    if url.startswith(\"/url?\"):\n",
        "        url = parse_qs(urlparse(url).query)['q']\n",
        "    print(url[0])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ6O_hSOwgd3",
        "outputId": "bb1f512c-a0c6-4256-d1b6-d2fc6a0a0a00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install google-search-results\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.0.tar.gz (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from google-search-results) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->google-search-results) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->google-search-results) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->google-search-results) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->google-search-results) (1.24.3)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.0-py3-none-any.whl size=19876 sha256=946b304bfacaa40e2b364f4e925bcba082545180d76fa81e10b3aabb01b490a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/32/5f/313cc6b6c013f9c6386fc0a75d10b6b1aa7fe6867acc704d41\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRVWMjjfyEvJ"
      },
      "source": [
        "!pip install search-engine-parser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "kL3MhZDGxY3f",
        "outputId": "73f82c6e-8f0f-40b1-94ba-c558e726eb09"
      },
      "source": [
        "from search_engine_parser import GoogleSearch\n",
        "\n",
        "def google(query):\n",
        "    search_args = (query, 1)\n",
        "    gsearch = GoogleSearch()\n",
        "    gresults = gsearch.search(*search_args)\n",
        "    return gresults['links']\n",
        "\n",
        "google('Is it illegal to scrape google results')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7488ee91144d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'links'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgoogle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Is it illegal to scrape google results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-7488ee91144d>\u001b[0m in \u001b[0;36mgoogle\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msearch_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgsearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msearch_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'links'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/search_engine_parser/core/base.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, query, page, cache, proxy, proxy_auth, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             self.get_soup(url, cache=cache,\n\u001b[1;32m    286\u001b[0m                          \u001b[0mproxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m                          proxy_auth=proxy_auth))\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \"\"\"\n\u001b[1;32m    562\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_runnung\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mnew_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfuture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/asyncio/base_events.py\u001b[0m in \u001b[0;36m_check_runnung\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_runnung\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idydeoc1R2RR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198a4c32-d735-4283-ed3d-861d02259dbf"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "url = \"https://www.google.com/search?q=املاک+تهران+اجاره\"\n",
        "r = requests.get(url)\n",
        "page = r.text \n",
        "soup = BeautifulSoup(page, 'lxml') \n",
        "\n",
        "i = 0\n",
        "\n",
        "link_list = []\n",
        "for tag in soup.find_all('a'):\n",
        "    i+=1\n",
        "    href = tag['href']\n",
        "    if re.search('http',href):\n",
        "        try:\n",
        "            link = re.search('https://.+\\.com',href).group(0)\n",
        "            link_list.append(link)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "link_list = list(set(link_list))\n",
        "\n",
        "link_list2 = [] \n",
        "\n",
        "for link in link_list:\n",
        "    if not re.search('google.com',link):\n",
        "        link_list2.append(link)\n",
        "        \n",
        "print(link_list2)\n",
        "\n",
        "# import pandas as pd\n",
        "\n",
        "# df = pd.DataFrame(link_list2)\n",
        "# df.to_csv('/content/sample_data/bs4_final.csv', index=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyZZ55qMMNly",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "12cd36de-795d-46af-e809-ef5ac9a04490"
      },
      "source": [
        "df = pd.read_csv(\"/content/sample_data/bs4_final.csv\" , delim_whitespace=True)#\"/kaggle/input/japanese-property-urls/tokyo_property_urls.csv\")\n",
        "print(df)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EmptyDataError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-debcdc58e079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sample_data/bs4_final.csv\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\"/kaggle/input/japanese-property-urls/tokyo_property_urls.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMTpsHJVRHX1"
      },
      "source": [
        "urls = df.columns[0:]\n",
        "len(urls)\n",
        "print (urls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxMqqYQSRVsQ"
      },
      "source": [
        "## Scrape Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm1GJ66jRUrf"
      },
      "source": [
        "real_estate_df = pd.DataFrame(columns=[\"URL\", \"مناسب برای\", \"شماره واحد\", \"قیمت\", \"نام ساختمان\", \"طبقه\", \"در دسترس از\", \"نوع\", \"اندازه\", \"بازده ناخالص\",\n",
        "                                      \"حقوق زمین\", \"هزینه نگهداری\", \"موقعیت مکانی\", \"شغل\", \"نزدیکترین ایستگاه\", \"راه تا نزدیکترین ایستگاه\", \"فاصله از ایستگاه (دقیقه\",\n",
        "                                      \"نما\", \"سال ساخت\", \"رو به جهت\", \"نوع معامله\", \"اندازه بالکن (متر مربع)\", \"شرح ساختمان\", \"سایر هزینه ها\",\n",
        "                                      \"پارکینگ موجود\", \"هزینه پارکینگ\", \"برنامه به‌روزرسانی بعدی\", \"برنامه به‌روزرسانی بعدی\"])\n",
        "for url in urls:\n",
        "    print (url)\n",
        "    # res = get_data(url)\n",
        "    # real_estate_df = real_estate_df.append(res, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}