{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SEMRush Weekly Wisdom - Competitor SERP Features.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soheilpaper/-tft-2.4-ili9341-STM32/blob/master/Real_state_url_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIWnvByQQBB3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import re,os\n",
        "import time\n",
        "from datetime import datetime\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as ticker\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "for dirname, _, filenames in os.walk('/content/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZpKA3gPQNWi"
      },
      "source": [
        "def get_data(url):  \n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    real_estate_data = soup.find_all(\"dl\", class_='dl-horizontal-border')\n",
        "    is_property_found = \"Yes\"\n",
        "    data_dict = {}\n",
        "    data_dict[\"URL\"] = url\n",
        "    if real_estate_data:\n",
        "        for d in real_estate_data:\n",
        "            dt = d.find_all('dt')\n",
        "            dd = d.find_all('dd')\n",
        "            \n",
        "            for i,j in zip(dt, dd):\n",
        "                i = i.contents[0].strip()\n",
        "                j = j.contents[0].strip()\n",
        "                if i == \"Unit Number\":\n",
        "                    if j == \"-\":\n",
        "                        data_dict[\"Unit Number\"] = np.nan\n",
        "                    else:\n",
        "                        data_dict[\"Unit Number\"] = j\n",
        "                elif i == \"Price\":\n",
        "                    data_dict[\"Price(¥)\"] = float(j.replace(\",\",\"\").replace(\"¥\",\"\").strip())\n",
        "                elif i == \"Building Name\":\n",
        "                    data_dict[\"Building Name\"] = j\n",
        "                elif i == \"Available From\":\n",
        "                    if \"Please Inquire\" in j:\n",
        "                        data_dict[\"Available From\"] = np.nan\n",
        "                    else:\n",
        "                        data_dict[\"Available From\"] = datetime.strptime(j, '%b %d, %Y')\n",
        "                elif i == \"Type\":\n",
        "                    data_dict[\"Type\"] = j.replace(\" \", \"\")\n",
        "                elif i == \"Size\":\n",
        "                    data_dict[\"Size(m²)\"] = float(j.replace(\"m²\", \"\").replace(\",\", \"\").strip())\n",
        "                elif i == \"Gross Yield\":\n",
        "                    data_dict[\"Gross Yield(%)\"] = float(j.replace(\"%\", \"\").strip())\n",
        "                elif i == \"Land Rights\":\n",
        "                    data_dict[\"Land Rights\"] = j\n",
        "                elif i == \"Maintenance Fee\":\n",
        "                    data_dict[\"Maintenance Fee(¥/mnt)\"] = float(j.replace(\"¥\", \"\").replace(\" / mth\", \"\").strip().replace(\",\",\"\"))\n",
        "                elif i == \"Location\":\n",
        "                    data_dict[\"Location\"] = j.replace(\",\", \"\")\n",
        "                elif i == \"Occupancy\":\n",
        "                    data_dict[\"Occupancy\"] = j\n",
        "                elif i == \"Floor\":\n",
        "                    data_dict[\"Floor\"] = j.replace(\" \", \"\")\n",
        "                elif i == \"Nearest Station\":\n",
        "                    data_dict[\"Nearest Station\"] = j.split(\"(\")[0].strip()\n",
        "                    if len(j.split(\"(\")) > 1:\n",
        "                        if \"walk\" in j:\n",
        "                            data_dict[\"Way to Nearest Station\"] = \"Walk\"\n",
        "                            data_dict[\"Distance From Station(min)\"] = j.split(\"(\")[1].split(\"min\")[0].strip()\n",
        "                        elif \"bus\" in j:\n",
        "                            data_dict[\"Way to Nearest Station\"] = \"Bus\"\n",
        "                            data_dict[\"Distance From Station(min)\"] = j.split(\"(\")[1].split(\"min\")[0].strip()\n",
        "                elif i == \"Layout\":\n",
        "                    data_dict[\"Layout\"] = j\n",
        "                elif i == \"Year Built\":\n",
        "                    data_dict[\"Year Built\"] = j\n",
        "                elif i == \"Direction Facing\":\n",
        "                    data_dict[\"Direction Facing\"] = j.replace(\",\", \"\")\n",
        "                elif i == \"Transaction Type\":\n",
        "                    data_dict[\"Transaction Type\"] = j\n",
        "                elif i == \"Balcony Size\":\n",
        "                    data_dict[\"Balcony Size(m²)\"] = float(j.replace(\"m²\", \"\").replace(\",\", \"\").strip())\n",
        "                elif i == \"Building Description\":\n",
        "                    data_dict[\"Building Description\"] = j.replace(\",\", \"\")\n",
        "                elif i == \"Other Expenses\":\n",
        "                    j = j.replace(\",\", \"\").replace(\" \", \"\").replace(\"，\", \"\")\n",
        "                    lst = re.findall(r'\\d+', j)\n",
        "                    if len(lst) > 0:\n",
        "                        lst = [int(i) for i in lst] \n",
        "                        data_dict[\"Other Expenses\"] = sum(lst)\n",
        "                elif i == \"Parking\":\n",
        "                    data_dict[\"Parking Available\"] = j.split()[0].replace(\",\", \"\")\n",
        "                    if len(j.split()) > 1:\n",
        "                        if j.split()[0].replace(\",\", \"\") == \"Available\":\n",
        "                            data_dict[\"Parking Fee(¥/mnt)\"] = float(j.split()[1].replace(\",\", \"\").replace(\"¥\", \"\").strip())\n",
        "                elif i == \"Date Updated\":\n",
        "                    if \"Please Inquire\" in j:\n",
        "                        data_dict[\"Date Updated\"] = np.nan\n",
        "                    else:\n",
        "                        data_dict[\"Date Updated\"] = datetime.strptime(j, '%b %d, %Y')\n",
        "                elif i == \"Next Update Schedule\":\n",
        "                    if \"Please Inquire\" in j:\n",
        "                        data_dict[\"Next Update Schedule\"] = np.nan\n",
        "                    else:\n",
        "                        data_dict[\"Next Update Schedule\"] = datetime.strptime(j, '%b %d, %Y')\n",
        "                    \n",
        "    else:\n",
        "        is_property_found = \"No\"\n",
        "    data_dict[\"Is_Prop_Avl\"] = is_property_found\n",
        "    return data_dict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3msuyXsEQ38L"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idydeoc1R2RR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90be98ce-b88f-490c-a7c3-f3bd538f698b"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "url = \"https://www.google.com/search?q=املاک+تهران+اجاره\"\n",
        "r = requests.get(url)\n",
        "page = r.text \n",
        "soup = BeautifulSoup(page, 'lxml') \n",
        "\n",
        "i = 0\n",
        "\n",
        "link_list = []\n",
        "for tag in soup.find_all('a'):\n",
        "    i+=1\n",
        "    href = tag['href']\n",
        "    if re.search('http',href):\n",
        "        try:\n",
        "            link = re.search('https://.+\\.com',href).group(0)\n",
        "            link_list.append(link)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "link_list = list(set(link_list))\n",
        "\n",
        "link_list2 = [] \n",
        "\n",
        "for link in link_list:\n",
        "    if not re.search('google.com',link):\n",
        "        link_list2.append(link)\n",
        "        \n",
        "print(link_list2)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(link_list2)\n",
        "df.to_csv('/content/sample_data/bs4_final.csv', index=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://shabesh.com', 'https://www.sheypoor.com', 'https://www.zoomila.com', 'https://www.2nabsh.com', 'https://kilid.com']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyZZ55qMMNly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be961d20-76a0-4950-f457-18b2ca62ab7a"
      },
      "source": [
        "df = pd.read_csv(\"/content/sample_data/bs4_final.csv\" , delim_whitespace=True)#\"/kaggle/input/japanese-property-urls/tokyo_property_urls.csv\")\n",
        "print(df)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          0\n",
            "0       https://shabesh.com\n",
            "1  https://www.sheypoor.com\n",
            "2   https://www.zoomila.com\n",
            "3    https://www.2nabsh.com\n",
            "4         https://kilid.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMTpsHJVRHX1",
        "outputId": "bec010c9-fdc4-4404-9c2e-8677f6d66ee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "urls = df.columns[0:]\n",
        "len(urls)\n",
        "print (urls)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['0'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxMqqYQSRVsQ"
      },
      "source": [
        "## Scrape Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm1GJ66jRUrf",
        "outputId": "ffdebe7e-e13d-48cf-8561-2cd87b9123e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "real_estate_df = pd.DataFrame(columns=[\"URL\", \"مناسب برای\", \"شماره واحد\", \"قیمت\", \"نام ساختمان\", \"طبقه\", \"در دسترس از\", \"نوع\", \"اندازه\", \"بازده ناخالص\",\n",
        "                                      \"حقوق زمین\", \"هزینه نگهداری\", \"موقعیت مکانی\", \"شغل\", \"نزدیکترین ایستگاه\", \"راه تا نزدیکترین ایستگاه\", \"فاصله از ایستگاه (دقیقه\",\n",
        "                                      \"نما\", \"سال ساخت\", \"رو به جهت\", \"نوع معامله\", \"اندازه بالکن (متر مربع)\", \"شرح ساختمان\", \"سایر هزینه ها\",\n",
        "                                      \"پارکینگ موجود\", \"هزینه پارکینگ\", \"برنامه به‌روزرسانی بعدی\", \"برنامه به‌روزرسانی بعدی\"])\n",
        "for url in urls:\n",
        "    print (url)\n",
        "    # res = get_data(url)\n",
        "    # real_estate_df = real_estate_df.append(res, ignore_index=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    }
  ]
}